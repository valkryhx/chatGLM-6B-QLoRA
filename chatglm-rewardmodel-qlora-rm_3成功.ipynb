{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/\n!git clone https://github.com/valkryhx/chatGLM-6B-QLoRA","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:48:50.649653Z","iopub.execute_input":"2023-08-13T14:48:50.650057Z","iopub.status.idle":"2023-08-13T14:48:51.620197Z","shell.execute_reply.started":"2023-08-13T14:48:50.650025Z","shell.execute_reply":"2023-08-13T14:48:51.618915Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"/kaggle/working\nfatal: destination path 'chatGLM-6B-QLoRA' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:48:30.372864Z","iopub.execute_input":"2023-08-13T14:48:30.373240Z","iopub.status.idle":"2023-08-13T14:48:30.379926Z","shell.execute_reply.started":"2023-08-13T14:48:30.373209Z","shell.execute_reply":"2023-08-13T14:48:30.378860Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/kaggle/working/chatGLM-6B-QLoRA\n","output_type":"stream"}]},{"cell_type":"code","source":"#cat /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0812-v1/checkpoint-40/adapter_config.json","metadata":{"execution":{"iopub.status.busy":"2023-08-12T05:52:59.477242Z","iopub.execute_input":"2023-08-12T05:52:59.477619Z","iopub.status.idle":"2023-08-12T05:52:59.482401Z","shell.execute_reply.started":"2023-08-12T05:52:59.477585Z","shell.execute_reply":"2023-08-12T05:52:59.481200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd chatGLM-6B-QLoRA\n!git pull --all --force \n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:48:56.586969Z","iopub.execute_input":"2023-08-13T14:48:56.587399Z","iopub.status.idle":"2023-08-13T14:49:10.354885Z","shell.execute_reply.started":"2023-08-13T14:48:56.587367Z","shell.execute_reply":"2023-08-13T14:49:10.353676Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"/kaggle/working/chatGLM-6B-QLoRA\nFetching origin\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (18/18), done.\u001b[K\nremote: Total 18 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (18/18), 4.24 KiB | 434.00 KiB/s, done.\nFrom https://github.com/valkryhx/chatGLM-6B-QLoRA\n   d947d02..3013da0  main       -> origin/main\nUpdating d947d02..3013da0\nFast-forward\n ppo_chatglm2.py | 33 \u001b[32m+++++++++++++++++++++++++++\u001b[m\u001b[31m------\u001b[m\n 1 file changed, 27 insertions(+), 6 deletions(-)\nRequirement already satisfied: peft==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.4.0)\nRequirement already satisfied: transformers==4.30.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.30.2)\nRequirement already satisfied: datasets==2.12.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.12.0)\nRequirement already satisfied: tqdm==4.65.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.65.0)\nRequirement already satisfied: loguru==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.7.0)\nRequirement already satisfied: fire==0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.5.0)\nRequirement already satisfied: bitsandbytes==0.39.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.39.0)\nRequirement already satisfied: wandb==0.15.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.15.3)\nRequirement already satisfied: cpm_kernels==1.0.11 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0.11)\nRequirement already satisfied: accelerate==0.20.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.20.3)\nRequirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.99)\nRequirement already satisfied: deepspeed==0.9.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.9.5)\nRequirement already satisfied: evaluate==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.4.0)\nRequirement already satisfied: trl==0.4.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.4.7)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (0.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.13.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.1.31)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.20.3)\nRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (3.1.0)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.11.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (9.0.0)\nRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.10.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (4.0.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2->-r requirements.txt (line 2)) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (2023.5.7)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"cat /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0811-v3/config.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git pull --all --force\n!CUDA_VISIBLE_DEVICES=0 python  rm_trl.py \\\n--model_name 'THUDM/chatglm2-6b' \\\n--resume_from_checkpoint /kaggle/working/chatGLM-6B-QLoRA/reward_model_0809_v1/checkpoint-50 \\\n--num_train_epochs 2 \\\n--gradient_accumulation_steps 1 \\\n--per_device_train_batch_size 4 \\\n--per_device_eval_batch_size  4 \\\n--max_length 512 \\\n--output_dir ./reward_model_0810_v2 \\\n--train_subset 80 \\\n--eval_subset 20 \\\n--local_rank 0  \\\n--bf16 False","metadata":{"execution":{"iopub.status.busy":"2023-08-10T15:36:48.134969Z","iopub.execute_input":"2023-08-10T15:36:48.135458Z","iopub.status.idle":"2023-08-10T15:40:03.300811Z","shell.execute_reply.started":"2023-08-10T15:36:48.135418Z","shell.execute_reply":"2023-08-10T15:40:03.299460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 上面的warning There were missing keys in the checkpoint model loaded: 'transformer.embedding.word_embeddings.weight', 'transformer.rotary_pos_emb.inv_freq', 'transformer.encoder.layers.0.input_layernorm.weight', ....\n# 是 trainingArguments中设置 load_best_model_at_end = True 后出现的\n# 说明 trainer的确在最后把最好的那个adapters的参数做了load（只不过load时strict=True要求严格匹配了）\n# 这说明保存在output_dir中的pytorch_model.bin和vhead.bin参数都是最佳的 我们来验证下","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:20:02.990258Z","iopub.execute_input":"2023-08-11T13:20:02.990655Z","iopub.status.idle":"2023-08-11T13:20:04.059182Z","shell.execute_reply.started":"2023-08-11T13:20:02.990619Z","shell.execute_reply":"2023-08-11T13:20:04.057829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"验证成功  跑的是py中的test_load_best()\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# deepspeed 单机多卡从头训练 reward model","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!deepspeed --include localhost:0,1  rewardmodel_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0811-v2 \\\n  --num_train_samples 200 \\\n  --num_eval_samples 100 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 4 \\\n  --per_device_eval_batch_size 4  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  2  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T12:40:22.920460Z","iopub.execute_input":"2023-08-11T12:40:22.920924Z","iopub.status.idle":"2023-08-11T13:06:52.328475Z","shell.execute_reply.started":"2023-08-11T12:40:22.920884Z","shell.execute_reply":"2023-08-11T13:06:52.327240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--deepspeed ds_zero2_config.json","metadata":{}},{"cell_type":"markdown","source":"# 单机多卡deepspeed 从ckpt继续训练 ","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!deepspeed --include localhost:0,1  rewardmodel_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0811-v3 \\\n  --resume_from_checkpoint output-rm-1k-0811-v2 \\\n  --num_train_samples 200 \\\n  --num_eval_samples 100 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 4 \\\n  --per_device_eval_batch_size 4  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  2  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json","metadata":{"execution":{"iopub.status.busy":"2023-08-11T14:16:06.760852Z","iopub.execute_input":"2023-08-11T14:16:06.761319Z","iopub.status.idle":"2023-08-11T14:42:34.756018Z","shell.execute_reply.started":"2023-08-11T14:16:06.761278Z","shell.execute_reply":"2023-08-11T14:42:34.754676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -lrt /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0811-v3","metadata":{"execution":{"iopub.status.busy":"2023-08-11T14:43:55.710087Z","iopub.execute_input":"2023-08-11T14:43:55.710535Z","iopub.status.idle":"2023-08-11T14:43:56.997109Z","shell.execute_reply.started":"2023-08-11T14:43:55.710495Z","shell.execute_reply":"2023-08-11T14:43:56.995800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 单卡训练 reward model","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!CUDA_VISIBLE_DEVICES=0 python  rewardmodel_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0811-v1 \\\n  --num_train_samples 20 \\\n  --num_eval_samples 20 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 4 \\\n  --per_device_eval_batch_size 4  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  10  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git pull --all --force \n!CUDA_VISIBLE_DEVICES=0 python  rm_3.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0812-v1 \\\n  --num_train_samples 20 \\\n  --num_eval_samples 20 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 400 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 1 \\\n  --per_device_eval_batch_size 1  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  4  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True ","metadata":{"execution":{"iopub.status.busy":"2023-08-11T18:27:26.248812Z","iopub.execute_input":"2023-08-11T18:27:26.249305Z","iopub.status.idle":"2023-08-11T18:36:36.195541Z","shell.execute_reply.started":"2023-08-11T18:27:26.249258Z","shell.execute_reply":"2023-08-11T18:36:36.193892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rm -rf output-rm-1k-0812-v1","metadata":{"execution":{"iopub.status.busy":"2023-08-11T18:27:14.344853Z","iopub.execute_input":"2023-08-11T18:27:14.345318Z","iopub.status.idle":"2023-08-11T18:27:15.559789Z","shell.execute_reply.started":"2023-08-11T18:27:14.345279Z","shell.execute_reply":"2023-08-11T18:27:15.558472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"参考 https://github.com/hiyouga/ChatGLM-Efficient-Tuning/blob/main/src/glmtuner/tuner/core/adapter.py#L83\n实现 resume——from --checkpoint\n\n参考","metadata":{}},{"cell_type":"code","source":"https://huggingface.co/docs/trl/models#trl.AutoModelForCausalLMWithValueHead\n    https://github.com/yongzhuo/chatglm-maths/blob/main/chatglm_maths/t10_lora_trl_train_ppo.py#L175\n        https://huggingface.co/docs/trl/v0.5.0/en/customization#use-the-cuda-cache-optimizer\n            https://huggingface.co/docs/trl/trainer#trl.RewardTrainer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# python 【rm_3.py】 单卡训练 从头开始","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!CUDA_VISIBLE_DEVICES=0 python  rm_3.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0812-v1 \\\n  --num_train_samples 20 \\\n  --num_eval_samples 20 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 400 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 1 \\\n  --per_device_eval_batch_size 1  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  4  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# deepspeed train 【rm_3.py】恢复训练 \n#  batach_size 2  gradient accumulation steps 4","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!deepspeed --include localhost:0,1   rm_3.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0812-v2 \\\n  --resume_from_checkpoint output-rm-1k-0812-v1/checkpoint-60 \\\n  --num_train_samples 500 \\\n  --num_eval_samples 200 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 2  \\\n  --gradient_accumulation_steps 4 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  4  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True ","metadata":{"execution":{"iopub.status.busy":"2023-08-12T09:56:17.542178Z","iopub.execute_input":"2023-08-12T09:56:17.543246Z","iopub.status.idle":"2023-08-12T12:00:03.776289Z","shell.execute_reply.started":"2023-08-12T09:56:17.543199Z","shell.execute_reply":"2023-08-12T12:00:03.774957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls output-rm-1k-0812-v2","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:10:23.515397Z","iopub.execute_input":"2023-08-13T14:10:23.516269Z","iopub.status.idle":"2023-08-13T14:10:24.562689Z","shell.execute_reply.started":"2023-08-13T14:10:23.516225Z","shell.execute_reply":"2023-08-13T14:10:24.561455Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"README.md\nadapter_config.json\nadapter_model.bin\n\u001b[0m\u001b[01;34mcheckpoint-110\u001b[0m/\n\u001b[01;34mcheckpoint-120\u001b[0m/\nevents.out.tfevents.1691831244.e711a0a4361e.539.0\nevents.out.tfevents.1691831976.e711a0a4361e.593.0\nevents.out.tfevents.1691833306.a62342d81a09.196.0\nevents.out.tfevents.1691833749.a62342d81a09.298.0\nevents.out.tfevents.1691834459.a62342d81a09.394.0\nvalue_head.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"ls /kaggle/working/chatGLM-6B-QLoRA/data/rlhf-reward-single-round-trans_chinese/","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:11:33.123558Z","iopub.execute_input":"2023-08-13T14:11:33.124792Z","iopub.status.idle":"2023-08-13T14:11:34.141889Z","shell.execute_reply.started":"2023-08-13T14:11:33.124738Z","shell.execute_reply":"2023-08-13T14:11:34.140571Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"test-00000-of-00001-8ecd46436fadcf7f.parquet\ntrain-00000-of-00001-789dc5dece0f1fc1.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# PPO training ","metadata":{}},{"cell_type":"code","source":"!git pull --all --force\n!CUDA_VISIBLE_DEVICES=0,1 python ppo_chatglm2.py \\\n    --base_model_name THUDM/chatglm2-6b \\\n    --merged_sft_model_path THUDM/chatglm2-6b \\\n    --sft_model_lora_path ./output-rm-1k-0812-v2 \\\n    --reward_model_lora_path ./output-rm-1k-0812-v2 \\\n    --adafactor False \\\n    --save_freq 10 \\\n    --output_max_length 256 \\\n    --batch_size 1 \\\n    --gradient_accumulation_steps 1 \\\n    --batched_gen True \\\n    --ppo_epochs 4 \\\n    --seed 0 \\\n    --learning_rate 1e-5 \\\n    --early_stopping True \\\n    --output_dir ppo_0813_v1 \\\n    --log_with tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-08-13T17:50:13.506585Z","iopub.execute_input":"2023-08-13T17:50:13.507109Z","iopub.status.idle":"2023-08-13T17:54:17.717787Z","shell.execute_reply.started":"2023-08-13T17:50:13.507069Z","shell.execute_reply":"2023-08-13T17:54:17.716376Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Fetching origin\nremote: Enumerating objects: 5, done.\u001b[K\nremote: Counting objects: 100% (5/5), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (3/3), 687 bytes | 343.00 KiB/s, done.\nFrom https://github.com/valkryhx/chatGLM-6B-QLoRA\n   6f58a8a..3fab8b9  main       -> origin/main\nUpdating 6f58a8a..3fab8b9\nFast-forward\n ppo_chatglm2.py | 1 \u001b[32m+\u001b[m\n 1 file changed, 1 insertion(+)\n[2023-08-13 17:50:18,068] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 339.37it/s]\nLoading base model for ppo training...\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:18<00:00, 11.19s/it]\n\u001b[32m2023-08-13 17:51:46.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m286\u001b[0m - \u001b[1mprepare_model_for_kbit_training...\u001b[0m\n\u001b[32m2023-08-13 17:52:43.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1madapter_weights.keys()=dict_keys(['base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_B.weight'])\u001b[0m\n\u001b[32m2023-08-13 17:52:43.524\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m309\u001b[0m - \u001b[31m\u001b[1mlora model complete\u001b[0m\n\u001b[32m2023-08-13 17:52:43.542\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m314\u001b[0m - \u001b[31m\u001b[1mv_head_weights={'summary.weight': tensor([[ 0.0079,  0.0042,  0.0158,  ..., -0.0061,  0.0086,  0.0092]]), 'summary.bias': tensor([0.0048])}\u001b[0m\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:12<00:00, 10.36s/it]\n\u001b[32m2023-08-13 17:53:56.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m413\u001b[0m - \u001b[1mprepare_reward_model_for_kbit_training...\u001b[0m\n\u001b[32m2023-08-13 17:54:00.341\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m436\u001b[0m - \u001b[31m\u001b[1mlora reward_model complete\u001b[0m\n\u001b[32m2023-08-13 17:54:00.359\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m441\u001b[0m - \u001b[31m\u001b[1mv_head_weights={'summary.weight': tensor([[ 0.0079,  0.0042,  0.0158,  ..., -0.0061,  0.0086,  0.0092]]), 'summary.bias': tensor([0.0048])}\u001b[0m\n\u001b[32m2023-08-13 17:54:00.360\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m444\u001b[0m - \u001b[31m\u001b[1mreward model complete!\u001b[0m\n0it [00:00, ?it/s]\u001b[32m2023-08-13 17:54:00.373\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m509\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 54729, 55532, 54911, 54954, 49713,\n        54534, 40274, 31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-13 17:54:13.030\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m548\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([34211, 32522, 30989, 54729, 55532, 54911, 54954, 49713, 30991, 33662,\n        34711, 31810, 31155, 55353, 54558, 31692, 40715, 55398, 30987, 32098,\n        54964, 32308, 34711, 31733, 54746, 31640, 30932, 31767, 38108, 31901,\n        32149, 31707, 54556, 33855, 31646, 47218, 33222, 34973, 30987, 47504,\n        31692, 40715, 30932, 41198, 40328, 33287, 55353, 32184, 31155,     2],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-13 17:54:13.032\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m466\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 54729, 55532, 54911, 54954, 49713,\n        54534, 40274, 31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-13 17:54:13.034\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([34211, 32522, 30989, 54729, 55532, 54911, 54954, 49713, 30991, 33662,\n        34711, 31810, 31155, 55353, 54558, 31692, 40715, 55398, 30987, 32098,\n        54964, 32308, 34711, 31733, 54746, 31640, 30932, 31767, 38108, 31901,\n        32149, 31707, 54556, 33855, 31646, 47218, 33222, 34973, 30987, 47504,\n        31692, 40715, 30932, 41198, 40328, 33287, 55353, 32184, 31155,     2],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-13 17:54:13.157\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m562\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n/kaggle/working/chatGLM-6B-QLoRA/ppo_chatglm2.py:563: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  rewards = [torch.tensor(score - script_args.reward_baseline) for score in scores]\n0 query: 问：老奥查德海滩在哪儿？\n\n答：\nresponse: 我不知道“老奥查德海滩”是指哪个地方。您能提供更多信息吗?比如它位于哪个城市或国家,或者是否有任何具体信息来描述这个地方的独特之处?如果能提供更多信息,我将尽力回答您的问题。\nscore: tensor(-0.9816, device='cuda:0')\n\u001b[32m2023-08-13 17:54:13.264\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m570\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-13 17:54:13.265\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m571\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor(-0.9816, device='cuda:0')]\u001b[0m\n0it [00:14, ?it/s]\n\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/chatGLM-6B-QLoRA/\u001b[0m\u001b[1;33mppo_chatglm2.py\u001b[0m:\u001b[94m572\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run PPO step\u001b[0m                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m570 \u001b[0m\u001b[2m│   \u001b[0mlogger.error(\u001b[33m\"\u001b[0m\u001b[33mwe are at line 551\u001b[0m\u001b[33m\"\u001b[0m)                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2m│   \u001b[0mlogger.error(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mrewards=\u001b[0m\u001b[33m{\u001b[0mrewards\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m572 \u001b[2m│   \u001b[0mstats = ppo_trainer.step(question_tensors, response_tensors, rewar \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m573 \u001b[0m\u001b[2m│   \u001b[0mppo_trainer.log_stats(stats, batch, rewards)                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m574 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m script_args.save_freq \u001b[95mand\u001b[0m epoch \u001b[95mand\u001b[0m epoch % script_args.save_fr \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/\u001b[0m\u001b[1;33mcontextlib.py\u001b[0m:\u001b[94m79\u001b[0m in \u001b[92minner\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@wraps\u001b[0m(func)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minner\u001b[0m(*args, **kwds):                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._recreate_cm():                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 79 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwds)                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/trl/trainer/\u001b[0m\u001b[1;33mppo_trainer.py\u001b[0m:\u001b[94m663\u001b[0m in    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mstep\u001b[0m                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 660 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m return_dict                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 661 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 662 \u001b[0m\u001b[2m│   │   \u001b[0mmini_batch_dict.update(model_inputs)                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 663 \u001b[2m│   │   \u001b[0mmini_batch_data = Dataset.from_dict(mini_batch_dict)          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 664 \u001b[0m\u001b[2m│   │   \u001b[0mmini_batch_data.set_format(\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 665 \u001b[0m\u001b[2m│   │   \u001b[0mmini_batch_dataloader = torch.utils.data.DataLoader(          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 666 \u001b[0m\u001b[2m│   │   │   \u001b[0mmini_batch_data,                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m897\u001b[0m in     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mfrom_dict\u001b[0m                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 894 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 895 \u001b[0m\u001b[2m│   │   │   \u001b[0marrow_typed_mapping[col] = data                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 896 \u001b[0m\u001b[2m│   │   \u001b[0mmapping = arrow_typed_mapping                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 897 \u001b[2m│   │   \u001b[0mpa_table = InMemoryTable.from_pydict(mapping=mapping)         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 898 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m info \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 899 \u001b[0m\u001b[2m│   │   │   \u001b[0minfo = DatasetInfo()                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 900 \u001b[0m\u001b[2m│   │   \u001b[0minfo.features = features                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33mtable.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mfrom_pydict\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 782 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mReturns:\u001b[0m                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 783 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33m`datasets.table.Table`\u001b[0m                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 784 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 785 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mcls\u001b[0m(pa.Table.from_pydict(*args, **kwargs))             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 786 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 787 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 788 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfrom_pylist\u001b[0m(\u001b[96mcls\u001b[0m, mapping, *args, **kwargs):                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mpyarrow.lib.Table.from_pydict\u001b[0m:\u001b[94m3725\u001b[0m                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mpyarrow.lib._from_pydict\u001b[0m:\u001b[94m5255\u001b[0m                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mpyarrow.lib.Table.from_arrays\u001b[0m:\u001b[94m3674\u001b[0m                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mpyarrow.lib.Table.validate\u001b[0m:\u001b[94m2837\u001b[0m                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mpyarrow.lib.check_status\u001b[0m:\u001b[94m100\u001b[0m                                              \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mArrowInvalid: \u001b[0mColumn \u001b[1;36m3\u001b[0m named values expected length \u001b[1;36m1\u001b[0m but got length \u001b[1;36m67\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:48:08.885743Z","iopub.execute_input":"2023-08-13T14:48:08.886172Z","iopub.status.idle":"2023-08-13T14:48:09.907026Z","shell.execute_reply.started":"2023-08-13T14:48:08.886141Z","shell.execute_reply":"2023-08-13T14:48:09.905581Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:47:32.123289Z","iopub.execute_input":"2023-08-13T14:47:32.123835Z","iopub.status.idle":"2023-08-13T14:47:33.103497Z","shell.execute_reply.started":"2023-08-13T14:47:32.123788Z","shell.execute_reply":"2023-08-13T14:47:33.102280Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"ls: cannot access './output-rm-1k-0812-v2/adapter_model.bin': No such file or directory\n","output_type":"stream"}]}]}