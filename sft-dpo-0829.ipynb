{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!git clone https://github.com/valkryhx/chatGLM-6B-QLoRA\n%cd chatGLM-6B-QLoRA\n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:04:44.710864Z","iopub.execute_input":"2023-08-30T08:04:44.711339Z","iopub.status.idle":"2023-08-30T08:05:08.106918Z","shell.execute_reply.started":"2023-08-30T08:04:44.711298Z","shell.execute_reply":"2023-08-30T08:05:08.105706Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working\nfatal: destination path 'chatGLM-6B-QLoRA' already exists and is not an empty directory.\n/kaggle/working/chatGLM-6B-QLoRA\nCollecting peft==0.4.0 (from -r requirements.txt (line 1))\n  Using cached peft-0.4.0-py3-none-any.whl (72 kB)\nRequirement already satisfied: transformers==4.30.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.30.2)\nRequirement already satisfied: datasets==2.12.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.12.0)\nRequirement already satisfied: tqdm==4.65.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.65.0)\nRequirement already satisfied: loguru==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.7.0)\nRequirement already satisfied: fire==0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.5.0)\nCollecting bitsandbytes==0.39.0 (from -r requirements.txt (line 7))\n  Using cached bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\nRequirement already satisfied: wandb==0.15.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.15.3)\nRequirement already satisfied: cpm_kernels==1.0.11 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0.11)\nCollecting accelerate==0.20.3 (from -r requirements.txt (line 10))\n  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.99)\nRequirement already satisfied: deepspeed==0.9.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.9.5)\nRequirement already satisfied: evaluate==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.4.0)\nCollecting trl==0.5.0 (from -r requirements.txt (line 14))\n  Using cached trl-0.5.0-py3-none-any.whl (88 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (0.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.13.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.1.31)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.20.3)\nRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (3.1.0)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.11.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (9.0.0)\nRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.10.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (4.0.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2->-r requirements.txt (line 2)) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (2023.5.7)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.3.0)\nInstalling collected packages: bitsandbytes, accelerate, peft, trl\n  Attempting uninstall: bitsandbytes\n    Found existing installation: bitsandbytes 0.41.1\n    Uninstalling bitsandbytes-0.41.1:\n      Successfully uninstalled bitsandbytes-0.41.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.21.0\n    Uninstalling accelerate-0.21.0:\n      Successfully uninstalled accelerate-0.21.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.5.0\n    Uninstalling peft-0.5.0:\n      Successfully uninstalled peft-0.5.0\n  Attempting uninstall: trl\n    Found existing installation: trl 0.6.0\n    Uninstalling trl-0.6.0:\n      Successfully uninstalled trl-0.6.0\nSuccessfully installed accelerate-0.20.3 bitsandbytes-0.39.0 peft-0.4.0 trl-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes==0.41.1\n!pip install peft==0.5.0 \n!pip install accelerate==0.21.0 \n!pip install trl==0.6.0","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:05:19.739995Z","iopub.execute_input":"2023-08-30T08:05:19.740933Z","iopub.status.idle":"2023-08-30T08:06:13.269812Z","shell.execute_reply.started":"2023-08-30T08:05:19.740893Z","shell.execute_reply":"2023-08-30T08:06:13.268413Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes==0.41.1\n  Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\nInstalling collected packages: bitsandbytes\n  Attempting uninstall: bitsandbytes\n    Found existing installation: bitsandbytes 0.39.0\n    Uninstalling bitsandbytes-0.39.0:\n      Successfully uninstalled bitsandbytes-0.39.0\nSuccessfully installed bitsandbytes-0.41.1\nCollecting peft==0.5.0\n  Using cached peft-0.5.0-py3-none-any.whl (85 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.30.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.65.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.5.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.5.0) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.5.0) (1.3.0)\nInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.4.0\n    Uninstalling peft-0.4.0:\n      Successfully uninstalled peft-0.4.0\nSuccessfully installed peft-0.5.0\nCollecting accelerate==0.21.0\n  Using cached accelerate-0.21.0-py3-none-any.whl (244 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.21.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.20.3\n    Uninstalling accelerate-0.20.3:\n      Successfully uninstalled accelerate-0.20.3\nSuccessfully installed accelerate-0.21.0\nCollecting trl==0.6.0\n  Using cached trl-0.6.0-py3-none-any.whl (110 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (2.0.0)\nRequirement already satisfied: transformers>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (4.30.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (1.23.5)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (0.21.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (2.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (4.65.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.6.0) (5.9.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.18.0->trl==0.6.0) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.6.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.6.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.6.0) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.6.0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.6.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.6.0) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.6.0) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.6.0) (1.16.0)\nInstalling collected packages: trl\n  Attempting uninstall: trl\n    Found existing installation: trl 0.5.0\n    Uninstalling trl-0.5.0:\n      Successfully uninstalled trl-0.5.0\nSuccessfully installed trl-0.6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":" * # <font color=red>首先sft  with qlora </font> ","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/chatGLM-6B-QLoRA\n!git pull --all --force \n!deepspeed --include localhost:0,1  train_qlora_deepspeed_zero.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output_yungaun_0827_v1 \\\n  --num_train_samples -1 \\\n  --num_eval_samples 100 \\\n  --train_data_path ./data/augment_staff298_qa70and14  \\\n  --eval_data_path  ./data/augment_staff298_qa70and14    \\\n  --max_input_length 256 \\\n  --max_output_length 400 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 2  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  1e-5 \\\n  --num_train_epochs  20  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!git clone -b medGPT_0828  https://github.com/valkryhx/MedicalGPT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd MedicalGPT\n!git status","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat ./requirements.txt\n# 发现这项目的依赖和上面重合 不用再装一次","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 参考这里 colab的dpo运行demo  是使用base model（或者sft合并后的model 仍然是base model格式）传入的\nhttps://colab.research.google.com/drive/1kMIe3pTec2snQvLBA00Br8ND1_zwy3Gr?usp=sharing","metadata":{}},{"cell_type":"markdown","source":"# 使用运管数据 ./data/reward_yunguan\n# <font color=red>注意这里没有使用--qlora True 说明是使用普通lora来训练base model的</font>  代码中会加载两次chatglm2 一次作为可训练的model  一次作为ref_model 注意不要oom","metadata":{"execution":{"iopub.status.busy":"2023-08-29T01:55:58.634621Z","iopub.execute_input":"2023-08-29T01:55:58.635007Z","iopub.status.idle":"2023-08-29T01:55:59.623378Z","shell.execute_reply.started":"2023-08-29T01:55:58.634975Z","shell.execute_reply":"2023-08-29T01:55:59.622075Z"}}},{"cell_type":"markdown","source":"# 注意dpo_training.py 代码中 optim默认=adamw_hf  在lora训练时可以 但是qlora训练一定换成paged_adamw_8bit 不然loss=0 其他指标为nan\n# 注意dpo_training.py 代码中 find_all_linear_names(peft_model, int4=False, int8=False)定义时加入了判断是否int4 or int8 量化 lora训练一般不量化 此时cls = torch.nn.Linear  注意find_all_linear_names的层<font color=red>好像比我自己写qlora时的find_all_linear_names多了一层default  今天测试好像没多这个奇怪的default层</font>","metadata":{}},{"cell_type":"markdown","source":" # --lora_rank 64 \\ --lora_alpha 32 \\ 会oom\n # 我改成 --lora_rank 8 \\ --lora_alpha 16 \\ 没有oom\n # learning_rate 默认 5e-4 太大导致loss不稳定 我换成较小的1e-5\n # warmup_steps 默认100 我改成 10\n # <font color=red>train/eval数据从./data/reward_yunguan 换成./data/reward loss瞬间下降 毕竟这个只有100条数据 而reward_yunguan有2800多条</font>\n # [未实施]optim由adamw_hf 改成 paged_adamw_32bit？ 后者是trl官网dpo例子用的","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_training.py \\\n    --model_type chatglm \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward \\\n    --validation_file_dir ./data/reward \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 100 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-v1 \\\n    --target_modules all \\\n    --lora_rank 8 \\\n    --lora_alpha 16 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# optim 换成 paged_lion_32bit    lora_rank从8换到16 似乎有可见的波动 loss从0.6到1 而且显存占用明显比paged_adamw_32bit小（14.4G） 才12.9G\n# 我试试继续增加lora_rank 到64 \n# <font color=red>可以跑 train loss好像波动大 但是eval的margin和acc倒是越来越大</font>","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_training.py \\\n    --model_type chatglm \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 查看一下policy_chosen_logps 到底是啥\n# 这个reward_accuracies跟gradient_accumulation_steps有关 代码中默认是4 目前gradient_accumulation_steps=4  我在下面调用时显式的写出来\n# 所以每次是4对chosen_rewards与rejected_rewards比较 那难怪会在 [0 , 0.25 , 0.5 ,0.75] 之间跳 很离散 而且这样的话train过程中的acc其实没有多大指示性 毕竟只有4对\n# 还是要看eval_acc才有用 理解了！\n# 参考 https://github.com/valkryhx/MedicalGPT/blob/medGPT_0828/dpo_3.py#L327 和 L334 \n # 求了 reward_acc的mean() 因为reward_acc是类似[1,0,0,1]这种比较结果后得到的True/False 再float()转成1./0.的tensor！参考下面的代码：","metadata":{}},{"cell_type":"code","source":"import torch\na=torch.tensor([1])\nb=torch.tensor([5])\nc=(a>b)\nprint(c)\nprint(c.float())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_only_for_show_acc.py \\\n    --model_type chatglm \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dpo_for_peftmodel 直接加载一个 adapter\n# 这是  qlora的 还是感觉train loss 和eval loss 不怎么收敛 ","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_for_peftmodel.py \\\n    --model_type chatglm \\\n    --model_name_or_path /kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400 \\\n    --tokenizer_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --load_in_4bit True \\\n    --qlora True \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:16:30.739710Z","iopub.execute_input":"2023-08-30T08:16:30.740339Z","iopub.status.idle":"2023-08-30T08:17:26.083420Z","shell.execute_reply.started":"2023-08-30T08:16:30.740281Z","shell.execute_reply":"2023-08-30T08:17:26.061174Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working/MedicalGPT\nFetching origin\nAlready up to date.\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[2023-08-30 08:16:52,409] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[32m2023-08-30 08:17:08.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m242\u001b[0m - \u001b[1mParse args: ScriptArguments(model_type='chatglm', model_name_or_path='/kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400', tokenizer_name_or_path='THUDM/chatglm2-6b', load_in_8bit=False, load_in_4bit=True, cache_dir='./cache', use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward_yunguan', validation_file_dir='./data/reward_yunguan', template_name='vicuna', per_device_train_batch_size=1, per_device_eval_batch_size=1, max_source_length=256, max_target_length=128, min_target_length=4, max_train_samples=1000, max_eval_samples=20, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4, use_ref_model=True, use_peft=True, qlora=True, target_modules='all', lora_rank=64, lora_dropout=0.05, lora_alpha=32.0, peft_path=None, do_train=True, do_eval=True, beta=0.1, learning_rate=1e-05, lr_scheduler_type='cosine', warmup_steps=10, weight_decay=0.05, optim='paged_lion_32bit', fp16=True, bf16=False, gradient_checkpointing=True, gradient_accumulation_steps=4, save_total_limit=2, load_best_model_at_end=True, save_steps=40, eval_steps=10, logging_steps=1, output_dir='outputs-dpo-yunguan-v1', max_steps=200, eval_strategy='steps', remove_unused_columns=False, report_to='tensorboard')\u001b[0m\n\u001b[32m2023-08-30 08:17:08.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m286\u001b[0m - \u001b[1mtrain files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n\u001b[32m2023-08-30 08:17:08.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m291\u001b[0m - \u001b[1meval files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 40.08it/s]\n\u001b[32m2023-08-30 08:17:08.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n    train: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n    validation: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n})\u001b[0m\n\u001b[32m2023-08-30 08:17:08.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'question': '现在提供如下信息：\\n1. 审批出差申请的流程中，如何查询审批人的状态？ \\n\\n答：此问题是平台流程服务异常，IT会及时处理，您可以稍后再试，或上IT吧发帖反馈此问题\\n3. 负责 FMR 系统的是谁？ 请联系刘玉莎 (liuyusha@fiberhome.com)\\n4. 单位收款信息在哪里可以找到？ \\n\\n答：收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\\n请根据提供的信息回答问题。问：4. 单位收款信息在哪里可以找到？ \\n\\n答：', 'response_chosen': '收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。', 'response_rejected': '请联系刘玉莎 (liuyusha@fiberhome.com)'}\u001b[0m\n\u001b[32m2023-08-30 08:17:09.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 807\u001b[0m\n\u001b[32m2023-08-30 08:17:09.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m344\u001b[0m - \u001b[34m\u001b[1mFirst train example:\u001b[0m\n\u001b[32m2023-08-30 08:17:09.242\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n6. 谁负责管理和维护烽火通信费用报销系统（Self Service Expense）？ 请联系徐华志 (xuhzh@fiberhome.com)\n5. 国内项目经理的负责人是谁？ 请联系雷彪 (blei@fiberhome.com)\n3. 提供 XLOMES 项目的负责人姓名吗？ 请联系许礼 (xuli0955@fiberhome.com)\n请根据提供的信息回答问题。问：5. 国内项目经理的负责人是谁？ \n\nAnswer: 请联系雷彪 (blei@fiberhome.com)\u001b[0m\n\u001b[32m2023-08-30 08:17:09.244\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m357\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'question': '现在提供如下信息：\\n1. 审批出差申请的流程中，如何查询审批人的状态？ \\n\\n答：此问题是平台流程服务异常，IT会及时处理，您可以稍后再试，或上IT吧发帖反馈此问题\\n3. 负责 FMR 系统的是谁？ 请联系刘玉莎 (liuyusha@fiberhome.com)\\n4. 单位收款信息在哪里可以找到？ \\n\\n答：收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\\n请根据提供的信息回答问题。问：4. 单位收款信息在哪里可以找到？ \\n\\n答：', 'response_chosen': '收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。', 'response_rejected': '请联系刘玉莎 (liuyusha@fiberhome.com)'}\u001b[0m\n\u001b[32m2023-08-30 08:17:09.569\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m370\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 14\u001b[0m\n\u001b[32m2023-08-30 08:17:09.569\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m371\u001b[0m - \u001b[34m\u001b[1mFirst eval example:\u001b[0m\n\u001b[32m2023-08-30 08:17:09.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m372\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n1. 审批出差申请的流程中，如何查询审批人的状态？ \n\n答：此问题是平台流程服务异常，IT会及时处理，您可以稍后再试，或上IT吧发帖反馈此问题\n3. 负责 FMR 系统的是谁？ 请联系刘玉莎 (liuyusha@fiberhome.com)\n4. 单位收款信息在哪里可以找到？ \n\n答：收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\n请根据提供的信息回答问题。问：4. 单位收款信息在哪里可以找到？ \n\n答：\n\nAnswer: 收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\u001b[0m\n\u001b[32m2023-08-30 08:17:09.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1mLoading model\u001b[0m\n\u001b[32m2023-08-30 08:17:09.570\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m407\u001b[0m - \u001b[31m\u001b[1margs.qlora=True\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 试试普通lora 设置--use_ref_model False 让程序自己去create ref model  避免直接copy model构造ref model导致的oom\n# 普通lora 当ref_model=None时 lora target modules=[default。。。]居然会混入奇怪的default module 我只好在函数中强制删除\n# 普通lora 仍然oom  不能传 load_in_4bit 会导致参与训练的modules为[]\nTarget modules [] not found in the base model. Please check the target modules and try again.","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_for_peftmodel.py \\\n    --model_type chatglm \\\n    --model_name_or_path /kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400 \\\n    --tokenizer_name_or_path THUDM/chatglm2-6b \\\n    --use_ref_model False \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --load_in_4bit True \\\n    --qlora False \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-lora-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 试用","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_peftmodel_my_style_0830.py \\\n    --model_type chatglm \\\n    --model_name_or_path /kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400 \\\n    --tokenizer_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --load_in_4bit True \\\n    --qlora True \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-0830-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache \\\n    --train_args_json luzi.json \\\n    --compute_dtype fp16","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:14:17.498698Z","iopub.execute_input":"2023-08-30T08:14:17.499871Z","iopub.status.idle":"2023-08-30T08:15:12.746696Z","shell.execute_reply.started":"2023-08-30T08:14:17.499825Z","shell.execute_reply":"2023-08-30T08:15:12.745229Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working/MedicalGPT\nFetching origin\nremote: Enumerating objects: 5, done.\u001b[K\nremote: Counting objects: 100% (5/5), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (3/3), 698 bytes | 232.00 KiB/s, done.\nFrom https://github.com/valkryhx/MedicalGPT\n   0348649..0a2e2eb  medGPT_0828 -> origin/medGPT_0828\nUpdating 0348649..0a2e2eb\nFast-forward\n dpo_peftmodel_my_style_0830.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n 1 file changed, 1 insertion(+), 1 deletion(-)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[2023-08-30 08:14:30,054] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[32m2023-08-30 08:14:54.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m274\u001b[0m - \u001b[1m从json file中读取默认参数 并试用命令行参数覆盖\u001b[0m\n\u001b[32m2023-08-30 08:14:54.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m318\u001b[0m - \u001b[34m\u001b[1mhf_train_args=TrainingArguments(\n_n_gpu=2,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=False,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=10,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=True,\ngreater_is_better=False,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=1e-05,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=outputs-0830-dpo-yunguan-v1,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=1,\nlogging_strategy=steps,\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=loss,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=5,\noptim=paged_lion_32bit,\noptim_args=None,\noutput_dir=outputs-0830-dpo-yunguan-v1,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=1,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=tensorboard,\nresume_from_checkpoint=None,\nrun_name=dpo_chatglm,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=40,\nsave_strategy=steps,\nsave_total_limit=2,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=10,\nweight_decay=0.0,\nxpu_backend=None,\n)\u001b[0m\n\u001b[32m2023-08-30 08:14:54.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m342\u001b[0m - \u001b[1mtrain files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n\u001b[32m2023-08-30 08:14:54.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1meval files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 43.29it/s]\n\u001b[32m2023-08-30 08:14:54.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n    train: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n    validation: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n})\u001b[0m\n\u001b[32m2023-08-30 08:14:54.775\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m388\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'question': '现在提供如下信息：\\n2. 负责FSMES的部门或个人是谁？ 请联系许礼 (xuli0955@fiberhome.com)\\n关于系统责任人。FH Information Integration PM的责任人是谁请联系孟嘉鸣 (jmmeng@fiberhome.com)\\n3. 合同执行过程管理系统的责任人是谁？ 请联系舒思文 (swshu@fiberhome.com)\\n请根据提供的信息回答问题。问：3. 合同执行过程管理系统的责任人是谁？ ', 'response_chosen': '请联系舒思文 (swshu@fiberhome.com)', 'response_rejected': '请联系许礼 (xuli0955@fiberhome.com)'}\u001b[0m\n\u001b[32m2023-08-30 08:14:55.222\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m401\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 770\u001b[0m\n\u001b[32m2023-08-30 08:14:55.222\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m402\u001b[0m - \u001b[34m\u001b[1mFirst train example:\u001b[0m\n\u001b[32m2023-08-30 08:14:55.223\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m403\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n4. 谁是RDM_PM的操作者？ 请联系李晓瑞 (lixiaorui@fiberhome.com)\n7. 国内合同执行过程管理系统的效果如何，是否达到预期？ 请联系朱梆 (zhubang@fiberhome.com)\n谁承担了 CCM 的责任？ 请联系张建 (jzhang1284@fiberhome.com)\n请根据提供的信息回答问题。问：7. 国内合同执行过程管理系统的效果如何，是否达到预期？ \n\nAnswer: 请联系朱梆 (zhubang@fiberhome.com)\u001b[0m\n\u001b[32m2023-08-30 08:14:55.229\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m415\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'question': '现在提供如下信息：\\n4. 国内运输管理系统（Trans Management In China）的负责人是谁？ 请联系李晓瑞 (lixiaorui@fiberhome.com)\\n1. SOSM 责任单位是什么？ 请联系董振星 (zxdong@fiberhome.com)\\n4. 是否需要将所有士费发票的图片上传？ \\n\\n答：可以平铺从左往右依次粘贴在A4纸上，然后将整张A4纸拍照上传。系统支持同时识别多张发票\\n请根据提供的信息回答问题。问：4. 国内运输管理系统（Trans Management In China）的负责人是谁？ ', 'response_chosen': '请联系李晓瑞 (lixiaorui@fiberhome.com)', 'response_rejected': '可以平铺从左往右依次粘贴在A4纸上，然后将整张A4纸拍照上传。系统支持同时识别多张发票'}\u001b[0m\n\u001b[32m2023-08-30 08:14:55.534\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m428\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 15\u001b[0m\n\u001b[32m2023-08-30 08:14:55.534\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m429\u001b[0m - \u001b[34m\u001b[1mFirst eval example:\u001b[0m\n\u001b[32m2023-08-30 08:14:55.534\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m430\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n4. 国内运输管理系统（Trans Management In China）的负责人是谁？ 请联系李晓瑞 (lixiaorui@fiberhome.com)\n1. SOSM 责任单位是什么？ 请联系董振星 (zxdong@fiberhome.com)\n4. 是否需要将所有士费发票的图片上传？ \n\n答：可以平铺从左往右依次粘贴在A4纸上，然后将整张A4纸拍照上传。系统支持同时识别多张发票\n请根据提供的信息回答问题。问：4. 国内运输管理系统（Trans Management In China）的负责人是谁？ \n\nAnswer: 请联系李晓瑞 (lixiaorui@fiberhome.com)\u001b[0m\n\u001b[32m2023-08-30 08:14:55.535\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m437\u001b[0m - \u001b[31m\u001b[1margs.qlora=True\u001b[0m\n","output_type":"stream"}]}]}