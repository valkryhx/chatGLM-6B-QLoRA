{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!git clone https://github.com/valkryhx/chatGLM-6B-QLoRA\n%cd chatGLM-6B-QLoRA\n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:21:24.313149Z","iopub.execute_input":"2023-08-30T08:21:24.313554Z","iopub.status.idle":"2023-08-30T08:21:37.805377Z","shell.execute_reply.started":"2023-08-30T08:21:24.313517Z","shell.execute_reply":"2023-08-30T08:21:37.803636Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working\nfatal: destination path 'chatGLM-6B-QLoRA' already exists and is not an empty directory.\n/kaggle/working/chatGLM-6B-QLoRA\nRequirement already satisfied: peft==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.4.0)\nRequirement already satisfied: transformers==4.30.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.30.2)\nRequirement already satisfied: datasets==2.12.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.12.0)\nRequirement already satisfied: tqdm==4.65.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.65.0)\nRequirement already satisfied: loguru==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.7.0)\nRequirement already satisfied: fire==0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.5.0)\nRequirement already satisfied: bitsandbytes==0.39.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.39.0)\nRequirement already satisfied: wandb==0.15.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.15.3)\nRequirement already satisfied: cpm_kernels==1.0.11 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0.11)\nRequirement already satisfied: accelerate==0.20.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.20.3)\nRequirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.99)\nRequirement already satisfied: deepspeed==0.9.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.9.5)\nRequirement already satisfied: evaluate==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.4.0)\nRequirement already satisfied: trl==0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.5.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (0.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.13.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.1.31)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.20.3)\nRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (3.1.0)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.11.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (9.0.0)\nRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.10.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (4.0.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2->-r requirements.txt (line 2)) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (2023.5.7)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes==0.41.1\n!pip install peft==0.5.0 \n!pip install accelerate==0.21.0 \n!pip install trl==0.6.0","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:21:46.094926Z","iopub.execute_input":"2023-08-30T08:21:46.095316Z","iopub.status.idle":"2023-08-30T08:22:38.975206Z","shell.execute_reply.started":"2023-08-30T08:21:46.095278Z","shell.execute_reply":"2023-08-30T08:22:38.973947Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes==0.41.1\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\n  Attempting uninstall: bitsandbytes\n    Found existing installation: bitsandbytes 0.39.0\n    Uninstalling bitsandbytes-0.39.0:\n      Successfully uninstalled bitsandbytes-0.39.0\nSuccessfully installed bitsandbytes-0.41.1\nCollecting peft==0.5.0\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.30.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.65.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.5.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.5.0) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.5.0) (1.3.0)\nInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.4.0\n    Uninstalling peft-0.4.0:\n      Successfully uninstalled peft-0.4.0\nSuccessfully installed peft-0.5.0\nCollecting accelerate==0.21.0\n  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.21.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.20.3\n    Uninstalling accelerate-0.20.3:\n      Successfully uninstalled accelerate-0.20.3\nSuccessfully installed accelerate-0.21.0\nCollecting trl==0.6.0\n  Downloading trl-0.6.0-py3-none-any.whl (110 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (2.0.0)\nRequirement already satisfied: transformers>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (4.30.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (1.23.5)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (0.21.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.6.0) (2.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.6.0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.6.0) (4.65.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.6.0) (5.9.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.6.0) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.6.0) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.18.0->trl==0.6.0) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.6.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.6.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.6.0) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.6.0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.6.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.6.0) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.6.0) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.6.0) (1.16.0)\nInstalling collected packages: trl\n  Attempting uninstall: trl\n    Found existing installation: trl 0.5.0\n    Uninstalling trl-0.5.0:\n      Successfully uninstalled trl-0.5.0\nSuccessfully installed trl-0.6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":" * # <font color=red>首先sft  with qlora </font> ","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/chatGLM-6B-QLoRA\n!git pull --all --force \n!deepspeed --include localhost:0,1  train_qlora_deepspeed_zero.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output_yungaun_0827_v1 \\\n  --num_train_samples -1 \\\n  --num_eval_samples 100 \\\n  --train_data_path ./data/augment_staff298_qa70and14  \\\n  --eval_data_path  ./data/augment_staff298_qa70and14    \\\n  --max_input_length 256 \\\n  --max_output_length 400 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 2  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  1e-5 \\\n  --num_train_epochs  20  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!git clone -b medGPT_0828  https://github.com/valkryhx/MedicalGPT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd MedicalGPT\n!git status","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat ./requirements.txt\n# 发现这项目的依赖和上面重合 不用再装一次","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 参考这里 colab的dpo运行demo  是使用base model（或者sft合并后的model 仍然是base model格式）传入的\nhttps://colab.research.google.com/drive/1kMIe3pTec2snQvLBA00Br8ND1_zwy3Gr?usp=sharing","metadata":{}},{"cell_type":"markdown","source":"# 使用运管数据 ./data/reward_yunguan\n# <font color=red>注意这里没有使用--qlora True 说明是使用普通lora来训练base model的</font>  代码中会加载两次chatglm2 一次作为可训练的model  一次作为ref_model 注意不要oom","metadata":{"execution":{"iopub.status.busy":"2023-08-29T01:55:58.634621Z","iopub.execute_input":"2023-08-29T01:55:58.635007Z","iopub.status.idle":"2023-08-29T01:55:59.623378Z","shell.execute_reply.started":"2023-08-29T01:55:58.634975Z","shell.execute_reply":"2023-08-29T01:55:59.622075Z"}}},{"cell_type":"markdown","source":"# 注意dpo_training.py 代码中 optim默认=adamw_hf  在lora训练时可以 但是qlora训练一定换成paged_adamw_8bit 不然loss=0 其他指标为nan\n# 注意dpo_training.py 代码中 find_all_linear_names(peft_model, int4=False, int8=False)定义时加入了判断是否int4 or int8 量化 lora训练一般不量化 此时cls = torch.nn.Linear  注意find_all_linear_names的层<font color=red>好像比我自己写qlora时的find_all_linear_names多了一层default  今天测试好像没多这个奇怪的default层</font>","metadata":{}},{"cell_type":"markdown","source":" # --lora_rank 64 \\ --lora_alpha 32 \\ 会oom\n # 我改成 --lora_rank 8 \\ --lora_alpha 16 \\ 没有oom\n # learning_rate 默认 5e-4 太大导致loss不稳定 我换成较小的1e-5\n # warmup_steps 默认100 我改成 10\n # <font color=red>train/eval数据从./data/reward_yunguan 换成./data/reward loss瞬间下降 毕竟这个只有100条数据 而reward_yunguan有2800多条</font>\n # [未实施]optim由adamw_hf 改成 paged_adamw_32bit？ 后者是trl官网dpo例子用的","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_training.py \\\n    --model_type chatglm \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward \\\n    --validation_file_dir ./data/reward \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 100 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-v1 \\\n    --target_modules all \\\n    --lora_rank 8 \\\n    --lora_alpha 16 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# optim 换成 paged_lion_32bit    lora_rank从8换到16 似乎有可见的波动 loss从0.6到1 而且显存占用明显比paged_adamw_32bit小（14.4G） 才12.9G\n# 我试试继续增加lora_rank 到64 \n# <font color=red>可以跑 train loss好像波动大 但是eval的margin和acc倒是越来越大</font>","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_training.py \\\n    --model_type chatglm \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 查看一下policy_chosen_logps 到底是啥\n# 这个reward_accuracies跟gradient_accumulation_steps有关 代码中默认是4 目前gradient_accumulation_steps=4  我在下面调用时显式的写出来\n# 所以每次是4对chosen_rewards与rejected_rewards比较 那难怪会在 [0 , 0.25 , 0.5 ,0.75] 之间跳 很离散 而且这样的话train过程中的acc其实没有多大指示性 毕竟只有4对\n# 还是要看eval_acc才有用 理解了！\n# 参考 https://github.com/valkryhx/MedicalGPT/blob/medGPT_0828/dpo_3.py#L327 和 L334 \n # 求了 reward_acc的mean() 因为reward_acc是类似[1,0,0,1]这种比较结果后得到的True/False 再float()转成1./0.的tensor！参考下面的代码：","metadata":{}},{"cell_type":"code","source":"import torch\na=torch.tensor([1])\nb=torch.tensor([5])\nc=(a>b)\nprint(c)\nprint(c.float())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_only_for_show_acc.py \\\n    --model_type chatglm \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dpo_for_peftmodel 直接加载一个 adapter\n# 这是  qlora的 还是感觉train loss 和eval loss 不怎么收敛 ","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_for_peftmodel.py \\\n    --model_type chatglm \\\n    --model_name_or_path /kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400 \\\n    --tokenizer_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --load_in_4bit True \\\n    --qlora True \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"execution":{"iopub.status.busy":"2023-08-30T08:16:30.739710Z","iopub.execute_input":"2023-08-30T08:16:30.740339Z","iopub.status.idle":"2023-08-30T08:17:26.083420Z","shell.execute_reply.started":"2023-08-30T08:16:30.740281Z","shell.execute_reply":"2023-08-30T08:17:26.061174Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working/MedicalGPT\nFetching origin\nAlready up to date.\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[2023-08-30 08:16:52,409] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[32m2023-08-30 08:17:08.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m242\u001b[0m - \u001b[1mParse args: ScriptArguments(model_type='chatglm', model_name_or_path='/kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400', tokenizer_name_or_path='THUDM/chatglm2-6b', load_in_8bit=False, load_in_4bit=True, cache_dir='./cache', use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward_yunguan', validation_file_dir='./data/reward_yunguan', template_name='vicuna', per_device_train_batch_size=1, per_device_eval_batch_size=1, max_source_length=256, max_target_length=128, min_target_length=4, max_train_samples=1000, max_eval_samples=20, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4, use_ref_model=True, use_peft=True, qlora=True, target_modules='all', lora_rank=64, lora_dropout=0.05, lora_alpha=32.0, peft_path=None, do_train=True, do_eval=True, beta=0.1, learning_rate=1e-05, lr_scheduler_type='cosine', warmup_steps=10, weight_decay=0.05, optim='paged_lion_32bit', fp16=True, bf16=False, gradient_checkpointing=True, gradient_accumulation_steps=4, save_total_limit=2, load_best_model_at_end=True, save_steps=40, eval_steps=10, logging_steps=1, output_dir='outputs-dpo-yunguan-v1', max_steps=200, eval_strategy='steps', remove_unused_columns=False, report_to='tensorboard')\u001b[0m\n\u001b[32m2023-08-30 08:17:08.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m286\u001b[0m - \u001b[1mtrain files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n\u001b[32m2023-08-30 08:17:08.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m291\u001b[0m - \u001b[1meval files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 40.08it/s]\n\u001b[32m2023-08-30 08:17:08.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n    train: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n    validation: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n})\u001b[0m\n\u001b[32m2023-08-30 08:17:08.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'question': '现在提供如下信息：\\n1. 审批出差申请的流程中，如何查询审批人的状态？ \\n\\n答：此问题是平台流程服务异常，IT会及时处理，您可以稍后再试，或上IT吧发帖反馈此问题\\n3. 负责 FMR 系统的是谁？ 请联系刘玉莎 (liuyusha@fiberhome.com)\\n4. 单位收款信息在哪里可以找到？ \\n\\n答：收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\\n请根据提供的信息回答问题。问：4. 单位收款信息在哪里可以找到？ \\n\\n答：', 'response_chosen': '收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。', 'response_rejected': '请联系刘玉莎 (liuyusha@fiberhome.com)'}\u001b[0m\n\u001b[32m2023-08-30 08:17:09.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 807\u001b[0m\n\u001b[32m2023-08-30 08:17:09.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m344\u001b[0m - \u001b[34m\u001b[1mFirst train example:\u001b[0m\n\u001b[32m2023-08-30 08:17:09.242\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n6. 谁负责管理和维护烽火通信费用报销系统（Self Service Expense）？ 请联系徐华志 (xuhzh@fiberhome.com)\n5. 国内项目经理的负责人是谁？ 请联系雷彪 (blei@fiberhome.com)\n3. 提供 XLOMES 项目的负责人姓名吗？ 请联系许礼 (xuli0955@fiberhome.com)\n请根据提供的信息回答问题。问：5. 国内项目经理的负责人是谁？ \n\nAnswer: 请联系雷彪 (blei@fiberhome.com)\u001b[0m\n\u001b[32m2023-08-30 08:17:09.244\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m357\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'question': '现在提供如下信息：\\n1. 审批出差申请的流程中，如何查询审批人的状态？ \\n\\n答：此问题是平台流程服务异常，IT会及时处理，您可以稍后再试，或上IT吧发帖反馈此问题\\n3. 负责 FMR 系统的是谁？ 请联系刘玉莎 (liuyusha@fiberhome.com)\\n4. 单位收款信息在哪里可以找到？ \\n\\n答：收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\\n请根据提供的信息回答问题。问：4. 单位收款信息在哪里可以找到？ \\n\\n答：', 'response_chosen': '收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。', 'response_rejected': '请联系刘玉莎 (liuyusha@fiberhome.com)'}\u001b[0m\n\u001b[32m2023-08-30 08:17:09.569\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m370\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 14\u001b[0m\n\u001b[32m2023-08-30 08:17:09.569\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m371\u001b[0m - \u001b[34m\u001b[1mFirst eval example:\u001b[0m\n\u001b[32m2023-08-30 08:17:09.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m372\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n1. 审批出差申请的流程中，如何查询审批人的状态？ \n\n答：此问题是平台流程服务异常，IT会及时处理，您可以稍后再试，或上IT吧发帖反馈此问题\n3. 负责 FMR 系统的是谁？ 请联系刘玉莎 (liuyusha@fiberhome.com)\n4. 单位收款信息在哪里可以找到？ \n\n答：收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\n请根据提供的信息回答问题。问：4. 单位收款信息在哪里可以找到？ \n\n答：\n\nAnswer: 收款信息需报销人自行添加维护，首次添加后，下次可继续使用。报销人对本人维护的收款信息负责，若收款信息错误，审核会计将发回修改。\u001b[0m\n\u001b[32m2023-08-30 08:17:09.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1mLoading model\u001b[0m\n\u001b[32m2023-08-30 08:17:09.570\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m407\u001b[0m - \u001b[31m\u001b[1margs.qlora=True\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 试试普通lora 设置--use_ref_model False 让程序自己去create ref model  避免直接copy model构造ref model导致的oom\n# 普通lora 当ref_model=None时 lora target modules=[default。。。]居然会混入奇怪的default module 我只好在函数中强制删除\n# 普通lora 仍然oom  不能传 load_in_4bit 会导致参与训练的modules为[]\nTarget modules [] not found in the base model. Please check the target modules and try again.","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_for_peftmodel.py \\\n    --model_type chatglm \\\n    --model_name_or_path /kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400 \\\n    --tokenizer_name_or_path THUDM/chatglm2-6b \\\n    --use_ref_model False \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --load_in_4bit True \\\n    --qlora False \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-dpo-yunguan-lora-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --report_to tensorboard \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 试用","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/MedicalGPT\n!git pull --force --all\n!python dpo_peftmodel_my_style_0830.py \\\n    --model_type chatglm \\\n    --model_name_or_path /kaggle/working/chatGLM-6B-QLoRA/output_yungaun_0827_v1/checkpoint-400 \\\n    --tokenizer_name_or_path THUDM/chatglm2-6b \\\n    --train_file_dir ./data/reward_yunguan \\\n    --validation_file_dir ./data/reward_yunguan \\\n    --learning_rate 1e-5 \\\n    --warmup_steps 10 \\\n    --load_in_4bit True \\\n    --qlora True \\\n    --optim  paged_lion_32bit \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 4 \\\n    --do_train \\\n    --do_eval \\\n    --use_peft True \\\n    --max_train_samples 1000 \\\n    --max_eval_samples 20 \\\n    --max_steps 200 \\\n    --eval_steps 10 \\\n    --save_steps 40 \\\n    --save_total_limit 2 \\\n    --load_best_model_at_end True \\\n    --max_source_length 256 \\\n    --max_target_length 128 \\\n    --output_dir outputs-0830-dpo-yunguan-v1 \\\n    --target_modules all \\\n    --lora_rank 64 \\\n    --lora_alpha 32 \\\n    --lora_dropout 0.05 \\\n    --torch_dtype float16 \\\n    --fp16 True \\\n    --device_map auto \\\n    --remove_unused_columns False \\\n    --gradient_checkpointing True \\\n    --cache_dir ./cache \\\n    --train_args_json luzi.json \\\n    --compute_dtype fp16 ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T09:07:48.368995Z","iopub.execute_input":"2023-08-30T09:07:48.369924Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working/MedicalGPT\nFetching origin\nremote: Enumerating objects: 5, done.\u001b[K\nremote: Counting objects: 100% (5/5), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (3/3), 682 bytes | 341.00 KiB/s, done.\nFrom https://github.com/valkryhx/MedicalGPT\n   cfa38fa..687a72c  medGPT_0828 -> origin/medGPT_0828\nUpdating cfa38fa..687a72c\nFast-forward\n dpo_peftmodel_my_style_0830.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n 1 file changed, 1 insertion(+), 1 deletion(-)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[2023-08-30 09:07:56,061] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[32m2023-08-30 09:08:08.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1m从json file中读取默认参数 并试用命令行参数覆盖\u001b[0m\n\u001b[32m2023-08-30 09:08:08.133\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m321\u001b[0m - \u001b[34m\u001b[1mhf_train_args=TrainingArguments(\n_n_gpu=2,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=False,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=10,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=True,\ngreater_is_better=False,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=1e-05,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=outputs-0830-dpo-yunguan-v1,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=1,\nlogging_strategy=steps,\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=loss,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=5,\noptim=paged_lion_32bit,\noptim_args=None,\noutput_dir=outputs-0830-dpo-yunguan-v1,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=1,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=dpo_chatglm,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=40,\nsave_strategy=steps,\nsave_total_limit=2,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=10,\nweight_decay=0.0,\nxpu_backend=None,\n)\u001b[0m\n\u001b[32m2023-08-30 09:08:08.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mtrain files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n\u001b[32m2023-08-30 09:08:08.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m351\u001b[0m - \u001b[1meval files: ./data/reward_yunguan/paired_yunguan.json\u001b[0m\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 86.76it/s]\n\u001b[32m2023-08-30 09:08:08.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m373\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n    train: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n    validation: Dataset({\n        features: ['question', 'response_chosen', 'response_rejected'],\n        num_rows: 2855\n    })\n})\u001b[0m\n\u001b[32m2023-08-30 09:08:08.617\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m391\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'question': '现在提供如下信息：\\n7. 机酒预订客服电话是多少位数？ \\n\\n答：差旅壹号（机票/酒店） 028-65557315 龙翔航空（机票） 027-82666666\\n美亚航空（机票/酒店） 400-6139-139 珞珈航空（机票） 027-87888888\\n7. 负责固定资产管理系统维护的人员是谁？ 请联系董振星 (zxdong@fiberhome.com)\\n4. 谁来监督干部管理系统？ 请联系谭雪琴 (xqtan@fiberhome.com)\\n请根据提供的信息回答问题。问：7. 负责固定资产管理系统维护的人员是谁？ ', 'response_chosen': '请联系董振星 (zxdong@fiberhome.com)', 'response_rejected': '差旅壹号（机票/酒店） 028-65557315 龙翔航空（机票） 027-82666666\\n美亚航空（机票/酒店） 400-6139-139 珞珈航空（机票） 027-87888888'}\u001b[0m\n\u001b[32m2023-08-30 09:08:09.008\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m404\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 794\u001b[0m\n\u001b[32m2023-08-30 09:08:09.009\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m405\u001b[0m - \u001b[34m\u001b[1mFirst train example:\u001b[0m\n\u001b[32m2023-08-30 09:08:09.009\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m406\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n6. 谁是国际渠道管理系统的负责人？ 请联系陈良锋 (chenlf@fiberhome.com)\n5. 为什么在票夹中录入登机牌后无法提交发票？ \n\n答：登机牌不是发票，不需上传个人票夹，可和其他发票一起，粘贴在A4纸上，报销单交到财务即可。\n1. 请问客户侧返修（CUSTOM ISSUE TO RESOLUTION BJFX）的责任人是由哪个部门或团队负责的？ 请联系许多 (xuduo@fiberhome.com)\n请根据提供的信息回答问题。问：6. 谁是国际渠道管理系统的负责人？ \n\nAnswer: 请联系陈良锋 (chenlf@fiberhome.com)\u001b[0m\n\u001b[32m2023-08-30 09:08:09.016\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m418\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'question': '现在提供如下信息：\\n4. RMA终端返修平台（RMA）的创始人是谁？ 请联系余俊 (yujun5999@fiberhome.com)\\n谁负责处理 PIMS-2 中的问题和故障？ 请联系解雅斌 (ybjie@fiberhome.com)\\n4. 我需要修改发票上的公司名称吗？ \\n\\n答：发票抬头需与费用承担公司保持一致；请再次确认费用承担公司；\\n场景1：若费用由B公司承担，请重新开具发票，使发票抬头为B公司;\\n场景2：若存在借用等情况，费用应由A公司承担，请选择相应委派人\\n请根据提供的信息回答问题。问：4. RMA终端返修平台（RMA）的创始人是谁？ ', 'response_chosen': '请联系余俊 (yujun5999@fiberhome.com)', 'response_rejected': '请联系解雅斌 (ybjie@fiberhome.com)'}\u001b[0m\n\u001b[32m2023-08-30 09:08:09.311\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m431\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 15\u001b[0m\n\u001b[32m2023-08-30 09:08:09.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1mFirst eval example:\u001b[0m\n\u001b[32m2023-08-30 09:08:09.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m433\u001b[0m - \u001b[34m\u001b[1mQuestion: 现在提供如下信息：\n4. RMA终端返修平台（RMA）的创始人是谁？ 请联系余俊 (yujun5999@fiberhome.com)\n谁负责处理 PIMS-2 中的问题和故障？ 请联系解雅斌 (ybjie@fiberhome.com)\n4. 我需要修改发票上的公司名称吗？ \n\n答：发票抬头需与费用承担公司保持一致；请再次确认费用承担公司；\n场景1：若费用由B公司承担，请重新开具发票，使发票抬头为B公司;\n场景2：若存在借用等情况，费用应由A公司承担，请选择相应委派人\n请根据提供的信息回答问题。问：4. RMA终端返修平台（RMA）的创始人是谁？ \n\nAnswer: 请联系余俊 (yujun5999@fiberhome.com)\u001b[0m\n\u001b[32m2023-08-30 09:08:09.312\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m440\u001b[0m - \u001b[31m\u001b[1margs.qlora=True\u001b[0m\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:21<00:00, 11.58s/it]\n\u001b[32m2023-08-30 09:10:50.274\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m460\u001b[0m - \u001b[31m\u001b[1mid(model)=140449849155712\u001b[0m\n\u001b[32m2023-08-30 09:10:50.280\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m461\u001b[0m - \u001b[31m\u001b[1mid(model_ref)=140449819702944\u001b[0m\n\u001b[32m2023-08-30 09:10:50.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1mPeft target_modules: ['dense', 'dense_4h_to_h', 'dense_h_to_4h', 'query_key_value']\u001b[0m\n\u001b[32m2023-08-30 09:10:50.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m486\u001b[0m - \u001b[1mPeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): ChatGLMForConditionalGeneration(\n      (transformer): ChatGLMModel(\n        (embedding): Embedding(\n          (word_embeddings): Embedding(65024, 4096)\n        )\n        (rotary_pos_emb): RotaryEmbedding()\n        (encoder): GLMTransformer(\n          (layers): ModuleList(\n            (0-27): 28 x GLMBlock(\n              (input_layernorm): RMSNorm()\n              (self_attention): SelfAttention(\n                (query_key_value): Linear4bit(\n                  in_features=4096, out_features=4608, bias=True\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=64, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=64, out_features=4608, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (core_attention): CoreAttention(\n                  (attention_dropout): Dropout(p=0.0, inplace=False)\n                )\n                (dense): Linear4bit(\n                  in_features=4096, out_features=4096, bias=False\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=64, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=64, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n              )\n              (post_attention_layernorm): RMSNorm()\n              (mlp): MLP(\n                (dense_h_to_4h): Linear4bit(\n                  in_features=4096, out_features=27392, bias=False\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=64, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=64, out_features=27392, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (dense_4h_to_h): Linear4bit(\n                  in_features=13696, out_features=4096, bias=False\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=13696, out_features=64, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=64, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n              )\n            )\n          )\n          (final_layernorm): RMSNorm()\n        )\n        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n      )\n    )\n  )\n)\u001b[0m\n/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\ntrainable params: 118587392 || all params: 3506898944 || trainable%: 3.381545744364626\n\u001b[32m2023-08-30 09:10:52.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m502\u001b[0m - \u001b[34m\u001b[1m训练样本量: 794\u001b[0m\n\u001b[32m2023-08-30 09:10:52.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m503\u001b[0m - \u001b[34m\u001b[1m验证样本量: 15\u001b[0m\n  0%|                                                   | 0/200 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.6927, 'learning_rate': 1.0000000000000002e-06, 'rewards/chosen': 0.0028543472290039062, 'rewards/rejected': 0.0019991875160485506, 'rewards/accuracies': 0.5, 'rewards/margins': 0.000855160178616643, 'logps/rejected': -69.4194564819336, 'logps/chosen': -66.28802490234375, 'logits/rejected': -2.0570437908172607, 'logits/chosen': -2.0907115936279297, 'epoch': 0.01}\n{'loss': 0.6982, 'learning_rate': 2.0000000000000003e-06, 'rewards/chosen': -0.007575654424726963, 'rewards/rejected': 0.002487134886905551, 'rewards/accuracies': 0.25, 'rewards/margins': -0.010062789544463158, 'logps/rejected': -82.24858093261719, 'logps/chosen': -72.88040161132812, 'logits/rejected': -2.3094425201416016, 'logits/chosen': -2.279621124267578, 'epoch': 0.02}\n{'loss': 0.6981, 'learning_rate': 3e-06, 'rewards/chosen': 0.011002111248672009, 'rewards/rejected': 0.02063765376806259, 'rewards/accuracies': 0.5, 'rewards/margins': -0.009635543450713158, 'logps/rejected': -97.54814147949219, 'logps/chosen': -95.87877655029297, 'logits/rejected': -2.253507614135742, 'logits/chosen': -2.151224136352539, 'epoch': 0.03}\n{'loss': 0.6928, 'learning_rate': 4.000000000000001e-06, 'rewards/chosen': -0.015569258481264114, 'rewards/rejected': -0.016308974474668503, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0007397173903882504, 'logps/rejected': -66.38078308105469, 'logps/chosen': -71.26392364501953, 'logits/rejected': -2.113048553466797, 'logits/chosen': -2.09678053855896, 'epoch': 0.04}\n{'loss': 0.6902, 'learning_rate': 5e-06, 'rewards/chosen': -0.00892734620720148, 'rewards/rejected': -0.014939927496016026, 'rewards/accuracies': 0.5, 'rewards/margins': 0.006012582220137119, 'logps/rejected': -102.582763671875, 'logps/chosen': -102.33851623535156, 'logits/rejected': -2.1865437030792236, 'logits/chosen': -2.0406970977783203, 'epoch': 0.05}\n{'loss': 0.6973, 'learning_rate': 6e-06, 'rewards/chosen': 0.013932514935731888, 'rewards/rejected': 0.021385621279478073, 'rewards/accuracies': 0.75, 'rewards/margins': -0.0074531082063913345, 'logps/rejected': -88.55416870117188, 'logps/chosen': -74.48954010009766, 'logits/rejected': -2.221083164215088, 'logits/chosen': -2.110708713531494, 'epoch': 0.06}\n{'loss': 0.6942, 'learning_rate': 7e-06, 'rewards/chosen': -0.01347818411886692, 'rewards/rejected': -0.011529160663485527, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0019490235717967153, 'logps/rejected': -70.48872375488281, 'logps/chosen': -87.09455108642578, 'logits/rejected': -2.3014798164367676, 'logits/chosen': -2.229863166809082, 'epoch': 0.07}\n{'loss': 0.6754, 'learning_rate': 8.000000000000001e-06, 'rewards/chosen': -0.021237611770629883, 'rewards/rejected': -0.05941805988550186, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03818044438958168, 'logps/rejected': -97.54907989501953, 'logps/chosen': -65.07054138183594, 'logits/rejected': -2.2374868392944336, 'logits/chosen': -2.1559464931488037, 'epoch': 0.08}\n{'loss': 0.7106, 'learning_rate': 9e-06, 'rewards/chosen': -0.09961690753698349, 'rewards/rejected': -0.06755538284778595, 'rewards/accuracies': 0.5, 'rewards/margins': -0.03206152841448784, 'logps/rejected': -84.20132446289062, 'logps/chosen': -80.94524383544922, 'logits/rejected': -2.0012476444244385, 'logits/chosen': -2.1455185413360596, 'epoch': 0.09}\n{'loss': 0.7017, 'learning_rate': 1e-05, 'rewards/chosen': -0.0338987335562706, 'rewards/rejected': -0.017016220837831497, 'rewards/accuracies': 0.25, 'rewards/margins': -0.01688251458108425, 'logps/rejected': -60.808834075927734, 'logps/chosen': -75.73818969726562, 'logits/rejected': -2.0496816635131836, 'logits/chosen': -2.0714776515960693, 'epoch': 0.1}\n  5%|██                                      | 10/200 [08:03<2:36:44, 49.50s/it]\n  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n 25%|███████████▎                                 | 2/8 [00:05<00:15,  2.59s/it]\u001b[A\n 38%|████████████████▉                            | 3/8 [00:10<00:18,  3.69s/it]\u001b[A\n 50%|██████████████████████▌                      | 4/8 [00:16<00:18,  4.65s/it]\u001b[A\n 62%|████████████████████████████▏                | 5/8 [00:23<00:15,  5.26s/it]\u001b[A\n 75%|█████████████████████████████████▊           | 6/8 [00:29<00:11,  5.65s/it]\u001b[A\n 88%|███████████████████████████████████████▍     | 7/8 [00:34<00:05,  5.53s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6964589953422546, 'eval_runtime': 45.1819, 'eval_samples_per_second': 0.332, 'eval_steps_per_second': 0.177, 'eval_rewards/chosen': -0.00871496181935072, 'eval_rewards/rejected': -0.0021653175354003906, 'eval_rewards/accuracies': 0.5625, 'eval_rewards/margins': -0.006549644749611616, 'eval_logps/rejected': -70.22689819335938, 'eval_logps/chosen': -94.84001922607422, 'eval_logits/rejected': -2.1335268020629883, 'eval_logits/chosen': -2.1631665229797363, 'epoch': 0.1}\n  5%|██                                      | 10/200 [08:48<2:36:44, 49.50s/it]\n100%|█████████████████████████████████████████████| 8/8 [00:38<00:00,  5.06s/it]\u001b[A\n{'loss': 0.7029, 'learning_rate': 9.999316524962347e-06, 'rewards/chosen': -0.023343753069639206, 'rewards/rejected': -0.004221916198730469, 'rewards/accuracies': 0.25, 'rewards/margins': -0.019121836870908737, 'logps/rejected': -76.0340576171875, 'logps/chosen': -89.0771255493164, 'logits/rejected': -2.1284351348876953, 'logits/chosen': -2.1870100498199463, 'epoch': 0.11}\n{'loss': 0.683, 'learning_rate': 9.99726628670463e-06, 'rewards/chosen': 0.02632436901330948, 'rewards/rejected': 0.00562663096934557, 'rewards/accuracies': 0.75, 'rewards/margins': 0.020697737112641335, 'logps/rejected': -77.16521453857422, 'logps/chosen': -94.802978515625, 'logits/rejected': -2.107142925262451, 'logits/chosen': -2.1539883613586426, 'epoch': 0.12}\n{'loss': 0.6982, 'learning_rate': 9.993849845741525e-06, 'rewards/chosen': 0.004354143049567938, 'rewards/rejected': 0.014120531268417835, 'rewards/accuracies': 0.5, 'rewards/margins': -0.009766386821866035, 'logps/rejected': -86.712646484375, 'logps/chosen': -69.51136779785156, 'logits/rejected': -1.9548248052597046, 'logits/chosen': -1.9737765789031982, 'epoch': 0.13}\n{'loss': 0.692, 'learning_rate': 9.989068136093873e-06, 'rewards/chosen': 0.022766781970858574, 'rewards/rejected': 0.020284270867705345, 'rewards/accuracies': 0.375, 'rewards/margins': 0.002482509706169367, 'logps/rejected': -73.5347900390625, 'logps/chosen': -76.63933563232422, 'logits/rejected': -2.0873396396636963, 'logits/chosen': -2.048703908920288, 'epoch': 0.14}\n{'loss': 0.6865, 'learning_rate': 9.98292246503335e-06, 'rewards/chosen': 0.011653400026261806, 'rewards/rejected': -0.0018701078370213509, 'rewards/accuracies': 0.625, 'rewards/margins': 0.013523507863283157, 'logps/rejected': -84.21159362792969, 'logps/chosen': -72.11471557617188, 'logits/rejected': -2.3073019981384277, 'logits/chosen': -2.3444249629974365, 'epoch': 0.15}\n{'loss': 0.6922, 'learning_rate': 9.975414512725058e-06, 'rewards/chosen': 0.01797623559832573, 'rewards/rejected': 0.015987062826752663, 'rewards/accuracies': 0.375, 'rewards/margins': 0.001989173237234354, 'logps/rejected': -64.5318374633789, 'logps/chosen': -88.74539184570312, 'logits/rejected': -2.1599280834198, 'logits/chosen': -2.117354154586792, 'epoch': 0.16}\n{'loss': 0.6978, 'learning_rate': 9.966546331768192e-06, 'rewards/chosen': 0.07023711502552032, 'rewards/rejected': 0.07768526673316956, 'rewards/accuracies': 0.5, 'rewards/margins': -0.007448149845004082, 'logps/rejected': -69.87753295898438, 'logps/chosen': -61.89250564575195, 'logits/rejected': -2.171144485473633, 'logits/chosen': -2.1668264865875244, 'epoch': 0.17}\n{'loss': 0.6923, 'learning_rate': 9.956320346634877e-06, 'rewards/chosen': 0.03146872669458389, 'rewards/rejected': 0.02897782251238823, 'rewards/accuracies': 0.625, 'rewards/margins': 0.0024909013882279396, 'logps/rejected': -55.89548110961914, 'logps/chosen': -67.69197082519531, 'logits/rejected': -2.1656150817871094, 'logits/chosen': -2.154463291168213, 'epoch': 0.18}\n{'loss': 0.6827, 'learning_rate': 9.944739353007344e-06, 'rewards/chosen': 0.04388384893536568, 'rewards/rejected': 0.02254929579794407, 'rewards/accuracies': 0.5, 'rewards/margins': 0.021334553137421608, 'logps/rejected': -55.45472717285156, 'logps/chosen': -72.61614227294922, 'logits/rejected': -2.1733758449554443, 'logits/chosen': -2.1322972774505615, 'epoch': 0.19}\n 10%|███▊                                    | 19/200 [16:00<2:25:37, 48.27s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-30T09:01:26.595556Z","iopub.execute_input":"2023-08-30T09:01:26.596000Z","iopub.status.idle":"2023-08-30T09:01:27.666470Z","shell.execute_reply.started":"2023-08-30T09:01:26.595959Z","shell.execute_reply":"2023-08-30T09:01:27.665147Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"peft==0.4.0\ntransformers==4.30.2\ndatasets==2.12.0\ntqdm==4.65.0\nloguru==0.7.0\nfire==0.5.0\nbitsandbytes==0.39.0\nwandb==0.15.3\ncpm_kernels==1.0.11\naccelerate==0.20.3\nsentencepiece==0.1.99\ndeepspeed==0.9.5\nevaluate==0.4.0\ntrl==0.5.0\n","output_type":"stream"}]}]}