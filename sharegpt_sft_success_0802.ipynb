{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/valkryhx/chatGLM-6B-QLoRA","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:31:16.553977Z","iopub.execute_input":"2023-08-03T14:31:16.554588Z","iopub.status.idle":"2023-08-03T14:31:17.686860Z","shell.execute_reply.started":"2023-08-03T14:31:16.554558Z","shell.execute_reply":"2023-08-03T14:31:17.685533Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"fatal: destination path 'chatGLM-6B-QLoRA' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!git pull --all --force\n#!pip install peft==0.4.0\n#!pip install  -U git+https://github.com/huggingface/peft.git\n%cd /kaggle/working/chatGLM-6B-QLoRA \n!ls\n!pip install -r requirements.txt\n#!pip install deepspeed==0.9.5  这个也是需要的 但是目前kaggle 的runtime自带了","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:31:24.367182Z","iopub.execute_input":"2023-08-03T14:31:24.367580Z","iopub.status.idle":"2023-08-03T14:31:40.165336Z","shell.execute_reply.started":"2023-08-03T14:31:24.367547Z","shell.execute_reply":"2023-08-03T14:31:40.164089Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"fatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n/kaggle/working/chatGLM-6B-QLoRA\nREADME.md\nchatGLM_6B_QLoRA.json\ndata\nds_zero2_config.json\nds_zero3_config.json\ninference_qlora.py\ninference_test.py\nluzi.json\nmerge_lora_and_quantize.py\noutput-history-sft-0803-v1\noutput-sharegpt-sft-0802-v1\noutput-sharegpt-sft-0803-2kdata-v4\noutput-sharegpt-sft-0803-v1\noutput-sharegpt-sft-0803-v2\noutput-sharegpt-sft-0803-v3\npics\npretrain_chatglm2_v5.ipynb\npretrain_chatglm2_v7.ipynb\npretrain_chatglm2_v8.ipynb\npretrain_qlora_chatglm2.py\nqa_aug.json\nqlora_param.json\nremote_scripts\nrequirements.txt\nsft_multi_turn_qlora_chatglm2.py\nsharegpt_sft_success_0802.ipynb\nstate.db\ntrain_ds_zero2_test.py——错误的\ntrain_normal_lora.py\ntrain_qlora.py\ntrain_qlora_deepspeed_zero.py\n二次预训练pt_sft_继续lora训练_qlora_glm_成功0730.ipynb\n参考与经验\nRequirement already satisfied: peft==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.4.0)\nRequirement already satisfied: transformers==4.30.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.30.2)\nRequirement already satisfied: datasets==2.12.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.12.0)\nRequirement already satisfied: tqdm==4.65.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.65.0)\nRequirement already satisfied: loguru==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.7.0)\nRequirement already satisfied: fire==0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.5.0)\nRequirement already satisfied: bitsandbytes==0.39.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.39.0)\nRequirement already satisfied: wandb==0.15.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.15.3)\nRequirement already satisfied: cpm_kernels==1.0.11 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0.11)\nRequirement already satisfied: accelerate==0.20.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.20.3)\nRequirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.99)\nRequirement already satisfied: deepspeed==0.9.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.9.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (0.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.13.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.1.31)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.20.3)\nRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (3.1.0)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.11.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (9.0.0)\nRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.10.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (4.0.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2->-r requirements.txt (line 2)) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (2023.5.7)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color= brown>SFT sharegpt格式的多轮对话数据</font>","metadata":{}},{"cell_type":"code","source":"--resume_from_checkpoint ./output-sharegpt-sft-0803-v2/checkpoint-310 \\","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ./data/sharegpt_multi_turn_data 目录不能有空白json文件\n!git pull --all --force \n#!pip install  -U git+https://github.com/huggingface/peft.git   # 20230717 peft==0.4.0正式发布了 不用调版本了推理完后再训练需要重新升级到0.4.0dev 所以有这句\n!deepspeed --include localhost:0,1  sft_multi_turn_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-sharegpt-sft-0803-medi-v5 \\\n  --num_train_samples -1 \\\n  --num_eval_samples 20 \\\n  --train_data_path ./data/medi  \\\n  --eval_data_path  ./data/medi    \\\n  --data_type sharegpt  \\\n  --max_length 1800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 2  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  1e-4 \\\n  --num_train_epochs  40  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:06:00.617745Z","iopub.execute_input":"2023-08-03T16:06:00.618260Z","iopub.status.idle":"2023-08-03T23:11:33.127834Z","shell.execute_reply.started":"2023-08-03T16:06:00.618219Z","shell.execute_reply":"2023-08-03T23:11:33.121106Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Fetching origin\nremote: Enumerating objects: 5, done.\u001b[K\nremote: Counting objects: 100% (5/5), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (3/3), 773 bytes | 386.00 KiB/s, done.\nFrom https://github.com/valkryhx/chatGLM-6B-QLoRA\n   8527711..cf76749  main       -> origin/main\nUpdating 8527711..cf76749\nFast-forward\n sft_multi_turn_qlora_chatglm2.py | 5 \u001b[32m++++\u001b[m\u001b[31m-\u001b[m\n 1 file changed, 4 insertions(+), 1 deletion(-)\n[2023-08-03 16:06:08,165] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n[2023-08-03 16:06:22,398] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n[2023-08-03 16:06:22,420] [INFO] [runner.py:555:main] cmd = /opt/conda/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None sft_multi_turn_qlora_chatglm2.py --train_args_json luzi.json --model_name_or_path THUDM/chatglm2-6b --output_dir output-sharegpt-sft-0803-medi-v5 --num_train_samples -1 --num_eval_samples 20 --train_data_path ./data/medi --eval_data_path ./data/medi --data_type sharegpt --max_length 1800 --lora_rank 64 --lora_dropout 0.05 --compute_dtype fp16 --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --gradient_accumulation_steps 1 --learning_rate 1e-4 --num_train_epochs 40 --save_total_limit 2 --load_in_4bit True --deepspeed ds_zero2_config.json\n[2023-08-03 16:06:24,180] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n[2023-08-03 16:06:30,156] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n[2023-08-03 16:06:30,156] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n[2023-08-03 16:06:30,156] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n[2023-08-03 16:06:30,156] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n[2023-08-03 16:06:30,156] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n[2023-08-03 16:06:30,156] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n[2023-08-03 16:06:30,157] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n[2023-08-03 16:06:30,157] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1]}\n[2023-08-03 16:06:30,157] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0\n[2023-08-03 16:06:30,157] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n[2023-08-03 16:06:30,157] [INFO] [launch.py:163:main] dist_world_size=2\n[2023-08-03 16:06:30,157] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1\n[2023-08-03 16:06:33,178] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2023-08-03 16:06:33,197] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 118\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n/kaggle/working/chatGLM-6B-QLoRA/sft_multi_turn_qlora_chatglm2.py:84: FutureWarning: set_caching_enabled is deprecated and will be removed in the next major version of datasets. Use datasets.enable_caching() or datasets.disable_caching() instead. This function will be removed in a future version of datasets.\n  set_caching_enabled(False)\ninto lora trainer !!!\n/kaggle/working/chatGLM-6B-QLoRA/sft_multi_turn_qlora_chatglm2.py:84: FutureWarning: set_caching_enabled is deprecated and will be removed in the next major version of datasets. Use datasets.enable_caching() or datasets.disable_caching() instead. This function will be removed in a future version of datasets.\n  set_caching_enabled(False)\ninto lora trainer !!!\n\u001b[32m2023-08-03 16:06:42.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m441\u001b[0m - \u001b[1mloading parameters...\u001b[0m\n\u001b[32m2023-08-03 16:06:42.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m441\u001b[0m - \u001b[1mloading parameters...\u001b[0m\n\u001b[32m2023-08-03 16:06:42.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m487\u001b[0m - \u001b[1mloading dataset...\u001b[0m\n\u001b[32m2023-08-03 16:06:42.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m487\u001b[0m - \u001b[1mloading dataset...\u001b[0m\n\u001b[32m2023-08-03 16:06:42.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mdata files: ./data/medi/medical_sft_1K_format.jsonl\u001b[0m\n\u001b[32m2023-08-03 16:06:42.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mdata files: ./data/medi/medical_sft_1K_format.jsonl\u001b[0m\n100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 64.56it/s]\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 125.87it/s]\n\u001b[32m2023-08-03 16:06:43.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-03 16:06:43.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-03 16:06:43.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1m在取样之后 data len =1000\u001b[0m\n\u001b[32m2023-08-03 16:06:43.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\n\u001b[32m2023-08-03 16:06:43.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1m在取样之后 data len =1000\u001b[0m\n\u001b[32m2023-08-03 16:06:43.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\ntokenized_dataset=Dataset({                                                     \n    features: ['input_ids', 'labels', 'attention_mask'],\n    num_rows: 1000\n})\ntokenizer.decode(tokenized_dataset[0]['input_ids'],skip_special_tokens=False)=\n问：1 答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenized_dataset=Dataset({                                                     \n    features: ['input_ids', 'labels', 'attention_mask'],\n    num_rows: 1000\n})\ntokenizer.decode(tokenized_dataset[0]['labels'],skip_special_tokens=False)=\n答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenizer.decode(tokenized_dataset[0]['input_ids'],skip_special_tokens=False)=\n问：1 答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenized_dataset[0]['input_ids']=\n[30910, 54761, 31211, 30939, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ntokenized_dataset[0]['labels']=\n[-100, -100, -100, -100, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\ntokenized_dataset[0]['attention_mask']=\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ntokenizer.decode(tokenized_dataset[0]['labels'],skip_special_tokens=False)=\n答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\nlen(tokenized_dataset[0]['input_ids']=1800\ntokenized_dataset[0]['input_ids']=\n[30910, 54761, 31211, 30939, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nlen(tokenized_dataset[0]['labels']=1800\ntokenized_dataset[0]['labels']=\n[-100, -100, -100, -100, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\nFlattening the indices:   0%|                   | 0/1000 [00:00<?, ? examples/s]tokenized_dataset[0]['attention_mask']=\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nlen(tokenized_dataset[0]['input_ids']=1800\nlen(tokenized_dataset[0]['labels']=1800\n\u001b[32m2023-08-03 16:06:46.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mdata files: ./data/medi/medical_sft_1K_format.jsonl\u001b[0m\n\u001b[32m2023-08-03 16:06:46.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mdata files: ./data/medi/medical_sft_1K_format.jsonl\u001b[0m\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 656.28it/s]\n\u001b[32m2023-08-03 16:06:46.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-03 16:06:46.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1m在取样之后 data len =20\u001b[0m\n\u001b[32m2023-08-03 16:06:46.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 439.52it/s]\n\u001b[32m2023-08-03 16:06:46.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-03 16:06:46.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1m在取样之后 data len =20\u001b[0m\n\u001b[32m2023-08-03 16:06:46.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_multi_turn_conversations_datset\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\ntokenized_dataset=Dataset({                                                     \n    features: ['input_ids', 'labels', 'attention_mask'],\n    num_rows: 20\n})\ntokenized_dataset=Dataset({                                                     \n    features: ['input_ids', 'labels', 'attention_mask'],\n    num_rows: 20\n})\ntokenizer.decode(tokenized_dataset[0]['input_ids'],skip_special_tokens=False)=\n问：1 答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenizer.decode(tokenized_dataset[0]['input_ids'],skip_special_tokens=False)=\n问：1 答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenizer.decode(tokenized_dataset[0]['labels'],skip_special_tokens=False)=\n答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenized_dataset[0]['input_ids']=\n[30910, 54761, 31211, 30939, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ntokenizer.decode(tokenized_dataset[0]['labels'],skip_special_tokens=False)=\n答：男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。\ntokenized_dataset[0]['labels']=\n[-100, -100, -100, -100, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\ntokenized_dataset[0]['input_ids']=\n[30910, 54761, 31211, 30939, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ntokenized_dataset[0]['attention_mask']=\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ntokenized_dataset[0]['labels']=\n[-100, -100, -100, -100, 30910, 55437, 31211, 33326, 55120, 56873, 31201, 55120, 56873, 46596, 54530, 32462, 31763, 31123, 54573, 54781, 59580, 54623, 56396, 55934, 31123, 54746, 31998, 55742, 55580, 54642, 54745, 31123, 54774, 54934, 54811, 55068, 56419, 31123, 52919, 55725, 55774, 54659, 54746, 54872, 54698, 56377, 56378, 31123, 55328, 55635, 54581, 56456, 54659, 54746, 54674, 36355, 55328, 56341, 31123, 32106, 54674, 56019, 55002, 54578, 54920, 31123, 55452, 57028, 58536, 54617, 59412, 54530, 31155, 54688, 34024, 56341, 55069, 55725, 56419, 54617, 59412, 31155, 56341, 55069, 54541, 54728, 54715, 43129, 54586, 32400, 31123, 54536, 55166, 59353, 42191, 31123, 56486, 54615, 54683, 55706, 31123, 39372, 55197, 32133, 54625, 34960, 44641, 31155, 56341, 55069, 55725, 56419, 55066, 55166, 59353, 55107, 54979, 31123, 54802, 54615, 54716, 54991, 31155, 35519, 32462, 31763, 56865, 55774, 57032, 55496, 31123, 54642, 46971, 48914, 31155, 55080, 54904, 33326, 55120, 56873, 54535, 55122, 46375, 55070, 31123, 55025, 55508, 54559, 43038, 54684, 58657, 31155, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\nlen(tokenized_dataset[0]['input_ids']=1800\ntokenized_dataset[0]['attention_mask']=\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]len(tokenized_dataset[0]['labels']=1800\n\nFlattening the indices:   0%|                     | 0/20 [00:00<?, ? examples/s]len(tokenized_dataset[0]['input_ids']=1800\nlen(tokenized_dataset[0]['labels']=1800                                         \nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:44<00:00, 14.93s/it]\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:44<00:00, 14.94s/it]\nmemory footprint of model: 3.6520424485206604 GBmemory footprint of model: 3.6520424485206604 GB\n\n\u001b[32m2023-08-03 16:08:32.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m598\u001b[0m - \u001b[1mprepare_model_for_kbit_training...\u001b[0m\n\u001b[32m2023-08-03 16:08:32.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m598\u001b[0m - \u001b[1mprepare_model_for_kbit_training...\u001b[0m\ntrainable params: 118,587,392 || all params: 3,506,898,944 || trainable%: 3.381545744364626\nnumber_train_samples=1000\nnumber_of_eval_numbers=20\nTrainingArguments(\n_n_gpu=1,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=False,\nddp_timeout=1800,\ndebug=[],\ndeepspeed={'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': False}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'pin_memory': False}, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000.0, 'stage3_max_reuse_distance': 1000000.0, 'stage3_gather_16bit_weights_on_model_save': False}, 'train_batch_size': 8, 'train_micro_batch_size_per_gpu': 4},\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=10,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=False,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output-sharegpt-sft-0803-medi-v5,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=10,\nlogging_strategy=steps,\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=loss,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=40.0,\noptim=paged_adamw_8bit,\noptim_args=None,\noutput_dir=output-sharegpt-sft-0803-medi-v5,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=2,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=out/1,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=10,\nsave_strategy=steps,\nsave_total_limit=2,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=10,\nweight_decay=0.0,\nxpu_backend=None,\n)\ntrainable params: 118,587,392 || all params: 3,506,898,944 || trainable%: 3.381545744364626\nnumber_train_samples=1000\nnumber_of_eval_numbers=20\nTrainingArguments(\n_n_gpu=1,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=False,\nddp_timeout=1800,\ndebug=[],\ndeepspeed={'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': False}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'pin_memory': False}, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000.0, 'stage3_max_reuse_distance': 1000000.0, 'stage3_gather_16bit_weights_on_model_save': False}, 'train_batch_size': 8, 'train_micro_batch_size_per_gpu': 4},\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=10,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=False,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=1,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output-sharegpt-sft-0803-medi-v5,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=10,\nlogging_strategy=steps,\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=loss,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=40.0,\noptim=paged_adamw_8bit,\noptim_args=None,\noutput_dir=output-sharegpt-sft-0803-medi-v5,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=2,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=out/1,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=10,\nsave_strategy=steps,\nsave_total_limit=2,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=10,\nweight_decay=0.0,\nxpu_backend=None,\n)\n{'loss': 9.3724, 'learning_rate': 2e-05, 'epoch': 0.04}                         \n  0%|                                     | 10/10000 [01:50<30:11:33, 10.88s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 9.348450660705566, 'eval_runtime': 25.146, 'eval_samples_per_second': 0.795, 'eval_steps_per_second': 0.199, 'epoch': 0.04}\n  0%|                                     | 10/10000 [02:15<30:11:33, 10.88s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 7.8513, 'learning_rate': 9.997997997997999e-05, 'epoch': 0.08}         \n  0%|                                     | 20/10000 [04:05<31:02:49, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 5.527812957763672, 'eval_runtime': 24.6183, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 0.08}\n  0%|                                     | 20/10000 [04:30<31:02:49, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 4.5009, 'learning_rate': 9.987987987987989e-05, 'epoch': 0.12}         \n  0%|                                     | 30/10000 [06:20<31:00:34, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 4.047240257263184, 'eval_runtime': 24.6023, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 0.12}\n  0%|                                     | 30/10000 [06:45<31:00:34, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.8156, 'learning_rate': 9.977977977977978e-05, 'epoch': 0.16}         \n  0%|▏                                    | 40/10000 [08:36<30:59:35, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.655965805053711, 'eval_runtime': 24.5177, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 0.16}\n  0%|▏                                    | 40/10000 [09:00<30:59:35, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.76, 'learning_rate': 9.967967967967968e-05, 'epoch': 0.2}            \n  0%|▏                                    | 50/10000 [10:51<30:53:25, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.402106761932373, 'eval_runtime': 24.3989, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 0.2}\n  0%|▏                                    | 50/10000 [11:16<30:53:25, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 3.5095, 'learning_rate': 9.957957957957959e-05, 'epoch': 0.24}         \n  1%|▏                                    | 60/10000 [13:06<30:53:25, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.97s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.1867823600769043, 'eval_runtime': 24.3488, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 0.24}\n  1%|▏                                    | 60/10000 [13:30<30:53:25, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.2842, 'learning_rate': 9.947947947947949e-05, 'epoch': 0.28}         \n  1%|▎                                    | 70/10000 [15:21<30:54:15, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.0904502868652344, 'eval_runtime': 24.4243, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 0.28}\n  1%|▎                                    | 70/10000 [15:45<30:54:15, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.5413, 'learning_rate': 9.937937937937939e-05, 'epoch': 0.32}         \n  1%|▎                                    | 80/10000 [17:36<30:46:15, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.071610689163208, 'eval_runtime': 24.4394, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 0.32}\n  1%|▎                                    | 80/10000 [18:00<30:46:15, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 3.1848, 'learning_rate': 9.927927927927928e-05, 'epoch': 0.36}         \n  1%|▎                                    | 90/10000 [19:51<30:55:00, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.054062604904175, 'eval_runtime': 24.512, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 0.36}\n  1%|▎                                    | 90/10000 [20:16<30:55:00, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 3.1246, 'learning_rate': 9.917917917917918e-05, 'epoch': 0.4}          \n  1%|▎                                   | 100/10000 [22:06<30:46:50, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.016568660736084, 'eval_runtime': 24.5225, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 0.4}\n  1%|▎                                   | 100/10000 [22:30<30:46:50, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.3014, 'learning_rate': 9.907907907907908e-05, 'epoch': 0.44}         \n  1%|▍                                   | 110/10000 [24:22<30:45:33, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.9676425457000732, 'eval_runtime': 24.467, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 0.44}\n  1%|▍                                   | 110/10000 [24:46<30:45:33, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.4669, 'learning_rate': 9.897897897897899e-05, 'epoch': 0.48}         \n  1%|▍                                   | 120/10000 [26:37<30:44:08, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.0065598487854004, 'eval_runtime': 24.4132, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 0.48}\n  1%|▍                                   | 120/10000 [27:02<30:44:08, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.2424, 'learning_rate': 9.887887887887889e-05, 'epoch': 0.52}         \n  1%|▍                                   | 130/10000 [28:52<30:43:25, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.9422736167907715, 'eval_runtime': 24.4133, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 0.52}\n  1%|▍                                   | 130/10000 [29:17<30:43:25, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 3.3016, 'learning_rate': 9.877877877877878e-05, 'epoch': 0.56}         \n  1%|▌                                   | 140/10000 [31:07<30:29:49, 11.13s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.50s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.894469738006592, 'eval_runtime': 24.5563, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 0.56}\n  1%|▌                                   | 140/10000 [31:31<30:29:49, 11.13s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.2263, 'learning_rate': 9.867867867867868e-05, 'epoch': 0.6}          \n  2%|▌                                   | 150/10000 [33:22<30:31:10, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.9027018547058105, 'eval_runtime': 24.4708, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 0.6}\n  2%|▌                                   | 150/10000 [33:46<30:31:10, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.1737, 'learning_rate': 9.857857857857858e-05, 'epoch': 0.64}         \n  2%|▌                                   | 160/10000 [35:36<30:32:34, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.928332805633545, 'eval_runtime': 24.4558, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 0.64}\n  2%|▌                                   | 160/10000 [36:01<30:32:34, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 3.1549, 'learning_rate': 9.847847847847849e-05, 'epoch': 0.68}         \n  2%|▌                                   | 170/10000 [37:52<30:27:25, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 3.1514930725097656, 'eval_runtime': 24.4377, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 0.68}\n  2%|▌                                   | 170/10000 [38:16<30:27:25, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.3031, 'learning_rate': 9.837837837837839e-05, 'epoch': 0.72}         \n  2%|▋                                   | 180/10000 [40:06<30:21:34, 11.13s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.8193938732147217, 'eval_runtime': 24.4408, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 0.72}\n  2%|▋                                   | 180/10000 [40:31<30:21:34, 11.13s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.5223, 'learning_rate': 9.827827827827828e-05, 'epoch': 0.76}         \n  2%|▋                                   | 190/10000 [42:21<30:24:53, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.9028687477111816, 'eval_runtime': 24.3555, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 0.76}\n  2%|▋                                   | 190/10000 [42:45<30:24:53, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.4219, 'learning_rate': 9.817817817817818e-05, 'epoch': 0.8}          \n  2%|▋                                   | 200/10000 [44:36<30:22:16, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.8654448986053467, 'eval_runtime': 24.392, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 0.8}\n  2%|▋                                   | 200/10000 [45:00<30:22:16, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 3.3108, 'learning_rate': 9.807807807807808e-05, 'epoch': 0.84}         \n  2%|▊                                   | 210/10000 [46:51<30:24:38, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.7089524269104004, 'eval_runtime': 24.3777, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 0.84}\n  2%|▊                                   | 210/10000 [47:15<30:24:38, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.4624, 'learning_rate': 9.797797797797798e-05, 'epoch': 0.88}         \n  2%|▊                                   | 220/10000 [49:05<30:15:14, 11.14s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.7288174629211426, 'eval_runtime': 24.4398, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 0.88}\n  2%|▊                                   | 220/10000 [49:29<30:15:14, 11.14s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.3781, 'learning_rate': 9.787787787787788e-05, 'epoch': 0.92}         \n  2%|▊                                   | 230/10000 [51:19<30:08:56, 11.11s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.7245726585388184, 'eval_runtime': 24.3976, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 0.92}\n  2%|▊                                   | 230/10000 [51:44<30:08:56, 11.11s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.2093, 'learning_rate': 9.777777777777778e-05, 'epoch': 0.96}         \n  2%|▊                                   | 240/10000 [53:35<30:15:56, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.44s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.96s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.7587928771972656, 'eval_runtime': 24.2145, 'eval_samples_per_second': 0.826, 'eval_steps_per_second': 0.206, 'epoch': 0.96}\n  2%|▊                                   | 240/10000 [53:59<30:15:56, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.26s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.3591, 'learning_rate': 9.767767767767768e-05, 'epoch': 1.0}          \n  2%|▉                                   | 250/10000 [55:49<30:11:27, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.674816608428955, 'eval_runtime': 24.4076, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 1.0}\n  2%|▉                                   | 250/10000 [56:14<30:11:27, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.793, 'learning_rate': 9.757757757757758e-05, 'epoch': 1.04}          \n  3%|▉                                   | 260/10000 [58:04<30:14:37, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.5570857524871826, 'eval_runtime': 24.6081, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 1.04}\n  3%|▉                                   | 260/10000 [58:29<30:14:37, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.6708, 'learning_rate': 9.747747747747748e-05, 'epoch': 1.08}         \n  3%|▉                                 | 270/10000 [1:00:20<30:16:53, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.5203943252563477, 'eval_runtime': 24.3719, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 1.08}\n  3%|▉                                 | 270/10000 [1:00:44<30:16:53, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.7317, 'learning_rate': 9.737737737737738e-05, 'epoch': 1.12}         \n  3%|▉                                 | 280/10000 [1:02:34<30:11:15, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.6211886405944824, 'eval_runtime': 24.3972, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 1.12}\n  3%|▉                                 | 280/10000 [1:02:59<30:11:15, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.7594, 'learning_rate': 9.727727727727728e-05, 'epoch': 1.16}         \n  3%|▉                                 | 290/10000 [1:04:49<30:12:15, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.5383567810058594, 'eval_runtime': 24.4074, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 1.16}\n  3%|▉                                 | 290/10000 [1:05:14<30:12:15, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.7321, 'learning_rate': 9.717717717717718e-05, 'epoch': 1.2}          \n  3%|█                                 | 300/10000 [1:07:04<30:15:45, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.596472978591919, 'eval_runtime': 24.6262, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 1.2}\n  3%|█                                 | 300/10000 [1:07:29<30:15:45, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.0744, 'learning_rate': 9.707707707707708e-05, 'epoch': 1.24}         \n  3%|█                                 | 310/10000 [1:09:20<30:16:15, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.569699764251709, 'eval_runtime': 24.4961, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 1.24}\n  3%|█                                 | 310/10000 [1:09:44<30:16:15, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.8221, 'learning_rate': 9.697697697697698e-05, 'epoch': 1.28}         \n  3%|█                                 | 320/10000 [1:11:35<30:03:37, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.422272205352783, 'eval_runtime': 24.4797, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 1.28}\n  3%|█                                 | 320/10000 [1:11:59<30:03:37, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.9285, 'learning_rate': 9.687687687687688e-05, 'epoch': 1.32}         \n  3%|█                                 | 330/10000 [1:13:50<29:59:52, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.2637760639190674, 'eval_runtime': 24.4767, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 1.32}\n  3%|█                                 | 330/10000 [1:14:14<29:59:52, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.0259, 'learning_rate': 9.677677677677678e-05, 'epoch': 1.36}         \n  3%|█▏                                | 340/10000 [1:16:05<30:12:55, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.2240593433380127, 'eval_runtime': 24.6103, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 1.36}\n  3%|█▏                                | 340/10000 [1:16:29<30:12:55, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.9822, 'learning_rate': 9.667667667667668e-05, 'epoch': 1.4}          \n  4%|█▏                                | 350/10000 [1:18:20<29:59:13, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.314575672149658, 'eval_runtime': 24.4734, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 1.4}\n  4%|█▏                                | 350/10000 [1:18:44<29:59:13, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 3.1368, 'learning_rate': 9.657657657657658e-05, 'epoch': 1.44}         \n  4%|█▏                                | 360/10000 [1:20:35<29:57:32, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.2000911235809326, 'eval_runtime': 24.4763, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 1.44}\n  4%|█▏                                | 360/10000 [1:20:59<29:57:32, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!this process is not main process , do not save model.[for distributed training scenario]\n\nsave done !!!\n{'loss': 2.8484, 'learning_rate': 9.647647647647648e-05, 'epoch': 1.48}         \n  4%|█▎                                | 370/10000 [1:22:50<30:01:30, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.1363110542297363, 'eval_runtime': 24.46, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 1.48}\n  4%|█▎                                | 370/10000 [1:23:14<30:01:30, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.9354, 'learning_rate': 9.637637637637638e-05, 'epoch': 1.52}         \n  4%|█▎                                | 380/10000 [1:25:05<29:50:03, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.152104139328003, 'eval_runtime': 24.4205, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 1.52}\n  4%|█▎                                | 380/10000 [1:25:29<29:50:03, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.2035, 'learning_rate': 9.627627627627628e-05, 'epoch': 1.56}         \n  4%|█▎                                | 390/10000 [1:27:19<29:49:16, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.720171332359314, 'eval_runtime': 24.3529, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 1.56}\n  4%|█▎                                | 390/10000 [1:27:44<29:49:16, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.8962, 'learning_rate': 9.617617617617618e-05, 'epoch': 1.6}          \n  4%|█▎                                | 400/10000 [1:29:34<29:58:07, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7158029079437256, 'eval_runtime': 24.5677, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 1.6}\n  4%|█▎                                | 400/10000 [1:29:59<29:58:07, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.8434, 'learning_rate': 9.607607607607608e-05, 'epoch': 1.64}         \n  4%|█▍                                | 410/10000 [1:31:49<29:54:06, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7798925638198853, 'eval_runtime': 24.4197, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 1.64}\n  4%|█▍                                | 410/10000 [1:32:14<29:54:06, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.8732, 'learning_rate': 9.597597597597598e-05, 'epoch': 1.68}         \n  4%|█▍                                | 420/10000 [1:34:04<29:46:13, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.8023865222930908, 'eval_runtime': 24.5078, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 1.68}\n  4%|█▍                                | 420/10000 [1:34:28<29:46:13, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.9877, 'learning_rate': 9.587587587587588e-05, 'epoch': 1.72}         \n  4%|█▍                                | 430/10000 [1:36:19<29:49:08, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.821798324584961, 'eval_runtime': 24.5047, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 1.72}\n  4%|█▍                                | 430/10000 [1:36:44<29:49:08, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.8779, 'learning_rate': 9.577577577577578e-05, 'epoch': 1.76}         \n  4%|█▍                                | 440/10000 [1:38:35<29:42:27, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7883867025375366, 'eval_runtime': 24.4489, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 1.76}\n  4%|█▍                                | 440/10000 [1:38:59<29:42:27, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 3.0088, 'learning_rate': 9.567567567567568e-05, 'epoch': 1.8}          \n  4%|█▌                                | 450/10000 [1:40:50<29:37:39, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.8641351461410522, 'eval_runtime': 24.5947, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 1.8}\n  4%|█▌                                | 450/10000 [1:41:14<29:37:39, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.9508, 'learning_rate': 9.557557557557558e-05, 'epoch': 1.84}         \n  5%|█▌                                | 460/10000 [1:43:05<29:52:34, 11.27s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.74807608127594, 'eval_runtime': 24.4797, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 1.84}\n  5%|█▌                                | 460/10000 [1:43:29<29:52:34, 11.27s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.8956, 'learning_rate': 9.547547547547548e-05, 'epoch': 1.88}         \n  5%|█▌                                | 470/10000 [1:45:20<29:40:39, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7680940628051758, 'eval_runtime': 24.4142, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 1.88}\n  5%|█▌                                | 470/10000 [1:45:44<29:40:39, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.877, 'learning_rate': 9.537537537537537e-05, 'epoch': 1.92}          \n  5%|█▋                                | 480/10000 [1:47:36<30:01:11, 11.35s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7196204662322998, 'eval_runtime': 24.4579, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 1.92}\n  5%|█▋                                | 480/10000 [1:48:00<30:01:11, 11.35s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.8262, 'learning_rate': 9.527527527527528e-05, 'epoch': 1.96}         \n  5%|█▋                                | 490/10000 [1:49:51<29:31:28, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7104060649871826, 'eval_runtime': 24.6305, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 1.96}\n  5%|█▋                                | 490/10000 [1:50:15<29:31:28, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.8567, 'learning_rate': 9.517517517517518e-05, 'epoch': 2.0}          \n  5%|█▋                                | 500/10000 [1:52:05<29:25:48, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.949265718460083, 'eval_runtime': 24.5393, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 2.0}\n  5%|█▋                                | 500/10000 [1:52:30<29:25:48, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.1905, 'learning_rate': 9.507507507507508e-05, 'epoch': 2.04}         \n  5%|█▋                                | 510/10000 [1:54:21<29:47:58, 11.30s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7703930139541626, 'eval_runtime': 24.6374, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 2.04}\n  5%|█▋                                | 510/10000 [1:54:46<29:47:58, 11.30s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.1498, 'learning_rate': 9.497497497497498e-05, 'epoch': 2.08}         \n  5%|█▊                                | 520/10000 [1:56:37<29:37:35, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7994165420532227, 'eval_runtime': 24.6711, 'eval_samples_per_second': 0.811, 'eval_steps_per_second': 0.203, 'epoch': 2.08}\n  5%|█▊                                | 520/10000 [1:57:02<29:37:35, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.0553, 'learning_rate': 9.487487487487487e-05, 'epoch': 2.12}         \n  5%|█▊                                | 530/10000 [1:58:53<29:29:24, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.03s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7548412084579468, 'eval_runtime': 24.7279, 'eval_samples_per_second': 0.809, 'eval_steps_per_second': 0.202, 'epoch': 2.12}\n  5%|█▊                                | 530/10000 [1:59:17<29:29:24, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.377, 'learning_rate': 9.477477477477478e-05, 'epoch': 2.16}          \n  5%|█▊                                | 540/10000 [2:01:09<29:52:42, 11.37s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6278339624404907, 'eval_runtime': 24.5444, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 2.16}\n  5%|█▊                                | 540/10000 [2:01:34<29:52:42, 11.37s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.2697, 'learning_rate': 9.467467467467468e-05, 'epoch': 2.2}          \n  6%|█▊                                | 550/10000 [2:03:25<29:26:03, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.681532859802246, 'eval_runtime': 24.5621, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 2.2}\n  6%|█▊                                | 550/10000 [2:03:49<29:26:03, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.0598, 'learning_rate': 9.457457457457458e-05, 'epoch': 2.24}         \n  6%|█▉                                | 560/10000 [2:05:40<29:22:06, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6488126516342163, 'eval_runtime': 24.5179, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 2.24}\n  6%|█▉                                | 560/10000 [2:06:04<29:22:06, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.9916, 'learning_rate': 9.447447447447448e-05, 'epoch': 2.28}         \n  6%|█▉                                | 570/10000 [2:07:56<29:28:13, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7378549575805664, 'eval_runtime': 24.4573, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 2.28}\n  6%|█▉                                | 570/10000 [2:08:20<29:28:13, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.1425, 'learning_rate': 9.437437437437437e-05, 'epoch': 2.32}         \n  6%|█▉                                | 580/10000 [2:10:11<29:13:12, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6869966983795166, 'eval_runtime': 24.5646, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 2.32}\n  6%|█▉                                | 580/10000 [2:10:35<29:13:12, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.0652, 'learning_rate': 9.427427427427427e-05, 'epoch': 2.36}         \n  6%|██                                | 590/10000 [2:12:26<29:21:27, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.49s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7371774911880493, 'eval_runtime': 24.6738, 'eval_samples_per_second': 0.811, 'eval_steps_per_second': 0.203, 'epoch': 2.36}\n  6%|██                                | 590/10000 [2:12:51<29:21:27, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.3623, 'learning_rate': 9.417417417417418e-05, 'epoch': 2.4}          \n  6%|██                                | 600/10000 [2:14:41<29:15:45, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.68961501121521, 'eval_runtime': 24.4234, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 2.4}\n  6%|██                                | 600/10000 [2:15:06<29:15:45, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.087, 'learning_rate': 9.407407407407408e-05, 'epoch': 2.44}          \n  6%|██                                | 610/10000 [2:16:56<29:05:14, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6783628463745117, 'eval_runtime': 24.6206, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 2.44}\n  6%|██                                | 610/10000 [2:17:21<29:05:14, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.0073, 'learning_rate': 9.397397397397399e-05, 'epoch': 2.48}         \n  6%|██                                | 620/10000 [2:19:12<29:12:08, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6707566976547241, 'eval_runtime': 24.5996, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 2.48}\n  6%|██                                | 620/10000 [2:19:36<29:12:08, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.5386, 'learning_rate': 9.387387387387387e-05, 'epoch': 2.52}         \n  6%|██▏                               | 630/10000 [2:21:28<29:15:41, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6742357015609741, 'eval_runtime': 24.3863, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 2.52}\n  6%|██▏                               | 630/10000 [2:21:52<29:15:41, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.0428, 'learning_rate': 9.377377377377377e-05, 'epoch': 2.56}         \n  6%|██▏                               | 640/10000 [2:23:43<29:08:43, 11.21s/it]\n{'loss': 2.2448, 'learning_rate': 9.367367367367367e-05, 'epoch': 2.6}          \u001b[A\n  6%|██▏                               | 650/10000 [2:25:57<28:59:08, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7047672271728516, 'eval_runtime': 24.7228, 'eval_samples_per_second': 0.809, 'eval_steps_per_second': 0.202, 'epoch': 2.6}\n  6%|██▏                               | 650/10000 [2:26:22<28:59:08, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.311, 'learning_rate': 9.357357357357359e-05, 'epoch': 2.64}          \n  7%|██▏                               | 660/10000 [2:28:13<29:12:47, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.5663052797317505, 'eval_runtime': 24.6305, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 2.64}\n  7%|██▏                               | 660/10000 [2:28:37<29:12:47, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.1803, 'learning_rate': 9.347347347347349e-05, 'epoch': 2.68}         \n  7%|██▎                               | 670/10000 [2:30:28<28:59:07, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.5415385961532593, 'eval_runtime': 24.4556, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 2.68}\n  7%|██▎                               | 670/10000 [2:30:52<28:59:07, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.1872, 'learning_rate': 9.337337337337337e-05, 'epoch': 2.72}         \n  7%|██▎                               | 680/10000 [2:32:43<29:04:43, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.480701208114624, 'eval_runtime': 24.4657, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 2.72}\n  7%|██▎                               | 680/10000 [2:33:08<29:04:43, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.4561, 'learning_rate': 9.327327327327327e-05, 'epoch': 2.76}         \n  7%|██▎                               | 690/10000 [2:34:58<28:49:10, 11.14s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2718702554702759, 'eval_runtime': 24.6516, 'eval_samples_per_second': 0.811, 'eval_steps_per_second': 0.203, 'epoch': 2.76}\n  7%|██▎                               | 690/10000 [2:35:22<28:49:10, 11.14s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.5351, 'learning_rate': 9.317317317317317e-05, 'epoch': 2.8}          \n  7%|██▍                               | 700/10000 [2:37:13<28:53:12, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3018293380737305, 'eval_runtime': 24.5174, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 2.8}\n  7%|██▍                               | 700/10000 [2:37:38<28:53:12, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.4896, 'learning_rate': 9.307307307307309e-05, 'epoch': 2.84}         \n  7%|██▍                               | 710/10000 [2:39:28<28:53:56, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.332419753074646, 'eval_runtime': 24.5256, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 2.84}\n  7%|██▍                               | 710/10000 [2:39:53<28:53:56, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.3455, 'learning_rate': 9.297297297297299e-05, 'epoch': 2.88}         \n  7%|██▍                               | 720/10000 [2:41:44<29:00:23, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.419572114944458, 'eval_runtime': 24.5221, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 2.88}\n  7%|██▍                               | 720/10000 [2:42:08<29:00:23, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.7104, 'learning_rate': 9.287287287287287e-05, 'epoch': 2.92}         \n  7%|██▍                               | 730/10000 [2:43:59<28:59:24, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3556879758834839, 'eval_runtime': 24.5301, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 2.92}\n  7%|██▍                               | 730/10000 [2:44:24<28:59:24, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.4413, 'learning_rate': 9.277277277277277e-05, 'epoch': 2.96}         \n  7%|██▌                               | 740/10000 [2:46:14<28:47:58, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.375344157218933, 'eval_runtime': 24.7022, 'eval_samples_per_second': 0.81, 'eval_steps_per_second': 0.202, 'epoch': 2.96}\n  7%|██▌                               | 740/10000 [2:46:39<28:47:58, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.3539, 'learning_rate': 9.267267267267267e-05, 'epoch': 3.0}          \n  8%|██▌                               | 750/10000 [2:48:30<28:50:22, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.49s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3401906490325928, 'eval_runtime': 24.6295, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 3.0}\n  8%|██▌                               | 750/10000 [2:48:55<28:50:22, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.651, 'learning_rate': 9.257257257257257e-05, 'epoch': 3.04}          \n  8%|██▌                               | 760/10000 [2:50:46<28:48:58, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:05<00:07,  2.50s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.04s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6246618032455444, 'eval_runtime': 24.7939, 'eval_samples_per_second': 0.807, 'eval_steps_per_second': 0.202, 'epoch': 3.04}\n  8%|██▌                               | 760/10000 [2:51:11<28:48:58, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.6806, 'learning_rate': 9.247247247247249e-05, 'epoch': 3.08}         \n  8%|██▌                               | 770/10000 [2:53:02<28:41:15, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.5433385372161865, 'eval_runtime': 24.3951, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 3.08}\n  8%|██▌                               | 770/10000 [2:53:26<28:41:15, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.745, 'learning_rate': 9.237237237237237e-05, 'epoch': 3.12}          \n  8%|██▋                               | 780/10000 [2:55:17<28:38:13, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.97s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.4756702184677124, 'eval_runtime': 24.323, 'eval_samples_per_second': 0.822, 'eval_steps_per_second': 0.206, 'epoch': 3.12}\n  8%|██▋                               | 780/10000 [2:55:41<28:38:13, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.8745, 'learning_rate': 9.227227227227227e-05, 'epoch': 3.16}         \n  8%|██▋                               | 790/10000 [2:57:32<28:36:30, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.4394220113754272, 'eval_runtime': 24.4836, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 3.16}\n  8%|██▋                               | 790/10000 [2:57:56<28:36:30, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.9124, 'learning_rate': 9.217217217217217e-05, 'epoch': 3.2}          \n  8%|██▋                               | 800/10000 [2:59:48<28:49:12, 11.28s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.48s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:07,  3.51s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.4055323600769043, 'eval_runtime': 24.7571, 'eval_samples_per_second': 0.808, 'eval_steps_per_second': 0.202, 'epoch': 3.2}\n  8%|██▋                               | 800/10000 [3:00:12<28:49:12, 11.28s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.35s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.7003, 'learning_rate': 9.207207207207207e-05, 'epoch': 3.24}         \n  8%|██▊                               | 810/10000 [3:02:03<28:35:32, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.321783185005188, 'eval_runtime': 24.4945, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 3.24}\n  8%|██▊                               | 810/10000 [3:02:27<28:35:32, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.9365, 'learning_rate': 9.197197197197199e-05, 'epoch': 3.28}         \n  8%|██▊                               | 820/10000 [3:04:19<28:39:46, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2812503576278687, 'eval_runtime': 24.4773, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 3.28}\n  8%|██▊                               | 820/10000 [3:04:43<28:39:46, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.8687, 'learning_rate': 9.187187187187187e-05, 'epoch': 3.32}         \n  8%|██▊                               | 830/10000 [3:06:35<28:43:44, 11.28s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2275314331054688, 'eval_runtime': 24.4534, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 3.32}\n  8%|██▊                               | 830/10000 [3:06:59<28:43:44, 11.28s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!begin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\n\nsave done !!!\n{'loss': 1.9699, 'learning_rate': 9.177177177177177e-05, 'epoch': 3.36}         \n  8%|██▊                               | 840/10000 [3:08:50<28:36:59, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.4042737483978271, 'eval_runtime': 24.501, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 3.36}\n  8%|██▊                               | 840/10000 [3:09:15<28:36:59, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.7439, 'learning_rate': 9.167167167167167e-05, 'epoch': 3.4}          \n  8%|██▉                               | 850/10000 [3:11:05<28:25:50, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3148075342178345, 'eval_runtime': 24.5867, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 3.4}\n  8%|██▉                               | 850/10000 [3:11:30<28:25:50, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.8925, 'learning_rate': 9.157157157157157e-05, 'epoch': 3.44}         \n  9%|██▉                               | 860/10000 [3:13:21<28:26:14, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3486299514770508, 'eval_runtime': 24.5505, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 3.44}\n  9%|██▉                               | 860/10000 [3:13:45<28:26:14, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.8147, 'learning_rate': 9.147147147147147e-05, 'epoch': 3.48}         \n  9%|██▉                               | 870/10000 [3:15:36<28:27:13, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.44s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.97s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.287226915359497, 'eval_runtime': 24.5719, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.203, 'epoch': 3.48}\n  9%|██▉                               | 870/10000 [3:16:01<28:27:13, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.786, 'learning_rate': 9.137137137137138e-05, 'epoch': 3.52}          \n  9%|██▉                               | 880/10000 [3:17:51<28:23:11, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.232757329940796, 'eval_runtime': 24.4492, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 3.52}\n  9%|██▉                               | 880/10000 [3:18:16<28:23:11, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.9209, 'learning_rate': 9.127127127127128e-05, 'epoch': 3.56}         \n  9%|███                               | 890/10000 [3:20:07<28:22:13, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1371440887451172, 'eval_runtime': 24.4547, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 3.56}\n  9%|███                               | 890/10000 [3:20:31<28:22:13, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4972, 'learning_rate': 9.117117117117118e-05, 'epoch': 3.6}          \n  9%|███                               | 900/10000 [3:22:21<28:16:13, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2424678802490234, 'eval_runtime': 24.4936, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 3.6}\n  9%|███                               | 900/10000 [3:22:46<28:16:13, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.2435, 'learning_rate': 9.107107107107108e-05, 'epoch': 3.64}         \n  9%|███                               | 910/10000 [3:24:36<28:22:33, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.4494487047195435, 'eval_runtime': 24.5758, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.203, 'epoch': 3.64}\n  9%|███                               | 910/10000 [3:25:01<28:22:33, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!this process is not main process , do not save model.[for distributed training scenario]\n\nsave done !!!\n{'loss': 2.0661, 'learning_rate': 9.097097097097098e-05, 'epoch': 3.68}         \n  9%|███▏                              | 920/10000 [3:26:52<28:16:16, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.44s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.97s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.140265703201294, 'eval_runtime': 24.3249, 'eval_samples_per_second': 0.822, 'eval_steps_per_second': 0.206, 'epoch': 3.68}\n  9%|███▏                              | 920/10000 [3:27:16<28:16:16, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.7418, 'learning_rate': 9.087087087087088e-05, 'epoch': 3.72}         \n  9%|███▏                              | 930/10000 [3:29:07<28:04:08, 11.14s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0857970714569092, 'eval_runtime': 24.4267, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 3.72}\n  9%|███▏                              | 930/10000 [3:29:31<28:04:08, 11.14s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.3064, 'learning_rate': 9.077077077077078e-05, 'epoch': 3.76}         \n  9%|███▏                              | 940/10000 [3:31:21<28:04:46, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.97s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0776764154434204, 'eval_runtime': 24.3442, 'eval_samples_per_second': 0.822, 'eval_steps_per_second': 0.205, 'epoch': 3.76}\n  9%|███▏                              | 940/10000 [3:31:46<28:04:46, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.9782, 'learning_rate': 9.067067067067068e-05, 'epoch': 3.8}          \n 10%|███▏                              | 950/10000 [3:33:37<28:15:32, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.50s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.04s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.7327544689178467, 'eval_runtime': 24.6888, 'eval_samples_per_second': 0.81, 'eval_steps_per_second': 0.203, 'epoch': 3.8}\n 10%|███▏                              | 950/10000 [3:34:02<28:15:32, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.9179, 'learning_rate': 9.057057057057058e-05, 'epoch': 3.84}         \n 10%|███▎                              | 960/10000 [3:35:52<28:03:16, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1668105125427246, 'eval_runtime': 24.5472, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 3.84}\n 10%|███▎                              | 960/10000 [3:36:17<28:03:16, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 2.1454, 'learning_rate': 9.047047047047048e-05, 'epoch': 3.88}         \n 10%|███▎                              | 970/10000 [3:38:08<28:05:41, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1410300731658936, 'eval_runtime': 24.5732, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.203, 'epoch': 3.88}\n 10%|███▎                              | 970/10000 [3:38:32<28:05:41, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.1029, 'learning_rate': 9.037037037037038e-05, 'epoch': 3.92}         \n 10%|███▎                              | 980/10000 [3:40:23<28:02:48, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1598930358886719, 'eval_runtime': 24.572, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.203, 'epoch': 3.92}\n 10%|███▎                              | 980/10000 [3:40:47<28:02:48, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.2427, 'learning_rate': 9.027027027027028e-05, 'epoch': 3.96}         \n 10%|███▎                              | 990/10000 [3:42:38<28:00:57, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2228416204452515, 'eval_runtime': 24.4577, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 3.96}\n 10%|███▎                              | 990/10000 [3:43:03<28:00:57, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 2.0795, 'learning_rate': 9.017017017017018e-05, 'epoch': 4.0}          \n 10%|███▎                             | 1000/10000 [3:44:53<27:50:48, 11.14s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2727371454238892, 'eval_runtime': 24.4587, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 4.0}\n 10%|███▎                             | 1000/10000 [3:45:17<27:50:48, 11.14s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.1927, 'learning_rate': 9.007007007007008e-05, 'epoch': 4.04}         \n 10%|███▎                             | 1010/10000 [3:47:08<28:07:00, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.49s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.50s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.03s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2560317516326904, 'eval_runtime': 24.7173, 'eval_samples_per_second': 0.809, 'eval_steps_per_second': 0.202, 'epoch': 4.04}\n 10%|███▎                             | 1010/10000 [3:47:33<28:07:00, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.5683, 'learning_rate': 8.996996996996996e-05, 'epoch': 4.08}         \n 10%|███▎                             | 1020/10000 [3:49:24<27:57:46, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3131353855133057, 'eval_runtime': 24.5248, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 4.08}\n 10%|███▎                             | 1020/10000 [3:49:49<27:57:46, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.398, 'learning_rate': 8.986986986986988e-05, 'epoch': 4.12}          \n 10%|███▍                             | 1030/10000 [3:51:39<27:45:44, 11.14s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3825355768203735, 'eval_runtime': 24.4457, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 4.12}\n 10%|███▍                             | 1030/10000 [3:52:04<27:45:44, 11.14s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4233, 'learning_rate': 8.976976976976978e-05, 'epoch': 4.16}         \n 10%|███▍                             | 1040/10000 [3:53:54<27:51:24, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3351256847381592, 'eval_runtime': 24.4046, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 4.16}\n 10%|███▍                             | 1040/10000 [3:54:18<27:51:24, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.5704, 'learning_rate': 8.966966966966968e-05, 'epoch': 4.2}          \n 10%|███▍                             | 1050/10000 [3:56:09<27:50:41, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1598875522613525, 'eval_runtime': 24.5001, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 4.2}\n 10%|███▍                             | 1050/10000 [3:56:33<27:50:41, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.4104, 'learning_rate': 8.956956956956958e-05, 'epoch': 4.24}         \n 11%|███▍                             | 1060/10000 [3:58:24<27:50:08, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2509349584579468, 'eval_runtime': 24.3575, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 4.24}\n 11%|███▍                             | 1060/10000 [3:58:48<27:50:08, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6683, 'learning_rate': 8.946946946946946e-05, 'epoch': 4.28}         \n 11%|███▌                             | 1070/10000 [4:00:40<27:52:23, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.162742257118225, 'eval_runtime': 24.5089, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 4.28}\n 11%|███▌                             | 1070/10000 [4:01:04<27:52:23, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.6889, 'learning_rate': 8.936936936936938e-05, 'epoch': 4.32}         \n 11%|███▌                             | 1080/10000 [4:02:55<27:46:33, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.142932653427124, 'eval_runtime': 24.5897, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 4.32}\n 11%|███▌                             | 1080/10000 [4:03:19<27:46:33, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4731, 'learning_rate': 8.926926926926928e-05, 'epoch': 4.36}         \n 11%|███▌                             | 1090/10000 [4:05:11<27:52:23, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1484813690185547, 'eval_runtime': 24.5673, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 4.36}\n 11%|███▌                             | 1090/10000 [4:05:36<27:52:23, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.3479, 'learning_rate': 8.916916916916918e-05, 'epoch': 4.4}          \n 11%|███▋                             | 1100/10000 [4:07:26<27:35:11, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.190640926361084, 'eval_runtime': 24.4122, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 4.4}\n 11%|███▋                             | 1100/10000 [4:07:50<27:35:11, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.5404, 'learning_rate': 8.906906906906908e-05, 'epoch': 4.44}         \n 11%|███▋                             | 1110/10000 [4:09:41<27:37:15, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.271365761756897, 'eval_runtime': 24.4145, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 4.44}\n 11%|███▋                             | 1110/10000 [4:10:05<27:37:15, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.9124, 'learning_rate': 8.896896896896896e-05, 'epoch': 4.48}         \n 11%|███▋                             | 1120/10000 [4:11:56<27:35:47, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.112278938293457, 'eval_runtime': 24.4081, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 4.48}\n 11%|███▋                             | 1120/10000 [4:12:20<27:35:47, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6922, 'learning_rate': 8.886886886886887e-05, 'epoch': 4.52}         \n 11%|███▋                             | 1130/10000 [4:14:13<27:57:26, 11.35s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1198843717575073, 'eval_runtime': 24.4586, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 4.52}\n 11%|███▋                             | 1130/10000 [4:14:38<27:57:26, 11.35s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6384, 'learning_rate': 8.876876876876878e-05, 'epoch': 4.56}         \n 11%|███▊                             | 1140/10000 [4:16:29<27:36:10, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1655869483947754, 'eval_runtime': 24.5653, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 4.56}\n 11%|███▊                             | 1140/10000 [4:16:54<27:36:10, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.5691, 'learning_rate': 8.866866866866868e-05, 'epoch': 4.6}          \n 12%|███▊                             | 1150/10000 [4:18:44<27:27:38, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.162667155265808, 'eval_runtime': 24.3742, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 4.6}\n 12%|███▊                             | 1150/10000 [4:19:08<27:27:38, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4767, 'learning_rate': 8.856856856856858e-05, 'epoch': 4.64}         \n 12%|███▊                             | 1160/10000 [4:20:59<27:22:53, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1099742650985718, 'eval_runtime': 24.3387, 'eval_samples_per_second': 0.822, 'eval_steps_per_second': 0.205, 'epoch': 4.64}\n 12%|███▊                             | 1160/10000 [4:21:23<27:22:53, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.8604, 'learning_rate': 8.846846846846847e-05, 'epoch': 4.68}         \n 12%|███▊                             | 1170/10000 [4:23:14<27:30:37, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1288855075836182, 'eval_runtime': 24.4906, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 4.68}\n 12%|███▊                             | 1170/10000 [4:23:38<27:30:37, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n 12%|███▉                             | 1179/10000 [4:25:18<27:44:13, 11.32s/it]\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9534491300582886, 'eval_runtime': 24.441, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 4.72}\n 12%|███▉                             | 1180/10000 [4:25:53<27:19:40, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.6846, 'learning_rate': 8.826826826826828e-05, 'epoch': 4.76}         \n 12%|███▉                             | 1190/10000 [4:27:44<27:23:50, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0396969318389893, 'eval_runtime': 24.4736, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 4.76}\n 12%|███▉                             | 1190/10000 [4:28:09<27:23:50, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.8808, 'learning_rate': 8.816816816816818e-05, 'epoch': 4.8}          \n 12%|███▉                             | 1200/10000 [4:29:59<27:24:03, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.064544916152954, 'eval_runtime': 24.3798, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 4.8}\n 12%|███▉                             | 1200/10000 [4:30:23<27:24:03, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.8313, 'learning_rate': 8.806806806806808e-05, 'epoch': 4.84}         \n 12%|███▉                             | 1210/10000 [4:32:14<27:25:34, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9993106722831726, 'eval_runtime': 24.4491, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 4.84}\n 12%|███▉                             | 1210/10000 [4:32:39<27:25:34, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.5771, 'learning_rate': 8.796796796796797e-05, 'epoch': 4.88}         \n 12%|████                             | 1220/10000 [4:34:29<27:17:46, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0224871635437012, 'eval_runtime': 24.3765, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 4.88}\n 12%|████                             | 1220/10000 [4:34:53<27:17:46, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.684, 'learning_rate': 8.786786786786787e-05, 'epoch': 4.92}          \n 12%|████                             | 1230/10000 [4:36:45<27:18:27, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.074548363685608, 'eval_runtime': 24.5254, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 4.92}\n 12%|████                             | 1230/10000 [4:37:09<27:18:27, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.9494, 'learning_rate': 8.776776776776777e-05, 'epoch': 4.96}         \n 12%|████                             | 1240/10000 [4:39:00<27:16:34, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.97s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9900811910629272, 'eval_runtime': 24.3664, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 4.96}\n 12%|████                             | 1240/10000 [4:39:25<27:16:34, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.964, 'learning_rate': 8.766766766766768e-05, 'epoch': 5.0}           \n 12%|████▏                            | 1250/10000 [4:41:15<27:09:35, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0863559246063232, 'eval_runtime': 24.5291, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 5.0}\n 12%|████▏                            | 1250/10000 [4:41:39<27:09:35, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.171, 'learning_rate': 8.756756756756758e-05, 'epoch': 5.04}          \n 13%|████▏                            | 1260/10000 [4:43:31<27:25:06, 11.29s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0194671154022217, 'eval_runtime': 24.5578, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 5.04}\n 13%|████▏                            | 1260/10000 [4:43:55<27:25:06, 11.29s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.1604, 'learning_rate': 8.746746746746747e-05, 'epoch': 5.08}         \n 13%|████▏                            | 1270/10000 [4:45:46<27:13:48, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9768571853637695, 'eval_runtime': 24.5612, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 5.08}\n 13%|████▏                            | 1270/10000 [4:46:11<27:13:48, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.2461, 'learning_rate': 8.736736736736737e-05, 'epoch': 5.12}         \n 13%|████▏                            | 1280/10000 [4:48:01<27:11:02, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0631458759307861, 'eval_runtime': 24.6435, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 5.12}\n 13%|████▏                            | 1280/10000 [4:48:26<27:11:02, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.3964, 'learning_rate': 8.726726726726727e-05, 'epoch': 5.16}         \n 13%|████▎                            | 1290/10000 [4:50:16<26:57:57, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0981614589691162, 'eval_runtime': 24.3602, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 5.16}\n 13%|████▎                            | 1290/10000 [4:50:41<26:57:57, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.3735, 'learning_rate': 8.716716716716717e-05, 'epoch': 5.2}          \n 13%|████▎                            | 1300/10000 [4:52:31<26:59:58, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1794049739837646, 'eval_runtime': 24.3703, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 5.2}\n 13%|████▎                            | 1300/10000 [4:52:56<26:59:58, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.2613, 'learning_rate': 8.706706706706708e-05, 'epoch': 5.24}         \n 13%|████▎                            | 1310/10000 [4:54:46<27:01:10, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2015361785888672, 'eval_runtime': 24.4301, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 5.24}\n 13%|████▎                            | 1310/10000 [4:55:11<27:01:10, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6637, 'learning_rate': 8.696696696696697e-05, 'epoch': 5.28}         \n 13%|████▎                            | 1320/10000 [4:57:02<27:08:23, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2804819345474243, 'eval_runtime': 24.4546, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 5.28}\n 13%|████▎                            | 1320/10000 [4:57:26<27:08:23, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4337, 'learning_rate': 8.686686686686687e-05, 'epoch': 5.32}         \n 13%|████▍                            | 1330/10000 [4:59:17<27:10:21, 11.28s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2754865884780884, 'eval_runtime': 24.4577, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 5.32}\n 13%|████▍                            | 1330/10000 [4:59:41<27:10:21, 11.28s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.3893, 'learning_rate': 8.676676676676677e-05, 'epoch': 5.36}         \n 13%|████▍                            | 1340/10000 [5:01:33<27:06:10, 11.27s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0398627519607544, 'eval_runtime': 24.529, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 5.36}\n 13%|████▍                            | 1340/10000 [5:01:57<27:06:10, 11.27s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.3838, 'learning_rate': 8.666666666666667e-05, 'epoch': 5.4}          \n 14%|████▍                            | 1350/10000 [5:03:48<26:49:26, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0322630405426025, 'eval_runtime': 24.6195, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 5.4}\n 14%|████▍                            | 1350/10000 [5:04:12<26:49:26, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.5655, 'learning_rate': 8.656656656656658e-05, 'epoch': 5.44}         \n 14%|████▍                            | 1360/10000 [5:06:04<26:56:36, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1298120021820068, 'eval_runtime': 24.5887, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 5.44}\n 14%|████▍                            | 1360/10000 [5:06:28<26:56:36, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4488, 'learning_rate': 8.646646646646647e-05, 'epoch': 5.48}         \n 14%|████▌                            | 1370/10000 [5:08:18<26:44:34, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2085201740264893, 'eval_runtime': 24.3795, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 5.48}\n 14%|████▌                            | 1370/10000 [5:08:43<26:44:34, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.8459, 'learning_rate': 8.636636636636637e-05, 'epoch': 5.52}         \n 14%|████▌                            | 1380/10000 [5:10:34<27:00:06, 11.28s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.151917815208435, 'eval_runtime': 24.5296, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 5.52}\n 14%|████▌                            | 1380/10000 [5:10:59<27:00:06, 11.28s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6483, 'learning_rate': 8.626626626626627e-05, 'epoch': 5.56}         \n 14%|████▌                            | 1390/10000 [5:12:50<26:50:12, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1976635456085205, 'eval_runtime': 24.4821, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 5.56}\n 14%|████▌                            | 1390/10000 [5:13:14<26:50:12, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.6683, 'learning_rate': 8.616616616616617e-05, 'epoch': 5.6}          \n 14%|████▌                            | 1400/10000 [5:15:05<26:48:01, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1480989456176758, 'eval_runtime': 24.4041, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 5.6}\n 14%|████▌                            | 1400/10000 [5:15:29<26:48:01, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.3987, 'learning_rate': 8.606606606606607e-05, 'epoch': 5.64}         \n 14%|████▋                            | 1410/10000 [5:17:20<26:37:52, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0731620788574219, 'eval_runtime': 24.3947, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 5.64}\n 14%|████▋                            | 1410/10000 [5:17:44<26:37:52, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.5524, 'learning_rate': 8.596596596596597e-05, 'epoch': 5.68}         \n 14%|████▋                            | 1420/10000 [5:19:36<26:49:09, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1054565906524658, 'eval_runtime': 24.498, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 5.68}\n 14%|████▋                            | 1420/10000 [5:20:00<26:49:09, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.5636, 'learning_rate': 8.586586586586587e-05, 'epoch': 5.72}         \n 14%|████▋                            | 1430/10000 [5:21:51<26:38:40, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.04s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.2864421606063843, 'eval_runtime': 24.6695, 'eval_samples_per_second': 0.811, 'eval_steps_per_second': 0.203, 'epoch': 5.72}\n 14%|████▋                            | 1430/10000 [5:22:16<26:38:40, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.0048, 'learning_rate': 8.576576576576577e-05, 'epoch': 5.76}         \n 14%|████▊                            | 1440/10000 [5:24:07<26:44:38, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.3141329288482666, 'eval_runtime': 24.5342, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 5.76}\n 14%|████▊                            | 1440/10000 [5:24:32<26:44:38, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.8635, 'learning_rate': 8.566566566566567e-05, 'epoch': 5.8}          \n 14%|████▊                            | 1450/10000 [5:26:22<26:37:17, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1829168796539307, 'eval_runtime': 24.4017, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 5.8}\n 14%|████▊                            | 1450/10000 [5:26:46<26:37:17, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!begin to save  !!!\n\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.7882, 'learning_rate': 8.556556556556557e-05, 'epoch': 5.84}         \n 15%|████▊                            | 1460/10000 [5:28:37<26:28:53, 11.16s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.231873631477356, 'eval_runtime': 24.3515, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.205, 'epoch': 5.84}\n 15%|████▊                            | 1460/10000 [5:29:01<26:28:53, 11.16s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.8008, 'learning_rate': 8.546546546546547e-05, 'epoch': 5.88}         \n 15%|████▊                            | 1470/10000 [5:30:53<26:38:43, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9552232623100281, 'eval_runtime': 24.4136, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 5.88}\n 15%|████▊                            | 1470/10000 [5:31:17<26:38:43, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.7716, 'learning_rate': 8.536536536536537e-05, 'epoch': 5.92}         \n 15%|████▉                            | 1480/10000 [5:33:08<26:23:18, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9448516964912415, 'eval_runtime': 24.4352, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 5.92}\n 15%|████▉                            | 1480/10000 [5:33:33<26:23:18, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6569, 'learning_rate': 8.526526526526527e-05, 'epoch': 5.96}         \n 15%|████▉                            | 1490/10000 [5:35:23<26:31:43, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.98s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.907217800617218, 'eval_runtime': 24.5482, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 5.96}\n 15%|████▉                            | 1490/10000 [5:35:48<26:31:43, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.8065, 'learning_rate': 8.516516516516517e-05, 'epoch': 6.0}          \n 15%|████▉                            | 1500/10000 [5:37:39<26:31:25, 11.23s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.03s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.8698022961616516, 'eval_runtime': 24.6147, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.0}\n 15%|████▉                            | 1500/10000 [5:38:03<26:31:25, 11.23s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.34s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.2325, 'learning_rate': 8.506506506506507e-05, 'epoch': 6.04}         \n 15%|████▉                            | 1510/10000 [5:39:56<26:30:08, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9311502575874329, 'eval_runtime': 24.6095, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.04}\n 15%|████▉                            | 1510/10000 [5:40:20<26:30:08, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 0.9811, 'learning_rate': 8.496496496496497e-05, 'epoch': 6.08}         \n 15%|█████                            | 1520/10000 [5:42:11<26:22:25, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9984778165817261, 'eval_runtime': 24.4197, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 6.08}\n 15%|█████                            | 1520/10000 [5:42:35<26:22:25, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4263, 'learning_rate': 8.486486486486487e-05, 'epoch': 6.12}         \n 15%|█████                            | 1530/10000 [5:44:27<26:20:25, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1174123287200928, 'eval_runtime': 24.482, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 6.12}\n 15%|█████                            | 1530/10000 [5:44:51<26:20:25, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.2262, 'learning_rate': 8.476476476476477e-05, 'epoch': 6.16}         \n 15%|█████                            | 1540/10000 [5:46:42<26:22:19, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0443384647369385, 'eval_runtime': 24.6302, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 6.16}\n 15%|█████                            | 1540/10000 [5:47:06<26:22:19, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.2254, 'learning_rate': 8.466466466466467e-05, 'epoch': 6.2}          \n 16%|█████                            | 1550/10000 [5:48:57<26:19:07, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0154640674591064, 'eval_runtime': 24.5778, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.203, 'epoch': 6.2}\n 16%|█████                            | 1550/10000 [5:49:22<26:19:07, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.3352, 'learning_rate': 8.456456456456456e-05, 'epoch': 6.24}         \n 16%|█████▏                           | 1560/10000 [5:51:12<26:14:29, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.49s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.02s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0102403163909912, 'eval_runtime': 24.6823, 'eval_samples_per_second': 0.81, 'eval_steps_per_second': 0.203, 'epoch': 6.24}\n 16%|█████▏                           | 1560/10000 [5:51:37<26:14:29, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.35s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.1748, 'learning_rate': 8.446446446446447e-05, 'epoch': 6.28}         \n 16%|█████▏                           | 1570/10000 [5:53:28<26:12:29, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1148021221160889, 'eval_runtime': 24.6129, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.28}\n 16%|█████▏                           | 1570/10000 [5:53:52<26:12:29, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.3277, 'learning_rate': 8.436436436436437e-05, 'epoch': 6.32}         \n 16%|█████▏                           | 1580/10000 [5:55:43<26:12:45, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0516059398651123, 'eval_runtime': 24.4532, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 6.32}\n 16%|█████▏                           | 1580/10000 [5:56:07<26:12:45, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.1329, 'learning_rate': 8.426426426426427e-05, 'epoch': 6.36}         \n 16%|█████▏                           | 1590/10000 [5:57:58<26:11:08, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0011579990386963, 'eval_runtime': 24.6093, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.36}\n 16%|█████▏                           | 1590/10000 [5:58:22<26:11:08, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.3132, 'learning_rate': 8.416416416416417e-05, 'epoch': 6.4}          \n 16%|█████▎                           | 1600/10000 [6:00:13<26:05:26, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0009487867355347, 'eval_runtime': 24.5911, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.4}\n 16%|█████▎                           | 1600/10000 [6:00:38<26:05:26, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4112, 'learning_rate': 8.406406406406406e-05, 'epoch': 6.44}         \n 16%|█████▎                           | 1610/10000 [6:02:28<26:06:15, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0444092750549316, 'eval_runtime': 24.4491, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.205, 'epoch': 6.44}\n 16%|█████▎                           | 1610/10000 [6:02:53<26:06:15, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.4266, 'learning_rate': 8.396396396396397e-05, 'epoch': 6.48}         \n 16%|█████▎                           | 1620/10000 [6:04:43<25:56:43, 11.15s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.036206603050232, 'eval_runtime': 24.4232, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 6.48}\n 16%|█████▎                           | 1620/10000 [6:05:08<25:56:43, 11.15s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.3598, 'learning_rate': 8.386386386386387e-05, 'epoch': 6.52}         \n 16%|█████▍                           | 1630/10000 [6:06:58<26:00:50, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0870369672775269, 'eval_runtime': 24.5961, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.52}\n 16%|█████▍                           | 1630/10000 [6:07:23<26:00:50, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.4861, 'learning_rate': 8.376376376376377e-05, 'epoch': 6.56}         \n 16%|█████▍                           | 1640/10000 [6:09:13<25:56:30, 11.17s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9110094904899597, 'eval_runtime': 24.5577, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.204, 'epoch': 6.56}\n 16%|█████▍                           | 1640/10000 [6:09:38<25:56:30, 11.17s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.8843, 'learning_rate': 8.366366366366367e-05, 'epoch': 6.6}          \n 16%|█████▍                           | 1650/10000 [6:11:30<26:28:05, 11.41s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9028860330581665, 'eval_runtime': 24.3895, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 6.6}\n 16%|█████▍                           | 1650/10000 [6:11:54<26:28:05, 11.41s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.3703, 'learning_rate': 8.356356356356356e-05, 'epoch': 6.64}         \n 17%|█████▍                           | 1660/10000 [6:13:45<25:59:01, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:07,  3.52s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.05s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9660042524337769, 'eval_runtime': 24.7977, 'eval_samples_per_second': 0.807, 'eval_steps_per_second': 0.202, 'epoch': 6.64}\n 17%|█████▍                           | 1660/10000 [6:14:10<25:59:01, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.35s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.6196, 'learning_rate': 8.346346346346346e-05, 'epoch': 6.68}         \n 17%|█████▌                           | 1670/10000 [6:16:01<25:54:53, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.943343460559845, 'eval_runtime': 24.5518, 'eval_samples_per_second': 0.815, 'eval_steps_per_second': 0.204, 'epoch': 6.68}\n 17%|█████▌                           | 1670/10000 [6:16:25<25:54:53, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 2.0412, 'learning_rate': 8.336336336336337e-05, 'epoch': 6.72}         \n 17%|█████▌                           | 1680/10000 [6:18:17<25:50:34, 11.18s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0199888944625854, 'eval_runtime': 24.4741, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 6.72}\n 17%|█████▌                           | 1680/10000 [6:18:41<25:50:34, 11.18s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.6155, 'learning_rate': 8.326326326326327e-05, 'epoch': 6.76}         \n 17%|█████▌                           | 1690/10000 [6:20:32<25:51:15, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.49s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.03s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.976239025592804, 'eval_runtime': 24.6263, 'eval_samples_per_second': 0.812, 'eval_steps_per_second': 0.203, 'epoch': 6.76}\n 17%|█████▌                           | 1690/10000 [6:20:56<25:51:15, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:22<00:00,  4.33s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.627, 'learning_rate': 8.316316316316317e-05, 'epoch': 6.8}           \n 17%|█████▌                           | 1700/10000 [6:22:47<25:47:29, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9757863283157349, 'eval_runtime': 24.4969, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 6.8}\n 17%|█████▌                           | 1700/10000 [6:23:12<25:47:29, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!this process is not main process , do not save model.[for distributed training scenario]\n\nsave done !!!\n{'loss': 1.8782, 'learning_rate': 8.306306306306306e-05, 'epoch': 6.84}         \n 17%|█████▋                           | 1710/10000 [6:25:02<25:47:26, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.016719102859497, 'eval_runtime': 24.578, 'eval_samples_per_second': 0.814, 'eval_steps_per_second': 0.203, 'epoch': 6.84}\n 17%|█████▋                           | 1710/10000 [6:25:27<25:47:26, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.942, 'learning_rate': 8.296296296296296e-05, 'epoch': 6.88}          \n 17%|█████▋                           | 1720/10000 [6:27:18<25:58:42, 11.30s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.43s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9875646829605103, 'eval_runtime': 24.457, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 6.88}\n 17%|█████▋                           | 1720/10000 [6:27:42<25:58:42, 11.30s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.8435, 'learning_rate': 8.286286286286287e-05, 'epoch': 6.92}         \n 17%|█████▋                           | 1730/10000 [6:29:33<25:44:08, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.44s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9906173944473267, 'eval_runtime': 24.5082, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 6.92}\n 17%|█████▋                           | 1730/10000 [6:29:58<25:44:08, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!this process is not main process , do not save model.[for distributed training scenario]\n\nsave done !!!\n{'loss': 1.7284, 'learning_rate': 8.276276276276277e-05, 'epoch': 6.96}         \n 17%|█████▋                           | 1740/10000 [6:31:49<25:43:10, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0037775039672852, 'eval_runtime': 24.6136, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 6.96}\n 17%|█████▋                           | 1740/10000 [6:32:13<25:43:10, 11.21s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.897, 'learning_rate': 8.266266266266267e-05, 'epoch': 7.0}           \n 18%|█████▊                           | 1750/10000 [6:34:04<25:46:20, 11.25s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0360084772109985, 'eval_runtime': 24.4754, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 7.0}\n 18%|█████▊                           | 1750/10000 [6:34:29<25:46:20, 11.25s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.2602, 'learning_rate': 8.256256256256256e-05, 'epoch': 7.04}         \n 18%|█████▊                           | 1760/10000 [6:36:20<25:46:39, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0851771831512451, 'eval_runtime': 24.4193, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 7.04}\n 18%|█████▊                           | 1760/10000 [6:36:44<25:46:39, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.1668, 'learning_rate': 8.246246246246246e-05, 'epoch': 7.08}         \n 18%|█████▊                           | 1770/10000 [6:38:35<25:44:01, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0564978122711182, 'eval_runtime': 24.4209, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 7.08}\n 18%|█████▊                           | 1770/10000 [6:38:59<25:44:01, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.2638, 'learning_rate': 8.236236236236236e-05, 'epoch': 7.12}         \n 18%|█████▊                           | 1780/10000 [6:40:50<25:34:16, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0274107456207275, 'eval_runtime': 24.3981, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.205, 'epoch': 7.12}\n 18%|█████▊                           | 1780/10000 [6:41:14<25:34:16, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.227, 'learning_rate': 8.226226226226227e-05, 'epoch': 7.16}          \n 18%|█████▉                           | 1790/10000 [6:43:05<25:30:31, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0958800315856934, 'eval_runtime': 24.4775, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 7.16}\n 18%|█████▉                           | 1790/10000 [6:43:29<25:30:31, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.4273, 'learning_rate': 8.216216216216217e-05, 'epoch': 7.2}          \n 18%|█████▉                           | 1800/10000 [6:45:20<25:36:09, 11.24s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.1336497068405151, 'eval_runtime': 24.4981, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 7.2}\n 18%|█████▉                           | 1800/10000 [6:45:45<25:36:09, 11.24s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.506, 'learning_rate': 8.206206206206206e-05, 'epoch': 7.24}          \n 18%|█████▉                           | 1810/10000 [6:47:35<25:31:41, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  4.00s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0882148742675781, 'eval_runtime': 24.4748, 'eval_samples_per_second': 0.817, 'eval_steps_per_second': 0.204, 'epoch': 7.24}\n 18%|█████▉                           | 1810/10000 [6:48:00<25:31:41, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.1838, 'learning_rate': 8.196196196196196e-05, 'epoch': 7.28}         \n 18%|██████                           | 1820/10000 [6:49:51<25:36:02, 11.27s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.0544666051864624, 'eval_runtime': 24.4092, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 7.28}\n 18%|██████                           | 1820/10000 [6:50:15<25:36:02, 11.27s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.4092, 'learning_rate': 8.186186186186186e-05, 'epoch': 7.32}         \n 18%|██████                           | 1830/10000 [6:52:06<25:27:53, 11.22s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.44s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.47s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9183076620101929, 'eval_runtime': 24.4207, 'eval_samples_per_second': 0.819, 'eval_steps_per_second': 0.205, 'epoch': 7.32}\n 18%|██████                           | 1830/10000 [6:52:31<25:27:53, 11.22s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.4563, 'learning_rate': 8.176176176176177e-05, 'epoch': 7.36}         \n 18%|██████                           | 1840/10000 [6:54:22<25:21:39, 11.19s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.48s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.8508993983268738, 'eval_runtime': 24.4513, 'eval_samples_per_second': 0.818, 'eval_steps_per_second': 0.204, 'epoch': 7.36}\n 18%|██████                           | 1840/10000 [6:54:46<25:21:39, 11.19s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nbegin to save  !!!\nsave done !!!\n{'loss': 1.2407, 'learning_rate': 8.166166166166168e-05, 'epoch': 7.4}          \n 18%|██████                           | 1850/10000 [6:56:36<25:20:44, 11.20s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.45s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:03,  3.99s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.9357938766479492, 'eval_runtime': 24.5092, 'eval_samples_per_second': 0.816, 'eval_steps_per_second': 0.204, 'epoch': 7.4}\n 18%|██████                           | 1850/10000 [6:57:01<25:20:44, 11.20s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.31s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]begin to save  !!!\n\nsave done !!!\n{'loss': 1.4067, 'learning_rate': 8.156156156156156e-05, 'epoch': 7.44}         \n 19%|██████▏                          | 1860/10000 [6:58:52<25:27:31, 11.26s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.46s/it]\u001b[A\n 60%|███████████████████████████                  | 3/5 [00:09<00:06,  3.46s/it]\u001b[A\n 80%|████████████████████████████████████         | 4/5 [00:14<00:04,  4.01s/it]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.924467921257019, 'eval_runtime': 24.5854, 'eval_samples_per_second': 0.813, 'eval_steps_per_second': 0.203, 'epoch': 7.44}\n 19%|██████▏                          | 1860/10000 [6:59:17<25:27:31, 11.26s/it]\n100%|█████████████████████████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n                                                                                \u001b[Abegin to save  !!!\nbegin to save  !!!\nthis process is not main process , do not save model.[for distributed training scenario]\nsave done !!!\n{'loss': 1.4296, 'learning_rate': 8.146146146146146e-05, 'epoch': 7.48}         \n 19%|██████▏                          | 1870/10000 [7:01:08<25:18:49, 11.21s/it]\n  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A^C\n[2023-08-03 23:11:32,606] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 1401\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True)\ninput_ids = tokenizer(\n            \"1+2+3+4\",\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            max_length=20,\n            truncation=True,\n            add_special_tokens=False\n        ).input_ids","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:05:04.205740Z","iopub.execute_input":"2023-08-03T15:05:04.206200Z","iopub.status.idle":"2023-08-03T15:05:04.499392Z","shell.execute_reply.started":"2023-08-03T15:05:04.206163Z","shell.execute_reply":"2023-08-03T15:05:04.498342Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"input_ids.ne(0).int()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:05:34.918365Z","iopub.execute_input":"2023-08-03T15:05:34.918796Z","iopub.status.idle":"2023-08-03T15:05:34.932463Z","shell.execute_reply.started":"2023-08-03T15:05:34.918763Z","shell.execute_reply":"2023-08-03T15:05:34.931258Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]],\n       dtype=torch.int32)"},"metadata":{}}]},{"cell_type":"code","source":"a=[1,2,3,4,1]\nb=torch.Tensor(a)\nb","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:07:20.406312Z","iopub.execute_input":"2023-08-03T15:07:20.409149Z","iopub.status.idle":"2023-08-03T15:07:20.439066Z","shell.execute_reply.started":"2023-08-03T15:07:20.409111Z","shell.execute_reply":"2023-08-03T15:07:20.438060Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"tensor([1., 2., 3., 4., 1.])"},"metadata":{}}]},{"cell_type":"code","source":"b.ne(1).int()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:07:35.666478Z","iopub.execute_input":"2023-08-03T15:07:35.666896Z","iopub.status.idle":"2023-08-03T15:07:35.677545Z","shell.execute_reply.started":"2023-08-03T15:07:35.666862Z","shell.execute_reply":"2023-08-03T15:07:35.676471Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"tensor([0, 1, 1, 1, 0], dtype=torch.int32)"},"metadata":{}}]},{"cell_type":"code","source":"model.model.attentions.query_key_value.layer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sharegpt 格式数据sft后推理测试","metadata":{}},{"cell_type":"code","source":"!git pull --all --force\n#!pip install peft==0.4.0\n#!pip install  -U git+https://github.com/huggingface/peft.git\n%cd /kaggle/working/chatGLM-6B-QLoRA \n!ls\n!pip install -r requirements.txt\n#!pip install deepspeed==0.9.5  这个也是需要的 但是目前kaggle 的runtime自带了","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport argparse\nfrom typing import List, Dict, Optional\nfrom accelerate import init_empty_weights  # load an empty model,just structure , no real weight.\nimport bitsandbytes as bnb\nimport torch\nfrom glob import glob\nfrom loguru import logger\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModel,\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    HfArgumentParser,\n    set_seed,\n    TrainingArguments,\n    Trainer,\n    BitsAndBytesConfig \n)\nfrom peft import (\n    TaskType,\n    LoraConfig,\n    #AdaLoraConfig ,  #  提出自2020年 感觉和lora区别不大 而且和qlora有冲突 这里代码没有用到 \n                     #例子https://www.zhihu.com/question/596950521/answer/3109759716\n    get_peft_model,\n    set_peft_model_state_dict,\n    prepare_model_for_kbit_training\n)\nfrom peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\nfrom transformers.deepspeed import HfDeepSpeedConfig\nimport deepspeed\nimport json\nfrom itertools import chain","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:03:51.019552Z","iopub.execute_input":"2023-08-03T15:03:51.020062Z","iopub.status.idle":"2023-08-03T15:03:58.079794Z","shell.execute_reply.started":"2023-08-03T15:03:51.020008Z","shell.execute_reply":"2023-08-03T15:03:58.078773Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[2023-08-03 15:03:52,910] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 118\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu')}\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\nfrom peft import PeftModel, PeftConfig\n\n\n# 有效peft_model_path = '/kaggle/working/chatGLM-6B-QLoRA/output-sft-qlora-ds-yunguan0712-aug-v3'\n\npeft_model_path= \"/kaggle/working/chatGLM-6B-QLoRA/output-sharegpt-sft-0803-2kdata-v4/checkpoint-220\"\nconfig = PeftConfig.from_pretrained(peft_model_path)\nq_config = BitsAndBytesConfig(load_in_4bit=True,\n                              bnb_4bit_quant_type='nf4',\n                              bnb_4bit_use_double_quant=True,\n                              bnb_4bit_compute_dtype=torch.float16)\n# base_model加载时保持和train时完全一致的参数配置\nmodel = AutoModel.from_pretrained(config.base_model_name_or_path,\n                                       quantization_config=q_config,\n                                       trust_remote_code=True,\n                                       device_map='auto')\n\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n# input_text = '请你作为烽火SSE智能助手，帮我回答下面的问题。新型全电发票目前系统无法识别，要如何录入？'\n# print(f'输入：\\n{input_text}')\n#tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n\n# response, history = base_model.chat(tokenizer=tokenizer,history=[], query=input_text)\n# print(f'微调前：\\n{response}')\n\n# model = PeftModel.from_pretrained(base_model, peft_model_path)\n# response, history = model.chat(tokenizer=tokenizer, history=[] ,query=input_text)\n# print(f'微调后: \\n{response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 不加载peft 基座模型推理\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n\nprint(\"用户：你好，智能小助手\\n\")\nold_response = \"\"\nfor response, history in model.stream_chat(tokenizer, \"你好\", [], max_length=1024, \n                                           top_p=0.9, temperature=0.75,\n                                           num_beams=5):\n    print(response[len(old_response):], end=\"\")\n    old_response = response\nprint(end=\"\\r\")\n#print(1111,old_response)作为烽火智能助手，我遇到了以下故障现象，某地市某网络单盘占用槽位显示异常现场实际占用两个槽位。请给出类似案例以供参考。\n#print(\"ChatGLM2-6B：\\n\",response)\n#print(\"\\n------------------------------------------------\\n用户：\")\n#raise ValueError(123)\nline = input()\npast_key_values=None\nhistory =[]\n#prompt_format = \"[Round {}]\\n\\n问：{}\\n\\n答：\"\nwhile line:\n    if line.strip()==\"#QUIT\": # 输入#QUIT退出对话循环\n        break\n    #inst = \"我有关于烽火SSE的问题，请你作为烽火SSE智能助手，帮我回答下面的问题。\" #计算两个矩阵的乘积：\"\n    #line = PROMPT_TEMPLATE.format_map({'instruction': line})\n    if line.strip()==\"#CLEAR\" :  #清空历史对话\n        history=[]\n    #format_line = prompt_format.format(1,line)\n    #print(f\"【formatted line】={format_line}\")\n    #old_response = \"\"\n    beams =5\n    print(f\"num_beams={beams}\")\n    \n    for response, history  in model.stream_chat(tokenizer=tokenizer, \n                                               history=history ,\n                                               max_length=1024,\n                                               query=line,\n                                               top_p=0.95,temperature=0.55,\n                                               num_beams=beams,\n                                               return_past_key_values=False,\n                                               past_key_values=None):\n        #print(past_key_values) 不要打印 太长了\n        print(response[len(old_response):], end=\"\")\n        old_response = response\n    print(end=\"\\r\")\n    #print(f\"\\nold response=\\n{old_response}\")\n    #print(end=\"\\r\") # 量化后 num_beams只能=1 否则报错\n    #print(\"ChatGLM2-6B：\\n\", old_response.replace(\"\\\\n\",'\\n'))\n    #print(\"\\n------------------------------------------------\\n用户：\")\n    line = input()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PeftModel.from_pretrained(model, peft_model_path)\n\n#下面这三行貌似可以不用\n#peft_model_dict = model.state_dict()\n#peft_model_dict.update(torch.load(f\"{peft_model_path}/adapter_model.bin\"))\n#model.load_state_dict(peft_model_dict,strict=False)\n\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"我想开一辆移动餐车。我想做带有墨西哥风格影响的提升版希腊菜肴。你能为移动餐车写一个菜单吗？","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 不加载peft 基座模型推理\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n\nprint(\"用户：你好，智能小助手\\n\")\nold_response = \"\"\nfor response, history in model.stream_chat(tokenizer, \"你好\", [], max_length=1024, \n                                           top_p=0.9, temperature=0.75,\n                                           num_beams=5):\n    print(response[len(old_response):], end=\"\")\n    old_response = response\nprint(end=\"\\r\")\n#print(1111,old_response)作为烽火智能助手，我遇到了以下故障现象，某地市某网络单盘占用槽位显示异常现场实际占用两个槽位。请给出类似案例以供参考。\n#print(\"ChatGLM2-6B：\\n\",response)\n#print(\"\\n------------------------------------------------\\n用户：\")\n#raise ValueError(123)\nline = input()\npast_key_values=None\nhistory =[]\n#prompt_format = \"[Round {}]\\n\\n问：{}\\n\\n答：\"\nwhile line:\n    if line.strip()==\"#QUIT\": # 输入#QUIT退出对话循环\n        break\n    #inst = \"我有关于烽火SSE的问题，请你作为烽火SSE智能助手，帮我回答下面的问题。\" #计算两个矩阵的乘积：\"\n    #line = PROMPT_TEMPLATE.format_map({'instruction': line})\n    if line.strip()==\"#CLEAR\" :  #清空历史对话\n        history=[]\n    #format_line = prompt_format.format(1,line)\n    #print(f\"【formatted line】={format_line}\")\n    #old_response = \"\"\n    beams =5\n    print(f\"num_beams={beams}\")\n    \n    for response, history  in model.stream_chat(tokenizer=tokenizer, \n                                               history=history ,\n                                               max_length=1024,\n                                               query=line,\n                                               top_p=0.95,temperature=0.55,\n                                               num_beams=beams,\n                                               return_past_key_values=False,\n                                               past_key_values=None):\n        #print(past_key_values) 不要打印 太长了\n        print(response[len(old_response):], end=\"\")\n        old_response = response\n    print(end=\"\\r\")\n    #print(f\"\\nold response=\\n{old_response}\")\n    #print(end=\"\\r\") # 量化后 num_beams只能=1 否则报错\n    #print(\"ChatGLM2-6B：\\n\", old_response.replace(\"\\\\n\",'\\n'))\n    #print(\"\\n------------------------------------------------\\n用户：\")\n    line = input()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color= brown>SFT 测试history格式的多轮对话数据 注意--data_type 为history</font>","metadata":{}},{"cell_type":"code","source":"# ./data/sharegpt_multi_turn_data 目录不能有空白json文件\n!git pull --all --force \n#!pip install  -U git+https://github.com/huggingface/peft.git   # 20230717 peft==0.4.0正式发布了 不用调版本了推理完后再训练需要重新升级到0.4.0dev 所以有这句\n!deepspeed --include localhost:0,1  sft_multi_turn_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-history-sft-0803-v1 \\\n  --num_train_samples -1 \\\n  --num_eval_samples -1 \\\n  --train_data_path ./data/multi_turn_conversations/   \\\n  --eval_data_path  ./data/multi_turn_conversations    \\\n  --data_type history  \\\n  --max_length 1600 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 1 \\\n  --per_device_eval_batch_size 1  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  5e-5 \\\n  --num_train_epochs  40  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# history格式数据sft后的推理测试","metadata":{}},{"cell_type":"code","source":"import os\nimport argparse\nfrom typing import List, Dict, Optional\nfrom accelerate import init_empty_weights  # load an empty model,just structure , no real weight.\nimport bitsandbytes as bnb\nimport torch\nfrom glob import glob\nfrom loguru import logger\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModel,\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    HfArgumentParser,\n    set_seed,\n    TrainingArguments,\n    Trainer,\n    BitsAndBytesConfig \n)\nfrom peft import (\n    TaskType,\n    LoraConfig,\n    #AdaLoraConfig ,  #  提出自2020年 感觉和lora区别不大 而且和qlora有冲突 这里代码没有用到 \n                     #例子https://www.zhihu.com/question/596950521/answer/3109759716\n    get_peft_model,\n    set_peft_model_state_dict,\n    prepare_model_for_kbit_training\n)\nfrom peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\nfrom transformers.deepspeed import HfDeepSpeedConfig\nimport deepspeed\nimport json\nfrom itertools import chain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 加载基座模型 注意qconfig","metadata":{}},{"cell_type":"code","source":"\nimport torch\nfrom transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\nfrom peft import PeftModel, PeftConfig\n\n\n# 有效peft_model_path = '/kaggle/working/chatGLM-6B-QLoRA/output-sft-qlora-ds-yunguan0712-aug-v3'\n\npeft_model_path= \"./output-history-sft-0803-v1\"\nconfig = PeftConfig.from_pretrained(peft_model_path)\nq_config = BitsAndBytesConfig(load_in_4bit=True,\n                              bnb_4bit_quant_type='nf4',\n                              bnb_4bit_use_double_quant=True,\n                              bnb_4bit_compute_dtype=torch.float16)\n# base_model加载时保持和train时完全一致的参数配置\nbase_model = AutoModel.from_pretrained(config.base_model_name_or_path,\n                                       quantization_config=q_config,\n                                       trust_remote_code=True,\n                                       device_map='auto')\n\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n# input_text = '请你作为烽火SSE智能助手，帮我回答下面的问题。新型全电发票目前系统无法识别，要如何录入？'\n# print(f'输入：\\n{input_text}')\n#tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n\n# response, history = base_model.chat(tokenizer=tokenizer,history=[], query=input_text)\n# print(f'微调前：\\n{response}')\n\n# model = PeftModel.from_pretrained(base_model, peft_model_path)\n# response, history = model.chat(tokenizer=tokenizer, history=[] ,query=input_text)\n# print(f'微调后: \\n{response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"用户：你好，智能小助手\\n\")\nold_response = \"\"\nfor response, history in base_model.stream_chat(tokenizer, \"你好\", [], max_length=1024, \n                                           top_p=0.7, temperature=0.95,\n                                           num_beams=2):\n    print(response[len(old_response):], end=\"\")\n    old_response = response\nprint(end=\"\\r\")\n#print(1111,old_response)\n#print(\"ChatGLM2-6B：\\n\",response)\n#print(\"\\n------------------------------------------------\\n用户：\")\n#raise ValueError(123)\nline = input()\nwhile line:\n    if line.strip()==\"#QUIT\": # 输入#QUIT退出对话循环\n        break\n    #inst = \"我有关于烽火SSE的问题，请你作为烽火SSE智能助手，帮我回答下面的问题。\" #计算两个矩阵的乘积：\"\n    #line = PROMPT_TEMPLATE.format_map({'instruction': line})\n    if line.strip()==\"#CLEAR\" :  #清空历史对话\n        history=[]\n    #line = inst  + line\n    print(f\"【formatted line】={line}\")\n    old_response = \"\"\n    num_beams = 2\n    print(f\"num_beams={num_beams}\")\n    for response, history in base_model.stream_chat(tokenizer=tokenizer, \n                                               history=history ,\n                                               max_length=1024,\n                                               query=line,\n                                               top_p=0.95,temperature=0.55,\n                                               num_beams=num_beams):\n        print(response[len(old_response):], end=\"\")\n        old_response = response\n    print(end=\"\\r\")\n    print(f\"\\nold response=\\n{old_response}\")\n    print(end=\"\\r\") # 量化后 num_beams只能=1 否则报错\n    print(\"ChatGLM2-6B：\\n\", old_response.replace(\"\\\\n\",'\\n'))\n    print(\"\\n------------------------------------------------\\n用户：\")\n    line = input()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 上面的测试中 使用基座模型 看得出 回答确实跟语料的内容没关系 毕竟没有经过私有语料训练\n# 我们再看看经过训练后的模型回答","metadata":{}},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(base_model, peft_model_path)\n\n#下面这三行貌似可以不用\n#peft_model_dict = model.state_dict()\n#peft_model_dict.update(torch.load(f\"{peft_model_path}/adapter_model.bin\"))\n#model.load_state_dict(peft_model_dict,strict=False)\n\npeft_model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 查看一下layer weight\nprint(model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight)\nprint(model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_B.default.weight)","metadata":{}},{"cell_type":"markdown","source":"# qkv\nprint(model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.weight)\n# dense layer\nprint(model.base_model.model.transformer.encoder.layers[27].self_attention.dense.weight)\n# core attention\nprint(model.base_model.model.transformer.encoder.layers[27].self_attention.core_attention)","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 私有对话语料SFT后的推理 感觉好像因为语料太少 没学会什么东西","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n\nprint(\"用户：你好，智能小助手\\n\")\nold_response = \"\"\nfor response, history in peft_model.stream_chat(tokenizer, \"你好\", [], max_length=1024, \n                                           top_p=0.7, temperature=0.95,\n                                           num_beams=5):\n    print(response[len(old_response):], end=\"\")\n    old_response = response\nprint(end=\"\\r\")\n#print(1111,old_response)作为烽火智能助手，我遇到了以下故障现象，某地市某网络单盘占用槽位显示异常现场实际占用两个槽位。请给出类似案例以供参考。\n#print(\"ChatGLM2-6B：\\n\",response)\n#print(\"\\n------------------------------------------------\\n用户：\")\n#raise ValueError(123)\nline = input()\npast_key_values=None\nhistory =[]\nprompt_format = \"[Round {}]\\n\\n问：{}\\n\\n答：\"\nwhile line:\n    if line.strip()==\"#QUIT\": # 输入#QUIT退出对话循环\n        break\n    #inst = \"我有关于烽火SSE的问题，请你作为烽火SSE智能助手，帮我回答下面的问题。\" #计算两个矩阵的乘积：\"\n    #line = PROMPT_TEMPLATE.format_map({'instruction': line})\n    if line.strip()==\"#CLEAR\" :  #清空历史对话\n        history=[]\n    format_line = prompt_format.format(1,line)\n    print(f\"【formatted line】={format_line}\")\n    #old_response = \"\"\n    beams =2\n    print(f\"num_beams={beams}\")\n    \n    for response, history ,past_key_values in peft_model.stream_chat(tokenizer=tokenizer, \n                                               history=history ,\n                                               max_length=512,\n                                               query=format_line,\n                                               top_p=0.95,temperature=0.75,\n                                               num_beams=1,\n                                               return_past_key_values=True,\n                                               past_key_values=past_key_values):\n        #print(past_key_values) 不要打印 太长了\n        print(response[len(old_response):], end=\"\")\n        old_response = response\n    print(end=\"\\r\")\n    print(f\"\\nold response=\\n{old_response}\")\n    print(end=\"\\r\") # 量化后 num_beams只能=1 否则报错\n    print(\"ChatGLM2-6B：\\n\", old_response.replace(\"\\\\n\",'\\n'))\n    print(\"\\n------------------------------------------------\\n用户：\")\n    line = input()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_format = \"[Round {}]\\n\\n问：{}\\n\\n答：\"\nline = \"吃饭了吗\"\nprompt_format.format(1,line)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}