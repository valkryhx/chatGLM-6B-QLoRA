{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/\n!git clone https://github.com/valkryhx/chatGLM-6B-QLoRA","metadata":{"execution":{"iopub.status.busy":"2023-08-14T07:55:01.910253Z","iopub.execute_input":"2023-08-14T07:55:01.910665Z","iopub.status.idle":"2023-08-14T07:55:02.925821Z","shell.execute_reply.started":"2023-08-14T07:55:01.910627Z","shell.execute_reply":"2023-08-14T07:55:02.924481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\na=[i for i in range(24)]\nta=torch.tensor(a)\nta=ta.view(2,3,4)\nta","metadata":{"execution":{"iopub.status.busy":"2023-08-14T11:07:28.060674Z","iopub.execute_input":"2023-08-14T11:07:28.061103Z","iopub.status.idle":"2023-08-14T11:07:29.604758Z","shell.execute_reply.started":"2023-08-14T11:07:28.061066Z","shell.execute_reply":"2023-08-14T11:07:29.603689Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]])"},"metadata":{}}]},{"cell_type":"code","source":"ta[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-08-14T11:07:41.295222Z","iopub.execute_input":"2023-08-14T11:07:41.295859Z","iopub.status.idle":"2023-08-14T11:07:41.326011Z","shell.execute_reply.started":"2023-08-14T11:07:41.295823Z","shell.execute_reply":"2023-08-14T11:07:41.325083Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"tensor([[ 8,  9, 10, 11],\n        [20, 21, 22, 23]])"},"metadata":{}}]},{"cell_type":"code","source":"ta[:,-1].split(1,dim=0)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T11:08:49.440372Z","iopub.execute_input":"2023-08-14T11:08:49.440825Z","iopub.status.idle":"2023-08-14T11:08:49.454434Z","shell.execute_reply.started":"2023-08-14T11:08:49.440787Z","shell.execute_reply":"2023-08-14T11:08:49.453262Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 8,  9, 10, 11]]), tensor([[20, 21, 22, 23]]))"},"metadata":{}}]},{"cell_type":"code","source":"x,y=ta[-1].split(1,dim=0)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T11:09:49.154281Z","iopub.execute_input":"2023-08-14T11:09:49.154639Z","iopub.status.idle":"2023-08-14T11:09:49.627434Z","shell.execute_reply.started":"2023-08-14T11:09:49.154610Z","shell.execute_reply":"2023-08-14T11:09:49.625913Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x,y\u001b[38;5;241m=\u001b[39mta[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m1\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}]},{"cell_type":"code","source":"#cat /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0812-v1/checkpoint-40/adapter_config.json","metadata":{"execution":{"iopub.status.busy":"2023-08-12T05:52:59.477242Z","iopub.execute_input":"2023-08-12T05:52:59.477619Z","iopub.status.idle":"2023-08-12T05:52:59.482401Z","shell.execute_reply.started":"2023-08-12T05:52:59.477585Z","shell.execute_reply":"2023-08-12T05:52:59.481200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd chatGLM-6B-QLoRA\n!git pull --all --force \n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-08-14T11:25:37.435851Z","iopub.execute_input":"2023-08-14T11:25:37.436245Z","iopub.status.idle":"2023-08-14T11:26:20.395433Z","shell.execute_reply.started":"2023-08-14T11:25:37.436213Z","shell.execute_reply":"2023-08-14T11:26:20.394131Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working/chatGLM-6B-QLoRA\nFetching origin\nremote: Enumerating objects: 9, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (6/6), done.\u001b[K\nremote: Total 6 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (6/6), 1.67 KiB | 285.00 KiB/s, done.\nFrom https://github.com/valkryhx/chatGLM-6B-QLoRA\n   ae1bef3..5340192  main       -> origin/main\nUpdating ae1bef3..5340192\nFast-forward\n ppo_chatglm2.py | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n rm_3.py         | 7 \u001b[32m++++++\u001b[m\u001b[31m-\u001b[m\n 2 files changed, 9 insertions(+), 4 deletions(-)\nCollecting peft==0.4.0 (from -r requirements.txt (line 1))\n  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers==4.30.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.30.2)\nCollecting datasets==2.12.0 (from -r requirements.txt (line 3))\n  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm==4.65.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.65.0)\nCollecting loguru==0.7.0 (from -r requirements.txt (line 5))\n  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fire==0.5.0 (from -r requirements.txt (line 6))\n  Downloading fire-0.5.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bitsandbytes==0.39.0 (from -r requirements.txt (line 7))\n  Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting wandb==0.15.3 (from -r requirements.txt (line 8))\n  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cpm_kernels==1.0.11 (from -r requirements.txt (line 9))\n  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate==0.20.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.20.3)\nRequirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.99)\nCollecting deepspeed==0.9.5 (from -r requirements.txt (line 12))\n  Downloading deepspeed-0.9.5.tar.gz (809 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.9/809.9 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate==0.4.0 (from -r requirements.txt (line 13))\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting trl==0.5.0 (from -r requirements.txt (line 14))\n  Downloading trl-0.5.0-py3-none-any.whl (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 1)) (0.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2->-r requirements.txt (line 2)) (0.13.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.12.0->-r requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.1.31)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.15.3->-r requirements.txt (line 8)) (3.20.3)\nCollecting hjson (from deepspeed==0.9.5->-r requirements.txt (line 12))\n  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.11.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (9.0.0)\nRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->-r requirements.txt (line 12)) (1.10.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.12.0->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (4.0.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2->-r requirements.txt (line 2)) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 2)) (2023.5.7)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.12.0->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 8)) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 1)) (1.3.0)\nBuilding wheels for collected packages: fire, deepspeed\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=e52e3b7a9050b2d8f1a89687676f3ff3e74c3fd5d60f552d17452ecaf9cd8493\n  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.9.5-py3-none-any.whl size=844548 sha256=2f3af6426bc564e9dfbed1a334e160fb741526e459297f46c37631b66faca4ef\n  Stored in directory: /root/.cache/pip/wheels/7e/a9/bb/a00d383521da14dc91b65ae2d0062401b750d968a548401b2a\nSuccessfully built fire deepspeed\nInstalling collected packages: hjson, cpm_kernels, bitsandbytes, loguru, fire, wandb, deepspeed, peft, datasets, trl, evaluate\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.15.5\n    Uninstalling wandb-0.15.5:\n      Successfully uninstalled wandb-0.15.5\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed bitsandbytes-0.39.0 cpm_kernels-1.0.11 datasets-2.12.0 deepspeed-0.9.5 evaluate-0.4.0 fire-0.5.0 hjson-3.1.0 loguru-0.7.0 peft-0.4.0 trl-0.5.0 wandb-0.15.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"cat /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0811-v3/config.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git pull --all --force\n!CUDA_VISIBLE_DEVICES=0 python  rm_trl.py \\\n--model_name 'THUDM/chatglm2-6b' \\\n--resume_from_checkpoint /kaggle/working/chatGLM-6B-QLoRA/reward_model_0809_v1/checkpoint-50 \\\n--num_train_epochs 2 \\\n--gradient_accumulation_steps 1 \\\n--per_device_train_batch_size 4 \\\n--per_device_eval_batch_size  4 \\\n--max_length 512 \\\n--output_dir ./reward_model_0810_v2 \\\n--train_subset 80 \\\n--eval_subset 20 \\\n--local_rank 0  \\\n--bf16 False","metadata":{"execution":{"iopub.status.busy":"2023-08-10T15:36:48.134969Z","iopub.execute_input":"2023-08-10T15:36:48.135458Z","iopub.status.idle":"2023-08-10T15:40:03.300811Z","shell.execute_reply.started":"2023-08-10T15:36:48.135418Z","shell.execute_reply":"2023-08-10T15:40:03.299460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 上面的warning There were missing keys in the checkpoint model loaded: 'transformer.embedding.word_embeddings.weight', 'transformer.rotary_pos_emb.inv_freq', 'transformer.encoder.layers.0.input_layernorm.weight', ....\n# 是 trainingArguments中设置 load_best_model_at_end = True 后出现的\n# 说明 trainer的确在最后把最好的那个adapters的参数做了load（只不过load时strict=True要求严格匹配了）\n# 这说明保存在output_dir中的pytorch_model.bin和vhead.bin参数都是最佳的 我们来验证下","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:20:02.990258Z","iopub.execute_input":"2023-08-11T13:20:02.990655Z","iopub.status.idle":"2023-08-11T13:20:04.059182Z","shell.execute_reply.started":"2023-08-11T13:20:02.990619Z","shell.execute_reply":"2023-08-11T13:20:04.057829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"验证成功  跑的是py中的test_load_best()\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# deepspeed 单机多卡从头训练 reward model","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!deepspeed --include localhost:0,1  rewardmodel_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0811-v2 \\\n  --num_train_samples 200 \\\n  --num_eval_samples 100 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 4 \\\n  --per_device_eval_batch_size 4  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  2  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T12:40:22.920460Z","iopub.execute_input":"2023-08-11T12:40:22.920924Z","iopub.status.idle":"2023-08-11T13:06:52.328475Z","shell.execute_reply.started":"2023-08-11T12:40:22.920884Z","shell.execute_reply":"2023-08-11T13:06:52.327240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--deepspeed ds_zero2_config.json","metadata":{}},{"cell_type":"markdown","source":"# 单机多卡deepspeed 从ckpt继续训练 ","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!deepspeed --include localhost:0,1  rewardmodel_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0811-v3 \\\n  --resume_from_checkpoint output-rm-1k-0811-v2 \\\n  --num_train_samples 200 \\\n  --num_eval_samples 100 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 4 \\\n  --per_device_eval_batch_size 4  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  2  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \\\n--deepspeed ds_zero2_config.json","metadata":{"execution":{"iopub.status.busy":"2023-08-11T14:16:06.760852Z","iopub.execute_input":"2023-08-11T14:16:06.761319Z","iopub.status.idle":"2023-08-11T14:42:34.756018Z","shell.execute_reply.started":"2023-08-11T14:16:06.761278Z","shell.execute_reply":"2023-08-11T14:42:34.754676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -lrt /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0811-v3","metadata":{"execution":{"iopub.status.busy":"2023-08-11T14:43:55.710087Z","iopub.execute_input":"2023-08-11T14:43:55.710535Z","iopub.status.idle":"2023-08-11T14:43:56.997109Z","shell.execute_reply.started":"2023-08-11T14:43:55.710495Z","shell.execute_reply":"2023-08-11T14:43:56.995800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 单卡训练 reward model","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!CUDA_VISIBLE_DEVICES=0 python  rewardmodel_qlora_chatglm2.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0811-v1 \\\n  --num_train_samples 20 \\\n  --num_eval_samples 20 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 800 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 4 \\\n  --per_device_eval_batch_size 4  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  10  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git pull --all --force \n!CUDA_VISIBLE_DEVICES=0 python  rm_3.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0812-v1 \\\n  --num_train_samples 50 \\\n  --num_eval_samples 50 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 500 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 1 \\\n  --per_device_eval_batch_size 1  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  4  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rm -rf output-rm-1k-0812-v1","metadata":{"execution":{"iopub.status.busy":"2023-08-11T18:27:14.344853Z","iopub.execute_input":"2023-08-11T18:27:14.345318Z","iopub.status.idle":"2023-08-11T18:27:15.559789Z","shell.execute_reply.started":"2023-08-11T18:27:14.345279Z","shell.execute_reply":"2023-08-11T18:27:15.558472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"参考 https://github.com/hiyouga/ChatGLM-Efficient-Tuning/blob/main/src/glmtuner/tuner/core/adapter.py#L83\n实现 resume——from --checkpoint\n\n参考","metadata":{}},{"cell_type":"code","source":"https://huggingface.co/docs/trl/models#trl.AutoModelForCausalLMWithValueHead\n    https://github.com/yongzhuo/chatglm-maths/blob/main/chatglm_maths/t10_lora_trl_train_ppo.py#L175\n        https://huggingface.co/docs/trl/v0.5.0/en/customization#use-the-cuda-cache-optimizer\n            https://huggingface.co/docs/trl/trainer#trl.RewardTrainer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# python 【rm_3.py】 单卡训练 从头开始","metadata":{}},{"cell_type":"code","source":"!git pull --all --force \n!CUDA_VISIBLE_DEVICES=0 python  rm_3.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --output_dir output-rm-1k-0813-v1 \\\n  --num_train_samples 20 \\\n  --num_eval_samples 20 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 400 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 1  \\\n  --gradient_accumulation_steps 1 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  4  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True ","metadata":{"execution":{"iopub.status.busy":"2023-08-14T03:57:22.584752Z","iopub.execute_input":"2023-08-14T03:57:22.585176Z","iopub.status.idle":"2023-08-14T04:05:51.055637Z","shell.execute_reply.started":"2023-08-14T03:57:22.585141Z","shell.execute_reply":"2023-08-14T04:05:51.054256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# deepspeed train 【rm_3.py】恢复训练 \n#  batach_size 2  gradient accumulation steps 4","metadata":{}},{"cell_type":"code","source":"rm -rf output-rm-1k-0812-v2","metadata":{"execution":{"iopub.status.busy":"2023-08-14T12:30:13.281418Z","iopub.execute_input":"2023-08-14T12:30:13.281990Z","iopub.status.idle":"2023-08-14T12:30:14.257333Z","shell.execute_reply.started":"2023-08-14T12:30:13.281950Z","shell.execute_reply":"2023-08-14T12:30:14.255927Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"--resume_from_checkpoint output-rm-1k-0812-v1/checkpoint-60 \\","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git pull --all --force \n!deepspeed --include localhost:0,1   rm_3.py  \\\n  --train_args_json luzi.json \\\n  --model_name_or_path THUDM/chatglm2-6b \\\n  --resume_from_checkpoint output-rm-1k-0812-v2 \\\n  --output_dir output-rm-1k-0812-v3 \\\n  --num_train_samples 100 \\\n  --num_eval_samples 50 \\\n  --train_data_path ./data/rm_data  \\\n  --eval_data_path  ./data/rm_data    \\\n  --data_type sharegpt  \\\n  --max_length 400 \\\n  --lora_rank 64 \\\n  --lora_dropout 0.05 \\\n  --compute_dtype fp16 \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 2  \\\n  --gradient_accumulation_steps 4 \\\n  --learning_rate  2e-5 \\\n  --num_train_epochs  8  \\\n  --save_total_limit 2 \\\n  --load_in_4bit True ","metadata":{"execution":{"iopub.status.busy":"2023-08-14T12:49:25.617375Z","iopub.execute_input":"2023-08-14T12:49:25.618519Z","iopub.status.idle":"2023-08-14T13:11:21.607952Z","shell.execute_reply.started":"2023-08-14T12:49:25.618473Z","shell.execute_reply":"2023-08-14T13:11:21.606441Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Fetching origin\nremote: Enumerating objects: 11, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (9/9), done.\u001b[K\nremote: Total 9 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (9/9), 1.93 KiB | 152.00 KiB/s, done.\nFrom https://github.com/valkryhx/chatGLM-6B-QLoRA\n   7f84c1a..10b5810  main       -> origin/main\nUpdating 7f84c1a..10b5810\nFast-forward\n rm_3.py | 10 \u001b[32m+++++\u001b[m\u001b[31m-----\u001b[m\n 1 file changed, 5 insertions(+), 5 deletions(-)\n[2023-08-14 12:49:32,249] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n[2023-08-14 12:49:46,920] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n[2023-08-14 12:49:46,937] [INFO] [runner.py:555:main] cmd = /opt/conda/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None rm_3.py --train_args_json luzi.json --model_name_or_path THUDM/chatglm2-6b --resume_from_checkpoint output-rm-1k-0812-v2 --output_dir output-rm-1k-0812-v3 --num_train_samples 100 --num_eval_samples 50 --train_data_path ./data/rm_data --eval_data_path ./data/rm_data --data_type sharegpt --max_length 400 --lora_rank 64 --lora_dropout 0.05 --compute_dtype fp16 --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --gradient_accumulation_steps 4 --learning_rate 2e-5 --num_train_epochs 8 --save_total_limit 2 --load_in_4bit True\n[2023-08-14 12:49:48,709] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n[2023-08-14 12:49:54,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n[2023-08-14 12:49:54,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n[2023-08-14 12:49:54,794] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n[2023-08-14 12:49:54,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n[2023-08-14 12:49:54,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n[2023-08-14 12:49:54,795] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n[2023-08-14 12:49:54,795] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n[2023-08-14 12:49:54,795] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1]}\n[2023-08-14 12:49:54,795] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0\n[2023-08-14 12:49:54,795] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n[2023-08-14 12:49:54,795] [INFO] [launch.py:163:main] dist_world_size=2\n[2023-08-14 12:49:54,795] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n[2023-08-14 12:50:03,419] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2023-08-14 12:50:03,494] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================ and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n\n================================================================================\nbin bin/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so \n/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n\u001b[32m2023-08-14 12:50:09.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1346\u001b[0m - \u001b[1mloading parameters...\u001b[0m\n\u001b[32m2023-08-14 12:50:09.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1346\u001b[0m - \u001b[1mloading parameters...\u001b[0m\n\u001b[32m2023-08-14 12:50:10.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mloading dataset...\u001b[0m\n\u001b[32m2023-08-14 12:50:10.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mdata files: ./data/rm_data/samples_1k.jsonl\u001b[0m\n\u001b[32m2023-08-14 12:50:10.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mloading dataset...\u001b[0m\n\u001b[32m2023-08-14 12:50:10.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mdata files: ./data/rm_data/samples_1k.jsonl\u001b[0m\n100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 66.58it/s]\n\u001b[32m2023-08-14 12:50:10.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m612\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-14 12:50:10.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1m在取样之后 data len =100\u001b[0m\n\u001b[32m2023-08-14 12:50:10.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 455.61it/s]\n\u001b[32m2023-08-14 12:50:10.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m612\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-14 12:50:10.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1m在取样之后 data len =100\u001b[0m\n\u001b[32m2023-08-14 12:50:10.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\n\u001b[32m2023-08-14 12:50:11.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mdata files: ./data/rm_data/samples_1k.jsonl\u001b[0m\n\u001b[32m2023-08-14 12:50:11.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mdata files: ./data/rm_data/samples_1k.jsonl\u001b[0m\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 677.27it/s]\n\u001b[32m2023-08-14 12:50:11.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m612\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-14 12:50:11.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1m在取样之后 data len =50\u001b[0m\n\u001b[32m2023-08-14 12:50:11.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\nnumber_train_samples=100\nnumber_of_eval_samples=50\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 742.75it/s]\n\u001b[32m2023-08-14 12:50:11.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m612\u001b[0m - \u001b[1m在取样之前 data len =1000\u001b[0m\n\u001b[32m2023-08-14 12:50:11.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1m在取样之后 data len =50\u001b[0m\n\u001b[32m2023-08-14 12:50:11.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rm_datset\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mpreprocessing dataset...\u001b[0m\nnumber_train_samples=100\nnumber_of_eval_samples=50\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:38<00:00, 14.10s/it]\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:38<00:00, 14.10s/it]\nmemory footprint of model: 3.6520424485206604 GB\n\u001b[32m2023-08-14 12:51:51.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1503\u001b[0m - \u001b[1mprepare_model_for_kbit_training...\u001b[0m\nmemory footprint of model: 3.6520424485206604 GB\n\u001b[32m2023-08-14 12:51:51.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1503\u001b[0m - \u001b[1mprepare_model_for_kbit_training...\u001b[0m\nbelow trainable paramters only contains peft lora params.\ntrainable params: 118,587,392 || all params: 3,506,898,944 || trainable%: 3.381545744364626\nbelow trainable paramters only contains peft lora params.\ntrainable params: 118,587,392 || all params: 3,506,898,944 || trainable%: 3.381545744364626\n\u001b[32m2023-08-14 12:53:35.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1544\u001b[0m - \u001b[1madapter_weights.keys()=dict_keys(['base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_B.weight'])\u001b[0m\n\u001b[32m2023-08-14 12:53:35.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1544\u001b[0m - \u001b[1madapter_weights.keys()=dict_keys(['base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_B.weight'])\u001b[0m\nbefore load model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight=Parameter containing:\ntensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0095],\n        [-0.0082, -0.0100,  0.0104,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]],\n       device='cuda:1', requires_grad=True)before load model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight=Parameter containing:\ntensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0095],\n        [-0.0082, -0.0100,  0.0104,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]],\n       device='cuda:0', requires_grad=True)\n\nbefore load model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.weight=Parameter containing:\nParameter(Params4bit([[115],\n            [214],\n            [ 49],\n            ...,\n            [100],\n            [152],\n            [ 85]], device='cuda:0', dtype=torch.uint8))before load model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.weight=Parameter containing:\nParameter(Params4bit([[115],\n            [214],\n            [ 49],\n            ...,\n            [100],\n            [152],\n            [ 85]], device='cuda:1', dtype=torch.uint8))\n\nbefore load model.base_model.model.transformer.encoder.layers[27].self_attention.dense.weight=Parameter containing:\nParameter(Params4bit([[ 87],\n            [150],\n            [180],\n            ...,\n            [150],\n            [ 58],\n            [ 89]], device='cuda:1', dtype=torch.uint8))\nbefore load model.base_model.model.transformer.encoder.layers[27].self_attention.dense.weight=Parameter containing:\nParameter(Params4bit([[ 87],\n            [150],\n            [180],\n            ...,\n            [150],\n            [ 58],\n            [ 89]], device='cuda:0', dtype=torch.uint8))\nadapters_weigth:base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.weight=tensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0096],\n        [-0.0082, -0.0100,  0.0105,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]])adapters_weigth:base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.weight=tensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0096],\n        [-0.0082, -0.0100,  0.0105,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]])\n\nAfter load model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight=Parameter containing:\ntensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0096],\n        [-0.0082, -0.0100,  0.0105,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]],\n       device='cuda:1', requires_grad=True)\n\u001b[32m2023-08-14 12:53:36.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1559\u001b[0m - \u001b[31m\u001b[1mlora model complete\u001b[0m\nAfter load model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight=Parameter containing:\ntensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0096],\n        [-0.0082, -0.0100,  0.0105,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]],\n       device='cuda:0', requires_grad=True)\n\u001b[32m2023-08-14 12:53:36.174\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1559\u001b[0m - \u001b[31m\u001b[1mlora model complete\u001b[0m\nbefore load model.v_head.summary.weight=Parameter containing:\ntensor([[ 0.0090,  0.0039,  0.0154,  ..., -0.0065,  0.0088,  0.0089]],\n       device='cuda:1', requires_grad=True)before load model.v_head.summary.weight=Parameter containing:\ntensor([[ 0.0090,  0.0039,  0.0154,  ..., -0.0065,  0.0088,  0.0089]],\n       device='cuda:0', requires_grad=True)\n\nbefore load model.v_head.summary.bias=Parameter containing:\ntensor([0.0048], device='cuda:0', requires_grad=True)\nbefore load model.v_head.summary.bias=Parameter containing:\ntensor([0.0048], device='cuda:1', requires_grad=True)\n\u001b[32m2023-08-14 12:53:36.198\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1568\u001b[0m - \u001b[31m\u001b[1mv_head_weights={'summary.weight': tensor([[ 0.0090,  0.0039,  0.0154,  ..., -0.0065,  0.0088,  0.0089]]), 'summary.bias': tensor([0.0048])}\u001b[0m\n\u001b[32m2023-08-14 12:53:36.198\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1568\u001b[0m - \u001b[31m\u001b[1mv_head_weights={'summary.weight': tensor([[ 0.0090,  0.0039,  0.0154,  ..., -0.0065,  0.0088,  0.0089]]), 'summary.bias': tensor([0.0048])}\u001b[0m\nafter load model.pretrained_model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight=Parameter containing:\ntensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0096],\n        [-0.0082, -0.0100,  0.0105,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]],\n       device='cuda:0', requires_grad=True)\nafter load model.pretrained_model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.lora_A.default.weight=Parameter containing:\ntensor([[-0.0138,  0.0060,  0.0104,  ..., -0.0021,  0.0138, -0.0025],\n        [ 0.0086, -0.0063,  0.0156,  ..., -0.0151, -0.0130,  0.0096],\n        [-0.0082, -0.0100,  0.0105,  ..., -0.0017,  0.0141,  0.0023],\n        ...,\n        [-0.0139,  0.0006, -0.0147,  ..., -0.0025, -0.0010, -0.0067],\n        [-0.0144,  0.0014, -0.0067,  ...,  0.0120, -0.0013, -0.0006],\n        [-0.0054, -0.0127, -0.0020,  ..., -0.0086,  0.0132, -0.0045]],\n       device='cuda:1', requires_grad=True)\nafter load model.pretrained_model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.weight=Parameter containing:\nParameter(Params4bit([[115],\n            [214],\n            [ 49],\n            ...,\n            [100],\n            [152],\n            [ 85]], device='cuda:0', dtype=torch.uint8))\nafter load model.pretrained_model.base_model.model.transformer.encoder.layers[27].self_attention.query_key_value.weight=Parameter containing:\nParameter(Params4bit([[115],\n            [214],\n            [ 49],\n            ...,\n            [100],\n            [152],\n            [ 85]], device='cuda:1', dtype=torch.uint8))\nafter laod model.pretrained_model.base_model.model.transformer.encoder.layers[27].self_attention.dense.weight=Parameter containing:\nParameter(Params4bit([[ 87],\n            [150],\n            [180],\n            ...,\n            [150],\n            [ 58],\n            [ 89]], device='cuda:0', dtype=torch.uint8))\nafter laod model.pretrained_model.base_model.model.transformer.encoder.layers[27].self_attention.dense.weight=Parameter containing:\nParameter(Params4bit([[ 87],\n            [150],\n            [180],\n            ...,\n            [150],\n            [ 58],\n            [ 89]], device='cuda:1', dtype=torch.uint8))\nafter load model.v_head.summary.weight=Parameter containing:\ntensor([[ 0.0090,  0.0039,  0.0154,  ..., -0.0065,  0.0088,  0.0089]],\n       device='cuda:0', requires_grad=True)\nafter load model.v_head.summary.bias=Parameter containing:\ntensor([0.0048], device='cuda:0', requires_grad=True)\n\u001b[32m2023-08-14 12:53:36.206\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1585\u001b[0m - \u001b[31m\u001b[1mreward model with vhead complete\u001b[0m\nafter load model.v_head.summary.weight=Parameter containing:\ntensor([[ 0.0090,  0.0039,  0.0154,  ..., -0.0065,  0.0088,  0.0089]],\n       device='cuda:1', requires_grad=True)\nafter load model.v_head.summary.bias=Parameter containing:\ntensor([0.0048], device='cuda:1', requires_grad=True)\n\u001b[32m2023-08-14 12:53:36.207\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain2\u001b[0m:\u001b[36m1585\u001b[0m - \u001b[31m\u001b[1mreward model with vhead complete\u001b[0m\nbelow trainable params include v_head\nbelow trainable params include v_head\ntrainable params: 118591489 || all params: 3506903041 || trainable%: 3.3817\nFinished loading model/lora_adapter/value_head and tokenizer\ntrainable params: 118591489 || all params: 3506903041 || trainable%: 3.3817\nFinished loading model/lora_adapter/value_head and tokenizer\nTrainingArguments(\n_n_gpu=1,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=False,\nddp_timeout=1800,\ndebug=[],\ndeepspeed={'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': False}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'pin_memory': False}, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000.0, 'stage3_max_reuse_distance': 1000000.0, 'stage3_gather_16bit_weights_on_model_save': False}, 'train_batch_size': 8, 'train_micro_batch_size_per_gpu': 4},\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=10,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngreater_is_better=False,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=[],\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=1,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output-rm-1k-0812-v3,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=10,\nlogging_strategy=steps,\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=loss,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=8.0,\noptim=paged_adamw_8bit,\noptim_args=None,\noutput_dir=output-rm-1k-0812-v3,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=2,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=out/1,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=10,\nsave_strategy=steps,\nsave_total_limit=2,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=10,\nweight_decay=0.0,\nxpu_backend=None,\n)\nTrainingArguments(\n_n_gpu=1,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=False,\nddp_timeout=1800,\ndebug=[],\ndeepspeed={'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': False}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'pin_memory': False}, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000.0, 'stage3_max_reuse_distance': 1000000.0, 'stage3_gather_16bit_weights_on_model_save': False}, 'train_batch_size': 8, 'train_micro_batch_size_per_gpu': 4},\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=10,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngreater_is_better=False,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=[],\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output-rm-1k-0812-v3,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=10,\nlogging_strategy=steps,\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=loss,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=8.0,\noptim=paged_adamw_8bit,\noptim_args=None,\noutput_dir=output-rm-1k-0812-v3,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=2,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=out/1,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=10,\nsave_strategy=steps,\nsave_total_limit=2,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=10,\nweight_decay=0.0,\nxpu_backend=None,\n)\n  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[32m2023-08-14 12:53:41.635\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:41.635\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:41.637\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.8047,  7.0898], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:41.638\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.5430, 7.6875], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:41.705\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:41.705\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:41.707\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.1992, 10.8906], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:41.708\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 3.5469, -3.9336], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:47.653\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:47.654\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:47.656\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.0781, 5.0469], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:47.657\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 8.7031, -1.8789], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:47.873\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:47.877\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:47.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.2969, 2.9727], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:47.886\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3633, 4.6484], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:51.916\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:51.916\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:51.917\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.0156, 1.5986], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:51.918\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.7969, 6.4102], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:52.381\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:52.381\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:52.383\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.0664, 10.4297], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:52.385\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.0877, 8.1719], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:56.185\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:56.185\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:56.188\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.2422, 6.9141], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:56.190\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 9.6250, -4.8906], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:56.816\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:53:56.816\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:53:56.819\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.8359, 8.9844], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:53:56.821\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.1445, 10.7266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n  2%|▉                                           | 1/48 [00:22<17:14, 22.01s/it]\u001b[32m2023-08-14 12:54:01.303\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:01.304\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:01.305\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.5967, 2.7246], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:01.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5508, 1.1445], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:01.415\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:01.415\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:01.418\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.6953, 5.3086], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:01.420\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.5273, 4.7344], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:05.583\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:05.583\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:05.585\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.6152, 4.6133], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:05.586\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.0723, 5.5898], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:05.900\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:05.900\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:05.903\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.6641, 7.7539], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:05.904\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.8340, 9.0703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:09.884\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:09.884\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:09.886\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.5547, 7.7539], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:09.887\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.9453, 5.6992], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:10.380\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:10.380\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:10.382\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-0.0387,  7.7891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:10.384\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.2246, 7.1836], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:14.253\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:14.253\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:14.255\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.6719, 5.9609], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:14.257\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.0547, 4.2617], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:15.060\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:15.060\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:15.066\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.0391, 1.1025], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:15.068\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.0195, 7.0547], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n  4%|█▊                                          | 2/48 [00:40<15:14, 19.87s/it]\u001b[32m2023-08-14 12:54:19.777\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:19.777\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:19.779\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.9434, 8.1172], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:19.781\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.0000, 4.0859], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:19.901\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:19.902\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:19.904\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.5605, 4.1055], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:19.909\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.2383, 8.1172], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:24.161\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:24.162\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:24.163\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.1641,  6.2422], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:24.164\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3828, 7.5547], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:24.551\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:24.551\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:24.553\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.2695, 11.3359], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:24.555\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.3418,  3.0801], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:28.634\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:28.635\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:28.637\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.7344, 6.5625], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:28.639\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.5781,  7.0430], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:29.479\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:29.480\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:29.482\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.2783, 8.2578], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:29.484\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.9414, 4.8164], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:33.044\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:33.045\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:33.047\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 2.0137, 11.4766], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:33.048\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.3320, 7.2656], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:34.535\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:34.535\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:34.537\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.9531, 5.4688], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:34.538\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 7.0430, -0.1508], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n  6%|██▊                                         | 3/48 [01:00<14:50, 19.79s/it]\u001b[32m2023-08-14 12:54:39.438\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:39.439\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:39.440\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.6367, 8.4922], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:39.441\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.6484, 9.1484], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:39.661\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:39.662\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:39.664\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.6016, 8.4062], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:39.665\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.2517, 6.7656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:43.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:43.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:43.888\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.7344, 4.8906], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:43.890\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.1797, 5.3945], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:44.864\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:44.865\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:44.867\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.7119, 8.6953], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:44.868\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3984, 8.3906], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:48.339\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:48.340\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:48.342\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.2070, 7.2461], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:48.344\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.9062, 7.0625], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:49.893\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:49.894\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:49.901\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.6328, 8.1719], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:49.902\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.7266, 7.7930], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:52.806\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:52.807\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:52.808\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.9688, 3.8711], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:52.809\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.7910, 1.7188], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:54.921\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:54.921\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:54.923\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.1484,  7.2578], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:54.925\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 9.3984, 10.4531], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n  8%|███▋                                        | 4/48 [01:20<14:40, 20.00s/it]\u001b[32m2023-08-14 12:54:59.756\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:59.756\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:59.758\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.6406,  4.5195], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:59.759\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.2500,  9.2031], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:59.967\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:54:59.968\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:54:59.970\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-1.0918,  8.8047], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:54:59.971\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.9609, 6.2188], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:04.215\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:04.216\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:04.218\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.7305, 8.4531], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:04.220\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.8770, 1.5840], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:04.854\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:04.854\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:04.856\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.4219, 0.7622], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:04.858\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.3125, 3.1016], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:08.724\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:08.725\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:08.727\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.7344, 3.8926], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:08.728\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.1816, 6.9492], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:09.678\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:09.678\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:09.680\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.5898, 0.6191], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:09.682\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.2305, 3.2461], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:13.125\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:13.125\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:13.128\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.4844, 3.0176], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:13.129\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.9727, 7.2031], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:14.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:14.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:14.479\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.6016, 6.8789], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:14.480\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.9922, 6.3867], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 10%|████▌                                       | 5/48 [01:40<14:14, 19.87s/it]\u001b[32m2023-08-14 12:55:19.386\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:19.387\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:19.388\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.1406, -0.9653], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:19.390\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6074, 5.4805], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:19.537\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:19.538\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:19.540\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.3008, 8.8594], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:19.542\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3438, 8.4531], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:23.801\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:23.803\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:23.805\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.6250, -1.3057], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:23.810\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.6680, 6.1680], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:24.358\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:24.359\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:24.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.3203, 3.5332], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:24.363\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.3242, -0.9668], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:28.220\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:28.221\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:28.223\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.4570, 7.1523], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:28.225\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.9336, 8.1172], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:29.226\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:29.226\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:29.229\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.8125, 9.1797], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:29.230\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 9.7969, 11.8594], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:32.610\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:32.611\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:32.613\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.9766, 2.3926], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:32.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.4336, 0.5742], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:33.823\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:33.824\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:33.826\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.3828, -0.7109], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:33.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.9844, 3.8398], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 12%|█████▌                                      | 6/48 [01:59<13:43, 19.61s/it]\u001b[32m2023-08-14 12:55:38.487\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:38.487\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:38.489\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-3.4199,  7.6602], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:38.490\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.5898,  2.2305], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:38.610\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:38.610\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:38.612\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.4766, 4.9531], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:38.613\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.8594, 6.5430], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:42.841\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:42.841\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:42.842\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.1953, 8.6328], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:42.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.0469,  9.6484], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:43.192\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:43.192\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:43.195\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-0.2200,  4.3984], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:43.197\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 1.3809, -0.3430], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:47.230\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:47.230\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:47.232\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.4258, 6.7695], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:47.234\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.0508, 7.2461], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:48.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:48.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:48.084\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-0.3696,  7.0352], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:48.085\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.1494,  9.6953], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:51.711\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:51.711\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:51.713\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.8750, -1.0234], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:51.715\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.2148, 5.7422], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:52.732\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:52.733\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:52.735\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9531, 9.9062], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:52.737\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.9062, 8.5000], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 15%|██████▍                                     | 7/48 [02:18<13:15, 19.41s/it]\u001b[32m2023-08-14 12:55:57.526\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:57.526\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:57.528\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.2500,  7.4688], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:57.529\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.1016, 3.8906], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:57.680\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:55:57.680\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:55:57.682\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8672, 5.8984], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:55:57.684\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.5156, 7.0430], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:02.019\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:02.020\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:02.021\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.1836, 6.1055], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:02.023\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.0898, 6.9844], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:02.783\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:02.785\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:02.787\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.7383, 2.0820], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:02.789\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.1367, 4.0234], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:06.464\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:06.464\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:06.466\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.2656,  8.0703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:06.468\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.6523, 6.7109], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:07.508\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:07.508\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:07.510\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.3047,  8.3359], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:07.512\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.9062,  7.0586], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:10.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:10.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:10.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.6016,  5.2695], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:10.883\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.0781, 7.2227], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:12.334\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:12.335\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:12.337\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 3.0391, -2.0820], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:12.338\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.1465, 3.6934], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 17%|███████▎                                    | 8/48 [02:37<13:00, 19.52s/it]\u001b[32m2023-08-14 12:56:17.250\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:17.251\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:17.253\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 3.1602, 10.9453], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:17.254\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.8516, 10.6875], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:17.415\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:17.416\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:17.421\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.2188, 8.0000], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:17.422\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5547, 5.7656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:21.639\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:21.640\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:21.641\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.5547, 9.2656], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:21.642\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 8.5234, -3.4922], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:22.121\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:22.122\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:22.124\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.2266, 4.6055], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:22.126\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5430, 5.2188], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:26.069\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:26.069\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:26.071\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.8496, 8.3125], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:26.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.1406, 2.7676], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:26.930\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:26.931\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:26.934\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.7539, 7.5508], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:26.936\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.9375, 7.3516], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:30.508\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:30.508\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:30.511\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.1094,  8.7500], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:30.513\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.8516, 5.6836], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:31.779\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:31.780\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:31.782\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.3945, 6.0977], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:31.784\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6211, 5.4375], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 19%|████████▎                                   | 9/48 [02:57<12:36, 19.41s/it]\u001b[32m2023-08-14 12:56:36.409\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:36.410\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:36.411\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.9219, 2.5586], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:36.413\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5156, 8.5859], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:36.597\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:36.598\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:36.600\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.6445, 1.1436], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:36.602\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.2891, 3.1758], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:40.818\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:40.819\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:40.821\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9688, 3.1855], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:40.822\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 7.9414, -0.3647], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:41.645\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:41.646\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:41.648\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.0625,  6.2266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:41.650\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.1680, 1.5742], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:45.288\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:45.288\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:45.291\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.0703, 6.4727], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:45.293\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.7461, 7.7930], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:46.599\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:46.599\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:46.602\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.0215, 8.2891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:46.604\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.7397, 11.1484], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:49.657\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:49.657\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:49.659\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.8594, 3.8066], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:49.660\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.5508, -0.2546], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:51.333\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:51.334\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:51.336\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-2.0449,  8.8828], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:56:51.337\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3984, 0.4255], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n{'loss': 1.3731, 'learning_rate': 1e-05, 'epoch': 1.6}                          \n 21%|████████▉                                  | 10/48 [03:16<12:20, 19.48s/it]\u001b[32m2023-08-14 12:56:57.077\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:57.078\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:57.079\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.5402, 7.7453], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:56:57.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.9557, 7.7193], device='cuda:0')\u001b[0m\n\n  0%|                                                    | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[32m2023-08-14 12:56:57.303\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:57.304\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:57.305\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.6139, 5.2209], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:56:57.307\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.5676,  5.6411], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:56:59.194\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:59.195\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:59.196\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.6805, 3.0590], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:56:59.197\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.5736, 4.6302], device='cuda:0')\u001b[0m\n\n 15%|██████▊                                     | 2/13 [00:02<00:11,  1.07s/it]\u001b[A\u001b[32m2023-08-14 12:56:59.408\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:56:59.408\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:56:59.410\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.5194, 7.2417], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:56:59.411\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.0389, 7.5499], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:01.265\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:01.265\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:01.267\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.4425, 0.8545], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:01.268\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.4764, 1.7329], device='cuda:0')\u001b[0m\n\n 23%|██████████▏                                 | 3/13 [00:04<00:14,  1.48s/it]\u001b[A\u001b[32m2023-08-14 12:57:01.494\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:01.495\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:01.496\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.1738, 4.5018], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:01.497\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3343, 4.5018], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:03.359\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:03.359\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:03.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-1.2862,  9.3904], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:03.362\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3738, 4.4710], device='cuda:0')\u001b[0m\n\n 31%|█████████████▌                              | 4/13 [00:06<00:15,  1.71s/it]\u001b[A\u001b[32m2023-08-14 12:57:03.552\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:03.553\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:03.554\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.7667, 5.1272], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:03.556\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.7044, 5.1799], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:05.388\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:05.388\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:05.390\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.6768, 7.5485], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:05.391\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.5322, 5.7785], device='cuda:0')\u001b[0m\n\n 38%|████████████████▉                           | 5/13 [00:08<00:14,  1.82s/it]\u001b[A\u001b[32m2023-08-14 12:57:05.594\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:05.594\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:05.596\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.7343, 8.3946], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:05.597\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.5366, 7.9564], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:07.436\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:07.436\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:07.438\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.8762,  9.8476], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:07.439\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4737, 7.5644], device='cuda:0')\u001b[0m\n\n 46%|████████████████████▎                       | 6/13 [00:10<00:13,  1.90s/it]\u001b[A\u001b[32m2023-08-14 12:57:07.645\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:07.645\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:07.647\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.1614, 7.8627], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:07.648\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 3.6446, -1.2604], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:09.484\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:09.484\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:09.486\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.9508, 7.9076], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:09.487\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.2805, 7.9711], device='cuda:0')\u001b[0m\n\n 54%|███████████████████████▋                    | 7/13 [00:12<00:11,  1.94s/it]\u001b[A\u001b[32m2023-08-14 12:57:09.694\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:09.694\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:09.696\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.1116, 8.1758], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:09.697\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.5699, 7.1204], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:11.543\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:11.544\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:11.546\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.3978,  4.1847], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:11.547\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.2253, 6.3941], device='cuda:0')\u001b[0m\n\n 62%|███████████████████████████                 | 8/13 [00:14<00:09,  1.98s/it]\u001b[A\u001b[32m2023-08-14 12:57:11.739\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:11.739\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:11.741\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.9257, 10.3746], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:11.742\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.2683, 8.0387], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:13.578\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:13.578\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:13.580\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8174, 4.3617], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:13.581\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.7372, 7.8931], device='cuda:0')\u001b[0m\n\n 69%|██████████████████████████████▍             | 9/13 [00:16<00:07,  2.00s/it]\u001b[A\u001b[32m2023-08-14 12:57:13.784\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:13.785\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:13.786\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.0287, 1.0127], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:13.788\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.5897, 7.9645], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:15.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:15.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:15.616\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.8024, 9.6448], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:15.618\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.5452, 3.4061], device='cuda:0')\u001b[0m\n\n 77%|█████████████████████████████████          | 10/13 [00:18<00:06,  2.01s/it]\u001b[A\u001b[32m2023-08-14 12:57:15.827\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:15.827\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:15.829\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.3092,  9.6098], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:15.830\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.0975, 9.2005], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:17.661\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:17.662\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:17.663\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.7863, 6.4702], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:17.664\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.2207, 6.4022], device='cuda:0')\u001b[0m\n\n 85%|████████████████████████████████████▍      | 11/13 [00:20<00:04,  2.02s/it]\u001b[A\u001b[32m2023-08-14 12:57:17.877\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:17.877\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:17.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.5935, 7.9521], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:17.880\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3351, 6.6110], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:19.745\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:19.745\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:19.747\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.0643, 5.6751], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:19.748\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.8900, 3.7323], device='cuda:0')\u001b[0m\n\n 92%|███████████████████████████████████████▋   | 12/13 [00:22<00:02,  2.04s/it]\u001b[A\u001b[32m2023-08-14 12:57:19.933\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:19.934\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:19.935\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.3577, 4.9655], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:19.937\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.2092, 4.0947], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:21.768\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:21.768\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:21.769\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([0.3746, 2.1979], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 12:57:21.770\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.6131, 5.7756], device='cuda:0')\u001b[0m\n\n100%|███████████████████████████████████████████| 13/13 [00:24<00:00,  2.03s/it]\u001b[A\u001b[32m2023-08-14 12:57:21.995\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:21.996\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:21.998\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.5402, 7.7453], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 12:57:22.000\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.9557, 7.7193], device='cuda:1')\u001b[0m\n                                                                                \n\u001b[A{'eval_loss': 1.069419264793396, 'eval_accuracy': 0.6, 'eval_runtime': 27.4898, 'eval_samples_per_second': 1.819, 'eval_steps_per_second': 0.473, 'epoch': 1.6}\n 21%|████████▉                                  | 10/48 [03:44<12:20, 19.48s/it]\n100%|███████████████████████████████████████████| 13/13 [00:24<00:00,  2.03s/it]\u001b[A\n                                                                                \u001b[A\u001b[32m2023-08-14 12:57:22.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m853\u001b[0m - \u001b[1mSaving model checkpoint to output-rm-1k-0812-v3/checkpoint-10\u001b[0m\n\u001b[32m2023-08-14 12:57:22.038\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m857\u001b[0m - \u001b[31m\u001b[1m 111  model has pretrained_model\u001b[0m\n\u001b[32m2023-08-14 12:57:22.041\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m864\u001b[0m - \u001b[31m\u001b[1m222 backbone_model, PeftModel\u001b[0m\n\u001b[32m2023-08-14 12:57:26.301\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:26.302\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:26.304\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-1.3594,  9.3359], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:26.305\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.5469, 6.3750], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:26.401\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:26.401\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:26.404\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.1680, 4.7930], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:26.406\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.7793,  3.6738], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:30.691\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:30.691\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:30.693\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9141, 5.6641], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:30.694\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.1211, 7.4258], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:31.200\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:31.202\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:31.204\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.1875, 6.9453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:31.207\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.8164, 5.5703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:35.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:35.170\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:35.172\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.7344, 3.3613], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:35.174\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.0586, 6.2344], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:35.853\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:35.853\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:35.855\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.0391,  4.5547], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:35.857\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([12.0391,  5.5703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:39.650\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:39.651\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:39.653\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([0.6851, 4.8281], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:39.655\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.2969, 5.2891], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:40.486\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:40.487\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:40.489\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.8047, 9.4531], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:40.491\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.5547, 6.3242], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 23%|█████████▊                                 | 11/48 [04:05<17:36, 28.54s/it]\u001b[32m2023-08-14 12:57:45.159\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:45.159\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:45.161\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.4609, 4.6562], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:45.162\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.6211, 7.3867], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:45.304\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:45.304\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:45.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.5469, 7.6953], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:45.308\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.5469, 7.3555], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:49.575\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:49.575\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:49.577\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.0859, 6.3867], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:49.578\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.7148, 9.1641], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:50.270\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:50.270\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:50.272\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.1816, 9.6484], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:50.274\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-5.1133,  1.5684], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:54.003\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:54.003\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:54.006\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.5156, 8.9609], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:54.007\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6621, 7.8320], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:55.158\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:55.159\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:55.161\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9375, 6.1094], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:55.163\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.8438, 5.1758], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:58.398\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:58.398\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:58.400\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.6406,  5.4805], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:58.402\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.9180, 4.3203], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:59.862\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:57:59.863\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:57:59.865\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.4141, 0.0437], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:57:59.866\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.0111, 2.5020], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 25%|██████████▊                                | 12/48 [04:25<15:30, 25.84s/it]\u001b[32m2023-08-14 12:58:04.818\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:04.818\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:04.821\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.1855, 4.9961], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:04.822\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.1953, 4.5312], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:04.981\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:04.981\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:04.983\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.5176, 8.5156], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:04.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.8398, 9.5703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:09.211\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:09.211\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:09.213\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.5156, 7.8594], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:09.215\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.3496, 7.6172], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:09.793\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:09.794\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:09.796\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.8340, 6.8711], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:09.797\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3945, 6.4297], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:13.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:13.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:13.617\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.7129, 9.8281], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:13.619\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.8574, 6.2305], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:14.578\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:14.579\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:14.581\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.7266, 7.6367], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:14.583\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-5.6328,  5.6953], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:18.112\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:18.112\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:18.115\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.0273, 8.6406], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:18.116\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.4512, 9.9297], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:19.482\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:19.483\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:19.485\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.3164, -1.0713], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:19.486\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 7.4258, -1.6709], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 27%|███████████▋                               | 13/48 [04:44<13:56, 23.89s/it]\u001b[32m2023-08-14 12:58:24.208\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:24.208\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:24.210\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8320, 4.7617], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:24.211\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.9023, 7.7070], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:24.400\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:24.401\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:24.403\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.6172, 8.4453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:24.404\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.7461, 4.8828], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:28.674\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:28.674\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:28.676\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.5566, 5.3438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:28.682\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.0352, 4.0547], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:29.368\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:29.369\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:29.371\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.5938, 1.7168], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:29.372\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.4453, 0.6045], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:33.168\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:33.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:33.171\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.0762, 3.9473], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:33.173\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 3.9844, -3.0098], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:34.132\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:34.133\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:34.135\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.2422, 5.2734], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:34.138\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.9883, 2.2266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:37.631\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:37.632\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:37.634\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.4688, 9.7969], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:37.635\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3906, 7.2500], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:38.915\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:38.916\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:38.919\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.9863, 0.4355], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:38.921\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4980, 7.5391], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 29%|████████████▌                              | 14/48 [05:04<12:48, 22.59s/it]\u001b[32m2023-08-14 12:58:43.799\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:43.799\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:43.801\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.5508, 3.7422], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:43.802\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.5859, 6.0703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:43.983\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:43.984\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:43.986\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.0625, 5.7422], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:43.988\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.8906, 7.3789], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:48.209\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:48.210\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:48.212\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.1172, 5.2617], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:48.213\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.4844, 0.6909], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:48.826\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:48.826\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:48.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.1016,  4.6836], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:48.830\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6738, 4.3242], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:52.666\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:52.667\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:52.668\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.0000, 7.3516], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:52.670\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.9570,  3.1895], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:53.669\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:53.670\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:53.673\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.8984, 10.9609], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:53.674\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.9414, 8.3828], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:57.088\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:57.088\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:57.090\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.2188, 5.6758], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:57.092\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.4453, 5.8555], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:58.402\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:58:58.402\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:58:58.404\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.2109, 11.1562], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:58:58.406\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.8828, 8.2266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 31%|█████████████▍                             | 15/48 [05:23<11:53, 21.61s/it]\u001b[32m2023-08-14 12:59:03.128\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:03.128\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:03.129\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.6523, 7.9883], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:03.131\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.7363,  8.2891], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:03.305\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:03.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:03.308\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.9961, 2.5000], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:03.310\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.9609,  5.9727], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:07.652\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:07.652\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:07.654\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.4531, 11.8047], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:07.656\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5312, 8.1016], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:08.270\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:08.270\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:08.273\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.8555, 0.3083], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:08.275\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3008, 2.7168], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:12.058\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:12.059\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:12.061\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.1836, 6.9297], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:12.063\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.7383, 8.4531], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:13.082\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:13.083\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:13.085\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.8398, 1.6191], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:13.086\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.0898, 8.3125], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:16.458\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:16.458\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:16.460\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9688, 3.0234], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:16.462\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([12.7812,  7.2617], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:17.839\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:17.840\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:17.842\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.5625, 9.5469], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:17.844\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.0352, 1.0459], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 33%|██████████████▎                            | 16/48 [05:43<11:09, 20.93s/it]\u001b[32m2023-08-14 12:59:22.471\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:22.472\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:22.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 4.4258, -0.9185], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:22.478\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.3633, 4.4180], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:22.610\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:22.611\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:22.613\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.8438, 11.5625], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:22.614\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.0234,  6.9844], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:26.844\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:26.844\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:26.846\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 4.7109, 11.5391], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:26.847\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.6133, 4.6367], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:27.277\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:27.277\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:27.279\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.7070, 8.0703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:27.281\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.0938, 7.3359], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:31.277\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:31.277\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:31.279\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.2734, 7.9102], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:31.281\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.9844, 0.0963], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:32.271\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:32.272\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:32.274\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.3359, 12.6719], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:32.276\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.0547,  5.9961], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:35.714\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:35.715\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:35.717\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.8125, 3.6973], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:35.719\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.9512, 4.4961], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:36.924\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:36.925\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:36.927\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.4570, 2.0684], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:36.929\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.8320, 0.6348], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 35%|███████████████▏                           | 17/48 [06:02<10:32, 20.41s/it]\u001b[32m2023-08-14 12:59:41.666\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:41.667\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:41.668\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.1035, 8.3828], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:41.669\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.2734, 6.3203], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:41.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:41.844\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:41.845\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-2.2402,  7.3633], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:41.847\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.7500, 6.2148], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:46.132\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:46.132\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:46.134\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.2969, 7.5586], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:46.136\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.9062, 6.6836], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:46.743\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:46.744\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:46.746\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.1875,  0.0592], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:46.748\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.9336, -1.2969], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:50.590\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:50.591\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:50.593\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.4531, 4.7461], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:50.594\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.0898, 0.1357], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:51.539\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:51.539\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:51.541\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.8047, 4.2422], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:51.543\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.6016,  4.7773], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:55.126\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:55.126\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:55.129\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.9004, 4.7148], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:55.131\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.7871, 4.6641], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:56.211\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 12:59:56.211\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 12:59:56.213\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.2031, 7.9492], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 12:59:56.215\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.7188, 5.7891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 38%|████████████████▏                          | 18/48 [06:21<10:02, 20.09s/it]\u001b[32m2023-08-14 13:00:01.008\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:01.009\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:01.010\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.0625, 8.6641], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:01.012\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.9766, 7.1367], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:01.196\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:01.196\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:01.198\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.5820, 10.0625], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:01.200\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.8477, -4.7109], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:05.409\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:05.409\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:05.411\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-0.8188,  5.4922], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:05.413\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.1367, 1.5654], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:06.230\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:06.230\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:06.233\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.4453,  9.8125], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:06.234\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.3555, 7.7617], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:09.928\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:09.930\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:09.932\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.5000,  9.2266], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:09.935\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.4160, 3.9141], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:10.936\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:10.937\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:10.944\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.2500, 7.9453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:10.947\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.4609,  4.3789], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:14.385\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:14.386\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:14.388\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.0508, 3.3027], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:14.390\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.2891, -0.5337], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:15.689\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:15.689\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:15.691\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.9766, 10.1953], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:15.693\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.8770, 2.6582], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 40%|█████████████████                          | 19/48 [06:40<09:35, 19.86s/it]\u001b[32m2023-08-14 13:00:20.341\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:20.341\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:20.343\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.8594, 3.7578], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:20.344\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.6455, 1.2158], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:20.480\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:20.481\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:20.483\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.3750, 8.8828], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:20.484\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 7.1445, 10.3281], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:24.825\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:24.826\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:24.827\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.7656,  6.8242], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:24.829\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.9531,  6.9375], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:25.185\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:25.186\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:25.188\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.4609,  3.0098], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:25.190\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.3281, 2.0156], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:29.234\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:29.235\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:29.237\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.2852, 8.9141], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:29.239\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3711, 8.8828], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:30.144\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:30.144\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:30.146\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.0117, 7.3477], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:30.148\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6641, 5.5898], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:33.639\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:33.640\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:33.642\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.3008, 4.1602], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:33.644\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.5312, 1.9473], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:35.058\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:35.058\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:35.061\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.5664, 3.4297], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:00:35.063\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.3379, 4.8203], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n{'loss': 1.0313, 'learning_rate': 1.7894736842105264e-05, 'epoch': 3.2}         \n 42%|█████████████████▉                         | 20/48 [07:00<09:12, 19.72s/it]\u001b[32m2023-08-14 13:00:40.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:40.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:40.075\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9695, 5.6947], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:40.076\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.4983, 6.4599], device='cuda:0')\u001b[0m\n\n  0%|                                                    | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[32m2023-08-14 13:00:40.288\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:40.289\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:40.290\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.4603, 6.6570], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:40.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.3447,  4.9726], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:42.222\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:42.229\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:42.231\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.3265, 3.4094], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:42.232\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.2973, 2.9021], device='cuda:0')\u001b[0m\n\n 15%|██████▊                                     | 2/13 [00:02<00:11,  1.09s/it]\u001b[A\u001b[32m2023-08-14 13:00:42.420\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:42.420\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:42.422\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9596, 7.9188], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:42.423\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4350, 5.8188], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:44.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:44.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:44.294\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.7670, 2.7734], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:44.295\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3651, 0.7341], device='cuda:0')\u001b[0m\n\n 23%|██████████▏                                 | 3/13 [00:04<00:14,  1.49s/it]\u001b[A\u001b[32m2023-08-14 13:00:44.535\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:44.535\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:44.537\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.0321, 5.1921], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:44.538\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.0005, 5.1921], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:46.380\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:46.381\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:46.382\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-0.2721,  8.0405], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:46.383\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6182, 4.2425], device='cuda:0')\u001b[0m\n\n 31%|█████████████▌                              | 4/13 [00:06<00:15,  1.71s/it]\u001b[A\u001b[32m2023-08-14 13:00:46.609\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:46.610\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:46.612\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.5438, 5.9476], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:46.614\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4119, 3.4768], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:48.441\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:48.441\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:48.443\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.3258, 7.9177], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:48.444\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4333, 5.8363], device='cuda:0')\u001b[0m\n\n 38%|████████████████▉                           | 5/13 [00:08<00:14,  1.83s/it]\u001b[A\u001b[32m2023-08-14 13:00:48.654\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:48.655\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:48.656\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9179, 6.6829], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:48.658\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.2316, 5.9483], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:50.494\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:50.495\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:50.496\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.4760, 11.4544], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:50.497\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4525, 8.0631], device='cuda:0')\u001b[0m\n\n 46%|████████████████████▎                       | 6/13 [00:10<00:13,  1.91s/it]\u001b[A\u001b[32m2023-08-14 13:00:50.722\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:50.723\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:50.724\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.2016, 6.2227], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:50.725\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.9557, -1.2225], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:52.560\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:52.560\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:52.562\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.2564, 10.7632], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:52.563\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.0072, 4.4387], device='cuda:0')\u001b[0m\n\n 54%|███████████████████████▋                    | 7/13 [00:12<00:11,  1.96s/it]\u001b[A\u001b[32m2023-08-14 13:00:52.770\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:52.770\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:52.772\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.3161, 7.4945], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:52.773\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.9649, 5.9074], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:54.605\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:54.605\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:54.607\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.2021,  5.6680], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:54.608\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.5447, 5.1131], device='cuda:0')\u001b[0m\n\n 62%|███████████████████████████                 | 8/13 [00:14<00:09,  1.98s/it]\u001b[A\u001b[32m2023-08-14 13:00:54.813\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:54.813\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:54.815\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.2048, 9.3954], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:54.816\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3126, 5.8758], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:56.696\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:56.696\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:56.698\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8737, 6.7465], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:56.699\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.1986, 5.8034], device='cuda:0')\u001b[0m\n\n 69%|██████████████████████████████▍             | 9/13 [00:16<00:08,  2.02s/it]\u001b[A\u001b[32m2023-08-14 13:00:56.862\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:56.863\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:56.864\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.9574, 4.1027], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:56.866\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.1490, 3.5949], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:58.695\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:58.695\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:58.696\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.4282, 9.9454], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:00:58.697\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.0075,  3.0385], device='cuda:0')\u001b[0m\n\n 77%|█████████████████████████████████          | 10/13 [00:18<00:06,  2.01s/it]\u001b[A\u001b[32m2023-08-14 13:00:58.929\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:00:58.929\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:00:58.931\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.2450, 11.1993], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:00:58.932\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 7.5016, 10.5702], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:01:00.779\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:00.779\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:00.781\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.5378, 7.4527], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:01:00.782\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.8544, 4.3286], device='cuda:0')\u001b[0m\n\n 85%|████████████████████████████████████▍      | 11/13 [00:20<00:04,  2.03s/it]\u001b[A\u001b[32m2023-08-14 13:01:00.982\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:00.983\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:00.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.4388, 8.8542], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:01:00.986\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.6103, 5.2724], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:01:02.831\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:02.831\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:02.833\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.5340, 6.3110], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:01:02.834\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.7311, 3.0934], device='cuda:0')\u001b[0m\n\n 92%|███████████████████████████████████████▋   | 12/13 [00:22<00:02,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:01:03.056\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:03.056\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:03.058\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.4410, 5.9067], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:01:03.059\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.1072, 2.8778], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:01:04.907\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:04.908\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:04.909\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.2308, 3.8909], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:01:04.911\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.3096, 3.8557], device='cuda:0')\u001b[0m\n\n100%|███████████████████████████████████████████| 13/13 [00:24<00:00,  2.05s/it]\u001b[A\u001b[32m2023-08-14 13:01:05.142\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:05.148\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:05.149\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9695, 5.6947], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:01:05.151\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.4983, 6.4599], device='cuda:1')\u001b[0m\n                                                                                \n\u001b[A{'eval_loss': 0.3358353078365326, 'eval_accuracy': 0.88, 'eval_runtime': 26.942, 'eval_samples_per_second': 1.856, 'eval_steps_per_second': 0.483, 'epoch': 3.2}\n 42%|█████████████████▉                         | 20/48 [07:27<09:12, 19.72s/it]\n100%|███████████████████████████████████████████| 13/13 [00:25<00:00,  2.05s/it]\u001b[A\n                                                                                \u001b[A\u001b[32m2023-08-14 13:01:05.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m853\u001b[0m - \u001b[1mSaving model checkpoint to output-rm-1k-0812-v3/checkpoint-20\u001b[0m\n\u001b[32m2023-08-14 13:01:05.183\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m857\u001b[0m - \u001b[31m\u001b[1m 111  model has pretrained_model\u001b[0m\n\u001b[32m2023-08-14 13:01:05.184\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m864\u001b[0m - \u001b[31m\u001b[1m222 backbone_model, PeftModel\u001b[0m\n\u001b[32m2023-08-14 13:01:09.334\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:09.335\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:09.336\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.2422, 9.2891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:09.338\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.2812, 5.0742], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:09.407\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:09.408\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:09.410\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.2305, 0.7290], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:09.412\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.0977, 1.4424], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:13.918\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:13.922\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:13.924\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.0508, 1.9199], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:13.928\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.3242, -2.2520], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:14.086\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:14.087\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:14.088\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.4922, 5.4688], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:14.090\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.0156, 3.0762], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:18.458\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:18.458\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:18.459\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.4180, 9.0312], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:18.460\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.8867, 5.8750], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:18.999\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:18.999\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:19.001\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.7578, 6.9883], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:19.003\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.6016, -0.3545], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:22.877\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:22.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:22.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 2.9395, 10.8828], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:22.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.0387, 12.1328], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:23.876\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:23.876\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:23.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.7695, 8.9688], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:23.880\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.3105, 9.1016], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 44%|██████████████████▊                        | 21/48 [07:49<12:49, 28.49s/it]\u001b[32m2023-08-14 13:01:28.677\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:28.677\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:28.678\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.3164, 4.5898], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:28.679\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.3750, 2.5645], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:28.823\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:28.824\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:28.826\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.1562, 10.1328], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:28.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.8164, 10.1953], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:33.045\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:33.045\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:33.046\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.6953, 5.2773], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:33.047\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.9883, 6.6484], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:33.542\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:33.542\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:33.545\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.1328,  5.0352], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:33.546\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.8672,  6.5742], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:37.416\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:37.416\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:37.419\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.1484, 9.6094], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:37.420\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.5820, 7.5781], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:38.311\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:38.311\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:38.313\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([1.8770, 1.5117], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:38.315\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.2852, 0.6431], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:41.846\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:41.847\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:41.849\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.8945, 8.2656], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:41.851\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.9062, 7.4062], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:43.111\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:43.112\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:43.114\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.1719, 1.2451], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:43.116\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.1523, 4.3008], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 46%|███████████████████▋                       | 22/48 [08:08<11:09, 25.76s/it]\u001b[32m2023-08-14 13:01:48.102\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:48.103\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:48.105\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.3008, 7.6484], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:48.106\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6035, 5.4297], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:48.212\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:48.212\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:48.214\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.7656,  8.0547], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:48.216\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.3281,  4.0195], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:52.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:52.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:52.478\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.8047, 6.1602], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:52.479\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.2422, 2.1992], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:52.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:52.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:52.988\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.4023, 10.7422], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:52.990\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.3262,  6.2188], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:56.964\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:56.965\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:56.967\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.1602, 8.2500], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:56.968\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.7734, 5.9609], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:57.722\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:01:57.723\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:01:57.725\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.0469, 14.2891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:01:57.727\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.8438, 11.2344], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:01.426\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:01.427\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:01.429\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.2617, 10.3281], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:01.430\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.1055, 4.0781], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:02.393\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:02.394\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:02.396\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.7969, 4.3242], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:02.398\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.8359, 1.6494], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 48%|████████████████████▌                      | 23/48 [08:27<09:54, 23.77s/it]\u001b[32m2023-08-14 13:02:07.202\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:07.202\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:07.204\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.3477, 13.0312], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:07.205\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 2.7129, 10.1406], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:07.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:07.362\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:07.364\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.7051, 5.0430], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:07.365\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4355, 1.2832], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:11.620\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:11.620\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:11.621\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([-2.1095e-03,  7.1562e+00], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:11.622\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.9526, 4.1875], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:12.140\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:12.140\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:12.143\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 1.2764, 11.2891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:12.145\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.1400, 10.4844], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:16.014\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:16.015\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:16.017\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.8359, 17.3750], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:16.019\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.2812, 2.3730], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:16.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:16.979\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:16.982\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.4297, 12.4219], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:16.984\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.1445, -0.7051], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:20.527\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:20.527\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:20.529\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.0781,  8.9375], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:20.531\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.5918,  4.3438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:21.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:21.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:21.846\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.5000, 11.3750], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:21.848\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.5625, 3.8848], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 50%|█████████████████████▌                     | 24/48 [08:47<08:59, 22.50s/it]\u001b[32m2023-08-14 13:02:26.727\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:26.728\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:26.730\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.9609,  6.2305], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:26.731\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.6484, 5.7891], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:26.873\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:26.874\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:26.876\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.1680, 6.6094], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:26.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 1.6982, -3.9863], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:31.199\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:31.200\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:31.201\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.5508, 13.6250], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:31.202\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.3477, 9.5391], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:31.717\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:31.718\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:31.720\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.0000,  7.7422], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:31.722\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5039, 6.7656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:35.576\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:35.577\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:35.579\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 1.8926, 13.7500], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:35.581\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.8486, 8.6719], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:36.412\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:36.412\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:36.420\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.2500, 7.3008], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:36.422\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.2228,  6.4492], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:40.025\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:40.025\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:40.027\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.8984, 7.1406], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:40.030\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.2344, 3.2070], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:41.278\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:41.279\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:41.281\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.6680, 9.1406], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:41.282\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.3828, 1.3867], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 52%|██████████████████████▍                    | 25/48 [09:06<08:14, 21.51s/it]\u001b[32m2023-08-14 13:02:45.915\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:45.915\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:45.917\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8398, 9.9219], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:45.918\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.9082, 2.3203], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:46.083\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:46.083\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:46.085\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.4961, 7.9102], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:46.087\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.3591,  2.7832], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:50.357\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:50.358\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:50.359\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9844, 8.9141], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:50.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.4805, 4.8867], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:50.903\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:50.903\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:50.905\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.1172, 9.0781], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:50.907\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.1938, 8.3672], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:54.792\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:54.793\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:54.795\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 0.3679, 10.4609], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:54.797\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.2240, 5.3711], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:55.862\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:55.863\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:55.865\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.7578,  7.9180], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:55.867\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.6719, 3.0820], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:59.197\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:02:59.197\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:02:59.199\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.3398, 7.5625], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:02:59.201\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-6.1340e-03,  6.3594e+00], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:00.839\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:00.839\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:00.842\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.9375, 10.6484], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:00.844\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 2.7168, -5.6133], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 54%|███████████████████████▎                   | 26/48 [09:26<07:40, 20.95s/it]\u001b[32m2023-08-14 13:03:05.570\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:05.570\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:05.572\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.3984,  6.3828], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:05.573\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.9727, 0.1910], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:05.741\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:05.741\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:05.743\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.7422,  4.0273], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:05.745\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.0000, 1.1963], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:09.984\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:09.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:09.986\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.5859, 3.7285], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:09.987\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.0234, -5.1250], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:10.517\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:10.517\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:10.519\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.7656,  9.3359], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:10.521\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.3047, 4.1641], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:14.369\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:14.370\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:14.372\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.0156, 11.5391], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:14.374\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.7383, 9.8516], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:15.255\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:15.256\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:15.258\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.5547, 13.4219], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:15.260\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.6055, 11.3516], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:18.812\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:18.812\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:18.814\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.7422,  9.8906], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:18.816\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.4688, 4.7422], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:20.165\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:20.166\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:20.168\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.5293, 7.1211], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:20.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6660, 3.2637], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 56%|████████████████████████▏                  | 27/48 [09:45<07:10, 20.49s/it]\u001b[32m2023-08-14 13:03:24.996\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:24.997\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:24.998\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9219, 7.2227], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:25.000\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.7617, 2.9414], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:25.158\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:25.163\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:25.165\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.7266, 14.1875], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:25.166\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.7852, 10.8594], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:29.422\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:29.422\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:29.423\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.4531,  4.5859], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:29.424\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([13.7734, -0.2496], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:29.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:29.829\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:29.831\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.8789, 9.2031], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:29.832\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.4883, 9.5547], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:33.861\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:33.861\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:33.863\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.5391, 5.0156], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:33.865\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.3379, -2.2988], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:34.566\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:34.566\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:34.568\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 4.6406, 10.6719], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:34.570\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.9873,  4.7656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:38.316\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:38.319\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:38.321\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.3398, 6.1016], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:38.323\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.8926,  3.4980], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:39.332\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:39.333\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:39.335\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.9062, 8.5469], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:39.337\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.0141, 2.2070], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 58%|█████████████████████████                  | 28/48 [10:04<06:42, 20.10s/it]\u001b[32m2023-08-14 13:03:44.188\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:44.189\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:44.190\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.9414, 10.3438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:44.191\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.6992, 6.9219], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:44.363\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:44.363\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:44.366\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.2969, 4.4883], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:44.367\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.2402, 2.2695], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:48.601\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:48.601\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:48.604\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.0234, 7.7344], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:48.605\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.9180, 7.9023], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:49.214\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:49.214\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:49.217\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8672, 4.1719], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:49.218\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.6406, 0.4448], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:53.092\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:53.094\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:53.096\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.8281, 9.0234], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:53.099\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 2.3945, -0.3809], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:54.252\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:54.253\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:54.255\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.6992, 14.0547], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:54.256\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.7686, 7.9961], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:57.598\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:57.598\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:57.600\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.3438,  7.3516], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:57.601\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6094, 0.2610], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:59.242\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:03:59.243\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:03:59.245\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.5625, 10.5391], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:03:59.247\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.0391, 4.7227], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 60%|█████████████████████████▉                 | 29/48 [10:24<06:21, 20.06s/it]\u001b[32m2023-08-14 13:04:04.144\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:04.145\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:04.146\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.2344, 12.4375], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:04.147\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 9.7266, -1.4824], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:04.313\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:04.314\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:04.319\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.7773, 12.7500], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:04.321\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.0742, -0.2966], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:08.511\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:08.511\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:08.512\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.6641,  8.3516], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:08.513\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([12.1875, -1.8008], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:09.298\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:09.299\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:09.301\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.4844, 5.4414], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:09.302\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.6562, -4.9180], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:12.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:12.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:12.883\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.6758, 6.8008], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:12.884\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.0586, 1.4248], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:14.071\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:14.072\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:14.074\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.5234, 8.9375], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:14.077\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.3789, 6.3906], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:17.279\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:17.280\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:17.282\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.3047, 12.3750], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:17.284\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.6636, 0.7466], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:18.759\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:18.760\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:18.762\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 4.1562, 16.9062], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:18.763\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.9648, 9.8125], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n{'loss': 0.2453, 'learning_rate': 1.263157894736842e-05, 'epoch': 4.8}          \n 62%|██████████████████████████▉                | 30/48 [10:44<05:57, 19.85s/it]\u001b[32m2023-08-14 13:04:23.836\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:23.837\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:23.838\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.4545,  5.0042], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:23.840\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6223, 4.6754], device='cuda:0')\u001b[0m\n\n  0%|                                                    | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[32m2023-08-14 13:04:24.071\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:24.072\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:24.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.6196, 10.4957], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:24.075\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.1259,  4.1303], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:25.957\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:25.964\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:25.966\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.7581, 5.0760], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:25.967\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.5799,  0.6357], device='cuda:0')\u001b[0m\n\n 15%|██████▊                                     | 2/13 [00:02<00:11,  1.08s/it]\u001b[A\u001b[32m2023-08-14 13:04:26.158\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:26.158\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:26.159\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.3225, 10.1824], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:26.160\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.0176, 4.7183], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:27.984\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:27.984\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:27.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9986, 6.4621], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:27.987\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 1.5320, -0.8671], device='cuda:0')\u001b[0m\n\n 23%|██████████▏                                 | 3/13 [00:04<00:14,  1.46s/it]\u001b[A\u001b[32m2023-08-14 13:04:28.213\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:28.213\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:28.215\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.9475,  7.3041], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:28.216\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.9784, 7.3041], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:30.091\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:30.092\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:30.093\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([2.9878, 8.1474], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:30.094\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.5831,  3.7202], device='cuda:0')\u001b[0m\n\n 31%|█████████████▌                              | 4/13 [00:06<00:15,  1.70s/it]\u001b[A\u001b[32m2023-08-14 13:04:30.271\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:30.271\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:30.273\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.8075, 6.6780], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:30.274\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.4195,  1.8932], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:32.096\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:32.097\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:32.098\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 3.7493, 10.2620], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:32.099\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.1901,  5.9183], device='cuda:0')\u001b[0m\n\n 38%|████████████████▉                           | 5/13 [00:08<00:14,  1.81s/it]\u001b[A\u001b[32m2023-08-14 13:04:32.314\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:32.315\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:32.317\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.5170, 6.0929], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:32.318\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.6414, 4.7082], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:34.167\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:34.168\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:34.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.2039, 13.8903], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:34.171\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.3943, 9.3783], device='cuda:0')\u001b[0m\n\n 46%|████████████████████▎                       | 6/13 [00:10<00:13,  1.89s/it]\u001b[A\u001b[32m2023-08-14 13:04:34.371\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:34.371\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:34.372\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.0519, 5.3661], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:34.373\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.2274, -1.3097], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:36.191\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:36.191\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:36.193\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.2959, 14.2112], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:36.194\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.2598, 1.6726], device='cuda:0')\u001b[0m\n\n 54%|███████████████████████▋                    | 7/13 [00:12<00:11,  1.94s/it]\u001b[A\u001b[32m2023-08-14 13:04:36.424\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:36.425\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:36.427\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.9777,  8.6014], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:36.428\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.0346, 4.1705], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:38.254\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:38.254\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:38.256\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.5382,  7.4457], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:38.257\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.7207, 4.0500], device='cuda:0')\u001b[0m\n\n 62%|███████████████████████████                 | 8/13 [00:14<00:09,  1.98s/it]\u001b[A\u001b[32m2023-08-14 13:04:38.508\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:38.508\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:38.510\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.9142, 10.3715], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:38.511\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.3157, 2.4604], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:40.354\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:40.355\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:40.357\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.6872, 9.3808], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:40.358\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.7032, 5.1915], device='cuda:0')\u001b[0m\n\n 69%|██████████████████████████████▍             | 9/13 [00:16<00:08,  2.02s/it]\u001b[A\u001b[32m2023-08-14 13:04:40.552\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:40.553\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:40.554\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.4517, 7.5760], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:40.555\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.1049, -0.0699], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:42.376\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:42.377\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:42.378\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.1304, 11.0374], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:42.379\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.5106,  2.5868], device='cuda:0')\u001b[0m\n\n 77%|█████████████████████████████████          | 10/13 [00:18<00:06,  2.02s/it]\u001b[A\u001b[32m2023-08-14 13:04:42.594\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:42.595\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:42.596\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.1508, 14.0744], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:42.597\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 8.6219, 12.9459], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:44.431\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:44.431\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:44.433\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.7916, 9.1233], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:44.434\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.3843,  2.4924], device='cuda:0')\u001b[0m\n\n 85%|████████████████████████████████████▍      | 11/13 [00:20<00:04,  2.03s/it]\u001b[A\u001b[32m2023-08-14 13:04:44.642\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:44.643\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:44.644\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.2623, 10.4238], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:44.646\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.0934, 4.7483], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:46.483\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:46.484\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:46.485\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.8639, 7.3642], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:46.486\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.4657, 2.7139], device='cuda:0')\u001b[0m\n\n 92%|███████████████████████████████████████▋   | 12/13 [00:22<00:02,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:04:46.695\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:46.695\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:46.697\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.2882, 7.5910], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:46.698\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.1361,  2.2335], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:48.527\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:48.528\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:48.530\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.8806, 7.7596], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:04:48.531\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6720, 1.3786], device='cuda:0')\u001b[0m\n\n100%|███████████████████████████████████████████| 13/13 [00:24<00:00,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:04:48.739\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:48.740\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:48.741\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.4545,  5.0042], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:04:48.743\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6223, 4.6754], device='cuda:1')\u001b[0m\n                                                                                \n\u001b[A{'eval_loss': 0.07781531661748886, 'eval_accuracy': 0.96, 'eval_runtime': 26.7474, 'eval_samples_per_second': 1.869, 'eval_steps_per_second': 0.486, 'epoch': 4.8}\n 62%|██████████████████████████▉                | 30/48 [11:10<05:57, 19.85s/it]\n100%|███████████████████████████████████████████| 13/13 [00:24<00:00,  2.04s/it]\u001b[A\n                                                                                \u001b[A\u001b[32m2023-08-14 13:04:48.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m853\u001b[0m - \u001b[1mSaving model checkpoint to output-rm-1k-0812-v3/checkpoint-30\u001b[0m\n\u001b[32m2023-08-14 13:04:48.773\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m857\u001b[0m - \u001b[31m\u001b[1m 111  model has pretrained_model\u001b[0m\n\u001b[32m2023-08-14 13:04:48.774\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m864\u001b[0m - \u001b[31m\u001b[1m222 backbone_model, PeftModel\u001b[0m\n\u001b[32m2023-08-14 13:04:52.751\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:52.751\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:52.753\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.2109, 11.1562], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:52.754\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.7500, 5.0000], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:52.856\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:52.856\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:52.859\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 4.3555, 13.1406], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:52.861\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.2539, 10.4375], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:57.136\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:57.137\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:57.139\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.5078, 9.1797], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:57.140\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.2305, 1.3789], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:58.805\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:04:58.806\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:04:58.808\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.3750, 9.6719], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:04:58.810\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.9893, 7.7734], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:01.571\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:01.571\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:01.573\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 3.7188, 12.4531], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:01.574\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.0176,  1.3164], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:03.467\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:03.468\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:03.470\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.4766, 16.2812], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:03.472\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.5518, 2.1387], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:05.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:05.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:05.981\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.7891, 7.1914], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:05.982\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.3438, 3.4160], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:08.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:08.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:08.295\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.1797, 7.8047], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:08.297\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.0352, -1.0098], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 65%|███████████████████████████▊               | 31/48 [11:33<08:09, 28.77s/it]\u001b[32m2023-08-14 13:05:13.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:13.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:13.083\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.7344,  4.8398], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:13.084\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.2422,  3.8535], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:13.216\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:13.217\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:13.219\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9922, 7.4609], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:13.221\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.9922, 8.9141], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:17.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:17.475\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:17.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.7109, 12.1719], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:17.477\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.9297,  6.1172], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:17.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:17.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:17.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.0391, 11.9766], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:17.882\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.3672, 4.8008], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:21.874\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:21.875\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:21.876\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.9141, 7.4766], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:21.878\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.4141, -0.8042], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:22.620\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:22.621\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:22.623\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 3.4531, 11.2109], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:22.624\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-4.2148,  4.6484], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:26.342\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:26.342\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:26.344\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.9727, 6.0820], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:26.346\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.9443,  1.5625], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:27.427\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:27.427\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:27.430\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9180, 8.7266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:27.432\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 3.3125, -0.2047], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 67%|████████████████████████████▋              | 32/48 [11:52<06:54, 25.90s/it]\u001b[32m2023-08-14 13:05:32.280\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:32.280\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:32.282\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.7812, 7.8828], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:32.283\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.1641, 3.1895], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:32.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:32.475\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:32.477\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.6641, 8.0625], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:32.478\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.8560,  8.1406], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:36.668\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:36.669\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:36.671\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.6797, 10.3125], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:36.673\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.2812, 7.9531], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:37.254\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:37.254\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:37.257\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.6094, 9.5781], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:37.258\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.1250, 2.2773], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:41.061\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:41.062\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:41.064\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.9180, 12.7656], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:41.066\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.7314, 10.2734], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:42.163\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:42.164\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:42.168\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.6562, 7.9141], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:42.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.8188, -2.0586], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:45.535\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:45.536\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:45.538\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.9102, 9.8750], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:45.540\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.5625,  6.5273], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:46.954\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:46.955\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:46.957\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.4336, 10.4688], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:46.958\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.4492, 2.7441], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 69%|█████████████████████████████▌             | 33/48 [12:12<05:59, 23.93s/it]\u001b[32m2023-08-14 13:05:51.622\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:51.622\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:51.624\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.2891,  8.1406], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:51.625\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.0391, 10.6953], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:51.787\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:51.788\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:51.790\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9648, 8.4766], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:51.791\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.7188, 2.7285], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:55.976\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:55.976\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:55.977\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.4531, 10.8984], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:55.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.7520, 3.1680], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:56.488\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:05:56.488\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:05:56.491\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.3125, 8.2969], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:05:56.493\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.2188, 4.8516], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:00.372\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:00.375\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:00.377\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.3828,  4.0352], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:00.380\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 7.5195, -0.4492], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:01.549\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:01.553\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:01.556\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.6367, 9.8047], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:01.562\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.7368, 5.3555], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:04.840\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:04.841\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:04.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.9844, 13.4766], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:04.844\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([13.7812,  3.1855], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:06.514\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:06.514\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:06.517\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.1172, 11.0781], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:06.519\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([13.4453,  5.1016], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 71%|██████████████████████████████▍            | 34/48 [12:31<05:16, 22.60s/it]\u001b[32m2023-08-14 13:06:11.152\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:11.153\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:11.154\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.6289, 8.5078], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:11.156\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.1152, 3.0723], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:11.302\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:11.303\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:11.305\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.6562,  7.8281], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:11.307\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.9854, 3.0801], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:15.551\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:15.552\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:15.553\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.2188, 3.3105], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:15.554\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.5537, -3.4863], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:16.078\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:16.079\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:16.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.5938,  8.6172], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:16.083\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 1.9727, -1.8604], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:19.935\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:19.935\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:19.937\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.8359,  9.9062], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:19.939\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6797, 8.3281], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:20.796\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:20.797\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:20.800\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.7344, 11.7656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:20.802\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.6172,  0.1332], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:24.342\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:24.342\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:24.344\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.6172, 12.0234], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:24.346\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.6680, 1.6885], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:25.460\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:25.461\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:25.463\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.0156, 12.9297], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:25.465\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([13.6250, 11.4453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 73%|███████████████████████████████▎           | 35/48 [12:50<04:39, 21.53s/it]\u001b[32m2023-08-14 13:06:30.142\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:30.143\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:30.144\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.3320, 12.7188], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:30.145\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 2.5625, 10.2109], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:30.320\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:30.321\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:30.323\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.0234, 11.6016], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:30.325\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.2764, 2.2520], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:34.574\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:34.575\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:34.577\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.7402, 9.0156], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:34.579\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.2949,  0.1239], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:35.213\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:35.214\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:35.216\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.7383, 16.3125], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:35.218\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.1924, 0.7744], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:39.039\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:39.040\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:39.042\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.0469,  9.5938], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:39.044\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.3828, 6.0664], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:40.063\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:40.063\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:40.066\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.5391,  4.0391], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:40.067\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([15.3906,  0.2037], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:43.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:43.475\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:43.477\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.1953, 13.7578], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:43.479\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.6680, 12.6797], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:44.775\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:44.775\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:44.778\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9219, 9.3438], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:44.780\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.7935, -1.9678], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 75%|████████████████████████████████▎          | 36/48 [13:10<04:10, 20.85s/it]\u001b[32m2023-08-14 13:06:49.415\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:49.415\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:49.416\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.4531,  6.1836], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:49.418\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.2969,  1.7617], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:49.600\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:49.600\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:49.602\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.5000,  7.6406], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:49.604\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.9297, -4.0781], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:53.846\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:53.847\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:53.848\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.9531, 11.5703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:53.849\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.9961,  1.1045], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:54.349\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:54.350\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:54.352\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.0703, 7.3164], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:54.353\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.5605, -6.7070], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:58.232\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:58.233\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:58.235\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.1953, 13.3047], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:58.236\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.2969, 5.3906], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:59.177\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:06:59.179\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:06:59.182\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.7188, 15.3594], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:06:59.184\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.0352, 8.6797], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:02.643\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:02.644\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:02.646\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.1406, 15.5000], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:02.647\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.0625, 13.5469], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:04.137\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:04.138\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:04.140\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.6445, 9.4297], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:04.142\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.6816,  1.3467], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 77%|█████████████████████████████████▏         | 37/48 [13:29<03:45, 20.46s/it]\u001b[32m2023-08-14 13:07:08.979\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:08.980\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:08.981\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.8789, 11.7734], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:08.983\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.8672, 10.4453], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:09.141\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:09.141\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:09.143\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.2031, 13.8516], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:09.145\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.0469, 5.4688], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:13.332\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:13.333\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:13.334\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.5391, 16.9219], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:13.335\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.7412, 11.8594], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:13.854\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:13.855\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:13.857\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.1641, 9.6875], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:13.858\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.3584,  3.7109], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:17.708\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:17.709\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:17.712\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.2812, 15.0078], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:17.714\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.7461, 8.5625], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:18.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:18.616\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:18.618\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.0000, 12.5938], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:18.620\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.6660, 0.6382], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:22.087\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:22.088\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:22.090\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.1016, 15.9844], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:22.092\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.3750, 14.3516], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:23.356\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:23.356\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:23.358\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.7500, 12.0391], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:23.360\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.8037, 5.0234], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 79%|██████████████████████████████████         | 38/48 [13:48<03:20, 20.04s/it]\u001b[32m2023-08-14 13:07:28.020\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:28.020\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:28.022\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.6562, 12.2344], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:28.023\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.6250, 8.1250], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:28.190\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:28.190\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:28.192\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.6797, 11.2969], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:28.193\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.8428, 6.4180], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:32.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:32.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:32.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.4258, 4.9609], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:32.480\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.5752, -3.8125], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:33.140\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:33.140\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:33.143\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.8281, 13.4375], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:33.145\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.3320, 10.4219], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:36.960\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:36.964\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:36.966\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.1328, 12.6797], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:36.969\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.0767, 11.3359], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:38.103\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:38.106\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:38.109\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.4648, 12.6406], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:38.111\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.7817, 2.7637], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:41.390\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:41.390\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:41.393\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.2031, 6.7812], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:41.394\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.4932, 1.6074], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:42.938\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:42.939\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:42.945\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.6016,  9.7500], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:42.948\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 9.7891, -2.7051], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 81%|██████████████████████████████████▉        | 39/48 [14:08<02:59, 19.90s/it]\u001b[32m2023-08-14 13:07:47.604\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:47.607\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:47.609\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.5859, 13.8359], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:47.611\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.8486, 14.7812], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:47.769\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:47.770\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:47.772\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.4297, 10.7344], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:47.774\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([3.8262, 5.7891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:51.966\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:51.967\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:51.968\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.4844, 11.9219], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:51.969\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.8071, 8.8438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:52.503\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:52.504\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:52.505\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 4.1055, 11.4453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:52.507\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.2256, 10.1172], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:56.356\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:56.357\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:56.359\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([6.8984, 6.6680], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:56.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 3.3438, -3.3066], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:57.229\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:07:57.230\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:07:57.232\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.1016, 16.8281], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:07:57.234\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.0671, 12.9062], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:00.805\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:00.806\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:00.808\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.9375, 10.3047], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:00.810\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.2109, -0.0546], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:01.959\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:01.960\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:01.962\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.5547,  7.2891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:01.963\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.9688, 0.0536], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n{'loss': 0.116, 'learning_rate': 7.368421052631579e-06, 'epoch': 6.4}           \n 83%|███████████████████████████████████▊       | 40/48 [14:27<02:37, 19.67s/it]\u001b[32m2023-08-14 13:08:07.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:07.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:07.075\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.0286,  6.9629], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:07.076\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.8455, 2.9366], device='cuda:0')\u001b[0m\n\n  0%|                                                    | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[32m2023-08-14 13:08:07.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:07.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:07.308\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.0097, 13.4191], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:07.310\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.2962,  4.6960], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:09.169\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:09.170\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:09.171\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.9030, 6.9726], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:09.173\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.8663, -0.1214], device='cuda:0')\u001b[0m\n\n 15%|██████▊                                     | 2/13 [00:02<00:11,  1.05s/it]\u001b[A\u001b[32m2023-08-14 13:08:09.402\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:09.402\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:09.404\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.5715, 12.2212], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:09.408\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.0331, 5.3954], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:11.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:11.293\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:11.295\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.5272, 9.2764], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:11.296\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 1.3576, -1.5387], device='cuda:0')\u001b[0m\n\n 23%|██████████▏                                 | 3/13 [00:04<00:14,  1.49s/it]\u001b[A\u001b[32m2023-08-14 13:08:11.496\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:11.496\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:11.498\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([18.1090,  9.9500], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:11.499\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.0547, 9.9500], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:13.380\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:13.381\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:13.382\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([4.6537, 9.6020], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:13.384\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.3828,  3.4931], device='cuda:0')\u001b[0m\n\n 31%|█████████████▌                              | 4/13 [00:06<00:15,  1.72s/it]\u001b[A\u001b[32m2023-08-14 13:08:13.551\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:13.552\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:13.554\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.9721, 6.9613], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:13.555\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.6800,  1.5635], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:15.387\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:15.387\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:15.389\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.3655, 12.6038], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:15.390\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.2145,  6.9252], device='cuda:0')\u001b[0m\n\n 38%|████████████████▉                           | 5/13 [00:08<00:14,  1.82s/it]\u001b[A\u001b[32m2023-08-14 13:08:15.607\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:15.607\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:15.609\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.1427,  8.5296], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:15.611\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.1690, 4.7191], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:17.457\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:17.457\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:17.459\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.2173, 15.8474], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:17.460\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.3574, 9.9102], device='cuda:0')\u001b[0m\n\n 46%|████████████████████▎                       | 6/13 [00:10<00:13,  1.90s/it]\u001b[A\u001b[32m2023-08-14 13:08:17.663\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:17.663\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:17.665\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.9689, 6.3082], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:17.666\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.2840, -1.4944], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:19.501\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:19.501\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:19.503\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.1371, 16.6530], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:19.504\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.5032, 1.2142], device='cuda:0')\u001b[0m\n\n 54%|███████████████████████▋                    | 7/13 [00:12<00:11,  1.95s/it]\u001b[A\u001b[32m2023-08-14 13:08:19.730\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:19.730\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:19.732\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.2669, 10.4782], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:19.733\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.9906, 3.4701], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:21.589\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:21.589\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:21.591\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.7681,  8.3818], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:21.593\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3175, 3.5897], device='cuda:0')\u001b[0m\n\n 62%|███████████████████████████                 | 8/13 [00:14<00:09,  1.99s/it]\u001b[A\u001b[32m2023-08-14 13:08:21.799\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:21.799\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:21.801\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.8563, 11.9426], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:21.802\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.9661, 1.4972], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:23.632\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:23.632\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:23.634\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.0152, 10.8870], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:23.635\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.3785, 6.1743], device='cuda:0')\u001b[0m\n\n 69%|██████████████████████████████▍             | 9/13 [00:16<00:08,  2.01s/it]\u001b[A\u001b[32m2023-08-14 13:08:23.880\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:23.880\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:23.882\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.4432,  9.5823], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:23.883\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.2514,  0.0114], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:25.738\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:25.739\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:25.740\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.3536, 12.5442], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:25.741\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([13.4816,  2.6142], device='cuda:0')\u001b[0m\n\n 77%|█████████████████████████████████          | 10/13 [00:18<00:06,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:08:25.920\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:25.920\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:25.922\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.2729, 17.0536], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:25.923\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.0101, 14.9864], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:27.770\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:27.771\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:27.773\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.9914, 10.4826], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:27.774\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.8701,  1.6955], device='cuda:0')\u001b[0m\n\n 85%|████████████████████████████████████▍      | 11/13 [00:20<00:04,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:08:27.975\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:27.975\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:27.977\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.2545, 12.0265], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:27.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3008, 6.0086], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:29.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:29.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:29.833\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.5328,  8.8259], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:29.835\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.7896, 2.3068], device='cuda:0')\u001b[0m\n\n 92%|███████████████████████████████████████▋   | 12/13 [00:22<00:02,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:08:30.040\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:30.040\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:30.042\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([5.0523, 9.6763], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:30.043\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.4427,  2.8418], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:31.872\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:31.873\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:31.874\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 6.2492, 10.0073], device='cuda:0')\u001b[0m\n\u001b[32m2023-08-14 13:08:31.876\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.9378, 1.4390], device='cuda:0')\u001b[0m\n\n100%|███████████████████████████████████████████| 13/13 [00:24<00:00,  2.04s/it]\u001b[A\u001b[32m2023-08-14 13:08:32.089\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:32.089\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:32.091\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.0286,  6.9629], device='cuda:1')\u001b[0m\n\u001b[32m2023-08-14 13:08:32.093\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.8455, 2.9366], device='cuda:1')\u001b[0m\n                                                                                \n\u001b[A{'eval_loss': 0.03534507378935814, 'eval_accuracy': 0.96, 'eval_runtime': 26.8691, 'eval_samples_per_second': 1.861, 'eval_steps_per_second': 0.484, 'epoch': 6.4}\n 83%|███████████████████████████████████▊       | 40/48 [14:54<02:37, 19.67s/it]\n100%|███████████████████████████████████████████| 13/13 [00:25<00:00,  2.04s/it]\u001b[A\n                                                                                \u001b[A\u001b[32m2023-08-14 13:08:32.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m853\u001b[0m - \u001b[1mSaving model checkpoint to output-rm-1k-0812-v3/checkpoint-40\u001b[0m\n\u001b[32m2023-08-14 13:08:32.123\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m857\u001b[0m - \u001b[31m\u001b[1m 111  model has pretrained_model\u001b[0m\n\u001b[32m2023-08-14 13:08:32.124\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m864\u001b[0m - \u001b[31m\u001b[1m222 backbone_model, PeftModel\u001b[0m\n\u001b[32m2023-08-14 13:08:36.202\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:36.203\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:36.204\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.1875, 8.8359], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:36.205\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.2032, 4.4453], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:36.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:36.307\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:36.309\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([18.3438,  7.1289], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:36.310\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([12.5781,  2.4258], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:40.676\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:40.676\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:40.678\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.2578, 14.0938], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:40.679\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.9238, 6.5781], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:41.192\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:41.198\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:41.200\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.3398, 9.0469], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:41.209\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.5088,  0.6050], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:45.111\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:45.112\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:45.115\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.9766, 12.8438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:45.116\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.7969, 5.9141], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:46.116\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:46.116\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:46.118\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.1953, 14.4297], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:46.120\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.9688, 9.5000], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:49.522\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:49.523\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:49.525\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 2.5000, 15.1016], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:49.527\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-4.1367, 14.7344], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:50.754\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:50.755\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:50.757\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.0312, 11.2031], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:50.759\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([12.1719,  4.9844], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 85%|████████████████████████████████████▋      | 41/48 [15:16<03:18, 28.39s/it]\u001b[32m2023-08-14 13:08:55.473\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:55.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:55.476\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([3.9668, 7.5391], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:55.477\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.4648, -5.9961], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:55.623\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:55.624\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:55.626\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.0703, 10.0703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:55.628\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([6.3438, 1.2188], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:59.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:08:59.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:08:59.880\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.6406, 9.6484], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:08:59.881\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.5840, 0.0867], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:00.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:00.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:00.364\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.0000,  8.0703], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:00.365\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.8242, 6.1016], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:04.265\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:04.266\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:04.268\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.5391, 17.1875], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:04.269\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([12.2188, 11.3359], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:05.263\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:05.263\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:05.266\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.4062, 10.2656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:05.268\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.7305, 9.2266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:08.681\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:08.682\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:08.683\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.8828,  4.8047], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:08.687\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.0812, -2.5293], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:09.974\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:09.974\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:09.977\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.4688, 16.4062], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:09.978\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.4756, 1.2773], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 88%|█████████████████████████████████████▋     | 42/48 [15:35<02:33, 25.64s/it]\u001b[32m2023-08-14 13:09:14.717\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:14.717\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:14.720\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([18.7656,  9.1797], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:14.723\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([14.6094, -4.2500], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:14.875\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:14.876\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:14.877\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.4922, 10.6484], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:14.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.1484,  0.6699], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:19.096\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:19.096\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:19.097\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.3828, 13.0703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:19.098\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.6914,  3.9883], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:19.662\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:19.663\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:19.665\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.2891, 15.6094], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:19.667\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-4.7305, 11.4453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:23.469\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:23.469\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:23.472\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.1875,  9.2734], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:23.474\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([14.1641, 10.5000], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:24.350\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:24.351\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:24.353\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 7.9141, 10.8750], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:24.355\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.3149, 10.3672], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:27.863\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:27.864\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:27.866\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.2344, 11.1953], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:27.868\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.9727, 13.3672], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:29.111\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:29.111\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:29.113\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.1719, 11.7812], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:29.115\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.0391, 12.3203], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 90%|██████████████████████████████████████▌    | 43/48 [15:54<01:58, 23.66s/it]\u001b[32m2023-08-14 13:09:33.747\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:33.748\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:33.749\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([20.5312, 17.2812], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:33.750\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.7520, 2.0703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:33.914\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:33.915\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:33.917\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.0000,  6.6836], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:33.918\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.9844, -1.5625], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:38.119\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:38.119\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:38.121\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.8047,  8.3359], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:38.123\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.7969, 6.2852], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:38.698\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:38.698\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:38.700\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.6797, 3.7188], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:38.702\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.6548, -4.9219], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:42.530\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:42.530\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:42.532\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.0312, 11.5703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:42.534\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.8223, 12.6250], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:43.613\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:43.613\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:43.615\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.8750, 8.6094], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:43.617\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-1.0908,  2.3867], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:46.956\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:46.956\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:46.958\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.2031, 10.7734], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:46.960\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.3997, 6.3438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:48.499\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:48.499\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:48.501\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.1953, 11.3672], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:48.503\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([5.3398, 2.7891], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 92%|███████████████████████████████████████▍   | 44/48 [16:13<01:29, 22.38s/it]\u001b[32m2023-08-14 13:09:53.139\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:53.139\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:53.141\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.2422, 14.4297], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:53.142\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 2.6484, 11.2656], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:53.283\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:53.283\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:53.286\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.5234, 14.6797], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:53.288\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([13.4453,  6.0898], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:57.560\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:57.560\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:57.562\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.6875,  9.1953], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:57.563\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([9.4766, 4.1484], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:57.994\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:09:57.994\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:09:57.997\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 5.2656, 11.3125], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:09:57.999\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.0430, 2.4785], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:01.955\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:01.955\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:01.958\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.1641, 6.4805], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:01.959\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.6909, -6.5078], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:02.905\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:02.906\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:02.908\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.2344, 14.5625], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:02.910\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([14.2656,  5.2930], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:06.417\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:06.418\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:06.420\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.3281, 9.1797], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:06.422\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-3.8730,  2.0234], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:07.566\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:07.567\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:07.569\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.2031, 10.8516], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:07.571\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.8594, 6.7656], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 94%|████████████████████████████████████████▎  | 45/48 [16:32<01:04, 21.38s/it]\u001b[32m2023-08-14 13:10:12.157\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:12.158\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:12.159\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.0469, 15.7031], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:12.160\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.2891, 11.1797], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:12.350\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:12.350\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:12.353\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.8125, 6.7266], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:12.355\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-0.8726,  2.7441], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:16.581\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:16.583\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:16.589\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 9.3359, 18.6719], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:16.592\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 0.1875, 13.7969], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:17.188\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:17.193\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:17.195\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([7.5820, 4.0469], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:17.198\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.2148, -1.7695], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:20.964\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:20.965\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:20.968\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([16.1250, 17.0938], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:20.969\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.8281, 12.5781], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:22.093\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:22.094\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:22.096\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.7969, 12.4141], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:22.098\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.0781, 11.1328], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:25.360\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:25.361\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:25.363\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.3984, 18.1875], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:25.365\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.1250, 14.9688], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:26.868\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:26.868\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:26.871\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([14.5781,  9.4375], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:26.872\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 5.8164, -4.1758], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 96%|█████████████████████████████████████████▏ | 46/48 [16:52<00:41, 20.79s/it]\u001b[32m2023-08-14 13:10:31.597\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:31.597\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:31.599\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.4922, 13.0703], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:31.600\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.0938,  3.3672], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:31.784\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:31.784\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:31.786\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.8828, 14.4844], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:31.787\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.8569, 8.6641], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:35.984\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:35.985\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:35.988\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.0781, 5.0039], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:35.990\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 1.9551, -0.6724], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:36.621\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:36.621\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:36.623\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([13.3516,  8.3828], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:36.625\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([1.2109, 0.5371], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:40.449\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:40.450\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:40.452\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.5000, 12.3984], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:40.454\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([0.2524, 1.2568], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:41.456\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:41.456\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:41.463\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([12.8281, 18.1250], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:41.465\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([10.9062, 14.9844], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:44.868\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:44.868\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:44.871\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([9.1250, 9.2969], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:44.872\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([8.6328, 0.3682], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:46.093\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:46.094\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:46.096\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.5312,  9.9453], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:46.098\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 6.8945, -2.9922], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n 98%|██████████████████████████████████████████ | 47/48 [17:11<00:20, 20.32s/it]\u001b[32m2023-08-14 13:10:50.818\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:50.818\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:50.820\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([ 8.6719, 17.1562], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:50.821\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 9.6328, 17.5469], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:51.002\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:51.002\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:51.005\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.4844, 17.0781], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:51.007\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([11.3203,  8.8047], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:55.164\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:55.165\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:55.166\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.1719, 19.3438], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:55.167\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([7.5508, 3.3066], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:55.834\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:55.835\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:55.837\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([11.0547, 17.7500], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:55.839\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([4.1523, 1.7832], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:59.543\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:10:59.544\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:10:59.546\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.2969, 13.7109], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:10:59.548\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([2.8809, 3.3301], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:11:00.701\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:11:00.701\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:11:00.704\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([8.3047, 7.9141], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:11:00.705\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 2.6660, -5.4531], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:11:04.075\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:11:04.076\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:11:04.078\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([15.1641,  6.8750], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:11:04.080\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([ 4.4844, -3.2246], device='cuda:0', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:11:05.585\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m829\u001b[0m - \u001b[31m\u001b[1mline 820\u001b[0m\n\u001b[32m2023-08-14 13:11:05.586\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m831\u001b[0m - \u001b[31m\u001b[1mvalues from lmheadModel =torch.Size([400, 4])\u001b[0m\n\u001b[32m2023-08-14 13:11:05.588\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m832\u001b[0m - \u001b[31m\u001b[1mr_accept=tensor([10.8828, 10.5000], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n\u001b[32m2023-08-14 13:11:05.590\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m833\u001b[0m - \u001b[31m\u001b[1mr_reject=tensor([-2.9395, 10.9062], device='cuda:1', grad_fn=<SplitBackward0>)\u001b[0m\n100%|███████████████████████████████████████████| 48/48 [17:30<00:00, 20.05s/it]\u001b[32m2023-08-14 13:11:08.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_load_best_model\u001b[0m:\u001b[36m893\u001b[0m - \u001b[1mLoading best model from output-rm-1k-0812-v3/checkpoint-40 (score[here is best eval_loss]: 0.03534507378935814).\u001b[0m\n\u001b[32m2023-08-14 13:11:08.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_load_best_model\u001b[0m:\u001b[36m893\u001b[0m - \u001b[1mLoading best model from output-rm-1k-0812-v3/checkpoint-40 (score[here is best eval_loss]: 0.03534507378935814).\u001b[0m\n{'train_runtime': 1052.0693, 'train_samples_per_second': 0.76, 'train_steps_per_second': 0.046, 'train_loss': 0.6001418605446815, 'epoch': 7.68}\n100%|███████████████████████████████████████████| 48/48 [17:31<00:00, 21.91s/it]\n\u001b[32m2023-08-14 13:11:09.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m853\u001b[0m - \u001b[1mSaving model checkpoint to output-rm-1k-0812-v3\u001b[0m\n\u001b[32m2023-08-14 13:11:09.366\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m857\u001b[0m - \u001b[31m\u001b[1m 111  model has pretrained_model\u001b[0m\n\u001b[32m2023-08-14 13:11:09.367\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_save\u001b[0m:\u001b[36m864\u001b[0m - \u001b[31m\u001b[1m222 backbone_model, PeftModel\u001b[0m\n[2023-08-14 13:11:17,152] [INFO] [launch.py:347:main] Process 712 exits successfully.\n[2023-08-14 13:11:17,153] [INFO] [launch.py:347:main] Process 713 exits successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"ls output-rm-1k-0812-v2","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:10:23.515397Z","iopub.execute_input":"2023-08-13T14:10:23.516269Z","iopub.status.idle":"2023-08-13T14:10:24.562689Z","shell.execute_reply.started":"2023-08-13T14:10:23.516225Z","shell.execute_reply":"2023-08-13T14:10:24.561455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls /kaggle/working/chatGLM-6B-QLoRA/data/rlhf-reward-single-round-trans_chinese/","metadata":{"execution":{"iopub.status.busy":"2023-08-13T14:11:33.123558Z","iopub.execute_input":"2023-08-13T14:11:33.124792Z","iopub.status.idle":"2023-08-13T14:11:34.141889Z","shell.execute_reply.started":"2023-08-13T14:11:33.124738Z","shell.execute_reply":"2023-08-13T14:11:34.140571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PPO training ","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/trl.git","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2023-08-14T12:20:36.300600Z","iopub.execute_input":"2023-08-14T12:20:36.301051Z","iopub.status.idle":"2023-08-14T12:20:36.310372Z","shell.execute_reply.started":"2023-08-14T12:20:36.301011Z","shell.execute_reply":"2023-08-14T12:20:36.309241Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/chatGLM-6B-QLoRA'"},"metadata":{}}]},{"cell_type":"markdown","source":"# PPO能运行！千辛万苦改代码成功","metadata":{}},{"cell_type":"code","source":"!git pull --all --force\n!CUDA_VISIBLE_DEVICES=0,1 python ppo_chatglm2.py \\\n    --base_model_name THUDM/chatglm2-6b \\\n    --merged_sft_model_path THUDM/chatglm2-6b \\\n    --sft_model_lora_path output-rm-1k-0812-v3 \\\n    --reward_model_lora_path output-rm-1k-0812-v3 \\\n    --adafactor False \\\n    --save_freq 2 \\\n    --output_max_length 128 \\\n    --batch_size 1 \\\n    --gradient_accumulation_steps 1 \\\n    --batched_gen True \\\n    --ppo_epochs 2 \\\n    --seed 0 \\\n    --learning_rate 1e-5 \\\n    --early_stopping True \\\n    --output_dir ppo_0813_v1 \\\n    --log_with tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-08-14T17:28:42.498004Z","iopub.execute_input":"2023-08-14T17:28:42.498428Z","iopub.status.idle":"2023-08-14T17:42:08.373881Z","shell.execute_reply.started":"2023-08-14T17:28:42.498393Z","shell.execute_reply":"2023-08-14T17:42:08.372052Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Fetching origin\nremote: Enumerating objects: 5, done.\u001b[K\nremote: Counting objects: 100% (5/5), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (3/3), 737 bytes | 368.00 KiB/s, done.\nFrom https://github.com/valkryhx/chatGLM-6B-QLoRA\n   c152e02..0d44ebd  main       -> origin/main\nUpdating c152e02..0d44ebd\nFast-forward\n ppo_chatglm2.py | 1 \u001b[32m+\u001b[m\n 1 file changed, 1 insertion(+)\n[2023-08-14 17:28:47,349] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 118\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 28.81it/s]\nLoading base model for ppo training...\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:39<00:00, 14.22s/it]\n\u001b[32m2023-08-14 17:30:36.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mprepare_model_for_kbit_training...\u001b[0m\n\u001b[32m2023-08-14 17:31:31.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1madapter_weights.keys()=dict_keys(['base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.self_attention.dense.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.lora_B.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_A.weight', 'base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.lora_B.weight'])\u001b[0m\n\u001b[32m2023-08-14 17:31:31.452\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m310\u001b[0m - \u001b[31m\u001b[1mlora model complete\u001b[0m\n\u001b[32m2023-08-14 17:31:31.479\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m315\u001b[0m - \u001b[31m\u001b[1mv_head_weights={'summary.weight': tensor([[ 0.0090,  0.0042,  0.0155,  ..., -0.0063,  0.0089,  0.0090]]), 'summary.bias': tensor([0.0048])}\u001b[0m\nLoading checkpoint shards: 100%|██████████████████| 7/7 [01:42<00:00, 14.71s/it]\n\u001b[32m2023-08-14 17:33:15.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m414\u001b[0m - \u001b[1mprepare_reward_model_for_kbit_training...\u001b[0m\n\u001b[32m2023-08-14 17:33:18.885\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m437\u001b[0m - \u001b[31m\u001b[1mlora reward_model complete\u001b[0m\n\u001b[32m2023-08-14 17:33:18.899\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m442\u001b[0m - \u001b[31m\u001b[1mv_head_weights={'summary.weight': tensor([[ 0.0090,  0.0042,  0.0155,  ..., -0.0063,  0.0089,  0.0090]]), 'summary.bias': tensor([0.0048])}\u001b[0m\n\u001b[32m2023-08-14 17:33:18.899\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m445\u001b[0m - \u001b[31m\u001b[1mreward model complete!\u001b[0m\n0it [00:00, ?it/s]\u001b[32m2023-08-14 17:33:18.906\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 34953, 54628, 49682, 55341, 55868,\n        55228, 57492, 31867, 55282, 31514,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:15.334\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910,    13,    13, 33362, 31784, 46637, 54530, 55341, 55868, 55228,\n        57492, 31867, 30954,    13,    13, 30939, 30930, 32816, 54826, 55415,\n        58039, 55852, 55937, 54612, 31952,   560, 30910, 32910, 30954, 37134,\n        54663, 30932, 37451, 30954, 55266, 56322, 56692, 31155, 54960, 31952,\n        54532, 41250, 32221, 32458, 49316, 58039, 55852, 55937, 33273, 30932,\n        54732, 55341, 54562, 33839, 54585, 54875, 36960, 31155,    13,    13,\n        30943, 30930, 32816, 33768, 31872, 54612, 31952,   560, 30910, 32910,\n        30954, 55694, 55773, 55734, 30932, 37451, 30954, 54940, 57066, 31201,\n        55293, 32721, 31155, 54960, 31952, 54781, 32759, 31776, 33768, 54542,\n        32759, 31730, 36426, 32242, 54856, 52918, 31743, 32667, 30932, 31705,\n        32698, 33170, 55228, 57492, 54900, 31155,    13,    13, 30966, 30930,\n        32816, 30944, 10198, 55228, 55415, 54786, 54612, 31952,   560, 30910,\n        32910, 30954, 55235, 54662, 31065, 55403, 55075, 54702, 30932, 37451,\n        30954, 55937, 55264, 31065, 56052, 51145, 31155, 35562, 54605, 31685,\n        40778, 38119, 33839, 30932, 51863, 31721, 34597, 32999, 33231, 33273,\n        30932, 33705, 38628, 30944, 10198, 30946, 55026, 31799, 32191, 54542,\n        32381, 37687, 35564, 32482, 33096, 33217,    13,    13, 30972, 30930,\n        32816, 55255, 55268, 33577, 54612, 31952,   560, 30910, 32910, 30954,\n        55540, 54775, 55446, 30932, 37451, 30954, 57483, 56248, 31065, 54703,\n        40867, 31155, 54960, 31952, 33719, 32547, 55255, 55268, 41353, 42512,\n        33577, 33273, 30932, 31705, 31776, 55255, 55268, 43192, 32698, 39559,\n        31155,    13,    13, 30970, 30930, 32816, 57709, 54538, 58134, 54612,\n        31952,   560, 30910, 32910, 30954, 43273, 31065, 56187, 31845, 30932,\n        37451, 30954, 55246, 42249, 31065, 56072, 55777, 56408, 31155, 54960,\n        31952, 41536, 31685, 36960, 54530, 47904, 33170, 31867, 30932, 33705,\n        55743, 55804, 31065, 56187, 54827, 57726, 54733, 38628, 32035, 33560,\n        31730, 52918, 31155,    13,    13, 30978, 30930, 32816, 55602, 55255,\n        55219, 54612, 31952,   560, 30910, 32910, 30954, 55493, 55088, 54544,\n        30932, 37451, 30954, 55041, 55008, 56548, 31155, 54960, 31952, 41536,\n        31685, 37116, 54530, 32021, 32589, 55183, 30932, 32998, 34529, 32021,\n        54561, 31750, 31974, 55602, 55255, 55219, 32552, 47506, 36270, 31155,\n            2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:15.343\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 34953, 54628, 49682, 55341, 55868,\n        55228, 57492, 31867, 55282, 31514,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:15.348\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910,    13,    13, 33362, 31784, 46637, 54530, 55341, 55868, 55228,\n        57492, 31867, 30954,    13,    13, 30939, 30930, 32816, 54826, 55415,\n        58039, 55852, 55937, 54612, 31952,   560, 30910, 32910, 30954, 37134,\n        54663, 30932, 37451, 30954, 55266, 56322, 56692, 31155, 54960, 31952,\n        54532, 41250, 32221, 32458, 49316, 58039, 55852, 55937, 33273, 30932,\n        54732, 55341, 54562, 33839, 54585, 54875, 36960, 31155,    13,    13,\n        30943, 30930, 32816, 33768, 31872, 54612, 31952,   560, 30910, 32910,\n        30954, 55694, 55773, 55734, 30932, 37451, 30954, 54940, 57066, 31201,\n        55293, 32721, 31155, 54960, 31952, 54781, 32759, 31776, 33768, 54542,\n        32759, 31730, 36426, 32242, 54856, 52918, 31743, 32667, 30932, 31705,\n        32698, 33170, 55228, 57492, 54900, 31155,    13,    13, 30966, 30930,\n        32816, 30944, 10198, 55228, 55415, 54786, 54612, 31952,   560, 30910,\n        32910, 30954, 55235, 54662, 31065, 55403, 55075, 54702, 30932, 37451,\n        30954, 55937, 55264, 31065, 56052, 51145, 31155, 35562, 54605, 31685,\n        40778, 38119, 33839, 30932, 51863, 31721, 34597, 32999, 33231, 33273,\n        30932, 33705, 38628, 30944, 10198, 30946, 55026, 31799, 32191, 54542,\n        32381, 37687, 35564, 32482, 33096, 33217,    13,    13, 30972, 30930,\n        32816, 55255, 55268, 33577, 54612, 31952,   560, 30910, 32910, 30954,\n        55540, 54775, 55446, 30932, 37451, 30954, 57483, 56248, 31065, 54703,\n        40867, 31155, 54960, 31952, 33719, 32547, 55255, 55268, 41353, 42512,\n        33577, 33273, 30932, 31705, 31776, 55255, 55268, 43192, 32698, 39559,\n        31155,    13,    13, 30970, 30930, 32816, 57709, 54538, 58134, 54612,\n        31952,   560, 30910, 32910, 30954, 43273, 31065, 56187, 31845, 30932,\n        37451, 30954, 55246, 42249, 31065, 56072, 55777, 56408, 31155, 54960,\n        31952, 41536, 31685, 36960, 54530, 47904, 33170, 31867, 30932, 33705,\n        55743, 55804, 31065, 56187, 54827, 57726, 54733, 38628, 32035, 33560,\n        31730, 52918, 31155,    13,    13, 30978, 30930, 32816, 55602, 55255,\n        55219, 54612, 31952,   560, 30910, 32910, 30954, 55493, 55088, 54544,\n        30932, 37451, 30954, 55041, 55008, 56548, 31155, 54960, 31952, 41536,\n        31685, 37116, 54530, 32021, 32589, 55183, 30932, 32998, 34529, 32021,\n        54561, 31750, 31974, 55602, 55255, 55219, 32552, 47506, 36270, 31155,\n            2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:15.838\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 3.4225e+01,  4.7014e+01,  9.1332e-01,  5.2880e-02,  1.7725e+00,\n         5.5250e+00,  8.6551e-01,  1.5666e+00,  1.2277e+00,  2.3133e-01,\n         3.9361e+00, -1.3741e+00,  4.2013e+00,  3.9853e-02, -6.4408e+00,\n        -2.0945e+00, -4.6691e-01,  2.5163e+00, -1.8086e+00, -8.0590e+00,\n        -2.9714e+00, -6.3038e+00,  1.5434e+00, -1.2521e+00,  1.7173e+00,\n        -3.1428e-01,  3.6429e+00, -1.6390e+00,  4.3302e+00,  4.2990e-01,\n        -2.2837e+00, -3.1963e+00, -2.7681e-01, -2.0802e+00, -5.8379e+00,\n        -1.4605e+01, -1.0083e+01, -5.2075e+00, -5.2626e+00, -5.7509e-01,\n         3.6207e-01,  3.4033e+00,  1.4220e+00, -7.5951e-01,  2.3206e+00,\n        -2.2388e+00,  3.8159e+00, -1.2706e+00, -5.8988e-01, -2.9757e+00,\n        -8.5567e-01,  2.4251e+00,  2.1001e+00, -7.5810e-01,  3.6202e+00,\n         2.0968e+00, -6.0719e+00, -1.7860e+00,  4.5301e+00, -6.0549e-01,\n        -5.2571e+00, -3.3171e+00, -3.6449e+00,  1.8419e-01,  2.6915e+00,\n         4.7408e+00,  6.0890e-01,  2.0136e+00,  5.7783e+00,  1.0450e+01,\n         4.8943e+00,  3.5667e+00,  1.2911e+01, -1.4485e-01,  4.3416e+00,\n         4.9963e+00,  2.3464e+00, -9.8178e-01, -2.3350e+00, -2.0892e-01,\n        -2.5187e+00, -4.8526e+00, -4.9052e+00, -5.2476e-01, -1.5362e+00,\n        -2.4193e+00,  3.0176e-02, -3.6128e+00,  8.3082e-01, -3.4830e+00,\n        -3.3084e+00, -2.0244e-01, -3.7665e-01, -4.1204e+00,  2.7728e+00,\n         3.9957e+00,  6.1079e+00,  1.7904e+00, -2.6034e-01,  2.1171e+00,\n         1.6748e-01, -7.5473e+00,  1.2632e+00,  2.2401e+00, -5.8229e+00,\n        -3.1065e+00, -5.2495e+00,  1.6689e+00,  1.3526e+00,  3.2165e+00,\n        -5.5349e+00, -4.4114e+00, -3.5930e-01, -4.0353e+00,  1.5788e-01,\n         2.7166e+00, -2.1398e+00, -5.5854e+00, -1.0972e+00, -2.1997e+00,\n         1.8583e+00,  5.0481e+00, -3.3895e+00, -7.0574e-01,  1.9053e+00,\n        -1.6335e+00, -3.9091e-01, -1.9527e+00, -4.4480e+00, -6.9645e+00,\n         2.5362e-01, -2.8389e+00, -7.5892e-01,  4.0958e+00,  1.5709e+00,\n        -1.8096e+00, -1.4907e+00, -1.7102e-02, -3.6162e+00, -4.5761e-01,\n        -2.9409e+00,  2.3037e+00,  5.8189e+00,  9.4996e-01, -2.9325e+00,\n        -3.1376e-01,  8.4613e-01, -3.7548e+00, -6.7821e-01, -2.5628e+00,\n        -2.0950e+00, -6.1201e+00, -9.5605e-01, -2.4203e+00,  4.0319e+00,\n        -4.5844e+00,  1.5039e+00, -2.4791e+00,  2.5805e+00, -3.2106e+00,\n         4.5097e-01, -8.0356e-01,  3.1237e-01,  2.3460e+00, -4.4378e+00,\n         5.6236e-01,  5.8136e+00, -6.0998e+00,  5.9978e-01,  4.2684e+00,\n         1.4485e+00, -1.5429e+00,  1.0980e+01, -1.2573e+00, -2.4952e+00,\n         9.4527e-01, -3.8461e+00,  1.0246e+00, -2.1204e-01,  8.8314e-01,\n         5.6841e-01, -8.9751e+00,  2.3787e+00, -1.3709e+00, -2.7297e+00,\n        -7.0708e-01,  4.6175e+00, -1.0703e+00, -9.3798e-02, -4.7661e+00,\n        -1.0180e+01, -1.2055e+00,  1.1210e+00, -1.2766e+00, -2.2409e+00,\n        -7.9275e-01, -3.5694e-01,  2.8282e+00,  1.6509e+00, -8.6484e+00,\n        -3.7890e-01,  9.2439e-01, -5.0756e+00,  1.7729e+00,  8.9550e-01,\n         1.6217e+00,  2.8821e-01, -4.6995e+00,  4.9996e+00, -3.2946e-01,\n        -2.6868e+00,  4.2359e+00,  1.6986e+00, -1.7480e+00,  6.8499e+00,\n         3.3172e+00, -1.9181e+00,  8.2668e+00, -4.5789e+00,  4.3460e+00,\n         4.7758e+00,  4.9560e+00, -3.3324e+00,  3.1827e+00, -1.4832e+00,\n        -5.8185e-01, -1.0019e+01, -2.6322e+00,  4.6050e+00,  1.6725e+00,\n        -1.7762e-01,  7.4808e-01, -4.5542e+00, -8.7054e-01, -6.9265e-01,\n        -3.8895e-01, -4.9072e+00, -2.0234e+00, -9.1253e-01, -1.0855e+00,\n        -2.7951e+00, -6.0297e+00, -3.8092e+00, -2.7109e-01, -2.6828e+00,\n        -2.9903e+00, -4.3523e+00,  6.4567e+00, -5.5042e+00,  1.6748e+00,\n         1.6439e+00, -6.8131e+00,  1.5265e-01,  4.3887e-01,  2.7131e+00,\n         3.0274e+00,  2.3235e+00, -1.4779e+00, -2.4920e+00, -4.4219e+00,\n        -2.8739e+00,  8.5089e-01, -2.5209e+00,  6.7869e-01,  1.5752e+00,\n        -2.6332e-01,  4.2962e+00, -5.3603e+00,  5.7300e-01, -4.8388e+00,\n         6.3232e+00,  6.0677e+00, -8.7256e-01,  3.0702e+00,  1.5100e+00,\n         1.8836e-02, -5.4824e+00,  2.1659e+00,  1.0211e+00, -3.2480e-01,\n         6.1887e+00,  4.7091e-01,  2.0564e+00, -8.4224e-01,  1.4325e+00,\n        -1.4299e+00, -6.0377e+00,  5.3009e+00,  3.6579e-01,  1.3094e+00,\n        -5.2800e+00, -2.5490e+00, -5.2742e-02, -3.7514e+00, -2.5336e+00,\n        -5.7705e+00, -2.9970e+00,  4.7879e+00,  9.5048e-01, -5.7322e+00,\n         2.3611e+00,  4.4159e+00,  9.7155e-01, -2.1497e+00,  3.4214e+00,\n        -1.1093e-01,  4.2127e+00,  1.9375e+00,  4.4974e-01,  4.9478e+00,\n         1.1365e+00, -5.4101e+00, -2.5649e+00, -5.1486e+00,  3.6386e+00,\n        -1.5871e+00, -6.4748e+00,  2.4485e+00, -6.2459e+00,  2.6561e+00,\n        -1.5355e+00, -4.8367e+00,  2.6224e+00,  5.5857e+00,  6.6847e-01,\n        -1.9273e+00,  8.0236e+00,  4.8748e+00, -1.7222e+00, -1.5894e-01],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:15.838\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:34:15.839\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:34:15.847\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 3.4225e+01,  4.7014e+01,  9.1332e-01,  5.2880e-02,  1.7725e+00,\n         5.5250e+00,  8.6551e-01,  1.5666e+00,  1.2277e+00,  2.3133e-01,\n         3.9361e+00, -1.3741e+00,  4.2013e+00,  3.9853e-02, -6.4408e+00,\n        -2.0945e+00, -4.6691e-01,  2.5163e+00, -1.8086e+00, -8.0590e+00,\n        -2.9714e+00, -6.3038e+00,  1.5434e+00, -1.2521e+00,  1.7173e+00,\n        -3.1428e-01,  3.6429e+00, -1.6390e+00,  4.3302e+00,  4.2990e-01,\n        -2.2837e+00, -3.1963e+00, -2.7681e-01, -2.0802e+00, -5.8379e+00,\n        -1.4605e+01, -1.0083e+01, -5.2075e+00, -5.2626e+00, -5.7509e-01,\n         3.6207e-01,  3.4033e+00,  1.4220e+00, -7.5951e-01,  2.3206e+00,\n        -2.2388e+00,  3.8159e+00, -1.2706e+00, -5.8988e-01, -2.9757e+00,\n        -8.5567e-01,  2.4251e+00,  2.1001e+00, -7.5810e-01,  3.6202e+00,\n         2.0968e+00, -6.0719e+00, -1.7860e+00,  4.5301e+00, -6.0549e-01,\n        -5.2571e+00, -3.3171e+00, -3.6449e+00,  1.8419e-01,  2.6915e+00,\n         4.7408e+00,  6.0890e-01,  2.0136e+00,  5.7783e+00,  1.0450e+01,\n         4.8943e+00,  3.5667e+00,  1.2911e+01, -1.4485e-01,  4.3416e+00,\n         4.9963e+00,  2.3464e+00, -9.8178e-01, -2.3350e+00, -2.0892e-01,\n        -2.5187e+00, -4.8526e+00, -4.9052e+00, -5.2476e-01, -1.5362e+00,\n        -2.4193e+00,  3.0176e-02, -3.6128e+00,  8.3082e-01, -3.4830e+00,\n        -3.3084e+00, -2.0244e-01, -3.7665e-01, -4.1204e+00,  2.7728e+00,\n         3.9957e+00,  6.1079e+00,  1.7904e+00, -2.6034e-01,  2.1171e+00,\n         1.6748e-01, -7.5473e+00,  1.2632e+00,  2.2401e+00, -5.8229e+00,\n        -3.1065e+00, -5.2495e+00,  1.6689e+00,  1.3526e+00,  3.2165e+00,\n        -5.5349e+00, -4.4114e+00, -3.5930e-01, -4.0353e+00,  1.5788e-01,\n         2.7166e+00, -2.1398e+00, -5.5854e+00, -1.0972e+00, -2.1997e+00,\n         1.8583e+00,  5.0481e+00, -3.3895e+00, -7.0574e-01,  1.9053e+00,\n        -1.6335e+00, -3.9091e-01, -1.9527e+00, -4.4480e+00, -6.9645e+00,\n         2.5362e-01, -2.8389e+00, -7.5892e-01,  4.0958e+00,  1.5709e+00,\n        -1.8096e+00, -1.4907e+00, -1.7102e-02, -3.6162e+00, -4.5761e-01,\n        -2.9409e+00,  2.3037e+00,  5.8189e+00,  9.4996e-01, -2.9325e+00,\n        -3.1376e-01,  8.4613e-01, -3.7548e+00, -6.7821e-01, -2.5628e+00,\n        -2.0950e+00, -6.1201e+00, -9.5605e-01, -2.4203e+00,  4.0319e+00,\n        -4.5844e+00,  1.5039e+00, -2.4791e+00,  2.5805e+00, -3.2106e+00,\n         4.5097e-01, -8.0356e-01,  3.1237e-01,  2.3460e+00, -4.4378e+00,\n         5.6236e-01,  5.8136e+00, -6.0998e+00,  5.9978e-01,  4.2684e+00,\n         1.4485e+00, -1.5429e+00,  1.0980e+01, -1.2573e+00, -2.4952e+00,\n         9.4527e-01, -3.8461e+00,  1.0246e+00, -2.1204e-01,  8.8314e-01,\n         5.6841e-01, -8.9751e+00,  2.3787e+00, -1.3709e+00, -2.7297e+00,\n        -7.0708e-01,  4.6175e+00, -1.0703e+00, -9.3798e-02, -4.7661e+00,\n        -1.0180e+01, -1.2055e+00,  1.1210e+00, -1.2766e+00, -2.2409e+00,\n        -7.9275e-01, -3.5694e-01,  2.8282e+00,  1.6509e+00, -8.6484e+00,\n        -3.7890e-01,  9.2439e-01, -5.0756e+00,  1.7729e+00,  8.9550e-01,\n         1.6217e+00,  2.8821e-01, -4.6995e+00,  4.9996e+00, -3.2946e-01,\n        -2.6868e+00,  4.2359e+00,  1.6986e+00, -1.7480e+00,  6.8499e+00,\n         3.3172e+00, -1.9181e+00,  8.2668e+00, -4.5789e+00,  4.3460e+00,\n         4.7758e+00,  4.9560e+00, -3.3324e+00,  3.1827e+00, -1.4832e+00,\n        -5.8185e-01, -1.0019e+01, -2.6322e+00,  4.6050e+00,  1.6725e+00,\n        -1.7762e-01,  7.4808e-01, -4.5542e+00, -8.7054e-01, -6.9265e-01,\n        -3.8895e-01, -4.9072e+00, -2.0234e+00, -9.1253e-01, -1.0855e+00,\n        -2.7951e+00, -6.0297e+00, -3.8092e+00, -2.7109e-01, -2.6828e+00,\n        -2.9903e+00, -4.3523e+00,  6.4567e+00, -5.5042e+00,  1.6748e+00,\n         1.6439e+00, -6.8131e+00,  1.5265e-01,  4.3887e-01,  2.7131e+00,\n         3.0274e+00,  2.3235e+00, -1.4779e+00, -2.4920e+00, -4.4219e+00,\n        -2.8739e+00,  8.5089e-01, -2.5209e+00,  6.7869e-01,  1.5752e+00,\n        -2.6332e-01,  4.2962e+00, -5.3603e+00,  5.7300e-01, -4.8388e+00,\n         6.3232e+00,  6.0677e+00, -8.7256e-01,  3.0702e+00,  1.5100e+00,\n         1.8836e-02, -5.4824e+00,  2.1659e+00,  1.0211e+00, -3.2480e-01,\n         6.1887e+00,  4.7091e-01,  2.0564e+00, -8.4224e-01,  1.4325e+00,\n        -1.4299e+00, -6.0377e+00,  5.3009e+00,  3.6579e-01,  1.3094e+00,\n        -5.2800e+00, -2.5490e+00, -5.2742e-02, -3.7514e+00, -2.5336e+00,\n        -5.7705e+00, -2.9970e+00,  4.7879e+00,  9.5048e-01, -5.7322e+00,\n         2.3611e+00,  4.4159e+00,  9.7155e-01, -2.1497e+00,  3.4214e+00,\n        -1.1093e-01,  4.2127e+00,  1.9375e+00,  4.4974e-01,  4.9478e+00,\n         1.1365e+00, -5.4101e+00, -2.5649e+00, -5.1486e+00,  3.6386e+00,\n        -1.5871e+00, -6.4748e+00,  2.4485e+00, -6.2459e+00,  2.6561e+00,\n        -1.5355e+00, -4.8367e+00,  2.6224e+00,  5.5857e+00,  6.6847e-01,\n        -1.9273e+00,  8.0236e+00,  4.8748e+00, -1.7222e+00, -1.5894e-01],\n       device='cuda:0')]\u001b[0m\nepoch:  0 \nquery: 问：有哪些最棒的拍档警匪电影呢？\n\n答：\nresponse: \n\n整理一些最受欢迎的拍档警匪电影:\n\n1. 《神探狄仁杰》系列 - 导演:王朝安,编剧:陈燕霞。该系列是唐朝时期著名侦探狄仁杰的故事,被拍成电视剧后广受欢迎。\n\n2. 《警察故事》系列 - 导演:吴宇森,编剧:张炭、刘奋斗。该系列由一名香港警察和一名美国联邦调查局特工合作组成,成为经典动作警匪片。\n\n3. 《MIB警探组》系列 - 导演:巴里·索尔金,编剧:杰夫·贝维斯。这是一部非常有趣的科幻电视剧,围绕着国际恐怖分子展开的故事,主角是一名MIB(超自然生物和人类情报组织的特殊部队)。\n\n4. 《黑帮家族》系列 - 导演:叶世荣,编剧:詹姆·比尔德。该系列讲述了一个黑帮老大和他的家族的故事,成为香港黑帮电影的经典之作。\n\n5. 《碟中谍》系列 - 导演:詹姆斯·麦基本,编剧:罗伯特·瓦默臣。该系列是一部非常受欢迎的间谍动作电影,主角伊凡·麦格涅利是一名经验丰富的美国特工。\n\n6. 《洗黑钱》系列 - 导演:杨念生,编剧:李志毅。该系列是一部非常震撼的金融犯罪剧,展现了一些金融家如何利用洗黑钱的方式贪污腐败。\nscore: tensor([ 3.4225e+01,  4.7014e+01,  9.1332e-01,  5.2880e-02,  1.7725e+00,\n         5.5250e+00,  8.6551e-01,  1.5666e+00,  1.2277e+00,  2.3133e-01,\n         3.9361e+00, -1.3741e+00,  4.2013e+00,  3.9853e-02, -6.4408e+00,\n        -2.0945e+00, -4.6691e-01,  2.5163e+00, -1.8086e+00, -8.0590e+00,\n        -2.9714e+00, -6.3038e+00,  1.5434e+00, -1.2521e+00,  1.7173e+00,\n        -3.1428e-01,  3.6429e+00, -1.6390e+00,  4.3302e+00,  4.2990e-01,\n        -2.2837e+00, -3.1963e+00, -2.7681e-01, -2.0802e+00, -5.8379e+00,\n        -1.4605e+01, -1.0083e+01, -5.2075e+00, -5.2626e+00, -5.7509e-01,\n         3.6207e-01,  3.4033e+00,  1.4220e+00, -7.5951e-01,  2.3206e+00,\n        -2.2388e+00,  3.8159e+00, -1.2706e+00, -5.8988e-01, -2.9757e+00,\n        -8.5567e-01,  2.4251e+00,  2.1001e+00, -7.5810e-01,  3.6202e+00,\n         2.0968e+00, -6.0719e+00, -1.7860e+00,  4.5301e+00, -6.0549e-01,\n        -5.2571e+00, -3.3171e+00, -3.6449e+00,  1.8419e-01,  2.6915e+00,\n         4.7408e+00,  6.0890e-01,  2.0136e+00,  5.7783e+00,  1.0450e+01,\n         4.8943e+00,  3.5667e+00,  1.2911e+01, -1.4485e-01,  4.3416e+00,\n         4.9963e+00,  2.3464e+00, -9.8178e-01, -2.3350e+00, -2.0892e-01,\n        -2.5187e+00, -4.8526e+00, -4.9052e+00, -5.2476e-01, -1.5362e+00,\n        -2.4193e+00,  3.0176e-02, -3.6128e+00,  8.3082e-01, -3.4830e+00,\n        -3.3084e+00, -2.0244e-01, -3.7665e-01, -4.1204e+00,  2.7728e+00,\n         3.9957e+00,  6.1079e+00,  1.7904e+00, -2.6034e-01,  2.1171e+00,\n         1.6748e-01, -7.5473e+00,  1.2632e+00,  2.2401e+00, -5.8229e+00,\n        -3.1065e+00, -5.2495e+00,  1.6689e+00,  1.3526e+00,  3.2165e+00,\n        -5.5349e+00, -4.4114e+00, -3.5930e-01, -4.0353e+00,  1.5788e-01,\n         2.7166e+00, -2.1398e+00, -5.5854e+00, -1.0972e+00, -2.1997e+00,\n         1.8583e+00,  5.0481e+00, -3.3895e+00, -7.0574e-01,  1.9053e+00,\n        -1.6335e+00, -3.9091e-01, -1.9527e+00, -4.4480e+00, -6.9645e+00,\n         2.5362e-01, -2.8389e+00, -7.5892e-01,  4.0958e+00,  1.5709e+00,\n        -1.8096e+00, -1.4907e+00, -1.7102e-02, -3.6162e+00, -4.5761e-01,\n        -2.9409e+00,  2.3037e+00,  5.8189e+00,  9.4996e-01, -2.9325e+00,\n        -3.1376e-01,  8.4613e-01, -3.7548e+00, -6.7821e-01, -2.5628e+00,\n        -2.0950e+00, -6.1201e+00, -9.5605e-01, -2.4203e+00,  4.0319e+00,\n        -4.5844e+00,  1.5039e+00, -2.4791e+00,  2.5805e+00, -3.2106e+00,\n         4.5097e-01, -8.0356e-01,  3.1237e-01,  2.3460e+00, -4.4378e+00,\n         5.6236e-01,  5.8136e+00, -6.0998e+00,  5.9978e-01,  4.2684e+00,\n         1.4485e+00, -1.5429e+00,  1.0980e+01, -1.2573e+00, -2.4952e+00,\n         9.4527e-01, -3.8461e+00,  1.0246e+00, -2.1204e-01,  8.8314e-01,\n         5.6841e-01, -8.9751e+00,  2.3787e+00, -1.3709e+00, -2.7297e+00,\n        -7.0708e-01,  4.6175e+00, -1.0703e+00, -9.3798e-02, -4.7661e+00,\n        -1.0180e+01, -1.2055e+00,  1.1210e+00, -1.2766e+00, -2.2409e+00,\n        -7.9275e-01, -3.5694e-01,  2.8282e+00,  1.6509e+00, -8.6484e+00,\n        -3.7890e-01,  9.2439e-01, -5.0756e+00,  1.7729e+00,  8.9550e-01,\n         1.6217e+00,  2.8821e-01, -4.6995e+00,  4.9996e+00, -3.2946e-01,\n        -2.6868e+00,  4.2359e+00,  1.6986e+00, -1.7480e+00,  6.8499e+00,\n         3.3172e+00, -1.9181e+00,  8.2668e+00, -4.5789e+00,  4.3460e+00,\n         4.7758e+00,  4.9560e+00, -3.3324e+00,  3.1827e+00, -1.4832e+00,\n        -5.8185e-01, -1.0019e+01, -2.6322e+00,  4.6050e+00,  1.6725e+00,\n        -1.7762e-01,  7.4808e-01, -4.5542e+00, -8.7054e-01, -6.9265e-01,\n        -3.8895e-01, -4.9072e+00, -2.0234e+00, -9.1253e-01, -1.0855e+00,\n        -2.7951e+00, -6.0297e+00, -3.8092e+00, -2.7109e-01, -2.6828e+00,\n        -2.9903e+00, -4.3523e+00,  6.4567e+00, -5.5042e+00,  1.6748e+00,\n         1.6439e+00, -6.8131e+00,  1.5265e-01,  4.3887e-01,  2.7131e+00,\n         3.0274e+00,  2.3235e+00, -1.4779e+00, -2.4920e+00, -4.4219e+00,\n        -2.8739e+00,  8.5089e-01, -2.5209e+00,  6.7869e-01,  1.5752e+00,\n        -2.6332e-01,  4.2962e+00, -5.3603e+00,  5.7300e-01, -4.8388e+00,\n         6.3232e+00,  6.0677e+00, -8.7256e-01,  3.0702e+00,  1.5100e+00,\n         1.8836e-02, -5.4824e+00,  2.1659e+00,  1.0211e+00, -3.2480e-01,\n         6.1887e+00,  4.7091e-01,  2.0564e+00, -8.4224e-01,  1.4325e+00,\n        -1.4299e+00, -6.0377e+00,  5.3009e+00,  3.6579e-01,  1.3094e+00,\n        -5.2800e+00, -2.5490e+00, -5.2742e-02, -3.7514e+00, -2.5336e+00,\n        -5.7705e+00, -2.9970e+00,  4.7879e+00,  9.5048e-01, -5.7322e+00,\n         2.3611e+00,  4.4159e+00,  9.7155e-01, -2.1497e+00,  3.4214e+00,\n        -1.1093e-01,  4.2127e+00,  1.9375e+00,  4.4974e-01,  4.9478e+00,\n         1.1365e+00, -5.4101e+00, -2.5649e+00, -5.1486e+00,  3.6386e+00,\n        -1.5871e+00, -6.4748e+00,  2.4485e+00, -6.2459e+00,  2.6561e+00,\n        -1.5355e+00, -4.8367e+00,  2.6224e+00,  5.5857e+00,  6.6847e-01,\n        -1.9273e+00,  8.0236e+00,  4.8748e+00, -1.7222e+00, -1.5894e-01],\n       device='cuda:0')\n\u001b[32m2023-08-14 17:34:15.856\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:34:15.863\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 3.4225e+01,  4.7014e+01,  9.1332e-01,  5.2880e-02,  1.7725e+00,\n         5.5250e+00,  8.6551e-01,  1.5666e+00,  1.2277e+00,  2.3133e-01,\n         3.9361e+00, -1.3741e+00,  4.2013e+00,  3.9853e-02, -6.4408e+00,\n        -2.0945e+00, -4.6691e-01,  2.5163e+00, -1.8086e+00, -8.0590e+00,\n        -2.9714e+00, -6.3038e+00,  1.5434e+00, -1.2521e+00,  1.7173e+00,\n        -3.1428e-01,  3.6429e+00, -1.6390e+00,  4.3302e+00,  4.2990e-01,\n        -2.2837e+00, -3.1963e+00, -2.7681e-01, -2.0802e+00, -5.8379e+00,\n        -1.4605e+01, -1.0083e+01, -5.2075e+00, -5.2626e+00, -5.7509e-01,\n         3.6207e-01,  3.4033e+00,  1.4220e+00, -7.5951e-01,  2.3206e+00,\n        -2.2388e+00,  3.8159e+00, -1.2706e+00, -5.8988e-01, -2.9757e+00,\n        -8.5567e-01,  2.4251e+00,  2.1001e+00, -7.5810e-01,  3.6202e+00,\n         2.0968e+00, -6.0719e+00, -1.7860e+00,  4.5301e+00, -6.0549e-01,\n        -5.2571e+00, -3.3171e+00, -3.6449e+00,  1.8419e-01,  2.6915e+00,\n         4.7408e+00,  6.0890e-01,  2.0136e+00,  5.7783e+00,  1.0450e+01,\n         4.8943e+00,  3.5667e+00,  1.2911e+01, -1.4485e-01,  4.3416e+00,\n         4.9963e+00,  2.3464e+00, -9.8178e-01, -2.3350e+00, -2.0892e-01,\n        -2.5187e+00, -4.8526e+00, -4.9052e+00, -5.2476e-01, -1.5362e+00,\n        -2.4193e+00,  3.0176e-02, -3.6128e+00,  8.3082e-01, -3.4830e+00,\n        -3.3084e+00, -2.0244e-01, -3.7665e-01, -4.1204e+00,  2.7728e+00,\n         3.9957e+00,  6.1079e+00,  1.7904e+00, -2.6034e-01,  2.1171e+00,\n         1.6748e-01, -7.5473e+00,  1.2632e+00,  2.2401e+00, -5.8229e+00,\n        -3.1065e+00, -5.2495e+00,  1.6689e+00,  1.3526e+00,  3.2165e+00,\n        -5.5349e+00, -4.4114e+00, -3.5930e-01, -4.0353e+00,  1.5788e-01,\n         2.7166e+00, -2.1398e+00, -5.5854e+00, -1.0972e+00, -2.1997e+00,\n         1.8583e+00,  5.0481e+00, -3.3895e+00, -7.0574e-01,  1.9053e+00,\n        -1.6335e+00, -3.9091e-01, -1.9527e+00, -4.4480e+00, -6.9645e+00,\n         2.5362e-01, -2.8389e+00, -7.5892e-01,  4.0958e+00,  1.5709e+00,\n        -1.8096e+00, -1.4907e+00, -1.7102e-02, -3.6162e+00, -4.5761e-01,\n        -2.9409e+00,  2.3037e+00,  5.8189e+00,  9.4996e-01, -2.9325e+00,\n        -3.1376e-01,  8.4613e-01, -3.7548e+00, -6.7821e-01, -2.5628e+00,\n        -2.0950e+00, -6.1201e+00, -9.5605e-01, -2.4203e+00,  4.0319e+00,\n        -4.5844e+00,  1.5039e+00, -2.4791e+00,  2.5805e+00, -3.2106e+00,\n         4.5097e-01, -8.0356e-01,  3.1237e-01,  2.3460e+00, -4.4378e+00,\n         5.6236e-01,  5.8136e+00, -6.0998e+00,  5.9978e-01,  4.2684e+00,\n         1.4485e+00, -1.5429e+00,  1.0980e+01, -1.2573e+00, -2.4952e+00,\n         9.4527e-01, -3.8461e+00,  1.0246e+00, -2.1204e-01,  8.8314e-01,\n         5.6841e-01, -8.9751e+00,  2.3787e+00, -1.3709e+00, -2.7297e+00,\n        -7.0708e-01,  4.6175e+00, -1.0703e+00, -9.3798e-02, -4.7661e+00,\n        -1.0180e+01, -1.2055e+00,  1.1210e+00, -1.2766e+00, -2.2409e+00,\n        -7.9275e-01, -3.5694e-01,  2.8282e+00,  1.6509e+00, -8.6484e+00,\n        -3.7890e-01,  9.2439e-01, -5.0756e+00,  1.7729e+00,  8.9550e-01,\n         1.6217e+00,  2.8821e-01, -4.6995e+00,  4.9996e+00, -3.2946e-01,\n        -2.6868e+00,  4.2359e+00,  1.6986e+00, -1.7480e+00,  6.8499e+00,\n         3.3172e+00, -1.9181e+00,  8.2668e+00, -4.5789e+00,  4.3460e+00,\n         4.7758e+00,  4.9560e+00, -3.3324e+00,  3.1827e+00, -1.4832e+00,\n        -5.8185e-01, -1.0019e+01, -2.6322e+00,  4.6050e+00,  1.6725e+00,\n        -1.7762e-01,  7.4808e-01, -4.5542e+00, -8.7054e-01, -6.9265e-01,\n        -3.8895e-01, -4.9072e+00, -2.0234e+00, -9.1253e-01, -1.0855e+00,\n        -2.7951e+00, -6.0297e+00, -3.8092e+00, -2.7109e-01, -2.6828e+00,\n        -2.9903e+00, -4.3523e+00,  6.4567e+00, -5.5042e+00,  1.6748e+00,\n         1.6439e+00, -6.8131e+00,  1.5265e-01,  4.3887e-01,  2.7131e+00,\n         3.0274e+00,  2.3235e+00, -1.4779e+00, -2.4920e+00, -4.4219e+00,\n        -2.8739e+00,  8.5089e-01, -2.5209e+00,  6.7869e-01,  1.5752e+00,\n        -2.6332e-01,  4.2962e+00, -5.3603e+00,  5.7300e-01, -4.8388e+00,\n         6.3232e+00,  6.0677e+00, -8.7256e-01,  3.0702e+00,  1.5100e+00,\n         1.8836e-02, -5.4824e+00,  2.1659e+00,  1.0211e+00, -3.2480e-01,\n         6.1887e+00,  4.7091e-01,  2.0564e+00, -8.4224e-01,  1.4325e+00,\n        -1.4299e+00, -6.0377e+00,  5.3009e+00,  3.6579e-01,  1.3094e+00,\n        -5.2800e+00, -2.5490e+00, -5.2742e-02, -3.7514e+00, -2.5336e+00,\n        -5.7705e+00, -2.9970e+00,  4.7879e+00,  9.5048e-01, -5.7322e+00,\n         2.3611e+00,  4.4159e+00,  9.7155e-01, -2.1497e+00,  3.4214e+00,\n        -1.1093e-01,  4.2127e+00,  1.9375e+00,  4.4974e-01,  4.9478e+00,\n         1.1365e+00, -5.4101e+00, -2.5649e+00, -5.1486e+00,  3.6386e+00,\n        -1.5871e+00, -6.4748e+00,  2.4485e+00, -6.2459e+00,  2.6561e+00,\n        -1.5355e+00, -4.8367e+00,  2.6224e+00,  5.5857e+00,  6.6847e-01,\n        -1.9273e+00,  8.0236e+00,  4.8748e+00, -1.7222e+00, -1.5894e-01],\n       device='cuda:0')]\u001b[0m\nscores=[tensor([ 3.4225e+01,  4.7014e+01,  9.1332e-01,  5.2880e-02,  1.7725e+00,\n         5.5250e+00,  8.6551e-01,  1.5666e+00,  1.2277e+00,  2.3133e-01,\n         3.9361e+00, -1.3741e+00,  4.2013e+00,  3.9853e-02, -6.4408e+00,\n        -2.0945e+00, -4.6691e-01,  2.5163e+00, -1.8086e+00, -8.0590e+00,\n        -2.9714e+00, -6.3038e+00,  1.5434e+00, -1.2521e+00,  1.7173e+00,\n        -3.1428e-01,  3.6429e+00, -1.6390e+00,  4.3302e+00,  4.2990e-01,\n        -2.2837e+00, -3.1963e+00, -2.7681e-01, -2.0802e+00, -5.8379e+00,\n        -1.4605e+01, -1.0083e+01, -5.2075e+00, -5.2626e+00, -5.7509e-01,\n         3.6207e-01,  3.4033e+00,  1.4220e+00, -7.5951e-01,  2.3206e+00,\n        -2.2388e+00,  3.8159e+00, -1.2706e+00, -5.8988e-01, -2.9757e+00,\n        -8.5567e-01,  2.4251e+00,  2.1001e+00, -7.5810e-01,  3.6202e+00,\n         2.0968e+00, -6.0719e+00, -1.7860e+00,  4.5301e+00, -6.0549e-01,\n        -5.2571e+00, -3.3171e+00, -3.6449e+00,  1.8419e-01,  2.6915e+00,\n         4.7408e+00,  6.0890e-01,  2.0136e+00,  5.7783e+00,  1.0450e+01,\n         4.8943e+00,  3.5667e+00,  1.2911e+01, -1.4485e-01,  4.3416e+00,\n         4.9963e+00,  2.3464e+00, -9.8178e-01, -2.3350e+00, -2.0892e-01,\n        -2.5187e+00, -4.8526e+00, -4.9052e+00, -5.2476e-01, -1.5362e+00,\n        -2.4193e+00,  3.0176e-02, -3.6128e+00,  8.3082e-01, -3.4830e+00,\n        -3.3084e+00, -2.0244e-01, -3.7665e-01, -4.1204e+00,  2.7728e+00,\n         3.9957e+00,  6.1079e+00,  1.7904e+00, -2.6034e-01,  2.1171e+00,\n         1.6748e-01, -7.5473e+00,  1.2632e+00,  2.2401e+00, -5.8229e+00,\n        -3.1065e+00, -5.2495e+00,  1.6689e+00,  1.3526e+00,  3.2165e+00,\n        -5.5349e+00, -4.4114e+00, -3.5930e-01, -4.0353e+00,  1.5788e-01,\n         2.7166e+00, -2.1398e+00, -5.5854e+00, -1.0972e+00, -2.1997e+00,\n         1.8583e+00,  5.0481e+00, -3.3895e+00, -7.0574e-01,  1.9053e+00,\n        -1.6335e+00, -3.9091e-01, -1.9527e+00, -4.4480e+00, -6.9645e+00,\n         2.5362e-01, -2.8389e+00, -7.5892e-01,  4.0958e+00,  1.5709e+00,\n        -1.8096e+00, -1.4907e+00, -1.7102e-02, -3.6162e+00, -4.5761e-01,\n        -2.9409e+00,  2.3037e+00,  5.8189e+00,  9.4996e-01, -2.9325e+00,\n        -3.1376e-01,  8.4613e-01, -3.7548e+00, -6.7821e-01, -2.5628e+00,\n        -2.0950e+00, -6.1201e+00, -9.5605e-01, -2.4203e+00,  4.0319e+00,\n        -4.5844e+00,  1.5039e+00, -2.4791e+00,  2.5805e+00, -3.2106e+00,\n         4.5097e-01, -8.0356e-01,  3.1237e-01,  2.3460e+00, -4.4378e+00,\n         5.6236e-01,  5.8136e+00, -6.0998e+00,  5.9978e-01,  4.2684e+00,\n         1.4485e+00, -1.5429e+00,  1.0980e+01, -1.2573e+00, -2.4952e+00,\n         9.4527e-01, -3.8461e+00,  1.0246e+00, -2.1204e-01,  8.8314e-01,\n         5.6841e-01, -8.9751e+00,  2.3787e+00, -1.3709e+00, -2.7297e+00,\n        -7.0708e-01,  4.6175e+00, -1.0703e+00, -9.3798e-02, -4.7661e+00,\n        -1.0180e+01, -1.2055e+00,  1.1210e+00, -1.2766e+00, -2.2409e+00,\n        -7.9275e-01, -3.5694e-01,  2.8282e+00,  1.6509e+00, -8.6484e+00,\n        -3.7890e-01,  9.2439e-01, -5.0756e+00,  1.7729e+00,  8.9550e-01,\n         1.6217e+00,  2.8821e-01, -4.6995e+00,  4.9996e+00, -3.2946e-01,\n        -2.6868e+00,  4.2359e+00,  1.6986e+00, -1.7480e+00,  6.8499e+00,\n         3.3172e+00, -1.9181e+00,  8.2668e+00, -4.5789e+00,  4.3460e+00,\n         4.7758e+00,  4.9560e+00, -3.3324e+00,  3.1827e+00, -1.4832e+00,\n        -5.8185e-01, -1.0019e+01, -2.6322e+00,  4.6050e+00,  1.6725e+00,\n        -1.7762e-01,  7.4808e-01, -4.5542e+00, -8.7054e-01, -6.9265e-01,\n        -3.8895e-01, -4.9072e+00, -2.0234e+00, -9.1253e-01, -1.0855e+00,\n        -2.7951e+00, -6.0297e+00, -3.8092e+00, -2.7109e-01, -2.6828e+00,\n        -2.9903e+00, -4.3523e+00,  6.4567e+00, -5.5042e+00,  1.6748e+00,\n         1.6439e+00, -6.8131e+00,  1.5265e-01,  4.3887e-01,  2.7131e+00,\n         3.0274e+00,  2.3235e+00, -1.4779e+00, -2.4920e+00, -4.4219e+00,\n        -2.8739e+00,  8.5089e-01, -2.5209e+00,  6.7869e-01,  1.5752e+00,\n        -2.6332e-01,  4.2962e+00, -5.3603e+00,  5.7300e-01, -4.8388e+00,\n         6.3232e+00,  6.0677e+00, -8.7256e-01,  3.0702e+00,  1.5100e+00,\n         1.8836e-02, -5.4824e+00,  2.1659e+00,  1.0211e+00, -3.2480e-01,\n         6.1887e+00,  4.7091e-01,  2.0564e+00, -8.4224e-01,  1.4325e+00,\n        -1.4299e+00, -6.0377e+00,  5.3009e+00,  3.6579e-01,  1.3094e+00,\n        -5.2800e+00, -2.5490e+00, -5.2742e-02, -3.7514e+00, -2.5336e+00,\n        -5.7705e+00, -2.9970e+00,  4.7879e+00,  9.5048e-01, -5.7322e+00,\n         2.3611e+00,  4.4159e+00,  9.7155e-01, -2.1497e+00,  3.4214e+00,\n        -1.1093e-01,  4.2127e+00,  1.9375e+00,  4.4974e-01,  4.9478e+00,\n         1.1365e+00, -5.4101e+00, -2.5649e+00, -5.1486e+00,  3.6386e+00,\n        -1.5871e+00, -6.4748e+00,  2.4485e+00, -6.2459e+00,  2.6561e+00,\n        -1.5355e+00, -4.8367e+00,  2.6224e+00,  5.5857e+00,  6.6847e-01,\n        -1.9273e+00,  8.0236e+00,  4.8748e+00, -1.7222e+00, -1.5894e-01],\n       device='cuda:0')],type=<class 'list'>\n/kaggle/working/chatGLM-6B-QLoRA/trainer.py:654: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n  scores = torch.tensor(scores).to(self.current_device)\nvalues_994 = tensor([[ 3.2090e+01,  3.5163e+01,  8.5459e-01,  1.5749e+00,  1.4041e+00,\n          5.3792e+00,  4.1152e+00,  5.3022e-01,  2.1691e-01, -8.4130e-01,\n          3.6773e+00, -5.9319e-01,  2.7460e+00,  4.7306e-01, -6.0877e+00,\n         -2.8606e+00, -2.2596e+00,  2.3908e+00, -9.4706e-01, -5.8909e+00,\n         -1.2591e+00, -6.2231e+00,  1.0021e+00, -6.4453e-01,  2.0810e+00,\n         -3.8001e+00,  4.2140e+00, -1.4963e+00,  2.2024e+00,  1.7898e+00,\n         -1.4695e+00, -2.6918e+00,  4.7712e-01, -9.8108e-01, -7.0543e+00,\n         -1.7342e+01, -1.1603e+01, -7.8210e+00, -5.1047e+00,  1.6941e+00,\n         -3.9173e-02,  2.0003e+00,  2.8454e-02, -2.0706e+00, -3.0858e+00,\n         -2.2961e+00,  3.8232e+00,  1.4305e+00, -1.9594e+00, -1.4040e+00,\n         -1.1261e+00,  3.3980e+00,  3.6119e+00, -1.9157e+00,  4.5525e+00,\n          5.9964e-01, -2.7848e+00, -2.2302e+00,  1.8187e+00,  2.3063e+00,\n         -2.8515e+00, -6.1117e+00, -1.6879e+00,  2.8611e+00,  3.6643e+00,\n          1.7683e+00,  3.8997e-01,  4.8695e+00,  6.2636e+00,  1.0720e+01,\n          3.6388e+00,  4.9102e+00,  1.2461e+01,  1.0186e+00,  2.5091e+00,\n          3.8654e+00, -8.1330e-01,  1.2707e+00, -3.8122e-01, -1.4649e+00,\n         -2.7282e+00, -7.3067e+00, -4.5632e+00, -8.8356e-01, -3.5205e+00,\n         -1.4046e+00,  2.7285e+00, -7.3981e+00,  1.6206e+00, -5.6552e+00,\n         -4.8916e+00,  1.3811e+00,  1.2159e+00, -5.4998e+00,  3.7931e+00,\n          3.9511e+00,  6.1623e+00,  3.0173e+00,  8.0569e-01,  3.8788e-01,\n          2.8128e+00, -7.6417e+00, -9.1381e-01,  1.7985e+00, -4.4495e+00,\n         -4.4596e+00, -6.8293e+00,  2.7025e+00,  1.7624e+00,  2.9300e+00,\n         -3.5164e+00, -4.7514e+00, -1.3263e+00, -5.7900e+00, -2.6082e+00,\n          2.6336e-01, -3.3854e+00, -3.7112e+00, -9.5164e-01, -2.8322e+00,\n          3.5445e+00,  2.7991e+00, -2.8700e+00, -3.7804e-01,  9.5918e-01,\n         -1.2884e+00,  1.7602e+00, -1.3175e+00, -3.6381e+00, -6.8825e+00,\n          1.7709e-01, -5.6501e+00,  2.5406e+00,  3.5439e+00,  1.5360e+00,\n         -7.6631e-01, -3.3162e+00, -5.3528e-01, -3.0014e+00,  1.1371e+00,\n          3.3742e-01,  1.4276e+00,  5.3098e+00,  2.6231e+00, -3.0162e+00,\n         -5.5463e-02,  1.8564e-01, -6.1145e+00,  8.0334e-01, -1.9383e+00,\n         -1.2067e+00, -4.6157e+00, -2.1362e+00, -2.1981e+00,  1.9309e+00,\n         -5.5408e+00, -4.9669e-01, -1.4756e+00,  2.3024e+00, -2.7012e+00,\n         -2.0308e+00, -1.8487e+00, -1.0078e+00,  2.0943e-01, -5.3269e-01,\n          2.9415e-01,  1.3615e+00, -4.2804e+00, -2.1425e+00,  2.3520e+00,\n          2.5120e+00, -5.9744e-01,  1.1819e+01, -4.0083e+00, -3.6268e+00,\n          4.0654e+00, -3.9446e+00,  4.0086e-01,  4.8805e+00, -1.3094e+00,\n         -1.6763e+00, -5.9975e+00, -1.1472e-01, -1.4531e+00, -3.6785e-01,\n         -1.9281e+00,  6.2981e+00, -2.0675e+00, -4.0480e-01, -5.6428e+00,\n         -8.4534e+00, -2.8529e-01, -1.0763e+00,  2.6124e+00, -1.1786e+00,\n          1.7876e+00, -8.6277e-01,  3.0879e+00,  5.0344e+00, -7.8873e+00,\n         -1.1910e+00, -8.2794e-01, -7.2222e+00,  1.6480e+00,  1.7106e+00,\n         -2.6618e-01, -2.1819e+00, -4.6337e+00,  1.6300e+00, -1.4551e+00,\n         -1.5197e+00,  2.9515e+00,  4.3440e+00, -3.6706e+00,  3.8367e+00,\n          3.8889e-01, -1.3150e+00,  8.5866e+00, -3.0005e+00,  2.4487e+00,\n          6.3907e+00,  3.6748e+00, -3.4075e+00,  2.5435e+00, -1.2070e+00,\n         -8.0451e-01, -1.0636e+01,  1.0119e+00,  5.9493e+00,  1.9900e+00,\n         -1.4951e+00,  2.1622e+00, -4.0931e+00, -2.2920e+00, -1.3017e+00,\n         -1.4672e+00, -6.3168e+00,  9.3151e-02, -9.3755e-01, -1.2008e+00,\n         -4.3640e+00, -6.3300e+00, -1.3233e+00, -1.6504e-01, -3.0799e-01,\n         -4.4622e+00, -2.3438e+00,  7.2575e+00, -6.4959e+00, -2.8073e-01,\n          2.0556e+00, -4.9064e+00,  6.3072e-01, -6.4698e-02,  2.8376e+00,\n          1.2565e+00, -1.9813e-01, -2.0407e+00, -2.9250e+00, -1.3854e+00,\n         -3.6402e+00,  1.1008e+00, -2.4036e+00,  3.8375e+00,  9.1062e-01,\n          1.1048e+00,  1.7472e+00, -1.1215e+00,  1.0267e+00, -6.2683e+00,\n          7.0424e+00,  4.8188e+00,  1.5341e+00,  3.2282e+00,  1.6473e+00,\n          1.7336e+00, -4.2292e+00,  3.0943e-01,  6.6050e-01,  6.1106e-04,\n          5.6667e+00, -5.3609e-01,  7.6317e-01, -3.5679e-01,  1.5224e+00,\n          3.3730e-01, -5.9630e+00,  4.3002e+00,  2.2299e+00, -2.9005e-01,\n         -4.1222e+00, -6.0265e+00, -1.7569e+00, -2.5062e+00, -2.3622e+00,\n         -4.3619e+00, -3.1796e+00,  3.8149e+00,  1.7540e+00, -5.5147e+00,\n          1.8819e+00,  4.1891e+00, -5.2766e-02, -2.9924e+00,  2.7842e+00,\n         -1.8684e-01,  2.6958e+00, -5.9517e-01,  4.6009e+00,  3.0170e+00,\n          9.9771e-01, -4.6685e+00, -9.4414e-01, -3.7787e+00,  3.5194e-01,\n         -2.3821e+00, -5.0366e+00, -9.3494e-01, -6.7654e+00,  3.9184e-01,\n         -3.3178e+00, -2.2718e+00,  4.5820e+00,  6.0368e+00,  2.4966e+00,\n         -1.9844e+00,  5.0592e+00,  7.2431e+00, -2.1629e+00,  3.2492e-01]],\n       device='cuda:0')\nvalues_994 = tensor([[ 1.9485e+01,  5.4850e+01,  4.9601e-01,  2.3888e+00,  1.8573e+00,\n          6.0760e+00,  2.1144e+00,  1.8246e-01,  6.7918e-01, -1.4145e-01,\n          2.4824e+00,  8.3241e-01,  3.5717e+00, -1.8831e-01, -3.0728e+00,\n         -1.5287e+00, -1.5762e+00,  2.1912e+00, -1.3221e+00, -6.3689e+00,\n         -5.2126e+00, -4.9558e+00,  2.7084e+00, -1.3954e+00, -2.1286e-01,\n         -3.6647e+00,  3.0320e+00, -1.2571e+00,  1.0708e+00,  3.0215e+00,\n         -3.5252e+00, -2.2976e+00, -1.1415e+00, -7.5420e-02, -7.8211e+00,\n         -1.5231e+01, -9.0676e+00, -4.7579e+00, -5.5075e+00,  2.1026e+00,\n          8.5863e-01,  2.3238e+00, -1.4874e+00,  2.9773e+00,  2.5350e+00,\n         -1.7295e+00,  4.5010e+00, -1.6391e+00,  8.0645e-03, -8.6646e-01,\n         -5.0321e-01,  2.6958e+00,  5.0720e+00, -4.4811e-01,  3.5875e+00,\n          9.7621e-01, -5.6919e+00, -1.0628e+00,  1.7287e+00, -8.2440e-01,\n         -6.5001e+00, -4.4459e+00,  1.0768e+00,  5.2758e+00,  3.4161e-01,\n          4.9259e+00,  4.1993e-01,  1.3112e+00,  6.0902e+00,  9.9631e+00,\n          3.1051e+00,  2.3879e+00,  1.0992e+01, -3.7959e-01,  7.0221e-01,\n          5.8788e+00, -8.8939e-01,  1.5373e+00, -7.2553e-01, -5.7922e-01,\n         -4.1458e+00, -4.3978e+00, -4.1014e+00,  7.8302e-01, -1.8257e+00,\n         -5.8571e-01, -7.6828e-01, -7.6781e+00,  1.7745e+00, -2.4074e+00,\n         -2.4054e+00,  1.7283e+00,  2.9274e+00, -4.1003e+00,  5.4185e+00,\n         -8.1341e-01,  5.7384e+00,  2.0139e+00, -9.7706e-01, -9.3773e-01,\n          2.4735e+00, -6.8304e+00,  6.0636e-02,  3.1601e+00, -2.7928e+00,\n         -3.6712e+00, -4.6644e+00,  2.4423e+00,  1.1243e+00,  4.0060e+00,\n         -2.5456e+00, -4.9290e+00, -3.0983e-02, -7.3554e+00, -1.3374e+00,\n          2.9377e+00, -2.1037e+00, -3.9972e+00,  1.3338e+00, -1.0876e+00,\n          5.4097e+00,  2.2853e+00, -2.8655e+00, -3.2353e-01, -2.9408e-03,\n         -3.1131e+00, -3.7094e-01, -1.4592e-01, -3.5544e+00, -6.4536e+00,\n         -1.0172e+00, -3.7709e+00, -8.5968e-01,  2.8864e+00,  2.5363e+00,\n         -1.2916e-01, -5.5772e-01,  9.0636e-01, -1.6112e+00,  9.3703e-01,\n         -3.5371e+00,  3.0182e+00,  7.3639e+00, -7.5490e-01, -2.6172e+00,\n         -1.0122e+00,  2.0105e+00, -7.2818e+00,  9.2050e-01, -3.7507e+00,\n         -2.4071e+00, -4.8413e+00, -3.7394e-01, -2.0089e+00,  9.2405e-01,\n         -6.1214e+00, -1.3027e+00, -6.6538e-01,  2.5808e+00, -1.7984e+00,\n          1.3304e+00, -1.7524e+00, -2.6266e+00, -7.6765e-01, -1.5134e+00,\n          1.0901e-01,  7.1035e+00, -4.8257e+00, -1.9114e+00,  4.2184e+00,\n          3.4074e-01, -2.7572e+00,  6.9678e+00, -8.9899e-01,  1.3224e-01,\n          2.8927e+00, -1.4427e+00,  1.6021e-02,  1.8169e+00,  2.0568e-01,\n          2.1766e-02, -7.5876e+00,  1.6709e+00, -2.3246e+00,  1.2641e+00,\n          8.0230e-02,  4.6253e+00, -6.0902e-01,  8.1890e-01, -5.0727e+00,\n         -9.0284e+00,  2.6985e+00, -1.5558e+00,  2.5341e+00, -8.8600e-01,\n         -1.2402e-01,  1.0489e+00,  5.3944e-01,  3.0305e+00, -1.0595e+01,\n          1.4646e+00, -7.6287e-01, -4.8725e+00,  3.6415e-02,  1.2929e+00,\n          1.5679e+00,  8.7363e-02, -1.3189e+00,  2.4278e+00, -1.2805e+00,\n         -3.0101e+00,  3.7382e+00,  8.7561e-01, -4.7223e+00,  6.1193e+00,\n          2.5516e+00, -2.3346e+00,  7.5378e+00, -6.9242e+00,  3.5343e+00,\n          7.1791e+00,  3.0564e+00, -1.4318e+00,  6.2215e-01, -1.9578e+00,\n         -1.4060e+00, -1.1905e+01,  6.8803e-01,  6.3948e+00,  6.0108e-01,\n          7.8178e-01,  1.5787e+00, -2.5500e+00, -1.4141e+00, -2.8922e+00,\n         -1.6115e+00, -4.9802e+00, -7.7423e-01, -1.4105e+00, -4.9038e-01,\n         -3.9709e+00, -7.3714e+00, -8.7951e-01, -1.8637e+00, -4.4976e-01,\n         -3.1949e+00, -3.9763e+00,  1.0076e+01, -7.9545e+00,  9.1472e-01,\n          1.2488e+00, -6.7501e+00,  3.5162e+00,  2.9452e+00,  1.2329e+00,\n         -2.3515e-01,  1.9141e+00, -7.0979e-01, -1.9406e+00, -6.1599e-01,\n         -4.7275e+00, -2.8976e+00, -8.2589e-01, -3.9891e-01,  1.2241e+00,\n          2.5261e+00,  2.1088e+00, -4.6108e+00,  5.1625e-01, -5.1764e+00,\n          8.5989e+00,  4.5461e+00, -3.3811e-01,  1.0682e+00,  1.2344e+00,\n          1.1865e+00, -2.7501e+00,  2.5124e+00, -7.5661e-01,  1.3182e+00,\n          4.6743e+00, -5.7357e-01,  3.0772e+00, -1.1339e+00,  2.3245e+00,\n          1.1560e+00, -4.3269e+00,  4.9716e+00,  6.5881e-01,  1.1024e+00,\n         -5.1760e+00, -5.8056e+00,  1.0623e+00, -3.3213e+00, -1.1452e+00,\n         -2.4303e+00, -3.0369e+00,  3.2501e+00,  7.6837e-01, -6.4117e+00,\n          2.6456e+00,  5.0884e+00,  9.7998e-01, -3.2966e+00,  4.1604e+00,\n         -3.9903e-01,  2.4299e+00,  6.6668e-01,  4.4572e+00,  3.6815e+00,\n         -1.0604e-01, -7.6221e+00, -3.9484e-01, -4.9779e+00,  4.4973e+00,\n         -1.8366e+00, -3.9105e+00, -1.3009e+00, -3.4293e+00,  3.2901e-01,\n         -3.7905e+00, -1.3460e+00,  4.9052e+00,  4.1301e+00,  1.1033e+00,\n         -1.2377e+00,  4.5316e+00,  5.1258e+00,  6.0078e-01, -2.9924e-01]],\n       device='cuda:0')\nreward[last_non_masked_index]=tensor([-0.0006], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 3.4225e+01,  4.7014e+01,  9.1332e-01,  5.2880e-02,  1.7725e+00,\n         5.5250e+00,  8.6551e-01,  1.5666e+00,  1.2277e+00,  2.3133e-01,\n         3.9361e+00, -1.3741e+00,  4.2013e+00,  3.9853e-02, -6.4408e+00,\n        -2.0945e+00, -4.6691e-01,  2.5163e+00, -1.8086e+00, -8.0590e+00,\n        -2.9714e+00, -6.3038e+00,  1.5434e+00, -1.2521e+00,  1.7173e+00,\n        -3.1428e-01,  3.6429e+00, -1.6390e+00,  4.3302e+00,  4.2990e-01,\n        -2.2837e+00, -3.1963e+00, -2.7681e-01, -2.0802e+00, -5.8379e+00,\n        -1.4605e+01, -1.0083e+01, -5.2075e+00, -5.2626e+00, -5.7509e-01,\n         3.6207e-01,  3.4033e+00,  1.4220e+00, -7.5951e-01,  2.3206e+00,\n        -2.2388e+00,  3.8159e+00, -1.2706e+00, -5.8988e-01, -2.9757e+00,\n        -8.5567e-01,  2.4251e+00,  2.1001e+00, -7.5810e-01,  3.6202e+00,\n         2.0968e+00, -6.0719e+00, -1.7860e+00,  4.5301e+00, -6.0549e-01,\n        -5.2571e+00, -3.3171e+00, -3.6449e+00,  1.8419e-01,  2.6915e+00,\n         4.7408e+00,  6.0890e-01,  2.0136e+00,  5.7783e+00,  1.0450e+01,\n         4.8943e+00,  3.5667e+00,  1.2911e+01, -1.4485e-01,  4.3416e+00,\n         4.9963e+00,  2.3464e+00, -9.8178e-01, -2.3350e+00, -2.0892e-01,\n        -2.5187e+00, -4.8526e+00, -4.9052e+00, -5.2476e-01, -1.5362e+00,\n        -2.4193e+00,  3.0176e-02, -3.6128e+00,  8.3082e-01, -3.4830e+00,\n        -3.3084e+00, -2.0244e-01, -3.7665e-01, -4.1204e+00,  2.7728e+00,\n         3.9957e+00,  6.1079e+00,  1.7904e+00, -2.6034e-01,  2.1171e+00,\n         1.6748e-01, -7.5473e+00,  1.2632e+00,  2.2401e+00, -5.8229e+00,\n        -3.1065e+00, -5.2495e+00,  1.6689e+00,  1.3526e+00,  3.2165e+00,\n        -5.5349e+00, -4.4114e+00, -3.5930e-01, -4.0353e+00,  1.5788e-01,\n         2.7166e+00, -2.1398e+00, -5.5854e+00, -1.0972e+00, -2.1997e+00,\n         1.8583e+00,  5.0481e+00, -3.3895e+00, -7.0574e-01,  1.9053e+00,\n        -1.6335e+00, -3.9091e-01, -1.9527e+00, -4.4480e+00, -6.9645e+00,\n         2.5362e-01, -2.8389e+00, -7.5892e-01,  4.0958e+00,  1.5709e+00,\n        -1.8096e+00, -1.4907e+00, -1.7102e-02, -3.6162e+00, -4.5761e-01,\n        -2.9409e+00,  2.3037e+00,  5.8189e+00,  9.4996e-01, -2.9325e+00,\n        -3.1376e-01,  8.4613e-01, -3.7548e+00, -6.7821e-01, -2.5628e+00,\n        -2.0950e+00, -6.1201e+00, -9.5605e-01, -2.4203e+00,  4.0319e+00,\n        -4.5844e+00,  1.5039e+00, -2.4791e+00,  2.5805e+00, -3.2106e+00,\n         4.5097e-01, -8.0356e-01,  3.1237e-01,  2.3460e+00, -4.4378e+00,\n         5.6236e-01,  5.8136e+00, -6.0998e+00,  5.9978e-01,  4.2684e+00,\n         1.4485e+00, -1.5429e+00,  1.0980e+01, -1.2573e+00, -2.4952e+00,\n         9.4527e-01, -3.8461e+00,  1.0246e+00, -2.1204e-01,  8.8314e-01,\n         5.6841e-01, -8.9751e+00,  2.3787e+00, -1.3709e+00, -2.7297e+00,\n        -7.0708e-01,  4.6175e+00, -1.0703e+00, -9.3798e-02, -4.7661e+00,\n        -1.0180e+01, -1.2055e+00,  1.1210e+00, -1.2766e+00, -2.2409e+00,\n        -7.9275e-01, -3.5694e-01,  2.8282e+00,  1.6509e+00, -8.6484e+00,\n        -3.7890e-01,  9.2439e-01, -5.0756e+00,  1.7729e+00,  8.9550e-01,\n         1.6217e+00,  2.8821e-01, -4.6995e+00,  4.9996e+00, -3.2946e-01,\n        -2.6868e+00,  4.2359e+00,  1.6986e+00, -1.7480e+00,  6.8499e+00,\n         3.3172e+00, -1.9181e+00,  8.2668e+00, -4.5789e+00,  4.3460e+00,\n         4.7758e+00,  4.9560e+00, -3.3324e+00,  3.1827e+00, -1.4832e+00,\n        -5.8185e-01, -1.0019e+01, -2.6322e+00,  4.6050e+00,  1.6725e+00,\n        -1.7762e-01,  7.4808e-01, -4.5542e+00, -8.7054e-01, -6.9265e-01,\n        -3.8895e-01, -4.9072e+00, -2.0234e+00, -9.1253e-01, -1.0855e+00,\n        -2.7951e+00, -6.0297e+00, -3.8092e+00, -2.7109e-01, -2.6828e+00,\n        -2.9903e+00, -4.3523e+00,  6.4567e+00, -5.5042e+00,  1.6748e+00,\n         1.6439e+00, -6.8131e+00,  1.5265e-01,  4.3887e-01,  2.7131e+00,\n         3.0274e+00,  2.3235e+00, -1.4779e+00, -2.4920e+00, -4.4219e+00,\n        -2.8739e+00,  8.5089e-01, -2.5209e+00,  6.7869e-01,  1.5752e+00,\n        -2.6332e-01,  4.2962e+00, -5.3603e+00,  5.7300e-01, -4.8388e+00,\n         6.3232e+00,  6.0677e+00, -8.7256e-01,  3.0702e+00,  1.5100e+00,\n         1.8836e-02, -5.4824e+00,  2.1659e+00,  1.0211e+00, -3.2480e-01,\n         6.1887e+00,  4.7091e-01,  2.0564e+00, -8.4224e-01,  1.4325e+00,\n        -1.4299e+00, -6.0377e+00,  5.3009e+00,  3.6579e-01,  1.3094e+00,\n        -5.2800e+00, -2.5490e+00, -5.2742e-02, -3.7514e+00, -2.5336e+00,\n        -5.7705e+00, -2.9970e+00,  4.7879e+00,  9.5048e-01, -5.7322e+00,\n         2.3611e+00,  4.4159e+00,  9.7155e-01, -2.1497e+00,  3.4214e+00,\n        -1.1093e-01,  4.2127e+00,  1.9375e+00,  4.4974e-01,  4.9478e+00,\n         1.1365e+00, -5.4101e+00, -2.5649e+00, -5.1486e+00,  3.6386e+00,\n        -1.5871e+00, -6.4748e+00,  2.4485e+00, -6.2459e+00,  2.6561e+00,\n        -1.5355e+00, -4.8367e+00,  2.6224e+00,  5.5857e+00,  6.6847e-01,\n        -1.9273e+00,  8.0236e+00,  4.8748e+00, -1.7222e+00, -1.5894e-01],\n       device='cuda:0')\nvalues=tensor([[ 3.2090e+01,  3.5163e+01,  8.5459e-01,  1.5749e+00,  1.4041e+00,\n          5.3792e+00,  4.1152e+00,  5.3022e-01,  2.1691e-01, -8.4130e-01,\n          3.6773e+00, -5.9319e-01,  2.7460e+00,  4.7306e-01, -6.0877e+00,\n         -2.8606e+00, -2.2596e+00,  2.3908e+00, -9.4706e-01, -5.8909e+00,\n         -1.2591e+00, -6.2231e+00,  1.0021e+00, -6.4453e-01,  2.0810e+00,\n         -3.8001e+00,  4.2140e+00, -1.4963e+00,  2.2024e+00,  1.7898e+00,\n         -1.4695e+00, -2.6918e+00,  4.7712e-01, -9.8108e-01, -7.0543e+00,\n         -1.7342e+01, -1.1603e+01, -7.8210e+00, -5.1047e+00,  1.6941e+00,\n         -3.9173e-02,  2.0003e+00,  2.8454e-02, -2.0706e+00, -3.0858e+00,\n         -2.2961e+00,  3.8232e+00,  1.4305e+00, -1.9594e+00, -1.4040e+00,\n         -1.1261e+00,  3.3980e+00,  3.6119e+00, -1.9157e+00,  4.5525e+00,\n          5.9964e-01, -2.7848e+00, -2.2302e+00,  1.8187e+00,  2.3063e+00,\n         -2.8515e+00, -6.1117e+00, -1.6879e+00,  2.8611e+00,  3.6643e+00,\n          1.7683e+00,  3.8997e-01,  4.8695e+00,  6.2636e+00,  1.0720e+01,\n          3.6388e+00,  4.9102e+00,  1.2461e+01,  1.0186e+00,  2.5091e+00,\n          3.8654e+00, -8.1330e-01,  1.2707e+00, -3.8122e-01, -1.4649e+00,\n         -2.7282e+00, -7.3067e+00, -4.5632e+00, -8.8356e-01, -3.5205e+00,\n         -1.4046e+00,  2.7285e+00, -7.3981e+00,  1.6206e+00, -5.6552e+00,\n         -4.8916e+00,  1.3811e+00,  1.2159e+00, -5.4998e+00,  3.7931e+00,\n          3.9511e+00,  6.1623e+00,  3.0173e+00,  8.0569e-01,  3.8788e-01,\n          2.8128e+00, -7.6417e+00, -9.1381e-01,  1.7985e+00, -4.4495e+00,\n         -4.4596e+00, -6.8293e+00,  2.7025e+00,  1.7624e+00,  2.9300e+00,\n         -3.5164e+00, -4.7514e+00, -1.3263e+00, -5.7900e+00, -2.6082e+00,\n          2.6336e-01, -3.3854e+00, -3.7112e+00, -9.5164e-01, -2.8322e+00,\n          3.5445e+00,  2.7991e+00, -2.8700e+00, -3.7804e-01,  9.5918e-01,\n         -1.2884e+00,  1.7602e+00, -1.3175e+00, -3.6381e+00, -6.8825e+00,\n          1.7709e-01, -5.6501e+00,  2.5406e+00,  3.5439e+00,  1.5360e+00,\n         -7.6631e-01, -3.3162e+00, -5.3528e-01, -3.0014e+00,  1.1371e+00,\n          3.3742e-01,  1.4276e+00,  5.3098e+00,  2.6231e+00, -3.0162e+00,\n         -5.5463e-02,  1.8564e-01, -6.1145e+00,  8.0334e-01, -1.9383e+00,\n         -1.2067e+00, -4.6157e+00, -2.1362e+00, -2.1981e+00,  1.9309e+00,\n         -5.5408e+00, -4.9669e-01, -1.4756e+00,  2.3024e+00, -2.7012e+00,\n         -2.0308e+00, -1.8487e+00, -1.0078e+00,  2.0943e-01, -5.3269e-01,\n          2.9415e-01,  1.3615e+00, -4.2804e+00, -2.1425e+00,  2.3520e+00,\n          2.5120e+00, -5.9744e-01,  1.1819e+01, -4.0083e+00, -3.6268e+00,\n          4.0654e+00, -3.9446e+00,  4.0086e-01,  4.8805e+00, -1.3094e+00,\n         -1.6763e+00, -5.9975e+00, -1.1472e-01, -1.4531e+00, -3.6785e-01,\n         -1.9281e+00,  6.2981e+00, -2.0675e+00, -4.0480e-01, -5.6428e+00,\n         -8.4534e+00, -2.8529e-01, -1.0763e+00,  2.6124e+00, -1.1786e+00,\n          1.7876e+00, -8.6277e-01,  3.0879e+00,  5.0344e+00, -7.8873e+00,\n         -1.1910e+00, -8.2794e-01, -7.2222e+00,  1.6480e+00,  1.7106e+00,\n         -2.6618e-01, -2.1819e+00, -4.6337e+00,  1.6300e+00, -1.4551e+00,\n         -1.5197e+00,  2.9515e+00,  4.3440e+00, -3.6706e+00,  3.8367e+00,\n          3.8889e-01, -1.3150e+00,  8.5866e+00, -3.0005e+00,  2.4487e+00,\n          6.3907e+00,  3.6748e+00, -3.4075e+00,  2.5435e+00, -1.2070e+00,\n         -8.0451e-01, -1.0636e+01,  1.0119e+00,  5.9493e+00,  1.9900e+00,\n         -1.4951e+00,  2.1622e+00, -4.0931e+00, -2.2920e+00, -1.3017e+00,\n         -1.4672e+00, -6.3168e+00,  9.3151e-02, -9.3755e-01, -1.2008e+00,\n         -4.3640e+00, -6.3300e+00, -1.3233e+00, -1.6504e-01, -3.0799e-01,\n         -4.4622e+00, -2.3438e+00,  7.2575e+00, -6.4959e+00, -2.8073e-01,\n          2.0556e+00, -4.9064e+00,  6.3072e-01, -6.4698e-02,  2.8376e+00,\n          1.2565e+00, -1.9813e-01, -2.0407e+00, -2.9250e+00, -1.3854e+00,\n         -3.6402e+00,  1.1008e+00, -2.4036e+00,  3.8375e+00,  9.1062e-01,\n          1.1048e+00,  1.7472e+00, -1.1215e+00,  1.0267e+00, -6.2683e+00,\n          7.0424e+00,  4.8188e+00,  1.5341e+00,  3.2282e+00,  1.6473e+00,\n          1.7336e+00, -4.2292e+00,  3.0943e-01,  6.6050e-01,  6.1106e-04,\n          5.6667e+00, -5.3609e-01,  7.6317e-01, -3.5679e-01,  1.5224e+00,\n          3.3730e-01, -5.9630e+00,  4.3002e+00,  2.2299e+00, -2.9005e-01,\n         -4.1222e+00, -6.0265e+00, -1.7569e+00, -2.5062e+00, -2.3622e+00,\n         -4.3619e+00, -3.1796e+00,  3.8149e+00,  1.7540e+00, -5.5147e+00,\n          1.8819e+00,  4.1891e+00, -5.2766e-02, -2.9924e+00,  2.7842e+00,\n         -1.8684e-01,  2.6958e+00, -5.9517e-01,  4.6009e+00,  3.0170e+00,\n          9.9771e-01, -4.6685e+00, -9.4414e-01, -3.7787e+00,  3.5194e-01,\n         -2.3821e+00, -5.0366e+00, -9.3494e-01, -6.7654e+00,  3.9184e-01,\n         -3.3178e+00, -2.2718e+00,  4.5820e+00,  6.0368e+00,  2.4966e+00,\n         -1.9844e+00,  5.0592e+00,  7.2431e+00, -2.1629e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -1.1917e-07, -1.9149e-04, -0.0000e+00,  1.5262e-03,  5.8199e-04,\n          6.2485e-04, -1.9940e-03, -2.2950e-03, -8.4877e-04, -4.1703e-07,\n         -2.9800e-07, -1.4298e-06, -1.7881e-07, -2.3840e-07,  1.7879e-07,\n         -0.0000e+00, -6.4135e-05,  1.2498e-06,  1.1319e-06,  7.1432e-07,\n         -0.0000e+00,  5.9603e-08, -0.0000e+00, -0.0000e+00, -5.6297e-04,\n          3.5437e-07, -2.3836e-07, -6.5527e-07, -0.0000e+00, -0.0000e+00,\n          2.3186e-05, -2.8822e-03, -6.8259e-04,  3.0946e-03, -2.1178e-04,\n         -0.0000e+00,  1.4383e-04,  5.9604e-08,  8.1354e-04, -1.0698e-03,\n         -2.5046e-04, -2.6461e-05, -5.3655e-04, -5.9549e-07, -1.9896e-04,\n         -4.6206e-04,  1.7272e-06,  9.1253e-04,  1.5859e-05,  3.8448e-04,\n         -3.3951e-04, -3.2632e-04,  3.8644e-04, -3.8072e-06,  4.5542e-03,\n          3.6770e-04, -0.0000e+00,  6.1750e-05,  5.1271e-05, -0.0000e+00,\n         -0.0000e+00,  5.9601e-08, -5.9597e-08, -0.0000e+00, -7.8487e-04,\n          9.2638e-04, -4.9412e-03, -3.6932e-05, -3.5667e-03, -0.0000e+00,\n          1.0384e-03, -0.0000e+00, -5.3630e-07, -4.1715e-07, -0.0000e+00,\n          3.7491e-05, -1.2667e-04, -0.0000e+00, -1.1541e-04, -4.2008e-05,\n          2.7815e-03, -5.9603e-08, -0.0000e+00,  1.1919e-07, -8.1316e-04,\n          1.2884e-03,  2.9797e-07, -1.5003e-04,  1.8276e-03, -4.1715e-07,\n         -7.0620e-04, -0.0000e+00,  6.3106e-06, -6.3908e-04,  2.8744e-03,\n         -7.3633e-04, -0.0000e+00,  1.6141e-04, -1.6867e-03,  1.1507e-03,\n         -1.3410e-04, -1.2187e-03,  3.4615e-04, -5.4887e-04,  7.4267e-05,\n          1.5396e-03, -7.3466e-04,  2.3232e-06,  3.0552e-06, -3.3987e-04,\n         -8.9238e-07, -2.2721e-04,  1.4796e-03,  3.9013e-05, -4.2628e-04,\n         -8.6489e-04,  2.0850e-04,  3.1451e-04, -5.2286e-05,  5.9604e-08,\n         -0.0000e+00, -1.7878e-07, -1.7881e-07, -0.0000e+00, -9.6464e-04,\n          2.7958e-04,  1.9555e-03, -0.0000e+00, -9.2401e-04, -0.0000e+00,\n         -0.0000e+00,  2.3841e-07, -0.0000e+00,  2.5368e-04, -1.4082e-03,\n         -4.0222e-04, -0.0000e+00,  1.1920e-07, -5.9601e-08, -9.2983e-05,\n         -3.2723e-05, -1.1921e-07,  4.2589e-03,  1.9159e-03, -8.9273e-07,\n          1.5152e-04, -3.5753e-07,  2.0871e-03,  2.2075e-05, -3.4615e-04,\n         -0.0000e+00,  6.6144e-03, -1.2241e-04,  1.1621e-03, -4.4594e-06,\n         -0.0000e+00, -1.5910e-03,  2.5257e-05,  4.9710e-05, -1.0717e-06,\n         -3.1393e-03,  1.6081e-06,  1.9645e-06, -0.0000e+00, -5.9601e-08,\n         -0.0000e+00,  5.9604e-08, -0.0000e+00, -0.0000e+00, -4.6368e-03,\n          1.1920e-07, -0.0000e+00,  2.3839e-07, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00,  4.3403e-05, -0.0000e+00,\n         -1.8470e-03,  3.6309e-03,  1.7864e-07, -0.0000e+00,  5.9601e-08,\n         -3.9668e-03, -3.8028e-04, -0.0000e+00, -1.7501e-03, -1.0775e-03,\n         -3.0708e-04,  6.3665e-06, -2.6739e-05, -0.0000e+00, -1.5861e-03,\n          2.1594e-04, -1.0105e-03, -4.0762e-05,  7.1403e-07,  6.1978e-04,\n         -2.4371e-03, -5.9603e-08, -1.3867e-05,  1.1187e-03,  4.1163e-04,\n         -5.3625e-07, -3.8409e-04, -2.8777e-03,  5.9494e-03, -6.1421e-04,\n         -5.4388e-04, -6.1995e-04,  1.1917e-06, -1.8794e-03, -4.6681e-04,\n          1.1372e-05, -0.0000e+00, -5.3638e-07, -8.3710e-06, -5.9604e-08,\n         -0.0000e+00, -1.5028e-04, -9.5333e-07, -1.7880e-07,  2.3272e-04,\n          1.1242e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, -5.9604e-08,\n         -1.9360e-04,  1.5318e-03, -3.3739e-04, -5.9603e-08, -0.0000e+00,\n          1.1921e-07,  2.3824e-04, -5.4538e-06, -6.6566e-04,  7.1502e-07,\n          1.6683e-06, -5.9604e-08, -4.1604e-04,  8.0306e-05,  2.0903e-03,\n          6.0173e-06, -1.9917e-04, -9.5994e-06,  4.4711e-05, -0.0000e+00,\n          6.3682e-04,  3.2295e-05, -2.7357e-03, -8.5866e-04, -2.5444e-03,\n          6.3509e-04,  8.2809e-05,  4.0711e-04,  5.9603e-08,  4.5937e-04,\n         -4.9794e-04, -8.2618e-04,  3.6120e-05, -1.5957e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 2.9350e+01,  4.5748e+01,  5.5360e-01,  1.7044e+00,  1.3276e+00,\n          3.7627e+00,  1.7611e+00, -1.1210e+00,  2.9399e+00, -3.5508e-01,\n          4.0605e+00,  5.7328e-01,  2.5007e+00,  9.0170e-01, -6.1079e+00,\n         -3.3343e+00, -8.6135e-01,  1.8888e+00, -2.4710e+00, -6.1886e+00,\n         -2.3634e+00, -5.1311e+00,  1.7500e+00, -1.3429e+00,  9.9539e-01,\n         -2.9878e+00,  4.8656e+00,  4.4966e-01,  4.3922e+00,  2.2479e+00,\n         -3.1641e+00, -4.9516e+00,  8.8302e-01, -8.1241e-01, -6.5595e+00,\n         -1.8223e+01, -1.0077e+01, -4.3056e+00, -2.5043e+00,  2.9925e+00,\n         -1.3692e+00,  4.3250e+00, -1.1657e+00, -3.3491e-01,  1.0912e+00,\n         -3.3823e+00,  5.0583e+00, -2.9229e+00, -1.8596e+00, -2.3105e+00,\n         -9.9110e-01,  3.7953e+00,  1.4009e+00, -1.0057e-01,  1.4667e+00,\n          7.9612e-01, -3.7165e+00, -1.5128e+00,  2.8386e+00, -9.5000e-01,\n         -5.8614e+00, -1.5095e+00, -2.3179e+00,  3.3483e+00,  2.0858e+00,\n          4.3434e+00, -6.2032e-01,  8.9750e-01,  5.5107e+00,  8.4156e+00,\n          2.9579e+00,  6.1274e+00,  1.0875e+01,  2.8131e-01,  3.2154e+00,\n          5.7207e+00,  1.1778e-02, -8.9653e-01, -4.0259e-01, -1.1413e-02,\n         -3.3202e+00, -5.6211e+00, -5.3641e+00, -1.2784e+00, -2.6109e+00,\n          3.2980e-02,  8.8736e-01, -3.5606e+00,  2.3443e+00, -3.2493e+00,\n         -5.6337e+00,  1.8291e+00,  1.7147e+00, -2.9213e+00,  4.2255e+00,\n          6.6679e-01,  3.4298e+00,  2.6269e+00, -1.2497e+00,  2.9499e+00,\n          2.3098e-01, -5.3540e+00, -2.1183e-02,  2.4158e+00, -6.3894e+00,\n         -6.8688e+00, -4.7245e+00,  4.4991e+00,  1.0629e+00,  2.6858e+00,\n         -3.9570e+00, -2.2765e+00, -6.2107e-01, -4.2926e+00, -1.2611e+00,\n          2.7419e+00, -3.6114e-01, -3.5748e+00, -2.5581e+00, -2.8638e+00,\n          3.3623e+00, -8.7755e-02, -3.2267e+00, -2.9997e+00,  6.2296e-01,\n         -3.7940e+00, -7.8758e-01, -1.5131e-01, -6.0890e+00, -8.1293e+00,\n          4.1079e-02, -4.5297e+00,  9.2098e-01,  4.6291e+00,  1.7399e+00,\n         -1.6960e-01, -2.7151e+00, -1.8182e+00, -1.2409e+00, -5.5424e-02,\n         -1.0772e+00,  2.8636e+00,  4.1824e+00,  1.4116e+00, -2.7604e+00,\n         -8.0276e-01, -2.5153e-01, -6.9874e+00,  1.4357e+00, -1.7205e+00,\n         -1.5970e+00, -5.5685e+00, -1.3707e+00, -2.2838e+00,  2.3523e+00,\n         -4.7859e+00,  1.0539e-01,  1.3933e+00,  1.4722e+00, -4.0448e+00,\n         -6.0432e-03, -1.8195e+00, -3.5089e+00,  1.9824e+00, -3.7058e+00,\n         -2.0941e-01,  6.4984e+00, -6.9032e+00, -1.3488e+00,  7.8736e+00,\n          1.1372e+00, -3.8801e+00,  1.0401e+01, -3.2889e+00, -2.2187e+00,\n          3.3629e+00, -3.6224e+00,  3.2433e+00,  4.6243e+00, -2.2577e+00,\n         -2.3819e+00, -6.6536e+00, -1.1089e+00, -2.9367e+00, -2.2303e+00,\n         -2.3625e+00,  2.7360e+00, -1.5235e-02, -1.3149e-01, -5.8707e+00,\n         -9.9422e+00,  7.8693e-01, -2.9449e-01, -4.9920e-01, -1.9507e+00,\n          4.8084e-01, -7.4686e-01,  3.7443e-01,  1.1123e+00, -8.4654e+00,\n          2.7383e-01, -1.6068e-01, -5.0822e+00,  3.0536e+00,  1.2995e+00,\n         -1.4077e+00,  6.5778e-01, -5.0765e+00,  3.1930e+00,  6.4523e-01,\n         -3.1874e+00,  3.7434e+00,  3.5334e+00, -4.4134e+00,  4.7020e+00,\n          2.9090e+00, -1.0098e+00,  9.5475e+00, -4.6476e+00,  4.2392e+00,\n          4.4644e+00,  3.3189e+00, -1.9855e+00,  2.8129e+00, -1.4115e+00,\n          5.9588e-01, -1.0824e+01,  1.2980e-01,  4.5106e+00,  1.2031e-01,\n         -2.0689e+00,  3.1926e+00, -2.4547e+00, -1.4266e+00,  1.2850e+00,\n         -2.0923e+00, -6.6568e+00, -7.7348e-01, -1.2778e+00, -1.0582e+00,\n         -3.2455e+00, -6.8903e+00, -2.4312e+00, -3.8044e+00, -4.1907e-01,\n         -1.4723e+00, -3.7587e+00,  5.5997e+00, -7.9878e+00,  1.2072e+00,\n          2.0954e+00, -4.6072e+00, -3.9576e-02,  1.5853e+00,  8.3758e-01,\n          1.4750e+00,  9.9097e-01, -2.9199e+00, -1.9913e+00, -2.7703e+00,\n         -3.8475e+00, -1.1571e+00, -2.8431e+00, -1.6215e+00,  1.1922e+00,\n          3.3467e-01,  4.5542e+00, -4.6369e+00,  2.7194e+00, -4.4446e+00,\n          5.4141e+00,  1.8866e+00,  1.3315e+00,  4.3935e+00,  1.9109e+00,\n          9.3915e-01, -6.6314e+00,  6.9738e-01, -6.3866e-01,  9.7569e-01,\n          4.5918e+00, -2.5289e+00,  2.1722e+00, -1.1265e+00,  1.0936e+00,\n          1.2631e+00, -5.0825e+00,  3.3927e+00,  2.4375e+00,  9.1669e-01,\n         -3.0008e+00, -6.9464e+00, -3.4799e-01, -2.3153e+00,  1.3584e-02,\n         -3.6934e+00, -2.2065e+00,  3.9325e+00,  4.8018e-01, -3.3944e+00,\n          1.6102e+00,  1.6417e+00,  2.1921e+00, -3.2645e+00,  3.9814e+00,\n         -2.2636e+00,  3.0929e+00, -2.4221e-01,  1.7623e+00,  7.4673e+00,\n          2.3157e+00, -3.1123e+00, -2.9943e+00, -4.9896e+00,  2.6298e+00,\n         -3.7515e+00, -3.4549e+00,  6.1416e-01, -4.5391e+00,  2.3129e+00,\n         -6.9291e-01, -1.8131e+00,  2.7006e+00,  5.2080e+00,  3.0611e+00,\n         -3.1725e-01,  7.0668e+00,  5.5923e+00, -6.8916e-01, -3.6253e-01]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.1121e+01,  5.6507e+01,  4.5280e-01,  2.9907e+00,  1.4469e+00,\n          4.4612e+00,  5.4036e+00,  2.1798e-01, -3.6205e-01, -2.4803e-01,\n          3.2043e+00,  1.1294e+00,  2.9343e+00,  2.3582e+00, -7.2319e+00,\n         -3.7658e+00, -1.2084e+00,  2.2055e+00, -1.0857e+00, -6.3788e+00,\n         -5.5858e+00, -4.0252e+00,  1.2963e+00, -1.4376e+00,  1.4768e+00,\n         -1.0165e+00,  4.4176e+00, -1.7574e+00,  4.9328e+00,  4.8868e-01,\n          8.5831e-01, -4.5460e+00, -7.9387e-01, -1.0773e+00, -6.1081e+00,\n         -1.4397e+01, -8.3611e+00, -9.1959e+00, -7.3951e+00,  3.9404e+00,\n          1.5328e-01,  1.4158e+00, -3.4628e-01,  7.3908e-01, -1.4020e-01,\n         -2.8639e+00,  2.1542e+00,  2.9503e+00,  1.1274e+00, -1.9201e+00,\n         -1.4109e+00,  3.5615e+00,  5.3009e+00, -2.4461e+00,  3.7677e+00,\n          1.0350e+00, -3.1870e+00, -8.7673e-01,  3.2690e+00, -6.3218e-01,\n         -5.2352e+00, -4.8786e+00, -2.3655e+00,  3.8220e+00,  1.0939e+00,\n          3.2262e+00,  5.5991e-01,  2.0599e+00,  5.9015e+00,  1.1092e+01,\n          2.2866e+00,  4.1199e+00,  1.1891e+01,  6.6402e-01,  2.2663e+00,\n          6.1682e+00, -3.9949e-02,  1.3868e+00,  5.4033e-01, -1.6675e+00,\n         -2.8688e+00, -5.5233e+00, -3.7085e+00, -3.2569e-01,  3.7274e-01,\n         -2.6711e+00,  2.9688e+00, -2.7201e+00, -9.8199e-02, -3.5460e+00,\n         -4.3755e+00,  1.0585e+00,  2.4045e+00, -1.6154e+00,  2.6460e+00,\n          5.7260e+00,  3.8805e+00,  1.9504e+00, -1.3392e+00,  3.3276e-01,\n          1.6148e+00, -8.1827e+00,  3.8088e-01,  1.4439e+00, -2.9651e+00,\n         -3.5103e+00, -5.1011e+00,  3.4638e+00,  1.6436e+00,  2.6194e+00,\n         -3.7233e+00, -3.5860e+00, -2.4411e+00, -4.4463e+00,  4.9059e-01,\n          3.2903e+00, -4.2108e+00, -1.3631e+00, -3.3755e+00, -3.1816e+00,\n          4.3468e+00,  4.3679e+00, -3.2390e+00, -7.6092e-01,  1.4478e+00,\n         -9.9269e-01, -6.7036e-02, -4.1360e-01, -6.4368e+00, -5.1172e+00,\n          9.4607e-01, -1.7117e+00,  2.8786e-02,  3.0729e+00, -6.5573e-02,\n          7.0578e-01, -6.4156e-01,  4.1545e-01, -2.5708e+00,  1.2062e+00,\n         -1.6328e+00,  2.4975e-01,  4.2719e+00,  6.6581e-01, -5.5950e+00,\n         -7.5749e-01,  2.5413e+00, -4.7335e+00, -1.3273e+00, -1.4019e+00,\n         -2.3452e+00, -7.1097e+00, -3.2357e+00,  1.3045e+00,  2.5563e+00,\n         -5.6508e+00, -7.9615e-01, -1.9903e+00,  1.0476e+00, -2.3684e+00,\n          3.5505e-01, -2.3788e+00, -3.0831e+00,  5.7893e-01, -5.2296e+00,\n         -8.8923e-01,  7.1575e+00, -4.5468e+00,  3.9331e-02,  3.9299e+00,\n          3.4222e+00, -3.4493e-01,  1.0861e+01,  9.0146e-01, -5.9316e-01,\n          1.3721e+00, -1.8430e+00,  2.2769e+00,  1.9522e+00, -1.9487e+00,\n         -1.9889e+00, -5.7248e+00,  1.2108e+00, -3.1096e+00, -1.7253e+00,\n         -2.0113e+00,  5.1742e+00, -2.2139e+00,  1.7799e-01, -5.9207e+00,\n         -9.1797e+00,  1.0979e+00, -5.5790e-01,  4.8434e-01, -2.0975e+00,\n          1.6278e-01, -1.3017e+00,  3.5076e+00,  3.3949e+00, -8.5522e+00,\n          7.2875e-03, -9.0259e-02, -7.9148e+00, -2.7406e-01, -8.2611e-02,\n          7.5083e-02, -1.0298e+00, -5.8482e+00,  3.6017e+00, -5.9525e-01,\n         -4.3910e+00,  4.2376e+00,  1.7164e+00, -2.0097e+00,  5.3538e+00,\n          2.3475e+00,  3.2732e-01,  9.1324e+00, -6.6367e+00,  6.5251e+00,\n          4.9042e+00,  2.3667e+00, -8.2170e-02,  1.9433e-01, -2.5175e+00,\n          5.2394e-01, -9.3278e+00,  4.7525e-01,  7.5223e+00,  6.7399e-02,\n         -1.1374e+00,  2.4550e+00, -2.5888e+00, -1.8774e+00, -1.5249e+00,\n         -1.5199e+00, -5.4085e+00, -1.7424e+00, -8.3421e-01, -1.0775e+00,\n         -3.4396e+00, -4.8423e+00, -5.3116e-01, -2.6960e+00, -6.3826e-01,\n         -4.2770e+00, -4.7609e+00,  7.6494e+00, -6.3267e+00,  4.1911e-01,\n          1.1388e+00, -5.6476e+00,  1.4403e+00, -8.5943e-01, -1.6403e+00,\n         -8.8122e-01,  3.2089e+00,  6.6973e-01, -2.6958e+00, -2.5315e+00,\n         -5.0195e+00,  2.6405e-01, -4.7019e+00, -1.1413e+00,  3.0085e+00,\n          5.2171e-03,  3.2886e+00, -1.6320e+00,  2.2382e+00, -4.6037e+00,\n          7.6776e+00,  5.0402e+00,  1.2341e+00,  2.5769e+00,  1.1974e-01,\n         -1.4433e+00, -4.3916e+00,  3.6247e+00,  2.9402e+00, -1.9929e-01,\n          5.2572e+00, -9.2875e-02,  1.9017e+00, -1.8378e+00,  1.9331e+00,\n         -9.2229e-01, -4.5484e+00,  3.8141e+00,  1.4718e-01,  2.5019e+00,\n         -4.9350e+00, -5.0073e+00,  1.2394e-01, -1.9233e+00, -5.4917e-01,\n         -2.5406e+00, -4.1858e+00,  4.8050e+00,  1.2200e+00, -6.6719e+00,\n          2.1831e+00,  4.8689e+00,  1.3108e+00, -1.8746e+00,  2.1488e+00,\n         -1.0706e+00,  2.9510e+00,  1.6445e+00,  2.8558e+00,  6.3621e+00,\n          1.8779e+00, -5.2641e+00, -2.0785e+00, -7.6135e+00,  3.4442e+00,\n         -2.4046e+00, -4.1216e+00,  2.5956e+00, -4.6839e-01,  2.1108e+00,\n         -2.8575e+00, -4.2338e+00,  6.6614e+00,  6.4860e+00,  2.2878e+00,\n          7.4010e-01,  6.4048e+00,  5.9913e+00, -1.1886e+00, -2.1825e-02]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\n1it [01:04, 64.53s/it]\u001b[32m2023-08-14 17:34:23.431\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 54546, 31665, 36745, 55227, 34945,\n        54575, 31867, 54652, 31155, 45860, 54652, 34597, 31867, 31155, 54622,\n        33277, 32108, 55398, 31514,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:42.061\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910, 32276, 30932, 35094, 40328, 38549, 32495, 34945, 32570, 33379,\n        34597, 31867, 31155, 32040, 33534, 54541, 32495, 51694, 32543, 31867,\n        30954,    13,    13, 54611, 34300, 40228, 35181, 30956,   569, 26506,\n         2345, 30945,    13,    13, 34285, 31867, 41536, 31809, 52182, 54542,\n        48687, 33273, 30932, 39158, 32862, 31623, 33577, 33273, 31155, 32941,\n        31703, 33719, 31711, 33577, 54538, 32826, 32207, 54530, 32918, 32128,\n        31693, 31633, 31750, 31796, 48687, 54617, 33231, 31977, 31155, 54877,\n        48722, 32613, 33783, 33464, 46537, 30932, 44426, 33743, 54537, 32862,\n        37229, 34061, 33162, 30932, 47984, 54534, 34597, 33253, 32393, 32359,\n        33901, 33537, 31155,    13,    13, 31772, 55353, 54549, 31815, 45205,\n        30992,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:42.065\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 54546, 31665, 36745, 55227, 34945,\n        54575, 31867, 54652, 31155, 45860, 54652, 34597, 31867, 31155, 54622,\n        33277, 32108, 55398, 31514,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:42.067\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910, 32276, 30932, 35094, 40328, 38549, 32495, 34945, 32570, 33379,\n        34597, 31867, 31155, 32040, 33534, 54541, 32495, 51694, 32543, 31867,\n        30954,    13,    13, 54611, 34300, 40228, 35181, 30956,   569, 26506,\n         2345, 30945,    13,    13, 34285, 31867, 41536, 31809, 52182, 54542,\n        48687, 33273, 30932, 39158, 32862, 31623, 33577, 33273, 31155, 32941,\n        31703, 33719, 31711, 33577, 54538, 32826, 32207, 54530, 32918, 32128,\n        31693, 31633, 31750, 31796, 48687, 54617, 33231, 31977, 31155, 54877,\n        48722, 32613, 33783, 33464, 46537, 30932, 44426, 33743, 54537, 32862,\n        37229, 34061, 33162, 30932, 47984, 54534, 34597, 33253, 32393, 32359,\n        33901, 33537, 31155,    13,    13, 31772, 55353, 54549, 31815, 45205,\n        30992,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:42.377\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([35.4715, 50.5777,  1.0973,  1.1616,  2.0162, -1.6643,  3.6377,  8.7266,\n         1.7878,  4.6162, -0.4416,  2.0432,  1.1912, -0.2316,  3.3299,  1.3991,\n         4.2365,  2.8389, -2.0262,  1.0093, -5.2202,  0.4292,  2.7077,  1.9686,\n        -4.8101, -2.9711,  3.0639,  1.6806,  1.7020,  2.5190, -2.2384, -0.6754,\n         3.7532,  0.2759, -2.1704, -4.4529,  2.8754,  0.7417,  0.5216, -1.5204,\n        -1.2068, -3.2457,  0.9945, -2.9866, -0.5622,  1.3008,  7.7069, -1.6926,\n        -0.4749,  2.5365, -3.9021, -9.6419,  1.8070,  2.7383,  2.6731,  5.4720,\n        -6.9083, -3.7457, -0.7777, -3.5182, -2.7347, -8.1117, -1.4555,  0.5239,\n         0.4118,  6.2861,  6.2815,  5.8691,  0.5540, -0.2928,  1.6619,  1.7906,\n         2.5815,  3.2242,  1.2176,  4.2490, -3.8461,  3.0354,  3.1125, -3.1205,\n        -1.8978, -2.8862,  0.6134, -1.9909,  1.0950, -0.2235,  4.7518,  6.8181,\n        -0.2482,  6.6518, 10.6482, -0.8875,  6.0616,  5.0722, -2.9816,  6.1341,\n         3.9486,  2.0196,  4.6070,  0.1920, -0.6410, -5.3580,  0.9829,  3.9789,\n        -3.7755,  1.4932,  5.1212,  4.0147,  2.6240, -0.5142,  3.2892, -0.8990,\n        -3.6141, -4.5633,  2.1131, -2.7359, -4.8751,  5.1094, -4.1139, -0.1294,\n         2.5483,  5.0480,  1.7394, -5.4496, -5.2682, -9.7679, -2.5262,  5.3243,\n         4.9624, -0.6933], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:34:42.377\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:34:42.378\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:34:42.381\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([35.4715, 50.5777,  1.0973,  1.1616,  2.0162, -1.6643,  3.6377,  8.7266,\n         1.7878,  4.6162, -0.4416,  2.0432,  1.1912, -0.2316,  3.3299,  1.3991,\n         4.2365,  2.8389, -2.0262,  1.0093, -5.2202,  0.4292,  2.7077,  1.9686,\n        -4.8101, -2.9711,  3.0639,  1.6806,  1.7020,  2.5190, -2.2384, -0.6754,\n         3.7532,  0.2759, -2.1704, -4.4529,  2.8754,  0.7417,  0.5216, -1.5204,\n        -1.2068, -3.2457,  0.9945, -2.9866, -0.5622,  1.3008,  7.7069, -1.6926,\n        -0.4749,  2.5365, -3.9021, -9.6419,  1.8070,  2.7383,  2.6731,  5.4720,\n        -6.9083, -3.7457, -0.7777, -3.5182, -2.7347, -8.1117, -1.4555,  0.5239,\n         0.4118,  6.2861,  6.2815,  5.8691,  0.5540, -0.2928,  1.6619,  1.7906,\n         2.5815,  3.2242,  1.2176,  4.2490, -3.8461,  3.0354,  3.1125, -3.1205,\n        -1.8978, -2.8862,  0.6134, -1.9909,  1.0950, -0.2235,  4.7518,  6.8181,\n        -0.2482,  6.6518, 10.6482, -0.8875,  6.0616,  5.0722, -2.9816,  6.1341,\n         3.9486,  2.0196,  4.6070,  0.1920, -0.6410, -5.3580,  0.9829,  3.9789,\n        -3.7755,  1.4932,  5.1212,  4.0147,  2.6240, -0.5142,  3.2892, -0.8990,\n        -3.6141, -4.5633,  2.1131, -2.7359, -4.8751,  5.1094, -4.1139, -0.1294,\n         2.5483,  5.0480,  1.7394, -5.4496, -5.2682, -9.7679, -2.5262,  5.3243,\n         4.9624, -0.6933], device='cuda:0')]\u001b[0m\nepoch:  1 \nquery: 问：我需要帮忙找一部新电影看。我只看恐怖电影。你有什么建议吗？\n\n答：\nresponse: 当然,我会尽力为您推荐一部适合您的恐怖电影。以下是我为推荐的一部最新电影:\n\n《遗产之战》(Hare Krishna)\n\n这部电影是一部关于贪婪和复仇的故事,讲述了印度一个家族的故事。影片主要讲述的是家族中一位成员的复杂心理以及他们如何为了复仇而展开行动。整部电影有着紧张刺激的氛围,同时还融入了印度文化和信仰元素,让观众在恐怖的同时感受当地文化的魅力。\n\n希望您会喜欢这部电影!\nscore: tensor([35.4715, 50.5777,  1.0973,  1.1616,  2.0162, -1.6643,  3.6377,  8.7266,\n         1.7878,  4.6162, -0.4416,  2.0432,  1.1912, -0.2316,  3.3299,  1.3991,\n         4.2365,  2.8389, -2.0262,  1.0093, -5.2202,  0.4292,  2.7077,  1.9686,\n        -4.8101, -2.9711,  3.0639,  1.6806,  1.7020,  2.5190, -2.2384, -0.6754,\n         3.7532,  0.2759, -2.1704, -4.4529,  2.8754,  0.7417,  0.5216, -1.5204,\n        -1.2068, -3.2457,  0.9945, -2.9866, -0.5622,  1.3008,  7.7069, -1.6926,\n        -0.4749,  2.5365, -3.9021, -9.6419,  1.8070,  2.7383,  2.6731,  5.4720,\n        -6.9083, -3.7457, -0.7777, -3.5182, -2.7347, -8.1117, -1.4555,  0.5239,\n         0.4118,  6.2861,  6.2815,  5.8691,  0.5540, -0.2928,  1.6619,  1.7906,\n         2.5815,  3.2242,  1.2176,  4.2490, -3.8461,  3.0354,  3.1125, -3.1205,\n        -1.8978, -2.8862,  0.6134, -1.9909,  1.0950, -0.2235,  4.7518,  6.8181,\n        -0.2482,  6.6518, 10.6482, -0.8875,  6.0616,  5.0722, -2.9816,  6.1341,\n         3.9486,  2.0196,  4.6070,  0.1920, -0.6410, -5.3580,  0.9829,  3.9789,\n        -3.7755,  1.4932,  5.1212,  4.0147,  2.6240, -0.5142,  3.2892, -0.8990,\n        -3.6141, -4.5633,  2.1131, -2.7359, -4.8751,  5.1094, -4.1139, -0.1294,\n         2.5483,  5.0480,  1.7394, -5.4496, -5.2682, -9.7679, -2.5262,  5.3243,\n         4.9624, -0.6933], device='cuda:0')\n\u001b[32m2023-08-14 17:34:42.385\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:34:42.388\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([35.4715, 50.5777,  1.0973,  1.1616,  2.0162, -1.6643,  3.6377,  8.7266,\n         1.7878,  4.6162, -0.4416,  2.0432,  1.1912, -0.2316,  3.3299,  1.3991,\n         4.2365,  2.8389, -2.0262,  1.0093, -5.2202,  0.4292,  2.7077,  1.9686,\n        -4.8101, -2.9711,  3.0639,  1.6806,  1.7020,  2.5190, -2.2384, -0.6754,\n         3.7532,  0.2759, -2.1704, -4.4529,  2.8754,  0.7417,  0.5216, -1.5204,\n        -1.2068, -3.2457,  0.9945, -2.9866, -0.5622,  1.3008,  7.7069, -1.6926,\n        -0.4749,  2.5365, -3.9021, -9.6419,  1.8070,  2.7383,  2.6731,  5.4720,\n        -6.9083, -3.7457, -0.7777, -3.5182, -2.7347, -8.1117, -1.4555,  0.5239,\n         0.4118,  6.2861,  6.2815,  5.8691,  0.5540, -0.2928,  1.6619,  1.7906,\n         2.5815,  3.2242,  1.2176,  4.2490, -3.8461,  3.0354,  3.1125, -3.1205,\n        -1.8978, -2.8862,  0.6134, -1.9909,  1.0950, -0.2235,  4.7518,  6.8181,\n        -0.2482,  6.6518, 10.6482, -0.8875,  6.0616,  5.0722, -2.9816,  6.1341,\n         3.9486,  2.0196,  4.6070,  0.1920, -0.6410, -5.3580,  0.9829,  3.9789,\n        -3.7755,  1.4932,  5.1212,  4.0147,  2.6240, -0.5142,  3.2892, -0.8990,\n        -3.6141, -4.5633,  2.1131, -2.7359, -4.8751,  5.1094, -4.1139, -0.1294,\n         2.5483,  5.0480,  1.7394, -5.4496, -5.2682, -9.7679, -2.5262,  5.3243,\n         4.9624, -0.6933], device='cuda:0')]\u001b[0m\nscores=[tensor([35.4715, 50.5777,  1.0973,  1.1616,  2.0162, -1.6643,  3.6377,  8.7266,\n         1.7878,  4.6162, -0.4416,  2.0432,  1.1912, -0.2316,  3.3299,  1.3991,\n         4.2365,  2.8389, -2.0262,  1.0093, -5.2202,  0.4292,  2.7077,  1.9686,\n        -4.8101, -2.9711,  3.0639,  1.6806,  1.7020,  2.5190, -2.2384, -0.6754,\n         3.7532,  0.2759, -2.1704, -4.4529,  2.8754,  0.7417,  0.5216, -1.5204,\n        -1.2068, -3.2457,  0.9945, -2.9866, -0.5622,  1.3008,  7.7069, -1.6926,\n        -0.4749,  2.5365, -3.9021, -9.6419,  1.8070,  2.7383,  2.6731,  5.4720,\n        -6.9083, -3.7457, -0.7777, -3.5182, -2.7347, -8.1117, -1.4555,  0.5239,\n         0.4118,  6.2861,  6.2815,  5.8691,  0.5540, -0.2928,  1.6619,  1.7906,\n         2.5815,  3.2242,  1.2176,  4.2490, -3.8461,  3.0354,  3.1125, -3.1205,\n        -1.8978, -2.8862,  0.6134, -1.9909,  1.0950, -0.2235,  4.7518,  6.8181,\n        -0.2482,  6.6518, 10.6482, -0.8875,  6.0616,  5.0722, -2.9816,  6.1341,\n         3.9486,  2.0196,  4.6070,  0.1920, -0.6410, -5.3580,  0.9829,  3.9789,\n        -3.7755,  1.4932,  5.1212,  4.0147,  2.6240, -0.5142,  3.2892, -0.8990,\n        -3.6141, -4.5633,  2.1131, -2.7359, -4.8751,  5.1094, -4.1139, -0.1294,\n         2.5483,  5.0480,  1.7394, -5.4496, -5.2682, -9.7679, -2.5262,  5.3243,\n         4.9624, -0.6933], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 1.9535e+01,  4.7427e+01,  4.8896e-01,  2.0124e+00,  9.5510e-01,\n         -1.5964e+00,  1.1199e+00,  8.5044e+00,  9.9934e-01,  4.3900e+00,\n          1.6057e+00,  1.7847e+00,  7.3024e-01,  3.1776e-01,  2.1837e+00,\n          1.5244e+00,  4.4993e+00,  2.6564e+00, -4.9101e+00,  6.5431e-01,\n         -6.4965e+00, -3.5584e-01,  1.4117e+00,  1.8364e+00, -4.5212e+00,\n         -2.5381e+00,  3.7072e+00,  2.5408e+00, -3.9240e-02,  2.3966e+00,\n         -1.2330e+00, -1.4713e+00,  3.4950e+00, -2.0995e-02, -5.4677e+00,\n         -2.9549e+00,  6.9127e+00,  1.5526e+00, -3.0676e+00, -1.3743e+00,\n         -2.1596e+00, -2.1074e+00, -1.1195e+00,  1.9432e+00, -7.2331e-01,\n         -8.7685e-01,  7.4228e+00, -3.9402e+00, -1.8455e+00,  3.2568e+00,\n         -1.2480e+00, -7.8822e+00, -1.1846e+00,  1.8504e+00, -2.6531e-01,\n          8.0858e+00, -3.9024e+00, -2.7407e+00, -1.2089e+00, -4.5685e+00,\n         -1.7031e+00, -8.4735e+00, -4.7662e+00, -1.1659e-02, -2.5822e-01,\n          4.2869e+00,  5.7373e+00,  8.6634e+00, -1.5840e+00,  1.6166e+00,\n          1.3771e+00,  1.2991e+00, -1.7181e+00,  6.2829e+00,  6.2148e-01,\n          6.4936e+00, -3.6973e+00,  1.1676e+00,  3.9299e+00, -7.5701e-01,\n         -1.2503e+00,  8.5565e-03,  9.3160e-01, -7.6163e-01,  2.1189e+00,\n         -2.5460e+00,  2.2088e+00,  5.8018e+00,  1.4848e+00,  5.6049e+00,\n          1.1412e+01, -2.7449e+00,  6.8494e+00,  8.5445e+00, -2.0236e+00,\n          5.6047e+00,  2.7002e+00, -7.4753e-01,  4.8671e+00, -2.9622e+00,\n         -3.9028e-01, -4.1530e+00,  6.8163e-01,  2.7363e+00, -2.9957e+00,\n          1.3548e+00,  4.0053e+00,  3.4636e+00,  2.5969e+00, -8.9338e-01,\n          3.4592e+00, -5.8198e+00, -2.1437e+00, -3.1785e+00,  6.8610e-02,\n         -3.2629e+00, -4.6638e+00,  1.5496e+00, -2.1916e+00, -7.9228e-01,\n          4.3099e+00,  3.0004e+00,  2.3715e+00, -1.5575e+00, -3.9986e+00,\n         -8.5156e+00,  3.5234e-01,  4.3767e+00,  5.6749e+00, -1.3043e-01]],\n       device='cuda:0')\nvalues_994 = tensor([[ 3.4665e+01,  4.8020e+01,  5.8411e-01,  2.2431e+00,  1.8576e+00,\n         -1.1752e+00,  2.7404e+00,  4.5901e+00,  1.4086e+00,  3.8222e+00,\n         -1.1150e-01,  8.4184e-01,  1.2353e+00,  1.7493e+00,  1.9883e+00,\n          8.7485e-01,  3.4284e+00,  2.1466e+00, -4.2059e+00,  2.5000e+00,\n         -1.4378e+00,  2.0294e+00,  9.2224e-01,  3.7165e-01, -1.8748e+00,\n         -1.2559e+00,  4.0044e+00,  1.2188e+00, -8.3053e-02,  2.3854e+00,\n         -8.6894e-01, -4.8419e-01,  4.0890e+00,  2.3719e+00, -2.3063e+00,\n         -2.9646e+00,  9.1633e+00,  2.7893e-01,  3.1703e-02, -1.8897e+00,\n         -8.8757e-01, -1.2035e+00, -3.6189e-01,  7.6544e-01,  2.0982e+00,\n         -4.9771e-03,  5.9519e+00, -3.3572e+00,  1.1874e+00,  5.9055e-01,\n         -4.5482e+00, -9.3149e+00, -2.0221e+00,  2.3987e+00,  2.7835e+00,\n          5.7422e+00, -1.4240e+00, -3.4955e+00, -9.3849e-01, -4.3217e+00,\n         -3.0345e+00, -7.6223e+00, -1.1004e+00, -2.1001e-01, -5.0751e-02,\n          3.9985e+00,  7.8599e+00,  8.4063e+00,  1.3726e+00, -1.3181e+00,\n          6.8998e-01,  3.2773e+00, -3.4016e+00,  2.3615e+00, -1.2285e+00,\n          7.1967e+00, -2.1871e+00,  2.0918e+00,  3.6859e+00, -3.9422e+00,\n         -9.1294e-01,  2.5633e+00, -5.0020e-01, -1.1799e+00, -2.1072e+00,\n         -2.5502e+00,  1.3402e+00,  6.9512e+00, -5.8831e-01,  6.5948e+00,\n          1.0014e+01, -1.0671e+00,  5.2718e+00,  5.8848e+00, -4.2981e+00,\n          5.6223e+00,  4.2736e+00,  1.6618e-01,  3.6661e+00, -2.6584e+00,\n         -3.3005e+00, -3.2337e+00,  1.6702e-01,  2.6372e+00, -2.7464e+00,\n          1.8808e+00,  2.3416e+00,  3.8932e+00,  1.8585e+00,  2.1756e+00,\n          3.1263e+00, -2.7342e+00, -2.8288e+00, -4.5640e+00, -1.5057e-01,\n         -1.1064e+00, -2.6366e+00,  7.9528e-01, -1.8836e+00, -1.1922e-01,\n          3.3192e-01,  3.6227e+00,  3.6680e+00, -4.7223e+00, -2.8958e+00,\n         -1.0351e+01, -9.8847e-01,  2.6984e+00,  4.8396e+00, -2.0555e-01]],\n       device='cuda:0')\nreward[last_non_masked_index]=tensor([3.0942e-05], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([35.4715, 50.5777,  1.0973,  1.1616,  2.0162, -1.6643,  3.6377,  8.7266,\n         1.7878,  4.6162, -0.4416,  2.0432,  1.1912, -0.2316,  3.3299,  1.3991,\n         4.2365,  2.8389, -2.0262,  1.0093, -5.2202,  0.4292,  2.7077,  1.9686,\n        -4.8101, -2.9711,  3.0639,  1.6806,  1.7020,  2.5190, -2.2384, -0.6754,\n         3.7532,  0.2759, -2.1704, -4.4529,  2.8754,  0.7417,  0.5216, -1.5204,\n        -1.2068, -3.2457,  0.9945, -2.9866, -0.5622,  1.3008,  7.7069, -1.6926,\n        -0.4749,  2.5365, -3.9021, -9.6419,  1.8070,  2.7383,  2.6731,  5.4720,\n        -6.9083, -3.7457, -0.7777, -3.5182, -2.7347, -8.1117, -1.4555,  0.5239,\n         0.4118,  6.2861,  6.2815,  5.8691,  0.5540, -0.2928,  1.6619,  1.7906,\n         2.5815,  3.2242,  1.2176,  4.2490, -3.8461,  3.0354,  3.1125, -3.1205,\n        -1.8978, -2.8862,  0.6134, -1.9909,  1.0950, -0.2235,  4.7518,  6.8181,\n        -0.2482,  6.6518, 10.6482, -0.8875,  6.0616,  5.0722, -2.9816,  6.1341,\n         3.9486,  2.0196,  4.6070,  0.1920, -0.6410, -5.3580,  0.9829,  3.9789,\n        -3.7755,  1.4932,  5.1212,  4.0147,  2.6240, -0.5142,  3.2892, -0.8990,\n        -3.6141, -4.5633,  2.1131, -2.7359, -4.8751,  5.1094, -4.1139, -0.1294,\n         2.5483,  5.0480,  1.7394, -5.4496, -5.2682, -9.7679, -2.5262,  5.3243,\n         4.9624, -0.6933], device='cuda:0')\nvalues=tensor([[ 1.9535e+01,  4.7427e+01,  4.8896e-01,  2.0124e+00,  9.5510e-01,\n         -1.5964e+00,  1.1199e+00,  8.5044e+00,  9.9934e-01,  4.3900e+00,\n          1.6057e+00,  1.7847e+00,  7.3024e-01,  3.1776e-01,  2.1837e+00,\n          1.5244e+00,  4.4993e+00,  2.6564e+00, -4.9101e+00,  6.5431e-01,\n         -6.4965e+00, -3.5584e-01,  1.4117e+00,  1.8364e+00, -4.5212e+00,\n         -2.5381e+00,  3.7072e+00,  2.5408e+00, -3.9240e-02,  2.3966e+00,\n         -1.2330e+00, -1.4713e+00,  3.4950e+00, -2.0995e-02, -5.4677e+00,\n         -2.9549e+00,  6.9127e+00,  1.5526e+00, -3.0676e+00, -1.3743e+00,\n         -2.1596e+00, -2.1074e+00, -1.1195e+00,  1.9432e+00, -7.2331e-01,\n         -8.7685e-01,  7.4228e+00, -3.9402e+00, -1.8455e+00,  3.2568e+00,\n         -1.2480e+00, -7.8822e+00, -1.1846e+00,  1.8504e+00, -2.6531e-01,\n          8.0858e+00, -3.9024e+00, -2.7407e+00, -1.2089e+00, -4.5685e+00,\n         -1.7031e+00, -8.4735e+00, -4.7662e+00, -1.1659e-02, -2.5822e-01,\n          4.2869e+00,  5.7373e+00,  8.6634e+00, -1.5840e+00,  1.6166e+00,\n          1.3771e+00,  1.2991e+00, -1.7181e+00,  6.2829e+00,  6.2148e-01,\n          6.4936e+00, -3.6973e+00,  1.1676e+00,  3.9299e+00, -7.5701e-01,\n         -1.2503e+00,  8.5565e-03,  9.3160e-01, -7.6163e-01,  2.1189e+00,\n         -2.5460e+00,  2.2088e+00,  5.8018e+00,  1.4848e+00,  5.6049e+00,\n          1.1412e+01, -2.7449e+00,  6.8494e+00,  8.5445e+00, -2.0236e+00,\n          5.6047e+00,  2.7002e+00, -7.4753e-01,  4.8671e+00, -2.9622e+00,\n         -3.9028e-01, -4.1530e+00,  6.8163e-01,  2.7363e+00, -2.9957e+00,\n          1.3548e+00,  4.0053e+00,  3.4636e+00,  2.5969e+00, -8.9338e-01,\n          3.4592e+00, -5.8198e+00, -2.1437e+00, -3.1785e+00,  6.8610e-02,\n         -3.2629e+00, -4.6638e+00,  1.5496e+00, -2.1916e+00, -7.9228e-01,\n          4.3099e+00,  3.0004e+00,  2.3715e+00, -1.5575e+00, -3.9986e+00,\n         -8.5156e+00,  3.5234e-01,  4.3767e+00,  5.6749e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -6.4954e-04,\n         -1.6974e-03, -5.0843e-04,  5.9977e-05,  7.2621e-05, -1.5609e-04,\n         -9.8944e-05,  6.5199e-04,  2.5544e-04, -1.4794e-03, -1.0931e-03,\n          2.6276e-05, -1.0135e-03,  1.0125e-03,  6.2838e-05, -1.9097e-04,\n          5.7844e-06, -1.3120e-03,  3.6369e-04,  8.0451e-05,  1.2803e-03,\n         -3.2258e-04, -1.2194e-03,  3.3789e-03, -4.1427e-04, -1.0471e-03,\n         -9.7726e-04, -1.7096e-04, -2.3048e-04, -4.5326e-05, -2.2292e-04,\n         -3.6411e-05, -2.3159e-03,  7.0669e-06, -1.5676e-05,  2.8554e-04,\n          5.9603e-08, -2.1095e-03,  1.1920e-07, -3.5375e-05, -1.3337e-05,\n          2.1385e-04,  8.5716e-04,  7.0402e-04, -2.4699e-03,  2.1080e-05,\n         -9.2764e-04,  4.9525e-04,  5.0527e-03, -9.1860e-05,  1.0053e-03,\n         -4.7945e-03,  2.5713e-03, -7.1558e-04, -5.3379e-04, -7.1495e-07,\n         -8.9355e-07, -0.0000e+00, -1.7249e-03,  7.3086e-05,  1.2364e-05,\n          5.9601e-08,  4.2915e-05,  1.2477e-06, -6.9329e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[33.7884, 49.1008,  0.4856,  1.8825,  2.1436, -2.1828,  2.4699,  8.3747,\n         -0.4528,  3.8593,  1.5988,  1.8606,  0.2404, -2.1471,  3.0770,  2.5574,\n          3.9743,  1.6331, -2.3763, -0.6589, -4.4798, -0.7452,  1.2830,  0.2629,\n         -1.6522, -2.5781,  3.8741,  1.5441,  2.2544,  2.0138, -0.7365,  1.2391,\n          4.8047,  0.6173, -1.0393, -2.7382,  6.0797, -1.6997, -0.3192,  0.3673,\n         -1.2220, -1.3101,  2.6203, -1.1125,  1.8790, -0.7077,  4.4263, -2.3655,\n         -1.3267,  1.1431, -4.0818, -8.2086, -1.6672,  1.9727,  3.5387,  6.1080,\n         -3.2735, -3.1448, -3.7880, -2.8929, -3.4423, -6.6348, -1.3097, -0.3670,\n         -0.4598,  4.8521,  7.4788,  9.2640,  0.9575,  1.0726, -0.4432,  1.3681,\n         -1.0135,  1.1222, -1.1881,  5.8915, -3.4971,  4.1162,  4.7705, -2.0879,\n         -0.9340, -2.9730,  1.0001, -1.3282,  0.1693, -0.7690,  2.4203,  7.4007,\n         -1.0975,  4.4981, 12.6174, -0.6513,  4.3584,  5.4124, -2.7265,  4.1635,\n          4.2008, -0.5819,  2.9324, -1.4156, -0.8508, -5.6910,  1.9289,  2.5243,\n         -3.1199, -0.0842,  4.4742,  5.5582,  1.9986,  1.3452,  3.0962, -2.5769,\n         -2.3368, -4.7748, -0.6466, -0.5725, -3.8917,  2.1344, -2.2664,  2.0564,\n          3.7094,  3.4546, -0.0774, -6.4271, -3.3458, -7.3083, -1.1261,  5.6843,\n          6.2052, -0.5788]], device='cuda:0', grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.0696e+01,  5.4804e+01,  7.8600e-01,  7.5257e-01,  2.0880e+00,\n         -3.3924e+00,  1.7375e+00,  7.4639e+00,  2.7271e+00,  2.7648e+00,\n          2.2739e+00,  1.2831e+00,  2.3954e+00,  1.0221e+00,  3.3471e+00,\n          1.9591e+00,  3.3920e+00,  3.3653e+00, -3.0754e+00,  1.9979e+00,\n         -6.4988e+00,  2.0838e+00,  1.9869e+00,  1.9246e+00, -1.9553e+00,\n         -1.9652e+00,  2.9335e+00,  3.0703e+00,  9.2052e-01,  5.0218e-01,\n         -1.4592e+00, -1.4127e+00,  3.1081e+00,  2.0283e+00, -1.7530e+00,\n         -1.9028e+00,  5.4152e+00,  1.0989e-01, -9.1125e-01, -4.5064e-01,\n         -2.7228e+00, -1.4617e+00,  2.5759e+00,  6.0986e-01,  2.3178e+00,\n         -1.8449e+00,  6.3024e+00, -2.7061e+00, -2.5048e+00,  1.7908e+00,\n         -4.5444e+00, -9.4170e+00,  3.7349e-01,  2.8024e+00,  3.2795e+00,\n          8.1956e+00, -3.6200e+00, -8.6955e-01, -1.3719e+00, -3.0443e+00,\n         -1.5184e+00, -8.1575e+00, -2.2992e+00,  3.5097e+00,  7.9083e-01,\n          3.5772e+00,  6.9538e+00,  9.9784e+00,  6.3876e-01,  1.0035e+00,\n          2.7502e+00, -9.6108e-01, -2.0020e+00,  2.0913e+00, -2.2386e+00,\n          5.7030e+00, -1.3701e+00,  2.7070e+00,  3.0104e+00, -2.5454e+00,\n         -1.0039e+00,  1.1671e-01, -1.4349e-01,  1.5884e+00, -5.9703e-02,\n          5.0342e-02, -5.9247e-01,  7.2074e+00,  3.7628e+00,  5.1767e+00,\n          8.6219e+00,  1.3234e-01,  4.0337e+00,  6.2769e+00, -5.1069e+00,\n          4.4588e+00,  3.5337e+00,  3.0795e-01,  4.7077e+00,  8.3015e-02,\n         -2.3682e+00, -3.6446e+00, -5.7347e-02,  3.0610e+00, -4.2106e+00,\n          1.9030e+00,  3.0420e+00,  4.3216e+00,  1.1482e+00,  2.3456e+00,\n          3.1938e+00, -2.9860e+00, -2.9001e+00, -4.9366e+00, -2.0164e-01,\n         -5.4956e-01, -3.5752e+00,  2.1678e+00, -3.9857e+00,  2.5816e-01,\n          2.6170e+00,  4.2159e+00,  2.5769e+00, -3.7193e+00, -5.0205e+00,\n         -5.8505e+00, -1.3513e+00,  5.2107e+00,  5.4234e+00, -2.2937e-01]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\n2it [01:29, 41.36s/it]\u001b[32m2023-08-14 17:34:48.566\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 54546, 34022, 54549, 55970, 55490,\n        54955, 54805, 31155, 37474, 32495, 32071, 34177, 33607, 55398, 31514,\n           13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:35:25.095\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([44988, 31755, 55970, 55490, 54955, 54805, 32415, 30932, 32108, 32579,\n        32040, 32164, 31636, 34177, 30954,    13,    13, 30939, 30930, 30910,\n        32271, 33296, 30954, 32317, 33777, 54589, 56111, 31201, 54589, 33102,\n        54542, 48474, 32357, 30932, 54627, 44855, 31201, 56672, 57206, 31201,\n        34956, 54609, 31155, 36776, 45409, 54969, 54962, 32420, 32445, 30932,\n        54627, 55055, 57362, 31201, 54610, 54977, 31201, 37895, 31201, 42891,\n        54609, 31155,    13,    13, 30943, 30930, 30910, 31937, 49339, 30954,\n        31844, 35700, 41004, 31201, 55697, 55655, 55697, 54977, 54746, 32371,\n        44768, 30932, 33840, 32975, 55058, 30932, 31844, 55086, 54652, 32092,\n        54746, 41644, 52119, 55086, 34109, 31155,    13,    13, 30966, 30930,\n        30910, 32243, 39396, 30954, 33840, 32579, 43620, 56793, 54654, 33503,\n        30932, 54493, 56330, 56793, 30932, 54054, 31667, 54783, 55970, 55490,\n        36796, 56336, 54805, 31155,    13,    13, 30972, 30930, 50085, 55308,\n        55490, 32993, 30954, 54627, 54824, 54583, 57595, 50279, 31201, 30956,\n        30943, 51129, 59677, 55308, 55848, 54609, 55308, 55490, 32993, 41230,\n        35763, 32735, 30932, 54688, 54828, 32001, 43500, 32108, 31695, 31155,\n           13,    13, 30970, 30930, 30910, 31983, 34110, 55876, 56204, 30954,\n        32317, 32505, 36675, 42762, 30932, 34794, 34110, 30932, 35434, 34177,\n        32735, 31155,    13,    13, 31654, 31704, 31847, 32067, 34177, 32735,\n        30932, 31767, 32735, 31954, 54746, 37031, 30932, 55073, 32155, 38496,\n        31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:35:25.102\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 54546, 34022, 54549, 55970, 55490,\n        54955, 54805, 31155, 37474, 32495, 32071, 34177, 33607, 55398, 31514,\n           13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:35:25.110\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([44988, 31755, 55970, 55490, 54955, 54805, 32415, 30932, 32108, 32579,\n        32040, 32164, 31636, 34177, 30954,    13,    13, 30939, 30930, 30910,\n        32271, 33296, 30954, 32317, 33777, 54589, 56111, 31201, 54589, 33102,\n        54542, 48474, 32357, 30932, 54627, 44855, 31201, 56672, 57206, 31201,\n        34956, 54609, 31155, 36776, 45409, 54969, 54962, 32420, 32445, 30932,\n        54627, 55055, 57362, 31201, 54610, 54977, 31201, 37895, 31201, 42891,\n        54609, 31155,    13,    13, 30943, 30930, 30910, 31937, 49339, 30954,\n        31844, 35700, 41004, 31201, 55697, 55655, 55697, 54977, 54746, 32371,\n        44768, 30932, 33840, 32975, 55058, 30932, 31844, 55086, 54652, 32092,\n        54746, 41644, 52119, 55086, 34109, 31155,    13,    13, 30966, 30930,\n        30910, 32243, 39396, 30954, 33840, 32579, 43620, 56793, 54654, 33503,\n        30932, 54493, 56330, 56793, 30932, 54054, 31667, 54783, 55970, 55490,\n        36796, 56336, 54805, 31155,    13,    13, 30972, 30930, 50085, 55308,\n        55490, 32993, 30954, 54627, 54824, 54583, 57595, 50279, 31201, 30956,\n        30943, 51129, 59677, 55308, 55848, 54609, 55308, 55490, 32993, 41230,\n        35763, 32735, 30932, 54688, 54828, 32001, 43500, 32108, 31695, 31155,\n           13,    13, 30970, 30930, 30910, 31983, 34110, 55876, 56204, 30954,\n        32317, 32505, 36675, 42762, 30932, 34794, 34110, 30932, 35434, 34177,\n        32735, 31155,    13,    13, 31654, 31704, 31847, 32067, 34177, 32735,\n        30932, 31767, 32735, 31954, 54746, 37031, 30932, 55073, 32155, 38496,\n        31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:35:25.489\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 2.8971e+01,  5.0810e+01,  7.2438e-01,  1.9010e+00,  1.8037e+00,\n        -1.6414e+00,  8.8211e-01, -1.0864e+00,  1.1940e+00,  3.3773e-01,\n         1.8885e+00,  2.4777e-01, -8.6893e-01,  3.0240e+00,  4.9785e+00,\n         2.2986e+00,  3.7472e+00,  3.8027e+00,  3.1080e+00,  6.3486e+00,\n         2.5192e+00,  4.8707e+00,  3.9691e+00,  1.4606e+00,  6.3395e+00,\n         3.3643e+00,  6.2073e+00,  2.0486e+00,  5.6543e+00,  7.6161e+00,\n         5.1024e-01,  9.6858e-01,  2.2350e+00,  1.2705e+00,  6.3438e+00,\n         2.1946e+00, -7.8758e-02,  5.3360e+00,  5.9248e-01,  3.9854e+00,\n         6.7878e-01,  1.1565e+00, -5.1977e+00, -1.3537e+00, -2.8631e+00,\n        -1.1026e+00,  6.4968e+00,  4.3981e-01, -3.9078e+00, -3.3333e+00,\n         3.9331e-01, -2.3104e+00,  1.4794e+00,  6.7356e+00,  4.8651e+00,\n         1.0170e+00,  2.3899e+00, -4.0013e+00,  3.1142e+00, -1.9181e-01,\n         2.8283e+00,  3.9445e+00,  5.6390e-02, -4.6471e-01,  5.2564e+00,\n         4.6307e+00, -3.7811e+00,  8.0569e-01,  5.2746e+00,  1.0372e+01,\n         1.1598e+01,  1.0263e+01,  2.9111e+00, -3.3716e+00,  5.9105e-01,\n        -9.1534e-01, -4.0132e+00,  7.8234e-01, -2.3624e+00,  1.2042e+00,\n        -1.6353e+00,  3.9979e+00, -2.3644e+00,  8.4304e-01,  7.7734e+00,\n        -4.5670e+00, -1.2675e+00, -8.6220e-01, -2.4289e+00, -7.0568e+00,\n        -5.4398e+00, -1.7627e+00,  3.2294e+00, -3.6242e+00, -8.9213e+00,\n         1.4179e+00, -2.6260e+00, -5.0159e+00, -9.6812e-01,  2.6802e+00,\n         4.6608e+00,  4.6502e+00, -3.8036e+00,  3.3736e+00, -1.3777e+00,\n         8.2233e-01, -3.4202e+00,  3.2704e+00,  2.2160e+00, -6.1926e+00,\n        -8.4572e+00,  3.2748e+00, -6.0887e+00,  6.4971e+00, -5.7932e+00,\n        -3.5684e+00,  1.7877e+00,  8.6728e+00,  2.6226e+00, -5.3748e+00,\n        -1.6789e+00, -1.2319e+00, -4.0880e+00, -1.0073e+00, -5.3846e+00,\n        -2.7007e+00, -8.9828e-01, -6.2449e+00, -8.7980e+00, -1.1046e+01,\n        -7.4359e-01,  3.1047e+00, -5.4033e+00, -7.0038e-02, -7.9768e+00,\n        -1.0230e+01, -3.4234e+00, -7.7486e+00, -1.2137e+01, -1.0604e+00,\n        -3.5774e+00, -1.2378e+00, -5.0503e+00, -4.1562e+00,  5.3207e+00,\n         2.1230e+00,  3.2439e+00, -8.2765e+00,  2.5072e+00,  6.4326e-01,\n        -3.4425e+00, -6.1018e+00, -2.7954e+00,  4.3183e+00,  2.7065e+00,\n         6.3328e+00,  2.8750e+00, -5.6654e-01, -3.4208e+00, -2.7381e+00,\n         1.1226e+00,  4.4348e+00, -6.2716e-01, -3.6801e-01, -7.1598e+00,\n        -5.2037e+00,  2.6173e-01,  4.1187e-02,  2.6150e+00,  2.3907e+00,\n         4.6881e+00,  7.1074e+00,  5.2570e+00, -3.2223e+00,  4.9879e+00,\n        -1.4285e+00,  2.9812e+00,  8.5663e+00, -2.6390e-01,  2.4599e+00,\n         2.1256e+00,  4.6673e+00,  8.2685e+00, -1.2887e-01, -2.0330e-01,\n         3.8435e+00, -3.4254e+00, -5.0803e+00, -4.2571e+00,  2.8416e+00,\n        -5.0013e-01,  6.0509e+00,  3.4622e+00, -8.8885e-01, -4.2062e+00,\n        -2.2799e+00,  2.4055e+00,  5.0766e+00, -3.0360e+00, -3.7412e+00,\n         1.6770e+00, -5.1723e+00,  1.3964e-01,  5.8883e-01,  1.8565e+00,\n        -2.7150e+00, -1.2931e+00, -1.7356e+00,  9.9351e+00,  8.2365e+00,\n         3.9773e-01, -9.5121e-01,  1.2478e+00, -2.7209e-01, -9.3644e-01,\n         1.7486e+00,  6.4727e-01,  2.9747e+00,  8.9910e-01,  1.9004e+00,\n        -3.0941e+00,  3.9313e-01,  1.1647e-01, -4.7732e-01,  1.8589e+00,\n        -5.0131e-01], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:35:25.489\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:35:25.490\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:35:25.496\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 2.8971e+01,  5.0810e+01,  7.2438e-01,  1.9010e+00,  1.8037e+00,\n        -1.6414e+00,  8.8211e-01, -1.0864e+00,  1.1940e+00,  3.3773e-01,\n         1.8885e+00,  2.4777e-01, -8.6893e-01,  3.0240e+00,  4.9785e+00,\n         2.2986e+00,  3.7472e+00,  3.8027e+00,  3.1080e+00,  6.3486e+00,\n         2.5192e+00,  4.8707e+00,  3.9691e+00,  1.4606e+00,  6.3395e+00,\n         3.3643e+00,  6.2073e+00,  2.0486e+00,  5.6543e+00,  7.6161e+00,\n         5.1024e-01,  9.6858e-01,  2.2350e+00,  1.2705e+00,  6.3438e+00,\n         2.1946e+00, -7.8758e-02,  5.3360e+00,  5.9248e-01,  3.9854e+00,\n         6.7878e-01,  1.1565e+00, -5.1977e+00, -1.3537e+00, -2.8631e+00,\n        -1.1026e+00,  6.4968e+00,  4.3981e-01, -3.9078e+00, -3.3333e+00,\n         3.9331e-01, -2.3104e+00,  1.4794e+00,  6.7356e+00,  4.8651e+00,\n         1.0170e+00,  2.3899e+00, -4.0013e+00,  3.1142e+00, -1.9181e-01,\n         2.8283e+00,  3.9445e+00,  5.6390e-02, -4.6471e-01,  5.2564e+00,\n         4.6307e+00, -3.7811e+00,  8.0569e-01,  5.2746e+00,  1.0372e+01,\n         1.1598e+01,  1.0263e+01,  2.9111e+00, -3.3716e+00,  5.9105e-01,\n        -9.1534e-01, -4.0132e+00,  7.8234e-01, -2.3624e+00,  1.2042e+00,\n        -1.6353e+00,  3.9979e+00, -2.3644e+00,  8.4304e-01,  7.7734e+00,\n        -4.5670e+00, -1.2675e+00, -8.6220e-01, -2.4289e+00, -7.0568e+00,\n        -5.4398e+00, -1.7627e+00,  3.2294e+00, -3.6242e+00, -8.9213e+00,\n         1.4179e+00, -2.6260e+00, -5.0159e+00, -9.6812e-01,  2.6802e+00,\n         4.6608e+00,  4.6502e+00, -3.8036e+00,  3.3736e+00, -1.3777e+00,\n         8.2233e-01, -3.4202e+00,  3.2704e+00,  2.2160e+00, -6.1926e+00,\n        -8.4572e+00,  3.2748e+00, -6.0887e+00,  6.4971e+00, -5.7932e+00,\n        -3.5684e+00,  1.7877e+00,  8.6728e+00,  2.6226e+00, -5.3748e+00,\n        -1.6789e+00, -1.2319e+00, -4.0880e+00, -1.0073e+00, -5.3846e+00,\n        -2.7007e+00, -8.9828e-01, -6.2449e+00, -8.7980e+00, -1.1046e+01,\n        -7.4359e-01,  3.1047e+00, -5.4033e+00, -7.0038e-02, -7.9768e+00,\n        -1.0230e+01, -3.4234e+00, -7.7486e+00, -1.2137e+01, -1.0604e+00,\n        -3.5774e+00, -1.2378e+00, -5.0503e+00, -4.1562e+00,  5.3207e+00,\n         2.1230e+00,  3.2439e+00, -8.2765e+00,  2.5072e+00,  6.4326e-01,\n        -3.4425e+00, -6.1018e+00, -2.7954e+00,  4.3183e+00,  2.7065e+00,\n         6.3328e+00,  2.8750e+00, -5.6654e-01, -3.4208e+00, -2.7381e+00,\n         1.1226e+00,  4.4348e+00, -6.2716e-01, -3.6801e-01, -7.1598e+00,\n        -5.2037e+00,  2.6173e-01,  4.1187e-02,  2.6150e+00,  2.3907e+00,\n         4.6881e+00,  7.1074e+00,  5.2570e+00, -3.2223e+00,  4.9879e+00,\n        -1.4285e+00,  2.9812e+00,  8.5663e+00, -2.6390e-01,  2.4599e+00,\n         2.1256e+00,  4.6673e+00,  8.2685e+00, -1.2887e-01, -2.0330e-01,\n         3.8435e+00, -3.4254e+00, -5.0803e+00, -4.2571e+00,  2.8416e+00,\n        -5.0013e-01,  6.0509e+00,  3.4622e+00, -8.8885e-01, -4.2062e+00,\n        -2.2799e+00,  2.4055e+00,  5.0766e+00, -3.0360e+00, -3.7412e+00,\n         1.6770e+00, -5.1723e+00,  1.3964e-01,  5.8883e-01,  1.8565e+00,\n        -2.7150e+00, -1.2931e+00, -1.7356e+00,  9.9351e+00,  8.2365e+00,\n         3.9773e-01, -9.5121e-01,  1.2478e+00, -2.7209e-01, -9.3644e-01,\n         1.7486e+00,  6.4727e-01,  2.9747e+00,  8.9910e-01,  1.9004e+00,\n        -3.0941e+00,  3.9313e-01,  1.1647e-01, -4.7732e-01,  1.8589e+00,\n        -5.0131e-01], device='cuda:0')]\u001b[0m\nepoch:  2 \nquery: 问：我有时会胃酸反流。你能推荐一种缓解的方法吗？\n\n答：\nresponse: 当出现胃酸反流的情况,建议采取以下措施进行缓解:\n\n1. 调整饮食:避免食用高脂、高蛋白和辛辣食品,如油腻、蒜蓉、辣椒等。多吃清淡易消化的食物,如米粥、面食、土豆、黄瓜等。\n\n2. 注意饮食习惯:不要过度饮酒、暴饮暴食或快速进食,尽量慢慢吃,不要边看电视或低头玩手机边吃饭。\n\n3. 改变姿势:尽量采取左侧卧位休息,尽量不要仰卧,因为这可能使胃酸更容易逆流。\n\n4. 使用抗酸药物:如质子泵抑制剂、H2受体拮抗剂等抗酸药物可以帮助减轻症状,但需按照医生的建议使用。\n\n5. 保持心情舒畅:避免情绪波动过大,放松心情,有助于缓解症状。\n\n如果这些方法无法缓解症状,或者症状持续或加重,请及时就医。\nscore: tensor([ 2.8971e+01,  5.0810e+01,  7.2438e-01,  1.9010e+00,  1.8037e+00,\n        -1.6414e+00,  8.8211e-01, -1.0864e+00,  1.1940e+00,  3.3773e-01,\n         1.8885e+00,  2.4777e-01, -8.6893e-01,  3.0240e+00,  4.9785e+00,\n         2.2986e+00,  3.7472e+00,  3.8027e+00,  3.1080e+00,  6.3486e+00,\n         2.5192e+00,  4.8707e+00,  3.9691e+00,  1.4606e+00,  6.3395e+00,\n         3.3643e+00,  6.2073e+00,  2.0486e+00,  5.6543e+00,  7.6161e+00,\n         5.1024e-01,  9.6858e-01,  2.2350e+00,  1.2705e+00,  6.3438e+00,\n         2.1946e+00, -7.8758e-02,  5.3360e+00,  5.9248e-01,  3.9854e+00,\n         6.7878e-01,  1.1565e+00, -5.1977e+00, -1.3537e+00, -2.8631e+00,\n        -1.1026e+00,  6.4968e+00,  4.3981e-01, -3.9078e+00, -3.3333e+00,\n         3.9331e-01, -2.3104e+00,  1.4794e+00,  6.7356e+00,  4.8651e+00,\n         1.0170e+00,  2.3899e+00, -4.0013e+00,  3.1142e+00, -1.9181e-01,\n         2.8283e+00,  3.9445e+00,  5.6390e-02, -4.6471e-01,  5.2564e+00,\n         4.6307e+00, -3.7811e+00,  8.0569e-01,  5.2746e+00,  1.0372e+01,\n         1.1598e+01,  1.0263e+01,  2.9111e+00, -3.3716e+00,  5.9105e-01,\n        -9.1534e-01, -4.0132e+00,  7.8234e-01, -2.3624e+00,  1.2042e+00,\n        -1.6353e+00,  3.9979e+00, -2.3644e+00,  8.4304e-01,  7.7734e+00,\n        -4.5670e+00, -1.2675e+00, -8.6220e-01, -2.4289e+00, -7.0568e+00,\n        -5.4398e+00, -1.7627e+00,  3.2294e+00, -3.6242e+00, -8.9213e+00,\n         1.4179e+00, -2.6260e+00, -5.0159e+00, -9.6812e-01,  2.6802e+00,\n         4.6608e+00,  4.6502e+00, -3.8036e+00,  3.3736e+00, -1.3777e+00,\n         8.2233e-01, -3.4202e+00,  3.2704e+00,  2.2160e+00, -6.1926e+00,\n        -8.4572e+00,  3.2748e+00, -6.0887e+00,  6.4971e+00, -5.7932e+00,\n        -3.5684e+00,  1.7877e+00,  8.6728e+00,  2.6226e+00, -5.3748e+00,\n        -1.6789e+00, -1.2319e+00, -4.0880e+00, -1.0073e+00, -5.3846e+00,\n        -2.7007e+00, -8.9828e-01, -6.2449e+00, -8.7980e+00, -1.1046e+01,\n        -7.4359e-01,  3.1047e+00, -5.4033e+00, -7.0038e-02, -7.9768e+00,\n        -1.0230e+01, -3.4234e+00, -7.7486e+00, -1.2137e+01, -1.0604e+00,\n        -3.5774e+00, -1.2378e+00, -5.0503e+00, -4.1562e+00,  5.3207e+00,\n         2.1230e+00,  3.2439e+00, -8.2765e+00,  2.5072e+00,  6.4326e-01,\n        -3.4425e+00, -6.1018e+00, -2.7954e+00,  4.3183e+00,  2.7065e+00,\n         6.3328e+00,  2.8750e+00, -5.6654e-01, -3.4208e+00, -2.7381e+00,\n         1.1226e+00,  4.4348e+00, -6.2716e-01, -3.6801e-01, -7.1598e+00,\n        -5.2037e+00,  2.6173e-01,  4.1187e-02,  2.6150e+00,  2.3907e+00,\n         4.6881e+00,  7.1074e+00,  5.2570e+00, -3.2223e+00,  4.9879e+00,\n        -1.4285e+00,  2.9812e+00,  8.5663e+00, -2.6390e-01,  2.4599e+00,\n         2.1256e+00,  4.6673e+00,  8.2685e+00, -1.2887e-01, -2.0330e-01,\n         3.8435e+00, -3.4254e+00, -5.0803e+00, -4.2571e+00,  2.8416e+00,\n        -5.0013e-01,  6.0509e+00,  3.4622e+00, -8.8885e-01, -4.2062e+00,\n        -2.2799e+00,  2.4055e+00,  5.0766e+00, -3.0360e+00, -3.7412e+00,\n         1.6770e+00, -5.1723e+00,  1.3964e-01,  5.8883e-01,  1.8565e+00,\n        -2.7150e+00, -1.2931e+00, -1.7356e+00,  9.9351e+00,  8.2365e+00,\n         3.9773e-01, -9.5121e-01,  1.2478e+00, -2.7209e-01, -9.3644e-01,\n         1.7486e+00,  6.4727e-01,  2.9747e+00,  8.9910e-01,  1.9004e+00,\n        -3.0941e+00,  3.9313e-01,  1.1647e-01, -4.7732e-01,  1.8589e+00,\n        -5.0131e-01], device='cuda:0')\n\u001b[32m2023-08-14 17:35:25.501\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:35:25.507\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 2.8971e+01,  5.0810e+01,  7.2438e-01,  1.9010e+00,  1.8037e+00,\n        -1.6414e+00,  8.8211e-01, -1.0864e+00,  1.1940e+00,  3.3773e-01,\n         1.8885e+00,  2.4777e-01, -8.6893e-01,  3.0240e+00,  4.9785e+00,\n         2.2986e+00,  3.7472e+00,  3.8027e+00,  3.1080e+00,  6.3486e+00,\n         2.5192e+00,  4.8707e+00,  3.9691e+00,  1.4606e+00,  6.3395e+00,\n         3.3643e+00,  6.2073e+00,  2.0486e+00,  5.6543e+00,  7.6161e+00,\n         5.1024e-01,  9.6858e-01,  2.2350e+00,  1.2705e+00,  6.3438e+00,\n         2.1946e+00, -7.8758e-02,  5.3360e+00,  5.9248e-01,  3.9854e+00,\n         6.7878e-01,  1.1565e+00, -5.1977e+00, -1.3537e+00, -2.8631e+00,\n        -1.1026e+00,  6.4968e+00,  4.3981e-01, -3.9078e+00, -3.3333e+00,\n         3.9331e-01, -2.3104e+00,  1.4794e+00,  6.7356e+00,  4.8651e+00,\n         1.0170e+00,  2.3899e+00, -4.0013e+00,  3.1142e+00, -1.9181e-01,\n         2.8283e+00,  3.9445e+00,  5.6390e-02, -4.6471e-01,  5.2564e+00,\n         4.6307e+00, -3.7811e+00,  8.0569e-01,  5.2746e+00,  1.0372e+01,\n         1.1598e+01,  1.0263e+01,  2.9111e+00, -3.3716e+00,  5.9105e-01,\n        -9.1534e-01, -4.0132e+00,  7.8234e-01, -2.3624e+00,  1.2042e+00,\n        -1.6353e+00,  3.9979e+00, -2.3644e+00,  8.4304e-01,  7.7734e+00,\n        -4.5670e+00, -1.2675e+00, -8.6220e-01, -2.4289e+00, -7.0568e+00,\n        -5.4398e+00, -1.7627e+00,  3.2294e+00, -3.6242e+00, -8.9213e+00,\n         1.4179e+00, -2.6260e+00, -5.0159e+00, -9.6812e-01,  2.6802e+00,\n         4.6608e+00,  4.6502e+00, -3.8036e+00,  3.3736e+00, -1.3777e+00,\n         8.2233e-01, -3.4202e+00,  3.2704e+00,  2.2160e+00, -6.1926e+00,\n        -8.4572e+00,  3.2748e+00, -6.0887e+00,  6.4971e+00, -5.7932e+00,\n        -3.5684e+00,  1.7877e+00,  8.6728e+00,  2.6226e+00, -5.3748e+00,\n        -1.6789e+00, -1.2319e+00, -4.0880e+00, -1.0073e+00, -5.3846e+00,\n        -2.7007e+00, -8.9828e-01, -6.2449e+00, -8.7980e+00, -1.1046e+01,\n        -7.4359e-01,  3.1047e+00, -5.4033e+00, -7.0038e-02, -7.9768e+00,\n        -1.0230e+01, -3.4234e+00, -7.7486e+00, -1.2137e+01, -1.0604e+00,\n        -3.5774e+00, -1.2378e+00, -5.0503e+00, -4.1562e+00,  5.3207e+00,\n         2.1230e+00,  3.2439e+00, -8.2765e+00,  2.5072e+00,  6.4326e-01,\n        -3.4425e+00, -6.1018e+00, -2.7954e+00,  4.3183e+00,  2.7065e+00,\n         6.3328e+00,  2.8750e+00, -5.6654e-01, -3.4208e+00, -2.7381e+00,\n         1.1226e+00,  4.4348e+00, -6.2716e-01, -3.6801e-01, -7.1598e+00,\n        -5.2037e+00,  2.6173e-01,  4.1187e-02,  2.6150e+00,  2.3907e+00,\n         4.6881e+00,  7.1074e+00,  5.2570e+00, -3.2223e+00,  4.9879e+00,\n        -1.4285e+00,  2.9812e+00,  8.5663e+00, -2.6390e-01,  2.4599e+00,\n         2.1256e+00,  4.6673e+00,  8.2685e+00, -1.2887e-01, -2.0330e-01,\n         3.8435e+00, -3.4254e+00, -5.0803e+00, -4.2571e+00,  2.8416e+00,\n        -5.0013e-01,  6.0509e+00,  3.4622e+00, -8.8885e-01, -4.2062e+00,\n        -2.2799e+00,  2.4055e+00,  5.0766e+00, -3.0360e+00, -3.7412e+00,\n         1.6770e+00, -5.1723e+00,  1.3964e-01,  5.8883e-01,  1.8565e+00,\n        -2.7150e+00, -1.2931e+00, -1.7356e+00,  9.9351e+00,  8.2365e+00,\n         3.9773e-01, -9.5121e-01,  1.2478e+00, -2.7209e-01, -9.3644e-01,\n         1.7486e+00,  6.4727e-01,  2.9747e+00,  8.9910e-01,  1.9004e+00,\n        -3.0941e+00,  3.9313e-01,  1.1647e-01, -4.7732e-01,  1.8589e+00,\n        -5.0131e-01], device='cuda:0')]\u001b[0m\nscores=[tensor([ 2.8971e+01,  5.0810e+01,  7.2438e-01,  1.9010e+00,  1.8037e+00,\n        -1.6414e+00,  8.8211e-01, -1.0864e+00,  1.1940e+00,  3.3773e-01,\n         1.8885e+00,  2.4777e-01, -8.6893e-01,  3.0240e+00,  4.9785e+00,\n         2.2986e+00,  3.7472e+00,  3.8027e+00,  3.1080e+00,  6.3486e+00,\n         2.5192e+00,  4.8707e+00,  3.9691e+00,  1.4606e+00,  6.3395e+00,\n         3.3643e+00,  6.2073e+00,  2.0486e+00,  5.6543e+00,  7.6161e+00,\n         5.1024e-01,  9.6858e-01,  2.2350e+00,  1.2705e+00,  6.3438e+00,\n         2.1946e+00, -7.8758e-02,  5.3360e+00,  5.9248e-01,  3.9854e+00,\n         6.7878e-01,  1.1565e+00, -5.1977e+00, -1.3537e+00, -2.8631e+00,\n        -1.1026e+00,  6.4968e+00,  4.3981e-01, -3.9078e+00, -3.3333e+00,\n         3.9331e-01, -2.3104e+00,  1.4794e+00,  6.7356e+00,  4.8651e+00,\n         1.0170e+00,  2.3899e+00, -4.0013e+00,  3.1142e+00, -1.9181e-01,\n         2.8283e+00,  3.9445e+00,  5.6390e-02, -4.6471e-01,  5.2564e+00,\n         4.6307e+00, -3.7811e+00,  8.0569e-01,  5.2746e+00,  1.0372e+01,\n         1.1598e+01,  1.0263e+01,  2.9111e+00, -3.3716e+00,  5.9105e-01,\n        -9.1534e-01, -4.0132e+00,  7.8234e-01, -2.3624e+00,  1.2042e+00,\n        -1.6353e+00,  3.9979e+00, -2.3644e+00,  8.4304e-01,  7.7734e+00,\n        -4.5670e+00, -1.2675e+00, -8.6220e-01, -2.4289e+00, -7.0568e+00,\n        -5.4398e+00, -1.7627e+00,  3.2294e+00, -3.6242e+00, -8.9213e+00,\n         1.4179e+00, -2.6260e+00, -5.0159e+00, -9.6812e-01,  2.6802e+00,\n         4.6608e+00,  4.6502e+00, -3.8036e+00,  3.3736e+00, -1.3777e+00,\n         8.2233e-01, -3.4202e+00,  3.2704e+00,  2.2160e+00, -6.1926e+00,\n        -8.4572e+00,  3.2748e+00, -6.0887e+00,  6.4971e+00, -5.7932e+00,\n        -3.5684e+00,  1.7877e+00,  8.6728e+00,  2.6226e+00, -5.3748e+00,\n        -1.6789e+00, -1.2319e+00, -4.0880e+00, -1.0073e+00, -5.3846e+00,\n        -2.7007e+00, -8.9828e-01, -6.2449e+00, -8.7980e+00, -1.1046e+01,\n        -7.4359e-01,  3.1047e+00, -5.4033e+00, -7.0038e-02, -7.9768e+00,\n        -1.0230e+01, -3.4234e+00, -7.7486e+00, -1.2137e+01, -1.0604e+00,\n        -3.5774e+00, -1.2378e+00, -5.0503e+00, -4.1562e+00,  5.3207e+00,\n         2.1230e+00,  3.2439e+00, -8.2765e+00,  2.5072e+00,  6.4326e-01,\n        -3.4425e+00, -6.1018e+00, -2.7954e+00,  4.3183e+00,  2.7065e+00,\n         6.3328e+00,  2.8750e+00, -5.6654e-01, -3.4208e+00, -2.7381e+00,\n         1.1226e+00,  4.4348e+00, -6.2716e-01, -3.6801e-01, -7.1598e+00,\n        -5.2037e+00,  2.6173e-01,  4.1187e-02,  2.6150e+00,  2.3907e+00,\n         4.6881e+00,  7.1074e+00,  5.2570e+00, -3.2223e+00,  4.9879e+00,\n        -1.4285e+00,  2.9812e+00,  8.5663e+00, -2.6390e-01,  2.4599e+00,\n         2.1256e+00,  4.6673e+00,  8.2685e+00, -1.2887e-01, -2.0330e-01,\n         3.8435e+00, -3.4254e+00, -5.0803e+00, -4.2571e+00,  2.8416e+00,\n        -5.0013e-01,  6.0509e+00,  3.4622e+00, -8.8885e-01, -4.2062e+00,\n        -2.2799e+00,  2.4055e+00,  5.0766e+00, -3.0360e+00, -3.7412e+00,\n         1.6770e+00, -5.1723e+00,  1.3964e-01,  5.8883e-01,  1.8565e+00,\n        -2.7150e+00, -1.2931e+00, -1.7356e+00,  9.9351e+00,  8.2365e+00,\n         3.9773e-01, -9.5121e-01,  1.2478e+00, -2.7209e-01, -9.3644e-01,\n         1.7486e+00,  6.4727e-01,  2.9747e+00,  8.9910e-01,  1.9004e+00,\n        -3.0941e+00,  3.9313e-01,  1.1647e-01, -4.7732e-01,  1.8589e+00,\n        -5.0131e-01], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 3.3887e+01,  6.0952e+01,  4.0625e-01,  1.6832e+00,  1.8518e+00,\n         -1.9660e+00,  1.6515e+00, -1.7724e-01,  1.9950e+00, -5.8727e-01,\n          1.5898e+00,  9.8439e-01, -4.6636e-01,  6.3550e+00,  2.4457e+00,\n          3.0755e+00,  5.7324e+00,  3.9556e+00,  3.1190e+00,  6.1471e+00,\n          2.2842e+00,  1.6452e+00,  5.1933e+00,  4.6503e+00,  1.0772e+01,\n          2.9916e+00,  5.2772e+00,  4.9573e+00,  5.5624e+00,  6.3740e+00,\n          2.3801e-01,  1.3907e+00,  3.7305e+00, -1.3986e+00,  7.8590e+00,\n         -5.5159e-01,  1.4098e-01,  5.7531e+00, -6.8711e-01,  4.4877e+00,\n          8.4921e-01,  3.0399e+00, -4.8955e+00, -2.2453e+00, -2.0120e+00,\n         -1.4192e+00,  9.1026e+00, -3.8026e-01, -1.6719e+00, -4.0999e-01,\n          2.5511e-01,  2.1163e+00,  4.9121e+00,  5.6270e+00,  2.5856e+00,\n         -8.6257e-01,  2.4028e+00, -5.4651e+00,  6.1342e+00, -6.4300e-01,\n          1.4276e+00,  4.2680e+00, -1.0089e+00, -2.9423e+00,  6.2964e+00,\n          4.8229e+00, -5.1394e+00, -2.5669e-01,  8.0176e+00,  1.0619e+01,\n          1.0392e+01,  5.8118e+00,  4.6444e-01, -1.0043e+00,  2.8533e+00,\n         -6.5115e-01, -5.5271e+00, -7.9718e-02, -3.9374e+00,  3.5587e-01,\n         -6.5388e-01,  1.1780e+00, -9.1879e-01,  3.2900e-01,  6.9904e+00,\n         -3.6428e+00, -2.2212e+00, -1.1896e+00, -3.1243e+00, -6.2366e+00,\n         -6.1703e+00, -3.6876e+00,  2.7760e+00, -5.4000e+00, -8.8526e+00,\n         -1.3619e+00,  7.0229e-01, -5.7613e+00, -4.7923e+00,  1.5186e+00,\n          3.9216e+00,  6.1181e+00, -1.0526e+00, -7.8559e-01, -2.1270e+00,\n          7.4212e-01, -1.6938e+00,  4.4591e+00, -1.7795e+00, -3.6248e+00,\n         -6.5773e+00,  3.8552e+00, -6.7714e+00,  4.9581e+00, -4.4209e+00,\n         -4.2542e+00,  2.3813e+00,  7.9463e+00,  3.5178e+00, -3.5442e+00,\n          1.6182e+00, -1.0718e+00, -4.7795e+00, -9.8042e-01, -5.4560e+00,\n         -4.9234e+00, -4.1758e-01, -5.6676e+00, -7.8234e+00, -8.7795e+00,\n         -6.5855e-01,  2.8094e+00, -4.2062e+00, -2.6065e+00, -1.1264e+01,\n         -1.1208e+01, -5.9611e-02, -6.4072e+00, -1.4499e+01, -1.8083e+00,\n         -3.4377e+00,  3.2604e+00, -6.7722e+00, -3.1628e+00,  5.5771e+00,\n         -4.7426e-01,  2.6811e+00, -9.6623e+00,  2.9774e+00, -7.8550e-01,\n         -3.5373e+00, -6.6304e+00, -2.8059e+00,  5.8244e-02, -1.1312e+00,\n          5.9269e+00,  4.2271e+00,  2.6354e-01, -1.5365e+00,  4.1599e-01,\n          2.3276e+00,  2.2087e+00, -1.0531e-01,  3.9358e+00, -4.1686e+00,\n         -5.5083e+00, -7.1070e-01, -1.1423e+00,  7.4356e-01,  2.5445e+00,\n          6.3573e+00,  4.4067e+00,  5.4171e+00,  4.1097e-01,  3.2265e+00,\n         -2.4976e+00,  1.8606e+00,  6.0420e+00, -6.4797e-01, -8.0793e-01,\n          2.3597e+00,  7.6366e+00,  5.4874e+00, -1.0421e+00,  7.7511e-01,\n          2.0400e+00, -3.5910e+00, -4.3654e+00, -6.8197e+00,  4.2745e+00,\n         -9.9705e-01,  6.7533e+00,  4.9432e+00, -3.1547e+00, -3.2295e+00,\n         -2.0526e+00,  5.3937e+00,  6.1851e+00, -2.9077e+00, -2.0377e+00,\n          2.8606e+00, -7.0295e+00, -1.3463e+00,  3.4816e+00,  1.8215e+00,\n         -3.4578e+00, -3.7786e+00,  2.0591e+00,  1.0181e+01,  9.2818e+00,\n         -3.4067e-01, -4.5886e-01,  1.8592e+00,  7.4031e-01, -9.4908e-01,\n          2.1206e+00, -8.5515e-03,  1.4968e+00,  1.2053e+00,  2.4671e+00,\n         -8.9755e-01, -2.6354e+00,  8.7455e-01,  2.4538e+00,  4.8821e+00,\n         -2.5838e-01]], device='cuda:0')\nvalues_994 = tensor([[ 3.2808e+01,  5.4238e+01,  7.6382e-02,  1.6823e+00,  1.8362e+00,\n         -3.9698e-01,  1.3009e+00, -1.7026e+00,  1.3386e+00,  1.8928e+00,\n          4.3884e-01,  1.5255e+00, -9.7115e-01,  4.1176e+00,  2.5079e+00,\n          5.2777e+00,  5.3940e+00,  4.5476e+00,  4.1080e+00,  3.0084e+00,\n          1.8768e+00,  7.1561e+00,  3.5734e+00,  4.9531e+00,  1.0335e+01,\n          1.8500e+00,  6.0641e+00,  1.6967e+00,  4.4993e+00,  7.3010e+00,\n         -1.3068e+00, -1.0362e+00,  4.0401e+00, -7.4235e-03,  6.4712e+00,\n          2.4704e+00, -2.7259e-02,  3.4908e+00, -4.0365e-02,  3.3288e+00,\n          1.5068e+00, -4.9728e-01, -3.8746e+00, -2.2390e+00, -3.7976e+00,\n         -1.3348e+00,  5.2152e+00,  2.3331e-01,  2.4791e+00, -2.4523e+00,\n         -6.7545e-01,  4.1280e-01,  1.3224e+00,  7.5687e+00,  5.8293e+00,\n          5.6002e-01,  1.5033e+00, -3.7935e+00,  7.9666e+00,  1.2441e+00,\n          8.3445e-01,  3.6323e+00,  2.2084e+00, -1.1686e+00,  3.7229e+00,\n          4.1035e+00, -7.4740e+00,  2.5529e+00,  5.9643e+00,  1.2918e+01,\n          8.7825e+00,  5.4779e+00,  3.9788e+00, -8.4572e-01,  3.0251e+00,\n         -5.5856e-01, -2.2147e+00, -9.5020e-01, -2.3154e+00, -3.6312e-01,\n          2.1736e+00,  4.1028e+00, -8.4190e-01,  4.8806e-01,  5.2662e+00,\n         -2.6544e+00, -4.3409e+00, -2.6953e+00, -3.4571e+00, -5.4822e+00,\n         -5.3217e+00, -2.0651e+00,  2.1867e+00, -5.7445e+00, -9.0815e+00,\n         -2.6989e+00, -6.1621e-01, -6.7415e+00, -5.4855e-01,  2.0991e+00,\n          4.2197e+00,  2.0640e+00, -2.5575e+00,  3.6937e+00, -1.9362e+00,\n          9.9367e-01, -1.1976e+00,  5.0058e+00,  1.2011e+00, -4.7534e+00,\n         -5.5015e+00,  5.3702e+00, -6.7611e+00,  4.1271e+00, -4.8634e+00,\n         -3.6937e+00,  2.5206e+00,  7.0315e+00,  1.8354e+00, -4.1723e+00,\n         -1.3071e+00,  3.0791e-01, -5.6019e+00, -3.3091e+00, -6.4623e+00,\n         -1.1110e+00, -3.8613e+00, -4.7822e+00, -8.0901e+00, -1.1650e+01,\n         -4.2844e+00, -8.8027e-02, -3.4895e+00, -2.1175e+00, -9.0037e+00,\n         -1.0010e+01, -5.4019e-01, -6.5821e+00, -1.3105e+01, -2.8699e+00,\n         -4.8307e+00, -3.5742e-01, -2.7746e+00, -1.9156e+00,  7.7239e+00,\n          7.4021e-01,  2.1745e+00, -8.9101e+00,  2.6034e+00,  2.7427e+00,\n         -3.6167e+00, -3.4006e+00, -2.9883e+00,  2.6236e-01, -2.9288e+00,\n          7.9192e+00,  4.0512e+00,  5.6438e-01, -5.3772e+00, -1.4862e+00,\n          2.2982e+00,  2.9430e+00,  2.1975e+00,  3.4164e+00, -2.6919e+00,\n         -4.5989e+00, -1.9704e+00, -4.0218e+00,  2.3589e+00,  3.4273e+00,\n          4.4222e+00,  5.4888e+00,  3.6760e+00, -3.0919e+00,  4.0121e+00,\n         -2.7394e+00,  4.4539e+00,  4.4857e+00, -4.0041e-01,  1.8063e+00,\n          3.9488e+00,  5.6477e+00,  7.6247e+00,  3.9581e-01, -2.1315e-01,\n          4.5809e+00, -3.3110e+00, -2.4836e+00, -1.2165e+00,  3.0812e+00,\n         -1.4581e+00,  6.8170e+00,  4.4136e+00, -6.0662e-02, -2.9683e+00,\n         -1.8464e-01,  4.2165e+00,  4.8664e+00, -3.9041e+00, -3.6914e+00,\n          2.8066e+00, -5.1158e+00, -5.4492e-01,  1.1762e+00,  7.7071e-01,\n         -4.5330e+00, -2.7296e+00,  1.0380e-01,  8.7800e+00,  6.9889e+00,\n         -3.6510e+00, -1.7974e+00,  2.7634e+00,  2.7934e+00, -3.6011e-01,\n          2.4178e+00, -1.1614e+00,  5.7313e-01,  2.9869e-01,  2.0098e+00,\n         -2.3504e-01,  8.3777e-01, -2.1374e+00,  5.9283e-01,  2.6619e+00,\n         -9.1924e-01]], device='cuda:0')\nreward[last_non_masked_index]=tensor([2.3840e-07], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 2.8971e+01,  5.0810e+01,  7.2438e-01,  1.9010e+00,  1.8037e+00,\n        -1.6414e+00,  8.8211e-01, -1.0864e+00,  1.1940e+00,  3.3773e-01,\n         1.8885e+00,  2.4777e-01, -8.6893e-01,  3.0240e+00,  4.9785e+00,\n         2.2986e+00,  3.7472e+00,  3.8027e+00,  3.1080e+00,  6.3486e+00,\n         2.5192e+00,  4.8707e+00,  3.9691e+00,  1.4606e+00,  6.3395e+00,\n         3.3643e+00,  6.2073e+00,  2.0486e+00,  5.6543e+00,  7.6161e+00,\n         5.1024e-01,  9.6858e-01,  2.2350e+00,  1.2705e+00,  6.3438e+00,\n         2.1946e+00, -7.8758e-02,  5.3360e+00,  5.9248e-01,  3.9854e+00,\n         6.7878e-01,  1.1565e+00, -5.1977e+00, -1.3537e+00, -2.8631e+00,\n        -1.1026e+00,  6.4968e+00,  4.3981e-01, -3.9078e+00, -3.3333e+00,\n         3.9331e-01, -2.3104e+00,  1.4794e+00,  6.7356e+00,  4.8651e+00,\n         1.0170e+00,  2.3899e+00, -4.0013e+00,  3.1142e+00, -1.9181e-01,\n         2.8283e+00,  3.9445e+00,  5.6390e-02, -4.6471e-01,  5.2564e+00,\n         4.6307e+00, -3.7811e+00,  8.0569e-01,  5.2746e+00,  1.0372e+01,\n         1.1598e+01,  1.0263e+01,  2.9111e+00, -3.3716e+00,  5.9105e-01,\n        -9.1534e-01, -4.0132e+00,  7.8234e-01, -2.3624e+00,  1.2042e+00,\n        -1.6353e+00,  3.9979e+00, -2.3644e+00,  8.4304e-01,  7.7734e+00,\n        -4.5670e+00, -1.2675e+00, -8.6220e-01, -2.4289e+00, -7.0568e+00,\n        -5.4398e+00, -1.7627e+00,  3.2294e+00, -3.6242e+00, -8.9213e+00,\n         1.4179e+00, -2.6260e+00, -5.0159e+00, -9.6812e-01,  2.6802e+00,\n         4.6608e+00,  4.6502e+00, -3.8036e+00,  3.3736e+00, -1.3777e+00,\n         8.2233e-01, -3.4202e+00,  3.2704e+00,  2.2160e+00, -6.1926e+00,\n        -8.4572e+00,  3.2748e+00, -6.0887e+00,  6.4971e+00, -5.7932e+00,\n        -3.5684e+00,  1.7877e+00,  8.6728e+00,  2.6226e+00, -5.3748e+00,\n        -1.6789e+00, -1.2319e+00, -4.0880e+00, -1.0073e+00, -5.3846e+00,\n        -2.7007e+00, -8.9828e-01, -6.2449e+00, -8.7980e+00, -1.1046e+01,\n        -7.4359e-01,  3.1047e+00, -5.4033e+00, -7.0038e-02, -7.9768e+00,\n        -1.0230e+01, -3.4234e+00, -7.7486e+00, -1.2137e+01, -1.0604e+00,\n        -3.5774e+00, -1.2378e+00, -5.0503e+00, -4.1562e+00,  5.3207e+00,\n         2.1230e+00,  3.2439e+00, -8.2765e+00,  2.5072e+00,  6.4326e-01,\n        -3.4425e+00, -6.1018e+00, -2.7954e+00,  4.3183e+00,  2.7065e+00,\n         6.3328e+00,  2.8750e+00, -5.6654e-01, -3.4208e+00, -2.7381e+00,\n         1.1226e+00,  4.4348e+00, -6.2716e-01, -3.6801e-01, -7.1598e+00,\n        -5.2037e+00,  2.6173e-01,  4.1187e-02,  2.6150e+00,  2.3907e+00,\n         4.6881e+00,  7.1074e+00,  5.2570e+00, -3.2223e+00,  4.9879e+00,\n        -1.4285e+00,  2.9812e+00,  8.5663e+00, -2.6390e-01,  2.4599e+00,\n         2.1256e+00,  4.6673e+00,  8.2685e+00, -1.2887e-01, -2.0330e-01,\n         3.8435e+00, -3.4254e+00, -5.0803e+00, -4.2571e+00,  2.8416e+00,\n        -5.0013e-01,  6.0509e+00,  3.4622e+00, -8.8885e-01, -4.2062e+00,\n        -2.2799e+00,  2.4055e+00,  5.0766e+00, -3.0360e+00, -3.7412e+00,\n         1.6770e+00, -5.1723e+00,  1.3964e-01,  5.8883e-01,  1.8565e+00,\n        -2.7150e+00, -1.2931e+00, -1.7356e+00,  9.9351e+00,  8.2365e+00,\n         3.9773e-01, -9.5121e-01,  1.2478e+00, -2.7209e-01, -9.3644e-01,\n         1.7486e+00,  6.4727e-01,  2.9747e+00,  8.9910e-01,  1.9004e+00,\n        -3.0941e+00,  3.9313e-01,  1.1647e-01, -4.7732e-01,  1.8589e+00,\n        -5.0131e-01], device='cuda:0')\nvalues=tensor([[ 3.3887e+01,  6.0952e+01,  4.0625e-01,  1.6832e+00,  1.8518e+00,\n         -1.9660e+00,  1.6515e+00, -1.7724e-01,  1.9950e+00, -5.8727e-01,\n          1.5898e+00,  9.8439e-01, -4.6636e-01,  6.3550e+00,  2.4457e+00,\n          3.0755e+00,  5.7324e+00,  3.9556e+00,  3.1190e+00,  6.1471e+00,\n          2.2842e+00,  1.6452e+00,  5.1933e+00,  4.6503e+00,  1.0772e+01,\n          2.9916e+00,  5.2772e+00,  4.9573e+00,  5.5624e+00,  6.3740e+00,\n          2.3801e-01,  1.3907e+00,  3.7305e+00, -1.3986e+00,  7.8590e+00,\n         -5.5159e-01,  1.4098e-01,  5.7531e+00, -6.8711e-01,  4.4877e+00,\n          8.4921e-01,  3.0399e+00, -4.8955e+00, -2.2453e+00, -2.0120e+00,\n         -1.4192e+00,  9.1026e+00, -3.8026e-01, -1.6719e+00, -4.0999e-01,\n          2.5511e-01,  2.1163e+00,  4.9121e+00,  5.6270e+00,  2.5856e+00,\n         -8.6257e-01,  2.4028e+00, -5.4651e+00,  6.1342e+00, -6.4300e-01,\n          1.4276e+00,  4.2680e+00, -1.0089e+00, -2.9423e+00,  6.2964e+00,\n          4.8229e+00, -5.1394e+00, -2.5669e-01,  8.0176e+00,  1.0619e+01,\n          1.0392e+01,  5.8118e+00,  4.6444e-01, -1.0043e+00,  2.8533e+00,\n         -6.5115e-01, -5.5271e+00, -7.9718e-02, -3.9374e+00,  3.5587e-01,\n         -6.5388e-01,  1.1780e+00, -9.1879e-01,  3.2900e-01,  6.9904e+00,\n         -3.6428e+00, -2.2212e+00, -1.1896e+00, -3.1243e+00, -6.2366e+00,\n         -6.1703e+00, -3.6876e+00,  2.7760e+00, -5.4000e+00, -8.8526e+00,\n         -1.3619e+00,  7.0229e-01, -5.7613e+00, -4.7923e+00,  1.5186e+00,\n          3.9216e+00,  6.1181e+00, -1.0526e+00, -7.8559e-01, -2.1270e+00,\n          7.4212e-01, -1.6938e+00,  4.4591e+00, -1.7795e+00, -3.6248e+00,\n         -6.5773e+00,  3.8552e+00, -6.7714e+00,  4.9581e+00, -4.4209e+00,\n         -4.2542e+00,  2.3813e+00,  7.9463e+00,  3.5178e+00, -3.5442e+00,\n          1.6182e+00, -1.0718e+00, -4.7795e+00, -9.8042e-01, -5.4560e+00,\n         -4.9234e+00, -4.1758e-01, -5.6676e+00, -7.8234e+00, -8.7795e+00,\n         -6.5855e-01,  2.8094e+00, -4.2062e+00, -2.6065e+00, -1.1264e+01,\n         -1.1208e+01, -5.9611e-02, -6.4072e+00, -1.4499e+01, -1.8083e+00,\n         -3.4377e+00,  3.2604e+00, -6.7722e+00, -3.1628e+00,  5.5771e+00,\n         -4.7426e-01,  2.6811e+00, -9.6623e+00,  2.9774e+00, -7.8550e-01,\n         -3.5373e+00, -6.6304e+00, -2.8059e+00,  5.8244e-02, -1.1312e+00,\n          5.9269e+00,  4.2271e+00,  2.6354e-01, -1.5365e+00,  4.1599e-01,\n          2.3276e+00,  2.2087e+00, -1.0531e-01,  3.9358e+00, -4.1686e+00,\n         -5.5083e+00, -7.1070e-01, -1.1423e+00,  7.4356e-01,  2.5445e+00,\n          6.3573e+00,  4.4067e+00,  5.4171e+00,  4.1097e-01,  3.2265e+00,\n         -2.4976e+00,  1.8606e+00,  6.0420e+00, -6.4797e-01, -8.0793e-01,\n          2.3597e+00,  7.6366e+00,  5.4874e+00, -1.0421e+00,  7.7511e-01,\n          2.0400e+00, -3.5910e+00, -4.3654e+00, -6.8197e+00,  4.2745e+00,\n         -9.9705e-01,  6.7533e+00,  4.9432e+00, -3.1547e+00, -3.2295e+00,\n         -2.0526e+00,  5.3937e+00,  6.1851e+00, -2.9077e+00, -2.0377e+00,\n          2.8606e+00, -7.0295e+00, -1.3463e+00,  3.4816e+00,  1.8215e+00,\n         -3.4578e+00, -3.7786e+00,  2.0591e+00,  1.0181e+01,  9.2818e+00,\n         -3.4067e-01, -4.5886e-01,  1.8592e+00,  7.4031e-01, -9.4908e-01,\n          2.1206e+00, -8.5515e-03,  1.4968e+00,  1.2053e+00,  2.4671e+00,\n         -8.9755e-01, -2.6354e+00,  8.7455e-01,  2.4538e+00,  4.8821e+00]],\n       device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -5.3413e-05,\n         -6.7778e-05, -8.1576e-05, -4.3254e-03, -1.6677e-06,  2.9763e-06,\n         -0.0000e+00, -7.7381e-07, -0.0000e+00, -5.9597e-08,  5.3938e-05,\n         -5.9372e-08, -0.0000e+00, -5.4353e-04,  2.6571e-06, -1.7880e-07,\n          1.7626e-03, -3.3975e-04, -2.9236e-05, -1.1547e-05, -5.9601e-08,\n          9.5211e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00,  5.9590e-08,\n         -8.6308e-05,  1.2446e-05, -0.0000e+00,  9.6619e-04,  4.5653e-05,\n         -2.7939e-04, -3.0082e-04, -1.5807e-04, -5.9597e-08, -0.0000e+00,\n         -0.0000e+00,  3.2111e-04, -3.8229e-03, -2.1668e-04,  8.5225e-06,\n         -2.5852e-03,  4.7499e-04,  7.7406e-04,  1.1248e-06,  5.2592e-04,\n         -3.9371e-03,  1.4914e-05,  1.1766e-04,  3.5745e-07, -4.7956e-03,\n          1.2821e-04,  1.1102e-04,  3.1289e-05,  4.8816e-06, -5.2348e-05,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00,  3.6905e-05,  2.3383e-03,\n         -2.9609e-03, -0.0000e+00,  3.5769e-04, -2.1336e-03, -3.3744e-04,\n          1.0714e-06,  1.3521e-05, -1.2088e-04, -4.7581e-06, -2.0039e-04,\n          9.8921e-05, -1.1919e-07,  3.1296e-04,  8.3465e-05, -2.2964e-03,\n         -4.4024e-04, -3.8086e-06,  1.1921e-07,  1.3065e-04,  5.5712e-04,\n         -0.0000e+00,  1.6743e-04, -8.9381e-07, -0.0000e+00,  1.7881e-07,\n         -0.0000e+00, -2.4687e-03,  1.8381e-05, -0.0000e+00, -4.5731e-06,\n         -0.0000e+00,  2.1597e-03,  1.2057e-03, -5.9603e-08, -0.0000e+00,\n         -5.9590e-08,  9.8759e-04,  1.4267e-06, -3.5757e-07, -5.9603e-08,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0123e-06,  6.5631e-04,\n         -0.0000e+00,  1.1920e-07,  2.4484e-03, -2.1869e-04,  1.9539e-04,\n          7.6257e-05, -7.8948e-06, -1.6256e-04,  4.1172e-04,  7.8388e-04,\n         -7.1331e-06, -5.5211e-06,  7.1498e-07, -0.0000e+00, -0.0000e+00,\n          8.3284e-07, -0.0000e+00, -0.0000e+00, -2.5688e-03, -2.3894e-04,\n          1.8533e-05,  9.5289e-07, -0.0000e+00,  5.4525e-05, -4.2820e-04,\n          1.5961e-04,  8.2111e-04,  6.5548e-07,  8.2290e-04,  5.7742e-08,\n         -1.2483e-06,  1.2660e-04,  1.2396e-03,  7.7136e-05, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -1.2172e-03, -1.9771e-04,  3.6432e-05,\n         -3.5477e-04,  4.1719e-07,  1.3497e-05, -1.1966e-05,  6.5489e-04,\n          2.2203e-05,  1.2283e-05, -7.2330e-04,  1.2890e-06, -0.0000e+00,\n          1.5390e-04, -7.1025e-04, -1.7262e-06,  4.0522e-03, -5.0131e-01]],\n       device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 34.4712,  34.2315,   0.6770,   2.2006,   1.7926,  -2.1200,   2.6660,\n          -2.1748,   2.6987,   2.7472,   2.3818,   2.0339,  -2.5514,   3.9880,\n           4.0345,   5.0628,   6.0353,   3.6322,   3.3443,   6.5481,   4.0360,\n           3.8210,   5.0299,   0.9658,   9.9946,   4.2143,   5.8137,   4.8645,\n           5.3307,   6.6567,   0.8918,   2.3691,   6.7752,  -1.2447,   5.0308,\n           3.2242,  -0.5976,   6.9320,   0.1925,   5.3517,   0.1178,   0.4304,\n          -5.9156,  -2.7219,  -4.3380,   0.1163,   7.1489,  -0.6594,  -2.2028,\n          -2.3855,   0.9589,  -2.0125,   2.3743,   6.0994,   2.7897,  -2.7924,\n           2.5049,  -1.1837,   4.0598,   0.1464,   0.1798,   5.0649,   2.8346,\n           1.3214,   6.5784,   6.6105,  -4.8801,  -1.8641,   6.5709,  11.0129,\n          10.0657,   5.7187,   4.5998,   0.5957,   0.1785,   0.1055,  -2.4496,\n           4.5315,  -0.9413,   3.0123,   0.6695,   3.1505,  -2.8102,  -0.0972,\n           5.5347,  -4.8734,  -1.5908,   0.1037,  -4.3242,  -7.1897,  -5.2858,\n          -3.3450,   3.8402,  -4.9539, -10.2664,  -0.7595,   0.3768,  -3.6565,\n          -2.5075,   1.8416,   3.2683,   3.1697,  -2.4772,   2.4050,  -2.3654,\n          -2.5351,  -3.2692,   7.5949,   2.3262,  -6.0955,  -8.2239,   3.3541,\n          -4.7700,   6.2653,  -3.9857,  -4.5348,   4.5941,   6.4864,   2.1197,\n          -2.0560,  -2.4084,  -0.0706,  -5.3144,  -2.0948,  -7.4531,  -3.3670,\n          -2.4942,  -5.9712,  -6.3115,  -7.8603,  -0.8603,   1.3503,  -5.3552,\n          -1.1221, -11.0442,  -7.3155,  -2.8887,  -7.0582, -14.1742,  -1.0838,\n          -7.5695,   0.1688,  -4.7517,  -2.6982,   6.5335,   4.5127,   0.4788,\n          -8.0264,   4.5761,   2.2059,  -2.9955,  -3.5023,  -5.7800,  -2.4557,\n          -1.9201,   4.9310,   3.9576,   1.1838,  -1.5803,   2.1705,   2.3581,\n           3.5240,   1.9966,   4.1011,  -5.0389,  -3.6820,   0.3112,   0.2046,\n           2.5728,   3.2512,   5.6236,   4.0907,   6.0318,  -0.9652,   3.0864,\n          -3.3951,   3.2787,   5.1225,  -0.5137,   0.0628,   3.5151,   4.3606,\n           6.2312,  -1.6705,   0.4293,   2.2418,  -4.6778,  -4.7806,  -2.4433,\n           2.4705,  -0.9204,   5.6578,   4.6019,  -2.5393,  -3.2064,  -0.3876,\n           5.3981,   4.2915,  -3.0731,  -1.7475,   2.3608,  -4.5853,  -2.0856,\n           0.9865,   1.8542,  -4.2511,  -1.1660,  -1.6170,   7.6138,   6.2673,\n           0.4145,  -2.8692,   0.6891,   1.7654,  -2.9393,   1.3898,  -3.2258,\n           1.1942,   0.7386,   2.5129,   0.5608,  -2.1227,  -0.4729,   0.0994,\n           3.3925,  -0.6427]], device='cuda:0', grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.0807e+01,  5.4462e+01,  6.3534e-01,  6.3548e-01,  1.0261e+00,\n         -1.7706e+00,  1.7240e+00, -1.1727e+00,  1.6769e-01,  1.2687e+00,\n          6.4046e-01,  2.0313e+00, -4.2331e-01,  6.1635e+00,  4.2772e+00,\n          5.3116e+00,  4.9696e+00,  4.8681e+00,  2.1989e+00,  5.4763e+00,\n          2.5012e+00,  3.4603e+00,  6.0471e+00,  3.5137e+00,  8.2683e+00,\n          5.7768e-01,  7.6161e+00,  1.3979e+00,  5.7256e+00,  4.9821e+00,\n          1.0049e+00, -6.9006e-01,  3.8958e+00, -6.8689e-01,  6.1895e+00,\n          3.5467e+00, -1.4556e-01,  4.9718e+00,  2.2799e-01,  2.5951e+00,\n          1.9993e+00, -4.4833e-02, -5.9780e+00, -4.5325e+00, -3.7888e+00,\n         -7.0486e-01,  4.3288e+00,  9.8132e-01, -1.8405e+00,  1.1162e+00,\n          1.7644e-01,  5.2256e-01,  5.1677e+00,  7.6924e+00,  4.6083e+00,\n         -7.1335e-01, -1.4936e+00, -2.8868e+00,  1.8416e+00, -1.6907e+00,\n          1.1616e+00,  4.3977e+00,  1.2228e+00,  1.4308e+00,  5.8836e+00,\n          3.9436e+00, -4.1271e+00, -3.1527e-02,  6.2973e+00,  1.2536e+01,\n          8.8779e+00,  4.7122e+00,  4.8558e+00, -1.9864e+00, -7.2013e-02,\n          1.3115e+00, -1.8353e+00, -1.1058e+00, -4.0021e+00, -4.2061e-01,\n         -5.2651e-01,  2.7505e+00,  8.7358e-01, -8.2952e-01,  6.7438e+00,\n         -1.9367e+00, -2.1155e+00, -4.7548e-01, -3.6133e+00, -6.1468e+00,\n         -6.9784e+00, -7.2158e-01,  3.2472e-01, -6.4178e+00, -1.2357e+01,\n         -1.8328e+00, -3.3599e+00, -8.3576e+00, -5.2183e-01, -9.3398e-02,\n          4.0937e+00,  4.0226e+00, -2.6687e+00,  1.4835e+00,  1.3731e-01,\n         -4.8825e+00, -2.5143e+00,  5.0759e+00,  3.5463e+00, -6.8058e+00,\n         -6.6807e+00,  2.1040e+00, -5.6985e+00,  4.7308e+00, -3.4648e+00,\n         -3.7100e+00,  1.3796e+00,  6.3994e+00,  1.4649e+00, -3.4668e+00,\n         -4.2991e-01,  9.3635e-01, -5.5386e+00,  1.8920e+00, -7.2990e+00,\n         -3.5670e+00, -3.2962e+00, -6.3720e+00, -8.1562e+00, -8.2980e+00,\n         -2.9940e+00,  3.4865e+00, -5.7200e+00,  8.3431e-01, -7.8250e+00,\n         -9.3170e+00, -6.0374e-01, -5.1377e+00, -1.0399e+01, -7.7332e-01,\n         -5.3256e+00,  9.8395e-01, -3.0859e+00, -3.3018e+00,  7.0722e+00,\n          1.0228e+00,  2.6449e+00, -6.8218e+00,  4.8009e+00,  3.5730e+00,\n         -5.1102e+00, -2.0953e+00, -3.2875e+00, -1.8578e-01,  7.7158e-01,\n          4.5807e+00,  6.1507e+00, -1.3055e+00, -4.5698e+00, -1.5741e+00,\n          9.6251e-01,  3.0379e+00,  1.8731e+00,  1.8650e+00, -2.9949e+00,\n         -4.0808e+00, -4.1654e-01, -2.6347e+00,  2.0804e+00, -1.7627e+00,\n          5.9249e+00,  7.3025e+00,  3.5151e+00,  1.3404e+00,  4.2191e+00,\n         -3.2800e+00,  3.8662e+00,  4.5230e+00, -1.2960e+00, -2.7067e-01,\n          2.8862e+00,  4.7292e+00,  7.4265e+00, -1.2502e+00, -1.4615e+00,\n          3.6347e+00, -3.5313e+00, -4.1446e+00, -4.7650e+00,  1.5124e+00,\n         -3.6664e+00,  7.0220e+00,  3.5745e+00, -3.2242e+00, -2.2039e+00,\n          1.2898e+00,  3.9668e+00,  3.7657e+00, -2.8731e+00, -1.5236e+00,\n          2.9689e+00, -4.2441e+00, -1.3115e+00,  2.6920e+00, -1.0474e+00,\n         -3.0223e+00, -1.2320e+00, -1.8137e-01,  1.1154e+01,  8.5991e+00,\n          2.9553e-01, -1.0450e-01, -1.2067e+00,  6.6492e-01, -1.1694e+00,\n          1.4069e+00, -9.3901e-01, -6.8980e-01, -8.0489e-01,  2.8227e+00,\n         -1.4105e+00, -1.0073e+00, -1.1003e+00,  6.8863e-01, -5.6720e-01,\n         -1.0482e+00]], device='cuda:0', grad_fn=<PermuteBackward0>)\n\u001b[32m2023-08-14 17:35:32.011\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m592\u001b[0m - \u001b[31m\u001b[1mepoch=2, save to ppo_0813_v1step_2\u001b[0m\n/kaggle/working/chatGLM-6B-QLoRA/trainer.py:1405: UserWarning: Cannot retrieve user information assuming you are running in offline mode.\n  warnings.warn(\"Cannot retrieve user information assuming you are running in offline mode.\")\n3it [02:13, 42.65s/it]\u001b[32m2023-08-14 17:35:32.749\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 55227, 32024, 55256, 55883, 31065,\n        54974, 56072, 55942, 54827, 31301,  3319, 30916,   717, 29861,  1071,\n        27199, 31300, 38148, 31155,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:36:34.085\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([40976, 55883, 31065, 54974, 56072, 55942, 54827, 31301,  3319, 30916,\n          717, 29861,  1071, 27199, 31300, 36853, 34811, 31730, 32646, 31201,\n        32910, 54542, 55036, 54661, 35239, 31155, 54572, 42317, 37916, 54875,\n        36960, 38148, 31123, 31779, 32040, 55013, 54605, 31211,    13,    13,\n        30939, 30930, 32816, 41450, 54631, 30943, 31211, 35188, 54576, 32484,\n        17574,  8930, 30910, 30943, 30954,  4607,  4686,  2857, 30932, 30910,\n        30939, 30969, 30969, 30939, 54540, 34325, 54974, 56072, 55942, 54827,\n        54534, 40477, 34975, 32759, 34196, 54530, 35200, 55385, 55591, 54631,\n        31123, 54619, 43065, 31743, 35177, 31155,    13,    13, 30943, 30930,\n        32816, 37469, 47477, 32484,  8228,   380,   433, 30932, 30910, 30939,\n        30969, 30969, 30972, 54540, 34325, 54974, 56072, 55942, 54827, 54619,\n        55943, 56248, 31065, 54982, 55867, 54927, 31884, 36492, 34285, 38119,\n        33170, 54900, 31155,    13,    13, 30966, 30930, 32816, 42740, 38634,\n        32484, 49389,  7386, 30932, 30910, 30939, 30969, 30969, 30973, 54540,\n        34325, 54974, 56072, 55942, 54827, 54534, 40477, 34975, 32826, 54624,\n        42740, 54712, 33197, 31123, 33014, 37392, 37035, 32646, 33231, 38427,\n        31155,    13,    13, 30972, 30930, 32816, 31730, 55443, 31211, 57495,\n        55529, 54809, 55201, 32484,  7522, 26961,  2018,   595, 30954,  8443,\n         4416, 30932, 30910, 30943, 30940, 30940, 30970, 54540, 34325, 33526,\n        31952, 31867, 54538, 31123, 54974, 56072, 55942, 54827, 44821, 54557,\n        55888, 54724, 54736, 55492, 31123, 32998, 39948, 40447, 31155,    13,\n           13, 30970, 30930, 32816, 55405, 54682, 54751, 59272, 54992, 32484,\n         4649,  4690, 30954, 10509,  4004, 30932, 30910, 30943, 30940, 30943,\n        30943, 54540, 34325, 35562, 54605, 32696, 33238, 33162, 38148, 31123,\n        54974, 56072, 55942, 54827, 34295, 35200, 33705, 31123, 54541, 32941,\n        36819, 39291, 35024, 54706, 31155,    13,    13, 30978, 30930, 32816,\n        32372, 41084, 43399, 49587, 32484, 16486,   290, 14583, 30932, 30910,\n        30943, 30940, 30939, 30943, 54540, 34325, 31855, 32501, 54974, 56072,\n        55942, 54827, 35971, 54534, 40477, 33656, 31123, 54688, 33152, 47795,\n        33356, 54538, 35226, 31123, 32998, 36283, 54570, 44232, 32751, 32185,\n        31155,    13,    13, 32413, 31123, 54974, 56072, 55942, 54827, 54656,\n        31948, 34529, 33839, 54542, 32954, 33007, 31155, 33063, 33761, 31842,\n        32732, 41926, 31123, 54688, 31804, 34099, 31842, 54606, 34632, 40252,\n        31959, 39312, 44725, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:36:34.094\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 55227, 32024, 55256, 55883, 31065,\n        54974, 56072, 55942, 54827, 31301,  3319, 30916,   717, 29861,  1071,\n        27199, 31300, 38148, 31155,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:36:34.100\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([40976, 55883, 31065, 54974, 56072, 55942, 54827, 31301,  3319, 30916,\n          717, 29861,  1071, 27199, 31300, 36853, 34811, 31730, 32646, 31201,\n        32910, 54542, 55036, 54661, 35239, 31155, 54572, 42317, 37916, 54875,\n        36960, 38148, 31123, 31779, 32040, 55013, 54605, 31211,    13,    13,\n        30939, 30930, 32816, 41450, 54631, 30943, 31211, 35188, 54576, 32484,\n        17574,  8930, 30910, 30943, 30954,  4607,  4686,  2857, 30932, 30910,\n        30939, 30969, 30969, 30939, 54540, 34325, 54974, 56072, 55942, 54827,\n        54534, 40477, 34975, 32759, 34196, 54530, 35200, 55385, 55591, 54631,\n        31123, 54619, 43065, 31743, 35177, 31155,    13,    13, 30943, 30930,\n        32816, 37469, 47477, 32484,  8228,   380,   433, 30932, 30910, 30939,\n        30969, 30969, 30972, 54540, 34325, 54974, 56072, 55942, 54827, 54619,\n        55943, 56248, 31065, 54982, 55867, 54927, 31884, 36492, 34285, 38119,\n        33170, 54900, 31155,    13,    13, 30966, 30930, 32816, 42740, 38634,\n        32484, 49389,  7386, 30932, 30910, 30939, 30969, 30969, 30973, 54540,\n        34325, 54974, 56072, 55942, 54827, 54534, 40477, 34975, 32826, 54624,\n        42740, 54712, 33197, 31123, 33014, 37392, 37035, 32646, 33231, 38427,\n        31155,    13,    13, 30972, 30930, 32816, 31730, 55443, 31211, 57495,\n        55529, 54809, 55201, 32484,  7522, 26961,  2018,   595, 30954,  8443,\n         4416, 30932, 30910, 30943, 30940, 30940, 30970, 54540, 34325, 33526,\n        31952, 31867, 54538, 31123, 54974, 56072, 55942, 54827, 44821, 54557,\n        55888, 54724, 54736, 55492, 31123, 32998, 39948, 40447, 31155,    13,\n           13, 30970, 30930, 32816, 55405, 54682, 54751, 59272, 54992, 32484,\n         4649,  4690, 30954, 10509,  4004, 30932, 30910, 30943, 30940, 30943,\n        30943, 54540, 34325, 35562, 54605, 32696, 33238, 33162, 38148, 31123,\n        54974, 56072, 55942, 54827, 34295, 35200, 33705, 31123, 54541, 32941,\n        36819, 39291, 35024, 54706, 31155,    13,    13, 30978, 30930, 32816,\n        32372, 41084, 43399, 49587, 32484, 16486,   290, 14583, 30932, 30910,\n        30943, 30940, 30939, 30943, 54540, 34325, 31855, 32501, 54974, 56072,\n        55942, 54827, 35971, 54534, 40477, 33656, 31123, 54688, 33152, 47795,\n        33356, 54538, 35226, 31123, 32998, 36283, 54570, 44232, 32751, 32185,\n        31155,    13,    13, 32413, 31123, 54974, 56072, 55942, 54827, 54656,\n        31948, 34529, 33839, 54542, 32954, 33007, 31155, 33063, 33761, 31842,\n        32732, 41926, 31123, 54688, 31804, 34099, 31842, 54606, 34632, 40252,\n        31959, 39312, 44725, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:36:34.606\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 3.4296e+01,  5.7245e+01, -3.4173e-01,  1.0732e+00,  1.8514e+00,\n         3.7195e+00,  9.1810e+00, -5.0200e+00,  2.0666e+00,  5.3543e+00,\n        -1.1966e+00, -2.3492e+00,  2.0849e+00,  1.7445e+00, -1.2193e+00,\n        -4.2903e+00, -3.3085e+00,  3.8077e+00, -4.4564e+00,  2.0944e+00,\n         2.1661e+00,  4.9603e+00,  3.8769e+00, -1.0178e+00, -2.1964e+00,\n        -3.7696e+00,  2.9922e+00, -2.9759e+00,  3.9500e+00,  6.2525e+00,\n         2.8714e+00,  2.2254e+00,  2.6275e+00,  7.7435e+00,  2.5461e+00,\n         2.6868e+00, -6.6348e+00, -2.7627e+00,  2.5832e+00, -4.8588e+00,\n         2.8053e+00,  9.4535e-01,  6.2034e+00, -1.7067e+00, -3.9325e+00,\n         3.4279e+00,  3.7333e+00, -2.2788e-01,  2.7852e+00,  3.5750e+00,\n        -3.4897e+00,  1.6309e+00,  5.1453e-01, -2.2326e+00,  9.4474e-01,\n         1.5094e+00,  1.8203e+00,  2.8113e-02, -3.9560e+00, -4.5073e+00,\n         3.9179e+00, -5.5451e-01,  1.3044e+00, -2.4977e+00,  1.4056e+00,\n         8.6783e+00,  3.3090e+00,  4.7074e-01, -2.8421e+00, -4.3157e+00,\n        -8.7847e+00,  5.4433e-02,  9.8004e-01, -2.0724e+00, -1.8822e+00,\n        -4.5423e+00,  5.9508e+00,  3.7158e+00,  7.8284e-01,  6.4745e+00,\n         1.1400e-01,  1.7735e+00, -1.0970e+00,  4.4848e+00, -2.4315e-01,\n         1.4717e-01, -3.5114e+00,  1.6134e+00, -6.0287e+00,  2.1288e+00,\n         2.2380e+00, -4.3057e-01, -2.0770e+00, -4.3280e+00,  6.5873e-02,\n         3.6119e+00,  4.8346e+00,  1.3708e+00, -4.1261e+00, -3.8400e+00,\n        -2.9844e+00, -4.3532e+00,  4.1852e+00, -4.3863e+00,  1.3686e+00,\n        -1.3237e+00,  1.0197e+00, -2.6526e-01,  4.3457e+00,  2.2352e+00,\n        -3.3019e+00,  9.1908e-01, -3.1793e+00, -3.3927e+00, -2.7986e+00,\n        -1.8313e+00, -5.3981e+00, -5.2378e+00, -1.0750e+00, -6.9646e-01,\n         8.1524e+00,  2.1031e+00, -6.2335e+00, -4.4792e+00,  2.7338e+00,\n        -3.4973e+00, -2.6838e+00, -2.1525e+00, -2.2735e+00, -5.5038e+00,\n         1.7068e+00, -1.4420e+00, -1.0518e-01,  2.6567e+00,  2.2574e+00,\n         8.0893e-01,  2.0313e+00, -2.3769e+00, -6.9142e+00,  5.0267e+00,\n         2.6844e-01, -7.0587e-01,  4.5909e+00,  6.6801e-02,  2.1802e+00,\n        -9.5861e+00, -7.6504e+00,  1.4267e+00, -2.9378e+00,  3.3220e+00,\n        -1.1246e+00, -1.6681e+00,  6.5601e-01, -2.7801e+00, -5.8374e+00,\n        -4.8500e+00, -4.7838e+00,  7.1248e+00,  2.5099e+00,  4.9110e+00,\n         3.4504e+00,  1.4478e+00, -5.9584e-01,  9.8794e-01,  5.5499e-01,\n         2.7302e+00,  2.5695e+00,  3.3496e-02, -2.3803e+00,  3.5474e+00,\n         4.9866e+00,  2.1157e+00, -4.4914e-01, -6.2658e+00, -7.8908e+00,\n         1.2225e+00, -1.4019e+00, -7.3207e-01, -2.4060e+00, -2.4232e+00,\n         2.7389e+00,  4.2365e+00,  5.9394e+00,  8.0223e+00,  7.4132e-01,\n         5.1132e-01, -2.1605e+00,  6.5293e+00, -6.2644e-01, -1.2248e-02,\n         3.0211e+00, -2.5989e+00, -4.4759e+00, -5.0757e+00,  3.3103e-01,\n         8.0316e+00,  5.8939e-01, -9.3821e-02,  4.5739e+00,  1.2919e+00,\n         4.9879e+00, -2.6253e+00,  7.9448e+00,  2.6186e+00, -3.3308e+00,\n         5.5581e+00,  3.0607e+00,  4.0355e+00,  2.0919e+00, -1.6307e+00,\n        -1.3034e+00,  2.1696e+00,  2.9075e+00, -3.5802e+00,  9.3460e-01,\n         3.6711e+00, -3.4491e+00,  1.0421e+01,  5.1740e-01,  2.8213e-01,\n        -1.7228e-01,  2.5664e+00,  2.7048e+00,  4.8827e+00,  4.0648e+00,\n         1.4850e+00, -1.7006e-01,  1.0212e+01,  3.4075e+00,  3.5563e+00,\n        -1.0064e+00, -5.2011e+00,  4.8370e+00,  1.3409e+00, -2.5707e-01,\n         5.5842e+00,  7.0989e-01,  1.4320e+00, -1.0587e+00, -4.0606e+00,\n        -1.3765e+00, -5.3106e+00, -2.1791e+00, -9.7516e-01, -2.8993e+00,\n        -4.7489e+00, -2.0732e+00, -4.9433e+00,  3.5939e+00,  3.1986e-01,\n        -8.2117e+00, -7.7291e+00, -1.2833e+00, -6.9936e-01, -4.3675e+00,\n        -9.1125e-01, -5.3638e+00, -1.8944e+00,  4.6577e+00, -1.4666e+00,\n        -9.1116e+00, -1.1300e+00, -4.8533e+00, -6.8254e+00,  4.3193e+00,\n         5.8433e+00, -3.2335e+00,  3.2417e+00,  3.9123e+00,  4.6465e+00,\n         4.4165e+00, -3.7378e+00, -1.0727e+01, -7.4831e+00,  9.3274e-01,\n         6.1026e-01, -2.1846e+00, -1.2438e+00,  6.1305e-01, -5.0525e+00,\n        -6.9618e+00, -5.6158e+00,  5.6109e-01,  2.5618e+00,  2.8883e+00,\n        -1.7377e+00, -4.0750e+00, -6.6224e+00, -2.3536e+00, -2.8986e+00,\n         1.4949e+00,  2.7278e+00, -2.0280e+00,  3.1770e+00, -1.9191e-01,\n        -2.0512e+00,  3.4324e-01, -2.3173e+00, -1.3597e+00, -1.6575e+00,\n        -5.7879e-02,  4.3091e+00, -1.2774e+00, -5.4781e+00,  1.7975e+00,\n        -5.5706e-01,  5.6760e+00,  3.7405e+00,  7.3193e+00,  4.0970e+00,\n         2.3074e+00, -9.2674e-01, -3.9130e+00,  9.8264e-01, -3.3207e+00,\n        -1.2618e+00, -7.0933e+00, -2.1450e+00, -7.9025e-01,  7.1518e-01,\n        -9.2832e-01,  1.3717e+00, -2.9662e+00, -6.3992e+00, -8.5130e+00,\n        -3.5056e+00, -6.8514e-02,  2.4428e+00,  7.9716e-01,  2.4398e+00,\n         3.5792e+00, -1.0514e-01,  1.0037e+00,  3.6074e+00,  2.4670e+00,\n         7.5132e+00,  3.5364e+00,  1.8546e+00,  2.1394e+00, -9.0697e-01,\n        -3.7934e+00,  2.1237e+00, -5.9750e+00,  1.4347e+00,  2.6516e+00,\n         2.3747e+00, -4.4053e-01,  3.3619e+00,  6.4273e+00,  3.8224e+00,\n        -2.8302e+00, -9.9224e-01, -2.0866e+00, -5.1943e+00, -9.3268e-01,\n        -8.3262e+00, -1.0956e+01,  2.2687e+00,  6.0638e-01, -4.6699e+00,\n         1.0300e+00,  4.2104e+00,  1.1291e-01], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:36:34.607\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:36:34.607\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:36:34.616\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 3.4296e+01,  5.7245e+01, -3.4173e-01,  1.0732e+00,  1.8514e+00,\n         3.7195e+00,  9.1810e+00, -5.0200e+00,  2.0666e+00,  5.3543e+00,\n        -1.1966e+00, -2.3492e+00,  2.0849e+00,  1.7445e+00, -1.2193e+00,\n        -4.2903e+00, -3.3085e+00,  3.8077e+00, -4.4564e+00,  2.0944e+00,\n         2.1661e+00,  4.9603e+00,  3.8769e+00, -1.0178e+00, -2.1964e+00,\n        -3.7696e+00,  2.9922e+00, -2.9759e+00,  3.9500e+00,  6.2525e+00,\n         2.8714e+00,  2.2254e+00,  2.6275e+00,  7.7435e+00,  2.5461e+00,\n         2.6868e+00, -6.6348e+00, -2.7627e+00,  2.5832e+00, -4.8588e+00,\n         2.8053e+00,  9.4535e-01,  6.2034e+00, -1.7067e+00, -3.9325e+00,\n         3.4279e+00,  3.7333e+00, -2.2788e-01,  2.7852e+00,  3.5750e+00,\n        -3.4897e+00,  1.6309e+00,  5.1453e-01, -2.2326e+00,  9.4474e-01,\n         1.5094e+00,  1.8203e+00,  2.8113e-02, -3.9560e+00, -4.5073e+00,\n         3.9179e+00, -5.5451e-01,  1.3044e+00, -2.4977e+00,  1.4056e+00,\n         8.6783e+00,  3.3090e+00,  4.7074e-01, -2.8421e+00, -4.3157e+00,\n        -8.7847e+00,  5.4433e-02,  9.8004e-01, -2.0724e+00, -1.8822e+00,\n        -4.5423e+00,  5.9508e+00,  3.7158e+00,  7.8284e-01,  6.4745e+00,\n         1.1400e-01,  1.7735e+00, -1.0970e+00,  4.4848e+00, -2.4315e-01,\n         1.4717e-01, -3.5114e+00,  1.6134e+00, -6.0287e+00,  2.1288e+00,\n         2.2380e+00, -4.3057e-01, -2.0770e+00, -4.3280e+00,  6.5873e-02,\n         3.6119e+00,  4.8346e+00,  1.3708e+00, -4.1261e+00, -3.8400e+00,\n        -2.9844e+00, -4.3532e+00,  4.1852e+00, -4.3863e+00,  1.3686e+00,\n        -1.3237e+00,  1.0197e+00, -2.6526e-01,  4.3457e+00,  2.2352e+00,\n        -3.3019e+00,  9.1908e-01, -3.1793e+00, -3.3927e+00, -2.7986e+00,\n        -1.8313e+00, -5.3981e+00, -5.2378e+00, -1.0750e+00, -6.9646e-01,\n         8.1524e+00,  2.1031e+00, -6.2335e+00, -4.4792e+00,  2.7338e+00,\n        -3.4973e+00, -2.6838e+00, -2.1525e+00, -2.2735e+00, -5.5038e+00,\n         1.7068e+00, -1.4420e+00, -1.0518e-01,  2.6567e+00,  2.2574e+00,\n         8.0893e-01,  2.0313e+00, -2.3769e+00, -6.9142e+00,  5.0267e+00,\n         2.6844e-01, -7.0587e-01,  4.5909e+00,  6.6801e-02,  2.1802e+00,\n        -9.5861e+00, -7.6504e+00,  1.4267e+00, -2.9378e+00,  3.3220e+00,\n        -1.1246e+00, -1.6681e+00,  6.5601e-01, -2.7801e+00, -5.8374e+00,\n        -4.8500e+00, -4.7838e+00,  7.1248e+00,  2.5099e+00,  4.9110e+00,\n         3.4504e+00,  1.4478e+00, -5.9584e-01,  9.8794e-01,  5.5499e-01,\n         2.7302e+00,  2.5695e+00,  3.3496e-02, -2.3803e+00,  3.5474e+00,\n         4.9866e+00,  2.1157e+00, -4.4914e-01, -6.2658e+00, -7.8908e+00,\n         1.2225e+00, -1.4019e+00, -7.3207e-01, -2.4060e+00, -2.4232e+00,\n         2.7389e+00,  4.2365e+00,  5.9394e+00,  8.0223e+00,  7.4132e-01,\n         5.1132e-01, -2.1605e+00,  6.5293e+00, -6.2644e-01, -1.2248e-02,\n         3.0211e+00, -2.5989e+00, -4.4759e+00, -5.0757e+00,  3.3103e-01,\n         8.0316e+00,  5.8939e-01, -9.3821e-02,  4.5739e+00,  1.2919e+00,\n         4.9879e+00, -2.6253e+00,  7.9448e+00,  2.6186e+00, -3.3308e+00,\n         5.5581e+00,  3.0607e+00,  4.0355e+00,  2.0919e+00, -1.6307e+00,\n        -1.3034e+00,  2.1696e+00,  2.9075e+00, -3.5802e+00,  9.3460e-01,\n         3.6711e+00, -3.4491e+00,  1.0421e+01,  5.1740e-01,  2.8213e-01,\n        -1.7228e-01,  2.5664e+00,  2.7048e+00,  4.8827e+00,  4.0648e+00,\n         1.4850e+00, -1.7006e-01,  1.0212e+01,  3.4075e+00,  3.5563e+00,\n        -1.0064e+00, -5.2011e+00,  4.8370e+00,  1.3409e+00, -2.5707e-01,\n         5.5842e+00,  7.0989e-01,  1.4320e+00, -1.0587e+00, -4.0606e+00,\n        -1.3765e+00, -5.3106e+00, -2.1791e+00, -9.7516e-01, -2.8993e+00,\n        -4.7489e+00, -2.0732e+00, -4.9433e+00,  3.5939e+00,  3.1986e-01,\n        -8.2117e+00, -7.7291e+00, -1.2833e+00, -6.9936e-01, -4.3675e+00,\n        -9.1125e-01, -5.3638e+00, -1.8944e+00,  4.6577e+00, -1.4666e+00,\n        -9.1116e+00, -1.1300e+00, -4.8533e+00, -6.8254e+00,  4.3193e+00,\n         5.8433e+00, -3.2335e+00,  3.2417e+00,  3.9123e+00,  4.6465e+00,\n         4.4165e+00, -3.7378e+00, -1.0727e+01, -7.4831e+00,  9.3274e-01,\n         6.1026e-01, -2.1846e+00, -1.2438e+00,  6.1305e-01, -5.0525e+00,\n        -6.9618e+00, -5.6158e+00,  5.6109e-01,  2.5618e+00,  2.8883e+00,\n        -1.7377e+00, -4.0750e+00, -6.6224e+00, -2.3536e+00, -2.8986e+00,\n         1.4949e+00,  2.7278e+00, -2.0280e+00,  3.1770e+00, -1.9191e-01,\n        -2.0512e+00,  3.4324e-01, -2.3173e+00, -1.3597e+00, -1.6575e+00,\n        -5.7879e-02,  4.3091e+00, -1.2774e+00, -5.4781e+00,  1.7975e+00,\n        -5.5706e-01,  5.6760e+00,  3.7405e+00,  7.3193e+00,  4.0970e+00,\n         2.3074e+00, -9.2674e-01, -3.9130e+00,  9.8264e-01, -3.3207e+00,\n        -1.2618e+00, -7.0933e+00, -2.1450e+00, -7.9025e-01,  7.1518e-01,\n        -9.2832e-01,  1.3717e+00, -2.9662e+00, -6.3992e+00, -8.5130e+00,\n        -3.5056e+00, -6.8514e-02,  2.4428e+00,  7.9716e-01,  2.4398e+00,\n         3.5792e+00, -1.0514e-01,  1.0037e+00,  3.6074e+00,  2.4670e+00,\n         7.5132e+00,  3.5364e+00,  1.8546e+00,  2.1394e+00, -9.0697e-01,\n        -3.7934e+00,  2.1237e+00, -5.9750e+00,  1.4347e+00,  2.6516e+00,\n         2.3747e+00, -4.4053e-01,  3.3619e+00,  6.4273e+00,  3.8224e+00,\n        -2.8302e+00, -9.9224e-01, -2.0866e+00, -5.1943e+00, -9.3268e-01,\n        -8.3262e+00, -1.0956e+01,  2.2687e+00,  6.0638e-01, -4.6699e+00,\n         1.0300e+00,  4.2104e+00,  1.1291e-01], device='cuda:0')]\u001b[0m\nepoch:  3 \nquery: 问：找一下阿诺·施瓦辛格（Arnold Schwarzenegger）的电影。\n\n答：\nresponse: 阿诺·施瓦辛格（Arnold Schwarzenegger）是一位著名的美国演员、导演和健美运动员。他参演了许多广受欢迎的电影，包括以下几部：\n\n1. 《终结者2：审判日》（Terminator 2: Judgment Day, 1991年）：施瓦辛格在片中扮演一名回归的机器人追杀者，与成龙合作出演。\n\n2. 《真实的谎言》（True Lies, 1994年）：施瓦辛格与汤姆·克鲁斯共同演绎这部科幻动作片。\n\n3. 《银河大夫》（Galaxy Quest, 1998年）：施瓦辛格在片中扮演一位前银河系总统，带领一群喜剧演员展开冒险。\n\n4. 《美国派：裸露万岁》（American Pie Presents: Band Camp, 2005年）：在这个系列电影中，施瓦辛格本色出镜并题词，展现搞笑天赋。\n\n5. 《异次元骇客》（Alita: Battle Angel, 2022年）：这是一部充满战斗元素的电影，施瓦辛格饰演机器人主角，为影片注入强劲的力量感。\n\n6. 《少年派的奇幻漂流》（Life of Pi, 2012年）：虽然这次施瓦辛格并未在片中主演，但他在绑架场景中亮相，展现了他对角色的深刻理解。\n\n此外，施瓦辛格还参与了一些电视剧和广告拍摄。尽管现在的作品相对较少，但他的早期作品都取得了很高的关注度和市场份额。\nscore: tensor([ 3.4296e+01,  5.7245e+01, -3.4173e-01,  1.0732e+00,  1.8514e+00,\n         3.7195e+00,  9.1810e+00, -5.0200e+00,  2.0666e+00,  5.3543e+00,\n        -1.1966e+00, -2.3492e+00,  2.0849e+00,  1.7445e+00, -1.2193e+00,\n        -4.2903e+00, -3.3085e+00,  3.8077e+00, -4.4564e+00,  2.0944e+00,\n         2.1661e+00,  4.9603e+00,  3.8769e+00, -1.0178e+00, -2.1964e+00,\n        -3.7696e+00,  2.9922e+00, -2.9759e+00,  3.9500e+00,  6.2525e+00,\n         2.8714e+00,  2.2254e+00,  2.6275e+00,  7.7435e+00,  2.5461e+00,\n         2.6868e+00, -6.6348e+00, -2.7627e+00,  2.5832e+00, -4.8588e+00,\n         2.8053e+00,  9.4535e-01,  6.2034e+00, -1.7067e+00, -3.9325e+00,\n         3.4279e+00,  3.7333e+00, -2.2788e-01,  2.7852e+00,  3.5750e+00,\n        -3.4897e+00,  1.6309e+00,  5.1453e-01, -2.2326e+00,  9.4474e-01,\n         1.5094e+00,  1.8203e+00,  2.8113e-02, -3.9560e+00, -4.5073e+00,\n         3.9179e+00, -5.5451e-01,  1.3044e+00, -2.4977e+00,  1.4056e+00,\n         8.6783e+00,  3.3090e+00,  4.7074e-01, -2.8421e+00, -4.3157e+00,\n        -8.7847e+00,  5.4433e-02,  9.8004e-01, -2.0724e+00, -1.8822e+00,\n        -4.5423e+00,  5.9508e+00,  3.7158e+00,  7.8284e-01,  6.4745e+00,\n         1.1400e-01,  1.7735e+00, -1.0970e+00,  4.4848e+00, -2.4315e-01,\n         1.4717e-01, -3.5114e+00,  1.6134e+00, -6.0287e+00,  2.1288e+00,\n         2.2380e+00, -4.3057e-01, -2.0770e+00, -4.3280e+00,  6.5873e-02,\n         3.6119e+00,  4.8346e+00,  1.3708e+00, -4.1261e+00, -3.8400e+00,\n        -2.9844e+00, -4.3532e+00,  4.1852e+00, -4.3863e+00,  1.3686e+00,\n        -1.3237e+00,  1.0197e+00, -2.6526e-01,  4.3457e+00,  2.2352e+00,\n        -3.3019e+00,  9.1908e-01, -3.1793e+00, -3.3927e+00, -2.7986e+00,\n        -1.8313e+00, -5.3981e+00, -5.2378e+00, -1.0750e+00, -6.9646e-01,\n         8.1524e+00,  2.1031e+00, -6.2335e+00, -4.4792e+00,  2.7338e+00,\n        -3.4973e+00, -2.6838e+00, -2.1525e+00, -2.2735e+00, -5.5038e+00,\n         1.7068e+00, -1.4420e+00, -1.0518e-01,  2.6567e+00,  2.2574e+00,\n         8.0893e-01,  2.0313e+00, -2.3769e+00, -6.9142e+00,  5.0267e+00,\n         2.6844e-01, -7.0587e-01,  4.5909e+00,  6.6801e-02,  2.1802e+00,\n        -9.5861e+00, -7.6504e+00,  1.4267e+00, -2.9378e+00,  3.3220e+00,\n        -1.1246e+00, -1.6681e+00,  6.5601e-01, -2.7801e+00, -5.8374e+00,\n        -4.8500e+00, -4.7838e+00,  7.1248e+00,  2.5099e+00,  4.9110e+00,\n         3.4504e+00,  1.4478e+00, -5.9584e-01,  9.8794e-01,  5.5499e-01,\n         2.7302e+00,  2.5695e+00,  3.3496e-02, -2.3803e+00,  3.5474e+00,\n         4.9866e+00,  2.1157e+00, -4.4914e-01, -6.2658e+00, -7.8908e+00,\n         1.2225e+00, -1.4019e+00, -7.3207e-01, -2.4060e+00, -2.4232e+00,\n         2.7389e+00,  4.2365e+00,  5.9394e+00,  8.0223e+00,  7.4132e-01,\n         5.1132e-01, -2.1605e+00,  6.5293e+00, -6.2644e-01, -1.2248e-02,\n         3.0211e+00, -2.5989e+00, -4.4759e+00, -5.0757e+00,  3.3103e-01,\n         8.0316e+00,  5.8939e-01, -9.3821e-02,  4.5739e+00,  1.2919e+00,\n         4.9879e+00, -2.6253e+00,  7.9448e+00,  2.6186e+00, -3.3308e+00,\n         5.5581e+00,  3.0607e+00,  4.0355e+00,  2.0919e+00, -1.6307e+00,\n        -1.3034e+00,  2.1696e+00,  2.9075e+00, -3.5802e+00,  9.3460e-01,\n         3.6711e+00, -3.4491e+00,  1.0421e+01,  5.1740e-01,  2.8213e-01,\n        -1.7228e-01,  2.5664e+00,  2.7048e+00,  4.8827e+00,  4.0648e+00,\n         1.4850e+00, -1.7006e-01,  1.0212e+01,  3.4075e+00,  3.5563e+00,\n        -1.0064e+00, -5.2011e+00,  4.8370e+00,  1.3409e+00, -2.5707e-01,\n         5.5842e+00,  7.0989e-01,  1.4320e+00, -1.0587e+00, -4.0606e+00,\n        -1.3765e+00, -5.3106e+00, -2.1791e+00, -9.7516e-01, -2.8993e+00,\n        -4.7489e+00, -2.0732e+00, -4.9433e+00,  3.5939e+00,  3.1986e-01,\n        -8.2117e+00, -7.7291e+00, -1.2833e+00, -6.9936e-01, -4.3675e+00,\n        -9.1125e-01, -5.3638e+00, -1.8944e+00,  4.6577e+00, -1.4666e+00,\n        -9.1116e+00, -1.1300e+00, -4.8533e+00, -6.8254e+00,  4.3193e+00,\n         5.8433e+00, -3.2335e+00,  3.2417e+00,  3.9123e+00,  4.6465e+00,\n         4.4165e+00, -3.7378e+00, -1.0727e+01, -7.4831e+00,  9.3274e-01,\n         6.1026e-01, -2.1846e+00, -1.2438e+00,  6.1305e-01, -5.0525e+00,\n        -6.9618e+00, -5.6158e+00,  5.6109e-01,  2.5618e+00,  2.8883e+00,\n        -1.7377e+00, -4.0750e+00, -6.6224e+00, -2.3536e+00, -2.8986e+00,\n         1.4949e+00,  2.7278e+00, -2.0280e+00,  3.1770e+00, -1.9191e-01,\n        -2.0512e+00,  3.4324e-01, -2.3173e+00, -1.3597e+00, -1.6575e+00,\n        -5.7879e-02,  4.3091e+00, -1.2774e+00, -5.4781e+00,  1.7975e+00,\n        -5.5706e-01,  5.6760e+00,  3.7405e+00,  7.3193e+00,  4.0970e+00,\n         2.3074e+00, -9.2674e-01, -3.9130e+00,  9.8264e-01, -3.3207e+00,\n        -1.2618e+00, -7.0933e+00, -2.1450e+00, -7.9025e-01,  7.1518e-01,\n        -9.2832e-01,  1.3717e+00, -2.9662e+00, -6.3992e+00, -8.5130e+00,\n        -3.5056e+00, -6.8514e-02,  2.4428e+00,  7.9716e-01,  2.4398e+00,\n         3.5792e+00, -1.0514e-01,  1.0037e+00,  3.6074e+00,  2.4670e+00,\n         7.5132e+00,  3.5364e+00,  1.8546e+00,  2.1394e+00, -9.0697e-01,\n        -3.7934e+00,  2.1237e+00, -5.9750e+00,  1.4347e+00,  2.6516e+00,\n         2.3747e+00, -4.4053e-01,  3.3619e+00,  6.4273e+00,  3.8224e+00,\n        -2.8302e+00, -9.9224e-01, -2.0866e+00, -5.1943e+00, -9.3268e-01,\n        -8.3262e+00, -1.0956e+01,  2.2687e+00,  6.0638e-01, -4.6699e+00,\n         1.0300e+00,  4.2104e+00,  1.1291e-01], device='cuda:0')\n\u001b[32m2023-08-14 17:36:34.625\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:36:34.634\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 3.4296e+01,  5.7245e+01, -3.4173e-01,  1.0732e+00,  1.8514e+00,\n         3.7195e+00,  9.1810e+00, -5.0200e+00,  2.0666e+00,  5.3543e+00,\n        -1.1966e+00, -2.3492e+00,  2.0849e+00,  1.7445e+00, -1.2193e+00,\n        -4.2903e+00, -3.3085e+00,  3.8077e+00, -4.4564e+00,  2.0944e+00,\n         2.1661e+00,  4.9603e+00,  3.8769e+00, -1.0178e+00, -2.1964e+00,\n        -3.7696e+00,  2.9922e+00, -2.9759e+00,  3.9500e+00,  6.2525e+00,\n         2.8714e+00,  2.2254e+00,  2.6275e+00,  7.7435e+00,  2.5461e+00,\n         2.6868e+00, -6.6348e+00, -2.7627e+00,  2.5832e+00, -4.8588e+00,\n         2.8053e+00,  9.4535e-01,  6.2034e+00, -1.7067e+00, -3.9325e+00,\n         3.4279e+00,  3.7333e+00, -2.2788e-01,  2.7852e+00,  3.5750e+00,\n        -3.4897e+00,  1.6309e+00,  5.1453e-01, -2.2326e+00,  9.4474e-01,\n         1.5094e+00,  1.8203e+00,  2.8113e-02, -3.9560e+00, -4.5073e+00,\n         3.9179e+00, -5.5451e-01,  1.3044e+00, -2.4977e+00,  1.4056e+00,\n         8.6783e+00,  3.3090e+00,  4.7074e-01, -2.8421e+00, -4.3157e+00,\n        -8.7847e+00,  5.4433e-02,  9.8004e-01, -2.0724e+00, -1.8822e+00,\n        -4.5423e+00,  5.9508e+00,  3.7158e+00,  7.8284e-01,  6.4745e+00,\n         1.1400e-01,  1.7735e+00, -1.0970e+00,  4.4848e+00, -2.4315e-01,\n         1.4717e-01, -3.5114e+00,  1.6134e+00, -6.0287e+00,  2.1288e+00,\n         2.2380e+00, -4.3057e-01, -2.0770e+00, -4.3280e+00,  6.5873e-02,\n         3.6119e+00,  4.8346e+00,  1.3708e+00, -4.1261e+00, -3.8400e+00,\n        -2.9844e+00, -4.3532e+00,  4.1852e+00, -4.3863e+00,  1.3686e+00,\n        -1.3237e+00,  1.0197e+00, -2.6526e-01,  4.3457e+00,  2.2352e+00,\n        -3.3019e+00,  9.1908e-01, -3.1793e+00, -3.3927e+00, -2.7986e+00,\n        -1.8313e+00, -5.3981e+00, -5.2378e+00, -1.0750e+00, -6.9646e-01,\n         8.1524e+00,  2.1031e+00, -6.2335e+00, -4.4792e+00,  2.7338e+00,\n        -3.4973e+00, -2.6838e+00, -2.1525e+00, -2.2735e+00, -5.5038e+00,\n         1.7068e+00, -1.4420e+00, -1.0518e-01,  2.6567e+00,  2.2574e+00,\n         8.0893e-01,  2.0313e+00, -2.3769e+00, -6.9142e+00,  5.0267e+00,\n         2.6844e-01, -7.0587e-01,  4.5909e+00,  6.6801e-02,  2.1802e+00,\n        -9.5861e+00, -7.6504e+00,  1.4267e+00, -2.9378e+00,  3.3220e+00,\n        -1.1246e+00, -1.6681e+00,  6.5601e-01, -2.7801e+00, -5.8374e+00,\n        -4.8500e+00, -4.7838e+00,  7.1248e+00,  2.5099e+00,  4.9110e+00,\n         3.4504e+00,  1.4478e+00, -5.9584e-01,  9.8794e-01,  5.5499e-01,\n         2.7302e+00,  2.5695e+00,  3.3496e-02, -2.3803e+00,  3.5474e+00,\n         4.9866e+00,  2.1157e+00, -4.4914e-01, -6.2658e+00, -7.8908e+00,\n         1.2225e+00, -1.4019e+00, -7.3207e-01, -2.4060e+00, -2.4232e+00,\n         2.7389e+00,  4.2365e+00,  5.9394e+00,  8.0223e+00,  7.4132e-01,\n         5.1132e-01, -2.1605e+00,  6.5293e+00, -6.2644e-01, -1.2248e-02,\n         3.0211e+00, -2.5989e+00, -4.4759e+00, -5.0757e+00,  3.3103e-01,\n         8.0316e+00,  5.8939e-01, -9.3821e-02,  4.5739e+00,  1.2919e+00,\n         4.9879e+00, -2.6253e+00,  7.9448e+00,  2.6186e+00, -3.3308e+00,\n         5.5581e+00,  3.0607e+00,  4.0355e+00,  2.0919e+00, -1.6307e+00,\n        -1.3034e+00,  2.1696e+00,  2.9075e+00, -3.5802e+00,  9.3460e-01,\n         3.6711e+00, -3.4491e+00,  1.0421e+01,  5.1740e-01,  2.8213e-01,\n        -1.7228e-01,  2.5664e+00,  2.7048e+00,  4.8827e+00,  4.0648e+00,\n         1.4850e+00, -1.7006e-01,  1.0212e+01,  3.4075e+00,  3.5563e+00,\n        -1.0064e+00, -5.2011e+00,  4.8370e+00,  1.3409e+00, -2.5707e-01,\n         5.5842e+00,  7.0989e-01,  1.4320e+00, -1.0587e+00, -4.0606e+00,\n        -1.3765e+00, -5.3106e+00, -2.1791e+00, -9.7516e-01, -2.8993e+00,\n        -4.7489e+00, -2.0732e+00, -4.9433e+00,  3.5939e+00,  3.1986e-01,\n        -8.2117e+00, -7.7291e+00, -1.2833e+00, -6.9936e-01, -4.3675e+00,\n        -9.1125e-01, -5.3638e+00, -1.8944e+00,  4.6577e+00, -1.4666e+00,\n        -9.1116e+00, -1.1300e+00, -4.8533e+00, -6.8254e+00,  4.3193e+00,\n         5.8433e+00, -3.2335e+00,  3.2417e+00,  3.9123e+00,  4.6465e+00,\n         4.4165e+00, -3.7378e+00, -1.0727e+01, -7.4831e+00,  9.3274e-01,\n         6.1026e-01, -2.1846e+00, -1.2438e+00,  6.1305e-01, -5.0525e+00,\n        -6.9618e+00, -5.6158e+00,  5.6109e-01,  2.5618e+00,  2.8883e+00,\n        -1.7377e+00, -4.0750e+00, -6.6224e+00, -2.3536e+00, -2.8986e+00,\n         1.4949e+00,  2.7278e+00, -2.0280e+00,  3.1770e+00, -1.9191e-01,\n        -2.0512e+00,  3.4324e-01, -2.3173e+00, -1.3597e+00, -1.6575e+00,\n        -5.7879e-02,  4.3091e+00, -1.2774e+00, -5.4781e+00,  1.7975e+00,\n        -5.5706e-01,  5.6760e+00,  3.7405e+00,  7.3193e+00,  4.0970e+00,\n         2.3074e+00, -9.2674e-01, -3.9130e+00,  9.8264e-01, -3.3207e+00,\n        -1.2618e+00, -7.0933e+00, -2.1450e+00, -7.9025e-01,  7.1518e-01,\n        -9.2832e-01,  1.3717e+00, -2.9662e+00, -6.3992e+00, -8.5130e+00,\n        -3.5056e+00, -6.8514e-02,  2.4428e+00,  7.9716e-01,  2.4398e+00,\n         3.5792e+00, -1.0514e-01,  1.0037e+00,  3.6074e+00,  2.4670e+00,\n         7.5132e+00,  3.5364e+00,  1.8546e+00,  2.1394e+00, -9.0697e-01,\n        -3.7934e+00,  2.1237e+00, -5.9750e+00,  1.4347e+00,  2.6516e+00,\n         2.3747e+00, -4.4053e-01,  3.3619e+00,  6.4273e+00,  3.8224e+00,\n        -2.8302e+00, -9.9224e-01, -2.0866e+00, -5.1943e+00, -9.3268e-01,\n        -8.3262e+00, -1.0956e+01,  2.2687e+00,  6.0638e-01, -4.6699e+00,\n         1.0300e+00,  4.2104e+00,  1.1291e-01], device='cuda:0')]\u001b[0m\nscores=[tensor([ 3.4296e+01,  5.7245e+01, -3.4173e-01,  1.0732e+00,  1.8514e+00,\n         3.7195e+00,  9.1810e+00, -5.0200e+00,  2.0666e+00,  5.3543e+00,\n        -1.1966e+00, -2.3492e+00,  2.0849e+00,  1.7445e+00, -1.2193e+00,\n        -4.2903e+00, -3.3085e+00,  3.8077e+00, -4.4564e+00,  2.0944e+00,\n         2.1661e+00,  4.9603e+00,  3.8769e+00, -1.0178e+00, -2.1964e+00,\n        -3.7696e+00,  2.9922e+00, -2.9759e+00,  3.9500e+00,  6.2525e+00,\n         2.8714e+00,  2.2254e+00,  2.6275e+00,  7.7435e+00,  2.5461e+00,\n         2.6868e+00, -6.6348e+00, -2.7627e+00,  2.5832e+00, -4.8588e+00,\n         2.8053e+00,  9.4535e-01,  6.2034e+00, -1.7067e+00, -3.9325e+00,\n         3.4279e+00,  3.7333e+00, -2.2788e-01,  2.7852e+00,  3.5750e+00,\n        -3.4897e+00,  1.6309e+00,  5.1453e-01, -2.2326e+00,  9.4474e-01,\n         1.5094e+00,  1.8203e+00,  2.8113e-02, -3.9560e+00, -4.5073e+00,\n         3.9179e+00, -5.5451e-01,  1.3044e+00, -2.4977e+00,  1.4056e+00,\n         8.6783e+00,  3.3090e+00,  4.7074e-01, -2.8421e+00, -4.3157e+00,\n        -8.7847e+00,  5.4433e-02,  9.8004e-01, -2.0724e+00, -1.8822e+00,\n        -4.5423e+00,  5.9508e+00,  3.7158e+00,  7.8284e-01,  6.4745e+00,\n         1.1400e-01,  1.7735e+00, -1.0970e+00,  4.4848e+00, -2.4315e-01,\n         1.4717e-01, -3.5114e+00,  1.6134e+00, -6.0287e+00,  2.1288e+00,\n         2.2380e+00, -4.3057e-01, -2.0770e+00, -4.3280e+00,  6.5873e-02,\n         3.6119e+00,  4.8346e+00,  1.3708e+00, -4.1261e+00, -3.8400e+00,\n        -2.9844e+00, -4.3532e+00,  4.1852e+00, -4.3863e+00,  1.3686e+00,\n        -1.3237e+00,  1.0197e+00, -2.6526e-01,  4.3457e+00,  2.2352e+00,\n        -3.3019e+00,  9.1908e-01, -3.1793e+00, -3.3927e+00, -2.7986e+00,\n        -1.8313e+00, -5.3981e+00, -5.2378e+00, -1.0750e+00, -6.9646e-01,\n         8.1524e+00,  2.1031e+00, -6.2335e+00, -4.4792e+00,  2.7338e+00,\n        -3.4973e+00, -2.6838e+00, -2.1525e+00, -2.2735e+00, -5.5038e+00,\n         1.7068e+00, -1.4420e+00, -1.0518e-01,  2.6567e+00,  2.2574e+00,\n         8.0893e-01,  2.0313e+00, -2.3769e+00, -6.9142e+00,  5.0267e+00,\n         2.6844e-01, -7.0587e-01,  4.5909e+00,  6.6801e-02,  2.1802e+00,\n        -9.5861e+00, -7.6504e+00,  1.4267e+00, -2.9378e+00,  3.3220e+00,\n        -1.1246e+00, -1.6681e+00,  6.5601e-01, -2.7801e+00, -5.8374e+00,\n        -4.8500e+00, -4.7838e+00,  7.1248e+00,  2.5099e+00,  4.9110e+00,\n         3.4504e+00,  1.4478e+00, -5.9584e-01,  9.8794e-01,  5.5499e-01,\n         2.7302e+00,  2.5695e+00,  3.3496e-02, -2.3803e+00,  3.5474e+00,\n         4.9866e+00,  2.1157e+00, -4.4914e-01, -6.2658e+00, -7.8908e+00,\n         1.2225e+00, -1.4019e+00, -7.3207e-01, -2.4060e+00, -2.4232e+00,\n         2.7389e+00,  4.2365e+00,  5.9394e+00,  8.0223e+00,  7.4132e-01,\n         5.1132e-01, -2.1605e+00,  6.5293e+00, -6.2644e-01, -1.2248e-02,\n         3.0211e+00, -2.5989e+00, -4.4759e+00, -5.0757e+00,  3.3103e-01,\n         8.0316e+00,  5.8939e-01, -9.3821e-02,  4.5739e+00,  1.2919e+00,\n         4.9879e+00, -2.6253e+00,  7.9448e+00,  2.6186e+00, -3.3308e+00,\n         5.5581e+00,  3.0607e+00,  4.0355e+00,  2.0919e+00, -1.6307e+00,\n        -1.3034e+00,  2.1696e+00,  2.9075e+00, -3.5802e+00,  9.3460e-01,\n         3.6711e+00, -3.4491e+00,  1.0421e+01,  5.1740e-01,  2.8213e-01,\n        -1.7228e-01,  2.5664e+00,  2.7048e+00,  4.8827e+00,  4.0648e+00,\n         1.4850e+00, -1.7006e-01,  1.0212e+01,  3.4075e+00,  3.5563e+00,\n        -1.0064e+00, -5.2011e+00,  4.8370e+00,  1.3409e+00, -2.5707e-01,\n         5.5842e+00,  7.0989e-01,  1.4320e+00, -1.0587e+00, -4.0606e+00,\n        -1.3765e+00, -5.3106e+00, -2.1791e+00, -9.7516e-01, -2.8993e+00,\n        -4.7489e+00, -2.0732e+00, -4.9433e+00,  3.5939e+00,  3.1986e-01,\n        -8.2117e+00, -7.7291e+00, -1.2833e+00, -6.9936e-01, -4.3675e+00,\n        -9.1125e-01, -5.3638e+00, -1.8944e+00,  4.6577e+00, -1.4666e+00,\n        -9.1116e+00, -1.1300e+00, -4.8533e+00, -6.8254e+00,  4.3193e+00,\n         5.8433e+00, -3.2335e+00,  3.2417e+00,  3.9123e+00,  4.6465e+00,\n         4.4165e+00, -3.7378e+00, -1.0727e+01, -7.4831e+00,  9.3274e-01,\n         6.1026e-01, -2.1846e+00, -1.2438e+00,  6.1305e-01, -5.0525e+00,\n        -6.9618e+00, -5.6158e+00,  5.6109e-01,  2.5618e+00,  2.8883e+00,\n        -1.7377e+00, -4.0750e+00, -6.6224e+00, -2.3536e+00, -2.8986e+00,\n         1.4949e+00,  2.7278e+00, -2.0280e+00,  3.1770e+00, -1.9191e-01,\n        -2.0512e+00,  3.4324e-01, -2.3173e+00, -1.3597e+00, -1.6575e+00,\n        -5.7879e-02,  4.3091e+00, -1.2774e+00, -5.4781e+00,  1.7975e+00,\n        -5.5706e-01,  5.6760e+00,  3.7405e+00,  7.3193e+00,  4.0970e+00,\n         2.3074e+00, -9.2674e-01, -3.9130e+00,  9.8264e-01, -3.3207e+00,\n        -1.2618e+00, -7.0933e+00, -2.1450e+00, -7.9025e-01,  7.1518e-01,\n        -9.2832e-01,  1.3717e+00, -2.9662e+00, -6.3992e+00, -8.5130e+00,\n        -3.5056e+00, -6.8514e-02,  2.4428e+00,  7.9716e-01,  2.4398e+00,\n         3.5792e+00, -1.0514e-01,  1.0037e+00,  3.6074e+00,  2.4670e+00,\n         7.5132e+00,  3.5364e+00,  1.8546e+00,  2.1394e+00, -9.0697e-01,\n        -3.7934e+00,  2.1237e+00, -5.9750e+00,  1.4347e+00,  2.6516e+00,\n         2.3747e+00, -4.4053e-01,  3.3619e+00,  6.4273e+00,  3.8224e+00,\n        -2.8302e+00, -9.9224e-01, -2.0866e+00, -5.1943e+00, -9.3268e-01,\n        -8.3262e+00, -1.0956e+01,  2.2687e+00,  6.0638e-01, -4.6699e+00,\n         1.0300e+00,  4.2104e+00,  1.1291e-01], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 2.7377e+01,  5.4480e+01,  3.4466e-01,  1.7444e+00,  2.1332e+00,\n          3.6262e+00,  7.1368e+00, -5.3031e+00,  2.3778e+00,  6.9175e+00,\n         -3.5738e-01, -1.3420e+00,  2.7607e+00,  1.3647e+00,  1.8294e+00,\n         -3.8962e+00, -1.2148e+00,  4.8774e+00, -5.8988e+00,  3.5025e+00,\n          2.8316e+00,  3.4017e+00,  2.8249e+00, -1.2209e+00, -6.4926e+00,\n         -3.8399e+00,  3.0174e+00,  8.3152e-01,  4.1992e+00,  6.9650e+00,\n          1.6956e+00,  2.3522e+00,  2.9938e+00,  5.4226e+00,  2.5162e+00,\n          5.9313e+00, -6.3526e+00, -6.6269e+00,  2.5177e+00, -4.4031e+00,\n          1.1891e+00,  3.4314e+00,  6.6500e+00, -1.9988e+00,  1.3439e-01,\n          6.9368e-01,  3.9871e+00,  9.2437e-01,  2.1897e+00,  4.3025e+00,\n         -2.6864e+00,  2.3135e+00,  1.3738e+00, -3.1925e-01,  1.6949e+00,\n          2.1411e+00,  2.9677e+00, -2.8220e+00, -3.2835e+00, -2.8663e+00,\n          3.3590e+00, -2.8664e+00,  9.0953e-01, -5.5382e+00,  6.9948e-01,\n          9.2367e+00,  2.1977e+00,  2.5383e+00, -2.4781e+00, -5.3467e+00,\n         -8.5366e+00, -7.1017e-01, -1.8311e+00, -6.0671e-01, -1.4302e+00,\n         -2.0076e+00,  7.8576e+00,  4.8182e+00,  1.2364e+00,  5.4685e+00,\n          1.7708e+00,  1.0670e+00, -9.2515e-01,  1.3234e+00,  6.5565e-01,\n         -3.3257e+00, -2.4483e+00,  5.6583e-01, -7.1214e-01,  2.4809e+00,\n          8.7911e-01,  5.1250e-01, -3.5824e+00, -3.6066e+00,  1.3881e+00,\n          1.4479e+00,  5.1952e+00,  9.3430e-01, -6.8880e+00, -3.6655e+00,\n         -6.6178e+00, -3.8251e+00,  4.7689e+00, -3.5189e+00,  3.5744e+00,\n         -8.7168e-01,  1.6095e+00,  1.2388e+00,  4.0923e+00,  1.5827e+00,\n         -2.9313e+00,  2.7264e+00, -3.9727e+00, -2.7515e+00, -2.1438e+00,\n         -1.5865e+00, -4.8880e+00, -6.3541e+00, -2.8807e+00,  8.3949e-01,\n          7.7750e+00, -2.6761e-03, -4.6698e+00, -1.1237e+00,  3.0819e+00,\n         -2.9629e+00, -4.3871e+00, -5.1147e+00, -1.5926e-01, -3.7715e+00,\n          2.6859e+00, -1.1051e-01, -6.5189e-01,  1.7756e+00,  3.1864e+00,\n          3.4519e+00,  4.1892e+00, -3.8211e-01, -6.2794e+00,  2.8422e+00,\n         -1.0205e+00, -4.0056e-01,  9.2533e-01, -1.3257e-01, -1.7898e+00,\n         -8.1502e+00, -5.1368e+00,  7.1787e-01, -2.1208e+00,  1.6558e+00,\n         -1.3110e+00, -1.7918e+00,  2.3876e-01, -3.8691e+00, -4.5409e+00,\n         -5.1192e+00, -2.0536e+00,  6.7657e+00,  3.9086e+00,  4.3936e+00,\n          3.6619e+00,  1.1138e+00, -1.3621e+00,  1.4435e+00,  3.9846e-01,\n          2.4844e+00,  1.2504e+00, -2.5999e+00, -1.5096e+00,  2.9419e+00,\n          2.7273e+00,  3.0220e+00,  1.4051e+00, -9.8595e+00, -6.4283e+00,\n         -8.4977e-01,  4.4493e-01, -3.7462e-01,  1.6502e-01,  1.6523e-01,\n          4.4301e+00,  6.7797e+00,  5.7212e+00,  5.9997e+00,  2.9637e+00,\n          3.9178e+00, -2.9381e-01,  5.1489e+00,  4.6865e-01, -1.0575e-01,\n          3.3601e+00, -1.9099e+00, -4.2763e+00, -2.1918e+00,  2.6443e-01,\n          4.9313e+00,  1.1697e+00,  1.4543e+00,  3.2803e+00,  2.1232e+00,\n          6.8713e+00, -4.4787e+00,  4.3044e+00,  3.2470e-01, -3.8840e+00,\n          4.3226e+00,  8.3886e-01,  2.0769e+00,  8.0705e-01, -2.1097e+00,\n          1.3177e+00,  2.5399e+00,  6.1693e-01, -8.6409e-01,  1.3662e+00,\n          2.4664e+00, -1.0984e+00,  6.9676e+00, -1.7089e+00, -1.8425e+00,\n          1.7848e+00,  3.0696e+00,  4.7558e+00,  7.0294e+00,  5.7713e+00,\n          1.0889e+00,  1.4143e+00,  6.8016e+00,  4.6501e+00,  1.3652e+00,\n         -3.3054e+00, -6.3346e+00,  5.9181e+00,  2.6380e+00, -1.5213e-01,\n          5.4348e+00,  1.4028e+00, -7.4098e-01, -1.3291e+00, -4.9118e+00,\n         -6.0315e+00, -4.0276e+00, -1.3108e+00,  2.7443e+00, -2.2047e+00,\n         -4.1280e+00, -4.1186e+00, -4.5670e+00,  3.1811e+00,  1.3393e-01,\n         -8.5857e+00, -6.1901e+00, -8.7663e-01, -1.5339e-01, -1.8959e+00,\n         -7.7756e-01, -1.3670e+00, -2.4689e+00,  4.3938e+00,  1.7959e+00,\n         -8.2184e+00, -2.5044e+00, -3.8453e+00, -8.2682e+00,  1.8990e+00,\n          1.9497e+00, -3.1785e+00,  1.2457e+00,  4.4824e+00,  3.5835e+00,\n          5.9064e+00, -2.8914e+00, -5.1545e+00, -8.2481e+00, -2.7578e-01,\n         -2.7456e+00, -4.6174e-01, -8.3296e-01,  6.6963e-01, -5.5098e+00,\n         -8.8431e+00, -4.6932e+00, -3.9246e-01,  4.2318e+00,  1.4777e+00,\n         -1.8928e+00, -2.7400e+00, -7.2730e+00,  6.2033e-03,  4.3880e-01,\n          3.0775e+00,  2.7356e+00, -5.3669e+00,  4.6051e+00,  1.1010e+00,\n         -1.9218e+00, -1.0618e+00, -9.5048e-01,  7.2712e-01, -8.1831e-01,\n          5.8051e-01,  6.1449e+00,  9.7346e-02, -4.0155e+00,  3.4680e+00,\n         -6.2460e-01,  4.9772e+00,  4.7717e+00,  9.5134e+00,  5.8671e+00,\n          5.9407e+00, -2.6582e+00, -1.5177e+00,  9.0362e-01, -6.4167e-01,\n         -1.1229e+00, -3.5068e+00,  1.2569e+00, -7.4732e-01,  5.9155e-01,\n         -3.1019e-01,  3.4491e-01, -3.3326e+00, -7.0283e+00, -2.4488e+00,\n         -4.8532e+00,  9.4575e-01, -2.0705e+00, -1.6027e+00,  1.5126e+00,\n          3.9343e+00, -2.0524e+00,  2.8092e+00,  2.1084e+00,  2.2945e+00,\n          4.6171e+00,  4.2144e+00,  4.1053e+00,  2.3135e+00, -7.1037e-01,\n         -1.9254e+00,  2.0246e+00, -6.4683e+00,  2.1506e+00,  2.0889e+00,\n          2.5640e+00,  2.3720e-01,  3.8493e+00,  8.7498e+00,  3.3119e+00,\n         -4.4838e+00, -1.1951e+00, -2.2685e+00, -4.6903e+00, -8.9361e-03,\n         -9.9122e+00, -1.1343e+01,  1.4946e+00,  8.4260e-01, -2.0513e+00,\n          1.8804e+00,  3.0519e+00,  2.3131e-01]], device='cuda:0')\nvalues_994 = tensor([[ 2.5228e+01,  5.0931e+01,  1.2798e-01,  1.8170e+00,  1.6397e+00,\n          3.3837e+00,  7.5909e+00, -5.5554e+00,  3.5088e+00,  4.8004e+00,\n          2.7894e-01, -7.4496e-01,  2.6732e+00,  4.8378e-02,  2.7442e-02,\n         -4.6843e+00, -5.0974e+00,  3.0393e+00, -5.7824e+00,  3.2231e+00,\n          2.8218e+00,  3.4268e+00,  2.6220e+00,  3.9685e-01, -2.4571e+00,\n         -4.7789e+00,  2.6023e+00,  3.2599e-01,  4.5277e+00,  7.3027e+00,\n          2.3887e+00,  1.1533e+00,  7.0993e-02,  7.4120e+00,  2.9713e+00,\n          7.4697e+00, -8.4729e+00, -4.6798e+00,  1.4202e+00, -5.7381e+00,\n          1.5743e+00,  1.7830e+00,  8.5167e+00, -2.1395e+00, -2.2487e+00,\n          1.4752e+00,  4.9713e+00,  1.2822e-01,  6.3849e+00,  1.4292e+00,\n         -3.0308e+00,  1.8557e+00,  9.8686e-01, -2.9386e+00, -1.0406e-01,\n          4.7029e+00,  1.3694e+00, -2.8270e+00, -7.2320e+00, -2.8003e+00,\n          3.8168e+00, -4.0861e+00,  9.2162e-01, -4.0537e+00, -8.8774e-01,\n          8.8975e+00,  3.4551e+00,  2.8213e+00, -1.9307e+00, -5.7507e+00,\n         -6.0382e+00,  4.3882e-01, -1.0317e+00, -2.6034e+00, -2.8255e-01,\n         -4.1443e+00,  5.0855e+00,  2.6310e+00,  3.5562e+00,  6.5434e+00,\n          3.2961e+00, -2.0394e-01,  1.1045e+00,  2.3414e+00,  3.6832e+00,\n         -2.5119e+00, -1.5116e+00,  7.3927e-02, -2.4423e+00,  1.6972e+00,\n          4.0164e+00,  4.1416e-01, -2.4988e+00, -1.8140e+00,  3.4093e+00,\n          2.0812e+00,  5.0867e+00, -2.4689e+00, -5.5329e+00, -1.6180e+00,\n         -6.3038e+00, -4.6571e+00,  2.1461e+00, -2.3378e+00,  2.2324e-01,\n          9.4752e-01,  1.8990e+00, -9.7138e-01,  2.3736e+00,  7.8214e-01,\n          1.5679e-01, -8.2278e-01, -3.0746e+00,  5.9901e-02, -4.1298e+00,\n         -2.2322e+00, -3.6410e+00, -6.2586e+00, -1.7745e+00, -1.3204e+00,\n          5.7349e+00, -5.6162e-01, -3.0708e+00, -1.1174e+00,  2.0115e+00,\n         -2.0555e+00, -3.3591e+00, -1.2445e+00, -1.2310e+00, -3.8039e+00,\n          1.4481e+00,  2.1194e+00, -2.2052e+00,  5.7566e-01,  5.1378e+00,\n          2.9872e+00,  1.1169e-01, -1.5309e+00, -2.3413e+00,  3.7376e+00,\n         -9.0443e-01, -1.5147e+00,  2.4650e+00,  2.4403e+00, -3.1185e+00,\n         -1.0004e+01, -7.7435e+00,  1.6060e+00,  1.6506e+00,  1.9448e+00,\n         -3.5030e-01, -2.3270e+00, -8.0722e-01, -3.0536e+00, -5.4061e+00,\n         -4.5013e+00, -3.0695e+00,  5.7385e+00,  4.4142e-01,  3.3226e+00,\n          3.9398e+00,  6.8336e-01, -5.2928e-01, -1.2623e+00, -1.2184e+00,\n         -4.7675e-01,  7.0828e-01, -5.7959e-01, -1.6678e+00,  3.3693e+00,\n          4.7282e+00,  2.5641e+00, -5.7767e-01, -9.4921e+00, -6.1132e+00,\n          4.6176e-01, -2.4020e+00, -1.0725e+00, -5.7343e+00, -2.1923e+00,\n          5.3173e+00,  6.1429e+00,  6.3079e+00,  4.3833e+00,  2.2722e+00,\n          9.5431e-01, -3.0195e+00,  6.1836e+00,  8.0771e-01, -1.8254e+00,\n          1.2263e+00, -2.9403e+00, -2.5386e+00, -6.2723e+00, -3.3357e-01,\n          5.3411e+00, -2.9650e+00, -3.0603e-01,  3.1152e+00,  1.9255e+00,\n          7.1263e+00, -2.9120e+00,  9.1236e+00,  3.6414e+00, -2.0507e+00,\n          5.6669e+00,  2.9827e+00,  4.2888e+00,  1.5151e+00, -1.1431e+00,\n         -1.0221e+00,  2.2342e+00,  1.9389e+00, -9.7732e-01, -8.3250e-01,\n          1.4886e+00, -2.4051e+00,  6.5858e+00,  1.2570e+00, -2.8974e-01,\n          2.9611e+00,  3.3353e+00,  3.5034e+00,  3.8083e+00,  4.8103e+00,\n         -9.4525e-01,  2.9822e-01,  5.4048e+00,  3.0030e+00,  4.2061e+00,\n         -5.1444e-01, -6.5586e+00,  5.1725e+00,  3.5807e+00,  2.9852e-01,\n          4.7278e+00,  9.6140e-01,  1.4545e+00, -1.1932e+00, -5.6150e+00,\n         -4.1412e+00, -3.1907e+00, -8.2033e-01, -6.3895e-01, -2.4180e+00,\n         -5.7904e+00, -2.8773e+00, -6.3666e+00,  1.6095e+00, -2.3142e-01,\n         -8.0336e+00, -6.8739e+00, -2.2095e+00,  7.2746e-01, -4.5823e+00,\n         -9.5907e-01, -4.1514e+00, -4.0235e+00,  4.8602e+00, -2.6948e-01,\n         -1.1235e+01, -3.4414e+00, -3.0637e+00, -7.0251e+00,  4.2040e+00,\n          3.9435e+00, -4.0949e+00,  4.5017e+00,  4.1105e+00,  3.7754e+00,\n          4.0946e+00, -2.4070e+00, -6.6610e+00, -6.9007e+00, -1.8854e+00,\n         -1.2099e+00, -9.9985e-01, -4.6974e+00,  2.5173e-01, -6.5674e+00,\n         -6.6399e+00, -5.9229e+00, -1.1317e+00,  3.5380e+00,  6.8969e-01,\n         -1.7381e+00, -4.0330e+00, -5.5818e+00,  2.0628e+00, -3.2415e+00,\n         -2.6709e-01,  3.0894e+00,  1.8424e-02,  3.4983e+00,  2.0306e+00,\n         -1.2803e+00,  7.5540e-01, -1.2054e+00,  1.3587e-01, -2.1606e+00,\n          9.2416e-02,  2.8579e+00, -5.0509e-01, -4.2701e+00,  2.6467e+00,\n         -1.0329e+00,  4.9828e+00,  5.6717e+00,  1.0324e+01,  9.2245e-01,\n          5.8452e+00, -1.2319e+00, -1.1555e+00,  3.5472e-01, -1.5273e+00,\n         -1.5527e+00, -6.9633e+00, -1.7002e+00,  1.5430e+00,  1.3833e+00,\n         -1.3953e+00,  1.3877e+00, -2.2597e+00, -7.1276e+00, -4.2833e+00,\n         -4.7542e+00,  2.5255e+00,  6.5429e-01, -1.7444e+00,  3.3072e+00,\n          3.5585e+00, -9.4834e-01,  2.6878e+00,  5.4010e+00,  4.9159e+00,\n          2.9291e+00,  2.8414e+00,  1.3903e+00,  2.1913e-02,  2.6684e+00,\n         -1.5560e+00,  3.1641e+00, -7.5968e+00,  2.1268e+00,  3.4247e+00,\n         -2.3503e+00, -1.5895e+00,  1.3102e+00,  6.5377e+00,  1.3759e+00,\n         -4.4642e+00, -1.5614e+00, -1.7429e+00, -7.7072e+00, -2.6078e+00,\n         -7.7111e+00, -1.1166e+01,  2.4559e+00, -1.0928e+00, -4.7570e+00,\n          5.2206e-01,  1.2691e+00, -3.2247e-02]], device='cuda:0')\nreward[last_non_masked_index]=tensor([6.5513e-07], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 3.4296e+01,  5.7245e+01, -3.4173e-01,  1.0732e+00,  1.8514e+00,\n         3.7195e+00,  9.1810e+00, -5.0200e+00,  2.0666e+00,  5.3543e+00,\n        -1.1966e+00, -2.3492e+00,  2.0849e+00,  1.7445e+00, -1.2193e+00,\n        -4.2903e+00, -3.3085e+00,  3.8077e+00, -4.4564e+00,  2.0944e+00,\n         2.1661e+00,  4.9603e+00,  3.8769e+00, -1.0178e+00, -2.1964e+00,\n        -3.7696e+00,  2.9922e+00, -2.9759e+00,  3.9500e+00,  6.2525e+00,\n         2.8714e+00,  2.2254e+00,  2.6275e+00,  7.7435e+00,  2.5461e+00,\n         2.6868e+00, -6.6348e+00, -2.7627e+00,  2.5832e+00, -4.8588e+00,\n         2.8053e+00,  9.4535e-01,  6.2034e+00, -1.7067e+00, -3.9325e+00,\n         3.4279e+00,  3.7333e+00, -2.2788e-01,  2.7852e+00,  3.5750e+00,\n        -3.4897e+00,  1.6309e+00,  5.1453e-01, -2.2326e+00,  9.4474e-01,\n         1.5094e+00,  1.8203e+00,  2.8113e-02, -3.9560e+00, -4.5073e+00,\n         3.9179e+00, -5.5451e-01,  1.3044e+00, -2.4977e+00,  1.4056e+00,\n         8.6783e+00,  3.3090e+00,  4.7074e-01, -2.8421e+00, -4.3157e+00,\n        -8.7847e+00,  5.4433e-02,  9.8004e-01, -2.0724e+00, -1.8822e+00,\n        -4.5423e+00,  5.9508e+00,  3.7158e+00,  7.8284e-01,  6.4745e+00,\n         1.1400e-01,  1.7735e+00, -1.0970e+00,  4.4848e+00, -2.4315e-01,\n         1.4717e-01, -3.5114e+00,  1.6134e+00, -6.0287e+00,  2.1288e+00,\n         2.2380e+00, -4.3057e-01, -2.0770e+00, -4.3280e+00,  6.5873e-02,\n         3.6119e+00,  4.8346e+00,  1.3708e+00, -4.1261e+00, -3.8400e+00,\n        -2.9844e+00, -4.3532e+00,  4.1852e+00, -4.3863e+00,  1.3686e+00,\n        -1.3237e+00,  1.0197e+00, -2.6526e-01,  4.3457e+00,  2.2352e+00,\n        -3.3019e+00,  9.1908e-01, -3.1793e+00, -3.3927e+00, -2.7986e+00,\n        -1.8313e+00, -5.3981e+00, -5.2378e+00, -1.0750e+00, -6.9646e-01,\n         8.1524e+00,  2.1031e+00, -6.2335e+00, -4.4792e+00,  2.7338e+00,\n        -3.4973e+00, -2.6838e+00, -2.1525e+00, -2.2735e+00, -5.5038e+00,\n         1.7068e+00, -1.4420e+00, -1.0518e-01,  2.6567e+00,  2.2574e+00,\n         8.0893e-01,  2.0313e+00, -2.3769e+00, -6.9142e+00,  5.0267e+00,\n         2.6844e-01, -7.0587e-01,  4.5909e+00,  6.6801e-02,  2.1802e+00,\n        -9.5861e+00, -7.6504e+00,  1.4267e+00, -2.9378e+00,  3.3220e+00,\n        -1.1246e+00, -1.6681e+00,  6.5601e-01, -2.7801e+00, -5.8374e+00,\n        -4.8500e+00, -4.7838e+00,  7.1248e+00,  2.5099e+00,  4.9110e+00,\n         3.4504e+00,  1.4478e+00, -5.9584e-01,  9.8794e-01,  5.5499e-01,\n         2.7302e+00,  2.5695e+00,  3.3496e-02, -2.3803e+00,  3.5474e+00,\n         4.9866e+00,  2.1157e+00, -4.4914e-01, -6.2658e+00, -7.8908e+00,\n         1.2225e+00, -1.4019e+00, -7.3207e-01, -2.4060e+00, -2.4232e+00,\n         2.7389e+00,  4.2365e+00,  5.9394e+00,  8.0223e+00,  7.4132e-01,\n         5.1132e-01, -2.1605e+00,  6.5293e+00, -6.2644e-01, -1.2248e-02,\n         3.0211e+00, -2.5989e+00, -4.4759e+00, -5.0757e+00,  3.3103e-01,\n         8.0316e+00,  5.8939e-01, -9.3821e-02,  4.5739e+00,  1.2919e+00,\n         4.9879e+00, -2.6253e+00,  7.9448e+00,  2.6186e+00, -3.3308e+00,\n         5.5581e+00,  3.0607e+00,  4.0355e+00,  2.0919e+00, -1.6307e+00,\n        -1.3034e+00,  2.1696e+00,  2.9075e+00, -3.5802e+00,  9.3460e-01,\n         3.6711e+00, -3.4491e+00,  1.0421e+01,  5.1740e-01,  2.8213e-01,\n        -1.7228e-01,  2.5664e+00,  2.7048e+00,  4.8827e+00,  4.0648e+00,\n         1.4850e+00, -1.7006e-01,  1.0212e+01,  3.4075e+00,  3.5563e+00,\n        -1.0064e+00, -5.2011e+00,  4.8370e+00,  1.3409e+00, -2.5707e-01,\n         5.5842e+00,  7.0989e-01,  1.4320e+00, -1.0587e+00, -4.0606e+00,\n        -1.3765e+00, -5.3106e+00, -2.1791e+00, -9.7516e-01, -2.8993e+00,\n        -4.7489e+00, -2.0732e+00, -4.9433e+00,  3.5939e+00,  3.1986e-01,\n        -8.2117e+00, -7.7291e+00, -1.2833e+00, -6.9936e-01, -4.3675e+00,\n        -9.1125e-01, -5.3638e+00, -1.8944e+00,  4.6577e+00, -1.4666e+00,\n        -9.1116e+00, -1.1300e+00, -4.8533e+00, -6.8254e+00,  4.3193e+00,\n         5.8433e+00, -3.2335e+00,  3.2417e+00,  3.9123e+00,  4.6465e+00,\n         4.4165e+00, -3.7378e+00, -1.0727e+01, -7.4831e+00,  9.3274e-01,\n         6.1026e-01, -2.1846e+00, -1.2438e+00,  6.1305e-01, -5.0525e+00,\n        -6.9618e+00, -5.6158e+00,  5.6109e-01,  2.5618e+00,  2.8883e+00,\n        -1.7377e+00, -4.0750e+00, -6.6224e+00, -2.3536e+00, -2.8986e+00,\n         1.4949e+00,  2.7278e+00, -2.0280e+00,  3.1770e+00, -1.9191e-01,\n        -2.0512e+00,  3.4324e-01, -2.3173e+00, -1.3597e+00, -1.6575e+00,\n        -5.7879e-02,  4.3091e+00, -1.2774e+00, -5.4781e+00,  1.7975e+00,\n        -5.5706e-01,  5.6760e+00,  3.7405e+00,  7.3193e+00,  4.0970e+00,\n         2.3074e+00, -9.2674e-01, -3.9130e+00,  9.8264e-01, -3.3207e+00,\n        -1.2618e+00, -7.0933e+00, -2.1450e+00, -7.9025e-01,  7.1518e-01,\n        -9.2832e-01,  1.3717e+00, -2.9662e+00, -6.3992e+00, -8.5130e+00,\n        -3.5056e+00, -6.8514e-02,  2.4428e+00,  7.9716e-01,  2.4398e+00,\n         3.5792e+00, -1.0514e-01,  1.0037e+00,  3.6074e+00,  2.4670e+00,\n         7.5132e+00,  3.5364e+00,  1.8546e+00,  2.1394e+00, -9.0697e-01,\n        -3.7934e+00,  2.1237e+00, -5.9750e+00,  1.4347e+00,  2.6516e+00,\n         2.3747e+00, -4.4053e-01,  3.3619e+00,  6.4273e+00,  3.8224e+00,\n        -2.8302e+00, -9.9224e-01, -2.0866e+00, -5.1943e+00, -9.3268e-01,\n        -8.3262e+00, -1.0956e+01,  2.2687e+00,  6.0638e-01, -4.6699e+00,\n         1.0300e+00,  4.2104e+00,  1.1291e-01], device='cuda:0')\nvalues=tensor([[ 2.7377e+01,  5.4480e+01,  3.4466e-01,  1.7444e+00,  2.1332e+00,\n          3.6262e+00,  7.1368e+00, -5.3031e+00,  2.3778e+00,  6.9175e+00,\n         -3.5738e-01, -1.3420e+00,  2.7607e+00,  1.3647e+00,  1.8294e+00,\n         -3.8962e+00, -1.2148e+00,  4.8774e+00, -5.8988e+00,  3.5025e+00,\n          2.8316e+00,  3.4017e+00,  2.8249e+00, -1.2209e+00, -6.4926e+00,\n         -3.8399e+00,  3.0174e+00,  8.3152e-01,  4.1992e+00,  6.9650e+00,\n          1.6956e+00,  2.3522e+00,  2.9938e+00,  5.4226e+00,  2.5162e+00,\n          5.9313e+00, -6.3526e+00, -6.6269e+00,  2.5177e+00, -4.4031e+00,\n          1.1891e+00,  3.4314e+00,  6.6500e+00, -1.9988e+00,  1.3439e-01,\n          6.9368e-01,  3.9871e+00,  9.2437e-01,  2.1897e+00,  4.3025e+00,\n         -2.6864e+00,  2.3135e+00,  1.3738e+00, -3.1925e-01,  1.6949e+00,\n          2.1411e+00,  2.9677e+00, -2.8220e+00, -3.2835e+00, -2.8663e+00,\n          3.3590e+00, -2.8664e+00,  9.0953e-01, -5.5382e+00,  6.9948e-01,\n          9.2367e+00,  2.1977e+00,  2.5383e+00, -2.4781e+00, -5.3467e+00,\n         -8.5366e+00, -7.1017e-01, -1.8311e+00, -6.0671e-01, -1.4302e+00,\n         -2.0076e+00,  7.8576e+00,  4.8182e+00,  1.2364e+00,  5.4685e+00,\n          1.7708e+00,  1.0670e+00, -9.2515e-01,  1.3234e+00,  6.5565e-01,\n         -3.3257e+00, -2.4483e+00,  5.6583e-01, -7.1214e-01,  2.4809e+00,\n          8.7911e-01,  5.1250e-01, -3.5824e+00, -3.6066e+00,  1.3881e+00,\n          1.4479e+00,  5.1952e+00,  9.3430e-01, -6.8880e+00, -3.6655e+00,\n         -6.6178e+00, -3.8251e+00,  4.7689e+00, -3.5189e+00,  3.5744e+00,\n         -8.7168e-01,  1.6095e+00,  1.2388e+00,  4.0923e+00,  1.5827e+00,\n         -2.9313e+00,  2.7264e+00, -3.9727e+00, -2.7515e+00, -2.1438e+00,\n         -1.5865e+00, -4.8880e+00, -6.3541e+00, -2.8807e+00,  8.3949e-01,\n          7.7750e+00, -2.6761e-03, -4.6698e+00, -1.1237e+00,  3.0819e+00,\n         -2.9629e+00, -4.3871e+00, -5.1147e+00, -1.5926e-01, -3.7715e+00,\n          2.6859e+00, -1.1051e-01, -6.5189e-01,  1.7756e+00,  3.1864e+00,\n          3.4519e+00,  4.1892e+00, -3.8211e-01, -6.2794e+00,  2.8422e+00,\n         -1.0205e+00, -4.0056e-01,  9.2533e-01, -1.3257e-01, -1.7898e+00,\n         -8.1502e+00, -5.1368e+00,  7.1787e-01, -2.1208e+00,  1.6558e+00,\n         -1.3110e+00, -1.7918e+00,  2.3876e-01, -3.8691e+00, -4.5409e+00,\n         -5.1192e+00, -2.0536e+00,  6.7657e+00,  3.9086e+00,  4.3936e+00,\n          3.6619e+00,  1.1138e+00, -1.3621e+00,  1.4435e+00,  3.9846e-01,\n          2.4844e+00,  1.2504e+00, -2.5999e+00, -1.5096e+00,  2.9419e+00,\n          2.7273e+00,  3.0220e+00,  1.4051e+00, -9.8595e+00, -6.4283e+00,\n         -8.4977e-01,  4.4493e-01, -3.7462e-01,  1.6502e-01,  1.6523e-01,\n          4.4301e+00,  6.7797e+00,  5.7212e+00,  5.9997e+00,  2.9637e+00,\n          3.9178e+00, -2.9381e-01,  5.1489e+00,  4.6865e-01, -1.0575e-01,\n          3.3601e+00, -1.9099e+00, -4.2763e+00, -2.1918e+00,  2.6443e-01,\n          4.9313e+00,  1.1697e+00,  1.4543e+00,  3.2803e+00,  2.1232e+00,\n          6.8713e+00, -4.4787e+00,  4.3044e+00,  3.2470e-01, -3.8840e+00,\n          4.3226e+00,  8.3886e-01,  2.0769e+00,  8.0705e-01, -2.1097e+00,\n          1.3177e+00,  2.5399e+00,  6.1693e-01, -8.6409e-01,  1.3662e+00,\n          2.4664e+00, -1.0984e+00,  6.9676e+00, -1.7089e+00, -1.8425e+00,\n          1.7848e+00,  3.0696e+00,  4.7558e+00,  7.0294e+00,  5.7713e+00,\n          1.0889e+00,  1.4143e+00,  6.8016e+00,  4.6501e+00,  1.3652e+00,\n         -3.3054e+00, -6.3346e+00,  5.9181e+00,  2.6380e+00, -1.5213e-01,\n          5.4348e+00,  1.4028e+00, -7.4098e-01, -1.3291e+00, -4.9118e+00,\n         -6.0315e+00, -4.0276e+00, -1.3108e+00,  2.7443e+00, -2.2047e+00,\n         -4.1280e+00, -4.1186e+00, -4.5670e+00,  3.1811e+00,  1.3393e-01,\n         -8.5857e+00, -6.1901e+00, -8.7663e-01, -1.5339e-01, -1.8959e+00,\n         -7.7756e-01, -1.3670e+00, -2.4689e+00,  4.3938e+00,  1.7959e+00,\n         -8.2184e+00, -2.5044e+00, -3.8453e+00, -8.2682e+00,  1.8990e+00,\n          1.9497e+00, -3.1785e+00,  1.2457e+00,  4.4824e+00,  3.5835e+00,\n          5.9064e+00, -2.8914e+00, -5.1545e+00, -8.2481e+00, -2.7578e-01,\n         -2.7456e+00, -4.6174e-01, -8.3296e-01,  6.6963e-01, -5.5098e+00,\n         -8.8431e+00, -4.6932e+00, -3.9246e-01,  4.2318e+00,  1.4777e+00,\n         -1.8928e+00, -2.7400e+00, -7.2730e+00,  6.2033e-03,  4.3880e-01,\n          3.0775e+00,  2.7356e+00, -5.3669e+00,  4.6051e+00,  1.1010e+00,\n         -1.9218e+00, -1.0618e+00, -9.5048e-01,  7.2712e-01, -8.1831e-01,\n          5.8051e-01,  6.1449e+00,  9.7346e-02, -4.0155e+00,  3.4680e+00,\n         -6.2460e-01,  4.9772e+00,  4.7717e+00,  9.5134e+00,  5.8671e+00,\n          5.9407e+00, -2.6582e+00, -1.5177e+00,  9.0362e-01, -6.4167e-01,\n         -1.1229e+00, -3.5068e+00,  1.2569e+00, -7.4732e-01,  5.9155e-01,\n         -3.1019e-01,  3.4491e-01, -3.3326e+00, -7.0283e+00, -2.4488e+00,\n         -4.8532e+00,  9.4575e-01, -2.0705e+00, -1.6027e+00,  1.5126e+00,\n          3.9343e+00, -2.0524e+00,  2.8092e+00,  2.1084e+00,  2.2945e+00,\n          4.6171e+00,  4.2144e+00,  4.1053e+00,  2.3135e+00, -7.1037e-01,\n         -1.9254e+00,  2.0246e+00, -6.4683e+00,  2.1506e+00,  2.0889e+00,\n          2.5640e+00,  2.3720e-01,  3.8493e+00,  8.7498e+00,  3.3119e+00,\n         -4.4838e+00, -1.1951e+00, -2.2685e+00, -4.6903e+00, -8.9361e-03,\n         -9.9122e+00, -1.1343e+01,  1.4946e+00,  8.4260e-01, -2.0513e+00,\n          1.8804e+00,  3.0519e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -5.9603e-08, -9.7802e-05,  1.1917e-07,\n          9.3612e-06,  1.1919e-07,  2.1413e-05, -1.0279e-04,  1.9649e-06,\n          5.9601e-08,  1.2218e-05, -9.1188e-05, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00,  5.9603e-08,  5.9601e-08, -5.9603e-08, -2.3838e-07,\n         -3.6664e-03,  1.6039e-03, -2.7993e-06, -0.0000e+00, -0.0000e+00,\n          2.0251e-06, -1.9591e-03,  2.4829e-05,  1.1453e-03,  1.1920e-07,\n         -0.0000e+00,  5.9604e-08,  1.6668e-04,  3.7276e-05,  6.9305e-05,\n          6.3714e-04,  5.5958e-03,  3.5157e-03,  8.2299e-05,  3.8466e-04,\n          4.4718e-04,  6.8393e-06, -2.3497e-06, -4.1366e-05,  3.8815e-04,\n          1.0703e-03,  3.8218e-04,  1.6157e-05, -0.0000e+00, -1.4294e-06,\n         -0.0000e+00, -0.0000e+00,  5.9603e-08,  7.8678e-05,  1.2487e-06,\n          1.7877e-07, -5.3737e-05, -4.1712e-07,  2.3840e-07, -0.0000e+00,\n          5.9604e-08, -0.0000e+00, -0.0000e+00,  5.9604e-08, -6.2523e-05,\n         -0.0000e+00, -0.0000e+00, -4.4771e-05,  1.1921e-07, -0.0000e+00,\n         -0.0000e+00, -2.9358e-04,  4.1513e-04,  5.9601e-08, -0.0000e+00,\n          1.7405e-04,  6.0662e-06, -5.9603e-08,  1.2282e-03,  3.7014e-05,\n         -1.5786e-04, -8.1006e-04, -4.0925e-04, -2.6720e-06, -1.5693e-05,\n         -0.0000e+00,  1.1921e-07,  5.9604e-08, -0.0000e+00, -1.1920e-07,\n          2.7251e-04, -4.1485e-05,  2.0677e-05,  2.7800e-04, -3.2383e-04,\n         -5.9604e-08, -0.0000e+00,  1.7878e-07, -0.0000e+00, -0.0000e+00,\n         -1.7908e-04, -0.0000e+00, -0.0000e+00,  4.8624e-06, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -2.1409e-06, -8.9058e-07,  5.4011e-04,\n         -2.8921e-03,  2.4084e-03, -4.1716e-03, -8.9318e-04, -6.0374e-04,\n          5.9604e-08,  1.7719e-03,  1.1846e-03,  1.7825e-03,  3.6281e-06,\n         -1.6674e-06,  4.5984e-06, -4.1088e-06, -0.0000e+00, -5.9604e-08,\n         -1.1921e-07, -0.0000e+00, -0.0000e+00, -7.3266e-04,  2.4807e-04,\n          4.1212e-05,  1.0129e-04, -3.5123e-06,  1.6548e-04, -9.0846e-06,\n          1.0725e-06, -2.4892e-06,  3.0509e-05, -8.2923e-04, -2.2039e-06,\n         -5.9584e-07,  3.2673e-06,  2.2966e-06, -5.9604e-08, -0.0000e+00,\n         -1.6171e-04, -0.0000e+00, -0.0000e+00,  2.0633e-06, -0.0000e+00,\n         -5.9604e-08,  2.2376e-03,  1.2261e-03,  7.1287e-05,  1.7878e-07,\n         -0.0000e+00,  8.0594e-06,  5.9604e-08, -0.0000e+00, -0.0000e+00,\n          3.5894e-03,  1.0401e-03, -1.2468e-06, -2.2890e-05, -1.7304e-03,\n         -3.1102e-04,  1.5049e-03, -1.5785e-03, -6.8466e-04, -1.2936e-03,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.1920e-07,  5.9604e-08,\n          1.1919e-07, -1.1296e-03, -2.9723e-03,  5.9597e-08, -4.2125e-05,\n         -0.0000e+00, -1.1919e-07, -9.4891e-05, -1.6202e-04,  1.9063e-06,\n         -5.9601e-08, -4.4436e-06, -5.9597e-07, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -1.9175e-03,  1.5498e-03, -5.9604e-08, -5.9604e-08,\n         -2.0317e-03,  5.9605e-08, -5.2810e-05,  1.9312e-05,  6.3080e-04,\n          1.1818e-04, -2.9801e-07,  2.3827e-07, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00,  3.3051e-04,  3.2146e-03, -2.5994e-04,  2.5153e-04,\n          3.3295e-04, -1.2035e-03, -1.2586e-03,  1.9761e-03, -6.3062e-04,\n          3.9423e-04, -0.0000e+00, -4.7678e-07, -0.0000e+00,  3.4557e-04,\n         -0.0000e+00,  4.5858e-06, -1.1945e-03, -5.0980e-04, -4.7673e-07,\n          1.7748e-05,  2.3835e-07, -2.4522e-05, -0.0000e+00,  4.7668e-07,\n         -5.9601e-08, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -1.1142e-05, -0.0000e+00, -0.0000e+00, -1.7005e-03,  2.7268e-03,\n          4.5570e-04, -0.0000e+00, -0.0000e+00,  7.1510e-07, -3.0159e-03,\n          4.5493e-05, -9.0070e-05, -2.4136e-03,  5.9603e-08, -3.3431e-05,\n          9.1838e-05,  2.1811e-03,  3.1669e-03, -2.6184e-06,  2.2224e-03,\n          3.9312e-05,  3.5614e-05,  1.9374e-04,  1.6174e-04, -3.8767e-04,\n         -1.9329e-03, -5.9389e-05, -6.5553e-07, -4.1709e-07, -1.4892e-06,\n          1.0085e-04,  1.1921e-07, -7.3898e-05, -5.9604e-08,  5.9604e-08,\n          1.7881e-07,  7.9758e-06, -1.5846e-03, -5.1367e-06, -9.0133e-04,\n         -4.1218e-03, -9.2095e-04,  6.7115e-04, -2.4011e-04,  1.3837e-03,\n         -3.4952e-04,  2.4616e-03,  2.4531e-04, -1.4896e-06, -0.0000e+00,\n         -3.0837e-05, -9.9871e-04, -3.6597e-05,  2.3135e-05,  7.8207e-04,\n          3.0257e-04,  1.7445e-05, -7.0208e-04, -3.4698e-04,  1.4201e-03,\n         -1.4260e-03,  1.1291e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 2.7616e+01,  3.9513e+01,  6.3135e-01,  7.3922e-01,  1.7695e+00,\n          4.7628e+00,  8.6643e+00, -4.2440e+00,  1.5801e+00,  4.3431e+00,\n         -7.7647e-01, -2.3394e+00,  2.7086e+00,  8.3969e-01,  1.2056e+00,\n         -5.6251e+00, -3.0685e+00,  1.1339e+00, -4.7808e+00,  4.0535e+00,\n         -4.0698e-01,  2.2323e+00,  4.1442e+00, -6.0660e-01, -3.2123e+00,\n         -5.0049e+00,  2.7985e+00, -3.5812e+00,  4.3110e+00,  7.3680e+00,\n          1.7360e+00, -3.8641e-01,  2.3134e+00,  4.4890e+00,  2.0969e+00,\n          7.0170e+00, -6.9607e+00, -4.1343e+00,  1.1905e+00, -5.0726e+00,\n          2.7173e+00,  2.1527e+00,  7.2685e+00,  2.8168e-01, -2.3084e+00,\n          1.4020e+00,  2.6271e+00, -1.1718e+00,  6.9431e+00,  2.5973e+00,\n         -4.5389e+00,  7.3967e-01,  4.0912e-01,  4.4772e-01,  9.5321e-03,\n          2.3105e+00,  2.9928e+00, -2.8069e+00, -1.2419e+00, -4.6857e+00,\n          1.7384e+00,  5.0742e-01, -2.0060e+00, -5.7747e+00,  4.8258e-01,\n          9.1667e+00,  4.2809e+00,  5.7715e-01, -3.5548e+00, -5.5315e+00,\n         -9.1958e+00,  1.5142e+00,  2.9156e+00, -2.3567e+00, -1.2430e+00,\n         -5.3423e+00,  4.4656e+00,  2.9422e+00, -2.3491e-01,  6.8750e+00,\n         -6.1305e-01,  5.6353e-01, -1.2454e+00,  2.9447e+00, -5.2309e-01,\n         -1.5078e+00, -3.0009e+00,  1.0426e+00, -1.0992e+00,  2.3681e+00,\n          1.6723e+00,  2.3647e+00, -8.1903e-01, -3.2801e+00,  4.6493e-01,\n          3.3127e+00,  4.0973e+00, -1.1563e+00, -5.0792e+00, -5.2860e+00,\n         -5.0660e+00, -4.5767e+00,  5.1150e+00, -2.6151e+00,  4.0476e+00,\n          8.7745e-02,  6.7648e-01,  1.1662e+00,  5.4479e+00, -2.1072e-01,\n         -3.3330e+00,  2.2789e+00, -4.7424e+00, -2.6662e+00, -1.7591e+00,\n         -2.5673e+00, -3.1409e+00, -4.6320e+00,  5.8697e-02, -4.0743e-01,\n          5.2270e+00,  1.4992e+00, -4.5796e+00, -1.3710e+00,  5.5152e+00,\n         -3.3305e+00, -2.7845e+00, -1.6677e+00, -1.8928e+00, -2.9598e+00,\n          2.3322e+00,  1.6035e+00, -2.2776e+00,  2.9037e+00,  3.9910e+00,\n          3.4426e+00,  1.1111e+00, -6.6900e-01, -6.5173e+00,  2.2777e+00,\n          1.1841e+00,  3.5208e-01,  3.3931e+00,  5.2331e-01,  1.1715e+00,\n         -6.2254e+00, -8.7815e+00, -1.9602e+00, -2.2628e+00,  3.5096e+00,\n         -5.3464e-01, -2.3980e+00,  1.4939e+00, -3.7330e+00, -3.3625e+00,\n         -7.2815e+00, -4.7099e+00,  8.0822e+00,  5.6208e+00,  5.0948e+00,\n          2.4046e+00,  9.1119e-02,  5.7219e-01,  5.8927e-01, -2.5489e+00,\n          4.8996e-01,  9.4026e-01, -8.6079e-01, -1.1295e+00,  1.5631e+00,\n          3.9873e+00,  3.8856e+00,  2.5905e+00, -6.8626e+00, -5.8618e+00,\n          4.2452e-01,  3.8940e-01, -1.1241e+00, -2.8655e+00, -1.4053e+00,\n          3.7199e+00,  3.9505e+00,  8.0318e+00,  4.8351e+00,  2.4799e-01,\n          2.5491e+00, -9.4891e-01,  4.7378e+00, -1.8564e+00, -4.2643e-01,\n          2.8497e+00, -3.0334e+00, -3.6803e+00, -5.7320e+00, -1.6569e-01,\n          7.9602e+00, -1.8575e+00, -1.6928e-01,  2.1399e+00, -1.1415e+00,\n          5.9110e+00,  7.9965e-02,  7.0398e+00,  3.5896e+00, -2.3272e+00,\n          5.3885e+00,  2.1480e+00,  2.1268e+00,  1.4440e+00, -1.0061e+00,\n          6.0560e-01,  4.6755e+00,  2.5797e+00, -2.4442e+00, -1.2308e+00,\n          3.1627e+00, -1.8706e+00,  8.0661e+00,  5.8064e-01,  3.3402e-01,\n          2.4475e+00,  4.8196e+00,  2.7649e+00,  5.9091e+00,  6.2557e+00,\n         -1.4771e-01, -1.1820e-01,  8.7945e+00,  3.0347e+00,  6.7582e+00,\n         -2.8230e+00, -6.4724e+00,  5.6787e+00,  4.6468e+00,  2.2390e-01,\n          4.1441e+00, -5.4958e-01,  1.6001e+00,  4.9801e-01, -5.3500e+00,\n         -5.2999e+00, -4.2630e+00, -9.3628e-01, -3.2134e+00, -4.4184e+00,\n         -4.9805e+00,  3.2918e-01, -4.0460e+00,  1.4542e+00,  3.3381e-01,\n         -6.1721e+00, -6.9964e+00, -6.2938e-01, -1.5140e+00, -2.6905e+00,\n          1.9612e+00, -3.2241e+00, -3.7940e+00,  6.1420e+00,  3.4823e-01,\n         -9.4905e+00, -9.9655e-01, -2.8307e+00, -7.1494e+00,  3.8010e+00,\n          1.8416e+00, -4.3974e+00,  1.6941e+00,  3.3463e+00,  5.3710e+00,\n          5.9466e+00, -1.9778e+00, -7.2600e+00, -6.6754e+00, -9.3117e-02,\n         -1.0635e+00,  1.0531e-01, -3.5547e+00, -7.5120e-01, -4.1484e+00,\n         -5.2981e+00, -6.8478e+00,  8.9333e-02,  2.4035e+00,  1.9994e+00,\n         -8.3237e-02, -4.5687e+00, -7.0603e+00,  2.8389e+00, -1.8728e+00,\n          1.9201e+00,  2.8288e+00, -1.4751e+00,  4.5730e+00, -3.5251e-01,\n         -1.9225e+00, -1.9685e+00, -5.9119e-01,  7.5979e-01, -1.3111e+00,\n         -1.8570e+00,  4.7757e+00,  1.1461e+00, -5.7025e+00,  1.8904e+00,\n          9.2388e-01,  3.5780e+00,  5.4536e+00,  1.0392e+01,  5.3875e+00,\n          3.7954e+00, -1.4087e+00, -3.8387e-01,  1.8072e+00, -2.6673e+00,\n         -1.7169e-01, -6.1104e+00, -2.3090e+00,  2.4609e+00, -5.6436e-01,\n          8.9193e-01, -7.1322e-01, -1.8388e+00, -5.6309e+00, -5.8439e+00,\n         -2.4350e+00,  1.6793e+00, -8.5015e-01, -1.4481e+00,  1.5125e+00,\n          2.0990e+00,  8.5184e-01, -1.2839e-01,  2.9851e+00,  4.7566e+00,\n          3.7842e+00,  5.1770e+00,  2.0787e+00,  1.4871e+00,  8.5412e-01,\n         -3.6380e+00,  2.8043e+00, -4.5053e+00,  1.3579e+00,  4.7744e-01,\n          1.3251e+00, -5.2689e-01, -1.0037e+00,  8.7551e+00,  6.3618e-01,\n         -3.3262e+00,  1.0479e+00, -2.4737e+00, -5.5647e+00,  5.5663e-02,\n         -9.6698e+00, -9.6320e+00, -1.2486e-01, -3.6260e-01, -4.8428e+00,\n          1.3039e+00,  4.0335e+00, -1.3096e-01]], device='cuda:0',\n       grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 28.0652,  53.5995,   0.9782,   1.3522,   1.3388,   2.8160,   8.3474,\n          -3.5112,   1.8237,   5.4371,  -0.8643,  -0.6047,   1.5615,   0.8932,\n           0.4132,  -6.0441,  -1.9890,   3.3309,  -6.2508,   3.3513,   3.0036,\n           2.7031,   2.1699,  -1.2512,  -4.3586,  -5.0898,   1.4061,  -0.2866,\n           5.2213,   7.7998,   0.9470,   0.1846,   0.7312,   6.0786,   2.5913,\n           5.0716,  -7.1498,  -2.4081,  -0.4868,  -3.8170,   1.2688,   1.6014,\n           7.8103,  -1.1939,  -1.0010,   1.5462,   3.8127,  -1.9377,   4.4366,\n           4.9537,   0.7297,   1.5782,   1.5893,   0.7133,   3.1194,   6.8875,\n           1.7037,  -0.8630,  -5.3846,  -2.2228,   3.0826,  -1.7332,   0.7264,\n          -4.0240,   0.8811,   9.5940,   3.3083,   1.8591,  -2.1259,  -7.3123,\n          -7.6926,   0.4839,   0.4269,  -1.7992,  -0.8473,  -4.3455,   6.0485,\n           4.3313,   0.7454,   6.9533,   1.3985,   1.5643,  -1.1961,   3.1262,\n          -2.6249,  -4.3214,  -2.5848,   0.3034,  -2.1757,   4.6536,   1.9733,\n           0.2882,  -1.5510,  -4.6468,   2.1594,   3.8213,   4.3618,  -1.5793,\n          -3.4491,  -5.0547,  -2.8639,  -5.1519,   5.2605,  -2.7002,   2.1099,\n          -1.6038,   1.9959,  -1.5807,   5.4051,   1.2569,  -2.3252,   2.3453,\n          -5.2891,  -2.7805,  -4.3676,  -3.7241,  -3.2328,  -4.2517,  -2.5673,\n           1.8154,   6.9134,   3.5535,  -4.2911,  -0.2434,  -0.3408,  -3.3274,\n          -0.6981,  -2.4467,  -1.0671,  -4.4435,   2.8980,   0.2562,  -2.2812,\n           2.6508,   4.7028,   1.6049,  -0.4071,  -1.1773,  -5.2322,   2.3696,\n          -2.0968,  -1.4790,   1.3305,  -1.5596,  -1.0745,  -6.2535,  -7.2803,\n          -0.1247,   0.4058,   3.6939,  -0.3284,  -2.2349,   0.2596,  -2.7325,\n          -5.4597,  -3.3731,  -1.4493,   5.3324,  -1.7858,   4.4410,   2.3052,\n           0.6696,  -2.7745,  -2.2856,   0.6166,   0.3526,   0.2579,  -0.4232,\n          -2.9080,   3.7982,   2.6201,   3.6251,  -3.3597,  -8.3087,  -6.2810,\n           0.3699,  -2.9020,  -1.0860,  -5.8486,  -0.2044,   5.3820,   5.2429,\n           6.0299,   4.1038,   1.6004,   2.6622,  -0.5564,   6.6080,   1.6224,\n           0.5794,   3.4888,  -3.0038,  -3.4431,  -5.4840,   1.4382,   3.4126,\n          -0.6407,   0.1829,   1.2457,   1.8928,   7.4767,   1.4090,   8.9841,\n           1.7964,  -5.5091,   2.8400,  -0.5386,   4.7357,   2.2811,  -5.6187,\n           1.6686,   3.9166,   1.3221,   2.1832,   0.4028,   2.1277,  -0.3001,\n           7.1466,  -0.8425,   0.4450,   4.0793,   3.1579,   5.3909,   6.4326,\n           4.7012,   0.6820,   2.1246,   6.9220,   1.8446,   4.8339,  -1.9192,\n          -6.0941,   4.4379,   2.0174,  -0.9429,   1.8727,   1.4764,   1.7345,\n           2.0768,  -3.4572,  -7.8440,  -3.1744,  -1.8922,  -0.6208,  -3.1901,\n          -3.7217,  -2.9166,  -6.0696,   1.9320,   1.3753,  -7.7903,  -5.9928,\n          -2.7511,   1.2379,  -3.8388,   2.5851,  -1.9955,   1.1925,   5.4698,\n           1.2160, -10.5476,   0.1721,  -5.1929,  -3.7884,   6.5946,   2.7205,\n          -5.1421,   3.0793,   4.1294,   4.2357,   3.5610,  -3.5484,  -5.3478,\n         -10.9348,  -2.5783,  -1.0073,  -0.8308,  -3.2269,  -1.6259,  -4.4877,\n          -6.5331,  -5.0112,  -0.7330,   3.2653,   2.3659,  -1.7504,  -4.7406,\n          -3.8113,  -1.0099,  -2.2750,   2.9957,   3.6746,  -0.9038,   1.9054,\n           1.8777,  -1.3976,  -1.5796,  -0.5159,  -2.2423,  -0.5321,  -0.3202,\n           6.5226,   1.3765,  -2.6625,   1.0067,   1.5152,   6.6468,   6.5056,\n           8.2561,   7.9439,   3.7300,   0.1533,  -2.4443,  -0.1769,  -3.7407,\n          -1.6259,  -5.7377,   0.4612,  -0.1320,   1.0085,  -1.7215,   1.9138,\n          -3.8275,  -5.4824,  -7.1532,  -2.7281,  -1.9207,  -1.5905,  -2.4208,\n           1.8673,   4.0129,  -0.7047,   1.4414,   1.3762,   4.0394,   6.0227,\n           3.2935,   1.8926,   1.3102,  -2.8144,  -2.3222,   2.8188,  -6.4610,\n           2.5043,   3.2864,   2.8867,  -0.2661,   3.2752,   6.2071,   2.8990,\n          -1.3725,  -1.9285,  -5.8147,  -5.1122,   1.0986, -10.3507,  -9.4845,\n           0.0942,  -0.6462,  -4.9530,   2.5286,   2.0209,  -0.3833]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\n4it [03:23, 53.14s/it]\u001b[32m2023-08-14 17:36:41.966\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 54546, 55673, 31746, 33052, 31685,\n        36743, 31123, 49485, 57647, 56379, 31155, 54546, 49086, 31514,    13,\n           13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:37:27.144\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910, 55673, 54605, 33052, 36743, 31874, 57647, 56379, 31685, 33208,\n        30932, 41472, 38237, 36743, 47653, 54662, 31155, 32040, 43742, 35434,\n        34177, 31758, 33166, 33607, 30954,    13,    13, 30939, 30930, 30910,\n        32096, 55602, 55673, 49722, 47423, 56049, 55673, 30932, 31934, 55560,\n        54615, 54724, 35763, 33052, 36743, 31155, 55602, 55673, 54585, 54571,\n        39819, 54530, 46305, 36660, 56689, 54963, 30932, 54688, 31844, 56689,\n        54607, 54948, 54592, 30932, 37142, 33464, 33052, 31155,    13,    13,\n        30943, 30930, 30910, 50304, 55038, 54605, 54685, 56019, 57244, 54746,\n        56218, 55706, 30932, 31983, 55038, 54605, 33052, 33757, 54584, 31155,\n        32962, 54534, 32820, 43612, 31695, 30932, 31676, 40756, 55038, 54605,\n        54534, 38830, 33823, 36666, 54724, 31982, 41214, 33503, 31155,    13,\n           13, 30966, 30930, 30910, 32317, 41008, 55316, 54530, 41741, 54746,\n        58440, 54583, 31155, 54597, 55316, 46375, 55487, 34667, 56363, 40582,\n        58440, 54583, 32934, 37427, 55038, 54605, 33052, 33264, 54724, 31917,\n        33052, 36743, 34354, 31155,    13,    13, 30972, 30930, 30910, 31937,\n        31859, 55038, 54605, 33052, 30932, 41472, 38237, 33071, 54538, 31155,\n        39745, 38514, 33371, 54542, 56363, 30932, 31983, 55038, 54605, 33027,\n        54724, 35651, 55496, 54803, 31155,    13,    13, 30970, 30930, 30910,\n        31937, 33296, 30932, 31983, 33663, 33757, 54584, 36620, 31155, 33296,\n        54538, 33432, 36666, 37477, 33052, 36743, 30932, 31672, 54552, 33498,\n        55765, 33663, 33757, 54556, 31983, 31902, 33757, 54584, 33501, 31155,\n           13,    13, 31654, 31840, 31847, 31727, 34177, 31822, 32735, 30932,\n        31767, 32763, 54536, 31722, 31740, 31639, 30932, 54627, 34803, 54746,\n        56355, 46460, 54609, 30932, 32108, 54622, 32539, 32718, 54746, 33052,\n        54693, 32718, 54548, 34073, 33588, 31965, 32108, 31155,     2],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:37:27.150\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 54546, 55673, 31746, 33052, 31685,\n        36743, 31123, 49485, 57647, 56379, 31155, 54546, 49086, 31514,    13,\n           13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:37:27.154\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910, 55673, 54605, 33052, 36743, 31874, 57647, 56379, 31685, 33208,\n        30932, 41472, 38237, 36743, 47653, 54662, 31155, 32040, 43742, 35434,\n        34177, 31758, 33166, 33607, 30954,    13,    13, 30939, 30930, 30910,\n        32096, 55602, 55673, 49722, 47423, 56049, 55673, 30932, 31934, 55560,\n        54615, 54724, 35763, 33052, 36743, 31155, 55602, 55673, 54585, 54571,\n        39819, 54530, 46305, 36660, 56689, 54963, 30932, 54688, 31844, 56689,\n        54607, 54948, 54592, 30932, 37142, 33464, 33052, 31155,    13,    13,\n        30943, 30930, 30910, 50304, 55038, 54605, 54685, 56019, 57244, 54746,\n        56218, 55706, 30932, 31983, 55038, 54605, 33052, 33757, 54584, 31155,\n        32962, 54534, 32820, 43612, 31695, 30932, 31676, 40756, 55038, 54605,\n        54534, 38830, 33823, 36666, 54724, 31982, 41214, 33503, 31155,    13,\n           13, 30966, 30930, 30910, 32317, 41008, 55316, 54530, 41741, 54746,\n        58440, 54583, 31155, 54597, 55316, 46375, 55487, 34667, 56363, 40582,\n        58440, 54583, 32934, 37427, 55038, 54605, 33052, 33264, 54724, 31917,\n        33052, 36743, 34354, 31155,    13,    13, 30972, 30930, 30910, 31937,\n        31859, 55038, 54605, 33052, 30932, 41472, 38237, 33071, 54538, 31155,\n        39745, 38514, 33371, 54542, 56363, 30932, 31983, 55038, 54605, 33027,\n        54724, 35651, 55496, 54803, 31155,    13,    13, 30970, 30930, 30910,\n        31937, 33296, 30932, 31983, 33663, 33757, 54584, 36620, 31155, 33296,\n        54538, 33432, 36666, 37477, 33052, 36743, 30932, 31672, 54552, 33498,\n        55765, 33663, 33757, 54556, 31983, 31902, 33757, 54584, 33501, 31155,\n           13,    13, 31654, 31840, 31847, 31727, 34177, 31822, 32735, 30932,\n        31767, 32763, 54536, 31722, 31740, 31639, 30932, 54627, 34803, 54746,\n        56355, 46460, 54609, 30932, 32108, 54622, 32539, 32718, 54746, 33052,\n        54693, 32718, 54548, 34073, 33588, 31965, 32108, 31155,     2],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:37:27.628\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 3.4563e+01,  5.4536e+01,  8.8155e-01,  1.6966e+00,  1.7980e+00,\n        -1.0693e+00, -1.0068e+00,  9.3025e-01,  1.0274e+00,  1.8244e+00,\n         5.0809e+00,  3.7241e+00, -1.4315e+00,  3.5722e-01, -2.2633e+00,\n         3.3920e+00,  1.0010e+00,  3.7402e+00,  5.5330e+00,  4.0801e+00,\n         1.1846e+00,  4.2309e+00,  5.1416e+00,  2.5881e+00,  6.6605e+00,\n         5.3632e+00,  4.1784e+00,  7.4665e+00, -3.5858e+00,  3.8442e-01,\n         1.8474e+00,  6.8850e+00,  5.5625e+00,  5.7987e+00,  3.9030e-01,\n         7.9213e+00, -2.6201e+00,  4.2194e+00,  8.2456e+00,  3.5174e+00,\n         9.8536e+00,  7.9613e+00,  2.4385e+00,  5.4579e+00,  6.6470e+00,\n         6.7393e+00,  6.6364e+00,  6.6223e+00,  4.3098e+00,  2.6796e+00,\n         6.0226e-01,  1.7064e+00, -7.3967e-02,  2.7702e+00,  4.7731e-01,\n        -3.7285e+00,  1.6057e+00,  1.6997e+00,  4.9441e+00, -2.2098e-01,\n         2.7085e-01,  4.2604e+00,  4.5215e+00,  6.8138e+00, -5.4014e-01,\n         3.3313e+00,  2.6294e+00,  2.3357e+00,  2.4242e+00,  5.9332e-01,\n         3.7759e+00, -1.7276e+00, -4.9263e-01,  4.3593e+00, -1.1188e+00,\n         4.5383e+00,  5.0369e+00,  1.5277e+01,  7.5928e+00,  1.5802e+00,\n        -5.1678e+00, -3.0927e-01,  2.9638e+00,  1.0561e+00,  7.1979e+00,\n         1.0977e+01,  1.0105e+00,  6.1499e+00,  2.6324e+00, -6.7684e-02,\n        -2.3181e-01,  4.2843e+00,  4.1511e+00, -9.1201e-01,  2.6330e+00,\n         1.6440e+00,  3.1580e+00,  8.3838e+00,  8.3435e+00,  4.7012e+00,\n         6.8169e+00,  3.5930e+00,  6.3288e+00,  3.5642e+00,  5.1565e+00,\n         1.5830e+00, -6.8903e+00,  3.6256e+00, -3.8895e-01,  3.9825e+00,\n        -3.0575e+00,  5.4251e+00,  2.1316e+00,  1.0906e+00, -3.4665e+00,\n         1.6530e-01,  3.5226e+00, -8.3693e-01,  4.8124e-01, -3.7906e+00,\n        -1.8750e+00, -2.4971e+00, -8.3109e+00,  4.3322e+00, -3.3943e+00,\n         3.1770e+00, -2.4080e+00,  2.4858e-01, -5.8558e-01, -7.8317e-01,\n        -4.2307e+00,  4.3103e+00,  1.8476e+00,  7.0660e+00, -3.2817e+00,\n        -1.7197e+00, -3.0666e+00, -6.5907e-01,  5.8979e+00,  5.3419e+00,\n         4.5299e+00,  6.4101e+00, -1.7462e+00,  2.9059e+00,  6.5885e+00,\n         2.2562e-01,  7.4545e+00,  1.3177e+00,  1.9733e+00,  1.9101e+00,\n        -4.4102e+00,  5.1020e+00,  2.4084e-01,  2.2230e+00,  6.9673e+00,\n         7.4742e+00,  7.1221e-01,  2.0784e+00, -5.8637e+00,  3.2032e+00,\n         1.5648e+00,  1.7818e+00, -4.0040e-01,  5.7592e+00,  5.1369e+00,\n         1.5350e+00,  2.3429e+00,  4.8104e+00,  4.1201e+00, -1.0027e+00,\n        -3.1620e+00, -1.5558e+00,  3.1239e+00,  7.8563e-02,  4.1644e+00,\n         4.3081e+00,  6.5075e+00,  4.1579e+00,  3.9794e+00,  4.2798e+00,\n         8.8993e+00,  2.9352e+00,  1.6434e-01,  7.2010e+00, -8.0604e-01,\n         1.9738e+00, -7.5794e-01, -2.6076e+00,  3.2611e+00,  1.6144e-01,\n         2.5887e+00, -2.0708e+00,  5.9349e+00, -1.5318e+00,  4.5121e+00,\n         8.5566e+00, -2.3010e+00,  2.3879e+00,  2.8700e+00,  3.2308e+00,\n        -3.2539e+00,  9.5746e-01,  2.5293e+00,  8.6360e+00,  2.2136e+00,\n         3.2268e+00,  3.9653e+00,  4.4887e-01,  4.0507e+00,  6.5455e+00,\n         1.7793e+00,  2.5373e+00,  4.6833e-02,  2.2210e+00, -4.7823e+00,\n         5.8249e+00, -3.1525e+00,  1.4347e+00,  5.9655e+00, -2.9133e+00,\n        -6.9146e-01,  1.2531e+00,  4.3051e+00,  4.0222e+00,  6.3615e+00,\n         2.6519e+00,  4.7256e+00,  1.0898e+00,  5.6918e+00, -1.1902e-01,\n        -1.5588e-01,  4.9494e+00,  3.1878e+00,  4.1551e+00, -2.7960e+00,\n         7.2202e+00,  3.1234e+00,  2.1782e+00,  2.1021e+00,  2.8086e+00,\n        -6.9743e-01,  3.0136e+00,  2.1790e+00,  4.9578e+00,  6.5371e+00,\n        -1.0388e+00, -2.6468e+00,  1.3700e+00, -2.4255e-01,  6.0341e+00,\n        -1.1192e+00, -2.6358e+00, -4.3606e+00,  5.1465e+00, -3.0093e+00,\n        -2.0184e+00,  1.4674e+00,  4.0139e+00,  2.3660e+00,  3.1432e+00,\n         1.0524e+01,  8.9642e+00,  4.8755e+00,  7.7214e+00,  1.0975e+01,\n         1.0583e+01,  7.8134e+00,  8.4188e+00, -2.5092e+00,  1.8614e-01,\n         2.0470e+00, -1.5885e-01], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:37:27.629\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:37:27.629\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:37:27.636\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 3.4563e+01,  5.4536e+01,  8.8155e-01,  1.6966e+00,  1.7980e+00,\n        -1.0693e+00, -1.0068e+00,  9.3025e-01,  1.0274e+00,  1.8244e+00,\n         5.0809e+00,  3.7241e+00, -1.4315e+00,  3.5722e-01, -2.2633e+00,\n         3.3920e+00,  1.0010e+00,  3.7402e+00,  5.5330e+00,  4.0801e+00,\n         1.1846e+00,  4.2309e+00,  5.1416e+00,  2.5881e+00,  6.6605e+00,\n         5.3632e+00,  4.1784e+00,  7.4665e+00, -3.5858e+00,  3.8442e-01,\n         1.8474e+00,  6.8850e+00,  5.5625e+00,  5.7987e+00,  3.9030e-01,\n         7.9213e+00, -2.6201e+00,  4.2194e+00,  8.2456e+00,  3.5174e+00,\n         9.8536e+00,  7.9613e+00,  2.4385e+00,  5.4579e+00,  6.6470e+00,\n         6.7393e+00,  6.6364e+00,  6.6223e+00,  4.3098e+00,  2.6796e+00,\n         6.0226e-01,  1.7064e+00, -7.3967e-02,  2.7702e+00,  4.7731e-01,\n        -3.7285e+00,  1.6057e+00,  1.6997e+00,  4.9441e+00, -2.2098e-01,\n         2.7085e-01,  4.2604e+00,  4.5215e+00,  6.8138e+00, -5.4014e-01,\n         3.3313e+00,  2.6294e+00,  2.3357e+00,  2.4242e+00,  5.9332e-01,\n         3.7759e+00, -1.7276e+00, -4.9263e-01,  4.3593e+00, -1.1188e+00,\n         4.5383e+00,  5.0369e+00,  1.5277e+01,  7.5928e+00,  1.5802e+00,\n        -5.1678e+00, -3.0927e-01,  2.9638e+00,  1.0561e+00,  7.1979e+00,\n         1.0977e+01,  1.0105e+00,  6.1499e+00,  2.6324e+00, -6.7684e-02,\n        -2.3181e-01,  4.2843e+00,  4.1511e+00, -9.1201e-01,  2.6330e+00,\n         1.6440e+00,  3.1580e+00,  8.3838e+00,  8.3435e+00,  4.7012e+00,\n         6.8169e+00,  3.5930e+00,  6.3288e+00,  3.5642e+00,  5.1565e+00,\n         1.5830e+00, -6.8903e+00,  3.6256e+00, -3.8895e-01,  3.9825e+00,\n        -3.0575e+00,  5.4251e+00,  2.1316e+00,  1.0906e+00, -3.4665e+00,\n         1.6530e-01,  3.5226e+00, -8.3693e-01,  4.8124e-01, -3.7906e+00,\n        -1.8750e+00, -2.4971e+00, -8.3109e+00,  4.3322e+00, -3.3943e+00,\n         3.1770e+00, -2.4080e+00,  2.4858e-01, -5.8558e-01, -7.8317e-01,\n        -4.2307e+00,  4.3103e+00,  1.8476e+00,  7.0660e+00, -3.2817e+00,\n        -1.7197e+00, -3.0666e+00, -6.5907e-01,  5.8979e+00,  5.3419e+00,\n         4.5299e+00,  6.4101e+00, -1.7462e+00,  2.9059e+00,  6.5885e+00,\n         2.2562e-01,  7.4545e+00,  1.3177e+00,  1.9733e+00,  1.9101e+00,\n        -4.4102e+00,  5.1020e+00,  2.4084e-01,  2.2230e+00,  6.9673e+00,\n         7.4742e+00,  7.1221e-01,  2.0784e+00, -5.8637e+00,  3.2032e+00,\n         1.5648e+00,  1.7818e+00, -4.0040e-01,  5.7592e+00,  5.1369e+00,\n         1.5350e+00,  2.3429e+00,  4.8104e+00,  4.1201e+00, -1.0027e+00,\n        -3.1620e+00, -1.5558e+00,  3.1239e+00,  7.8563e-02,  4.1644e+00,\n         4.3081e+00,  6.5075e+00,  4.1579e+00,  3.9794e+00,  4.2798e+00,\n         8.8993e+00,  2.9352e+00,  1.6434e-01,  7.2010e+00, -8.0604e-01,\n         1.9738e+00, -7.5794e-01, -2.6076e+00,  3.2611e+00,  1.6144e-01,\n         2.5887e+00, -2.0708e+00,  5.9349e+00, -1.5318e+00,  4.5121e+00,\n         8.5566e+00, -2.3010e+00,  2.3879e+00,  2.8700e+00,  3.2308e+00,\n        -3.2539e+00,  9.5746e-01,  2.5293e+00,  8.6360e+00,  2.2136e+00,\n         3.2268e+00,  3.9653e+00,  4.4887e-01,  4.0507e+00,  6.5455e+00,\n         1.7793e+00,  2.5373e+00,  4.6833e-02,  2.2210e+00, -4.7823e+00,\n         5.8249e+00, -3.1525e+00,  1.4347e+00,  5.9655e+00, -2.9133e+00,\n        -6.9146e-01,  1.2531e+00,  4.3051e+00,  4.0222e+00,  6.3615e+00,\n         2.6519e+00,  4.7256e+00,  1.0898e+00,  5.6918e+00, -1.1902e-01,\n        -1.5588e-01,  4.9494e+00,  3.1878e+00,  4.1551e+00, -2.7960e+00,\n         7.2202e+00,  3.1234e+00,  2.1782e+00,  2.1021e+00,  2.8086e+00,\n        -6.9743e-01,  3.0136e+00,  2.1790e+00,  4.9578e+00,  6.5371e+00,\n        -1.0388e+00, -2.6468e+00,  1.3700e+00, -2.4255e-01,  6.0341e+00,\n        -1.1192e+00, -2.6358e+00, -4.3606e+00,  5.1465e+00, -3.0093e+00,\n        -2.0184e+00,  1.4674e+00,  4.0139e+00,  2.3660e+00,  3.1432e+00,\n         1.0524e+01,  8.9642e+00,  4.8755e+00,  7.7214e+00,  1.0975e+01,\n         1.0583e+01,  7.8134e+00,  8.4188e+00, -2.5092e+00,  1.8614e-01,\n         2.0470e+00, -1.5885e-01], device='cuda:0')]\u001b[0m\nepoch:  4 \nquery: 问：我脚上的皮肤非常干燥，甚至会龟裂。我该怎么办？\n\n答：\nresponse: 脚部皮肤干燥甚至龟裂非常常见,特别是在寒冷干燥的季节里。以下是一些有助于缓解这种状况的方法:\n\n1. 每天洗脚并用温水泡脚,帮助软化并减轻皮肤干燥。洗脚后用柔软的毛巾轻轻擦干,但不要擦得太力,以免刺激皮肤。\n\n2. 涂抹足部保湿霜或乳液,保持足部皮肤的水分。最好在晚上睡前使用,这样可以让足部在夜间吸收水分并得到充分的休息。\n\n3. 避免穿过紧的鞋子或袜子。过紧或不透气的鞋子和袜子可能会阻止足部皮肤呼吸并增加皮肤干燥的机会。\n\n4. 注意保护足部皮肤,特别是在寒冷天气中。穿上合适的衣服和鞋,保持足部温暖并远离冷风。\n\n5. 注意饮食,保持足够的水分摄入。饮食中缺乏水分会导致皮肤干燥,所以要记得喝足够的水来保持身体的水分平衡。\n\n如果以上方法不能缓解你的症状,或者如果你有其他健康问题,如糖尿病或灰指甲等,建议你咨询医生或皮肤科医生以获取更好的治疗建议。\nscore: tensor([ 3.4563e+01,  5.4536e+01,  8.8155e-01,  1.6966e+00,  1.7980e+00,\n        -1.0693e+00, -1.0068e+00,  9.3025e-01,  1.0274e+00,  1.8244e+00,\n         5.0809e+00,  3.7241e+00, -1.4315e+00,  3.5722e-01, -2.2633e+00,\n         3.3920e+00,  1.0010e+00,  3.7402e+00,  5.5330e+00,  4.0801e+00,\n         1.1846e+00,  4.2309e+00,  5.1416e+00,  2.5881e+00,  6.6605e+00,\n         5.3632e+00,  4.1784e+00,  7.4665e+00, -3.5858e+00,  3.8442e-01,\n         1.8474e+00,  6.8850e+00,  5.5625e+00,  5.7987e+00,  3.9030e-01,\n         7.9213e+00, -2.6201e+00,  4.2194e+00,  8.2456e+00,  3.5174e+00,\n         9.8536e+00,  7.9613e+00,  2.4385e+00,  5.4579e+00,  6.6470e+00,\n         6.7393e+00,  6.6364e+00,  6.6223e+00,  4.3098e+00,  2.6796e+00,\n         6.0226e-01,  1.7064e+00, -7.3967e-02,  2.7702e+00,  4.7731e-01,\n        -3.7285e+00,  1.6057e+00,  1.6997e+00,  4.9441e+00, -2.2098e-01,\n         2.7085e-01,  4.2604e+00,  4.5215e+00,  6.8138e+00, -5.4014e-01,\n         3.3313e+00,  2.6294e+00,  2.3357e+00,  2.4242e+00,  5.9332e-01,\n         3.7759e+00, -1.7276e+00, -4.9263e-01,  4.3593e+00, -1.1188e+00,\n         4.5383e+00,  5.0369e+00,  1.5277e+01,  7.5928e+00,  1.5802e+00,\n        -5.1678e+00, -3.0927e-01,  2.9638e+00,  1.0561e+00,  7.1979e+00,\n         1.0977e+01,  1.0105e+00,  6.1499e+00,  2.6324e+00, -6.7684e-02,\n        -2.3181e-01,  4.2843e+00,  4.1511e+00, -9.1201e-01,  2.6330e+00,\n         1.6440e+00,  3.1580e+00,  8.3838e+00,  8.3435e+00,  4.7012e+00,\n         6.8169e+00,  3.5930e+00,  6.3288e+00,  3.5642e+00,  5.1565e+00,\n         1.5830e+00, -6.8903e+00,  3.6256e+00, -3.8895e-01,  3.9825e+00,\n        -3.0575e+00,  5.4251e+00,  2.1316e+00,  1.0906e+00, -3.4665e+00,\n         1.6530e-01,  3.5226e+00, -8.3693e-01,  4.8124e-01, -3.7906e+00,\n        -1.8750e+00, -2.4971e+00, -8.3109e+00,  4.3322e+00, -3.3943e+00,\n         3.1770e+00, -2.4080e+00,  2.4858e-01, -5.8558e-01, -7.8317e-01,\n        -4.2307e+00,  4.3103e+00,  1.8476e+00,  7.0660e+00, -3.2817e+00,\n        -1.7197e+00, -3.0666e+00, -6.5907e-01,  5.8979e+00,  5.3419e+00,\n         4.5299e+00,  6.4101e+00, -1.7462e+00,  2.9059e+00,  6.5885e+00,\n         2.2562e-01,  7.4545e+00,  1.3177e+00,  1.9733e+00,  1.9101e+00,\n        -4.4102e+00,  5.1020e+00,  2.4084e-01,  2.2230e+00,  6.9673e+00,\n         7.4742e+00,  7.1221e-01,  2.0784e+00, -5.8637e+00,  3.2032e+00,\n         1.5648e+00,  1.7818e+00, -4.0040e-01,  5.7592e+00,  5.1369e+00,\n         1.5350e+00,  2.3429e+00,  4.8104e+00,  4.1201e+00, -1.0027e+00,\n        -3.1620e+00, -1.5558e+00,  3.1239e+00,  7.8563e-02,  4.1644e+00,\n         4.3081e+00,  6.5075e+00,  4.1579e+00,  3.9794e+00,  4.2798e+00,\n         8.8993e+00,  2.9352e+00,  1.6434e-01,  7.2010e+00, -8.0604e-01,\n         1.9738e+00, -7.5794e-01, -2.6076e+00,  3.2611e+00,  1.6144e-01,\n         2.5887e+00, -2.0708e+00,  5.9349e+00, -1.5318e+00,  4.5121e+00,\n         8.5566e+00, -2.3010e+00,  2.3879e+00,  2.8700e+00,  3.2308e+00,\n        -3.2539e+00,  9.5746e-01,  2.5293e+00,  8.6360e+00,  2.2136e+00,\n         3.2268e+00,  3.9653e+00,  4.4887e-01,  4.0507e+00,  6.5455e+00,\n         1.7793e+00,  2.5373e+00,  4.6833e-02,  2.2210e+00, -4.7823e+00,\n         5.8249e+00, -3.1525e+00,  1.4347e+00,  5.9655e+00, -2.9133e+00,\n        -6.9146e-01,  1.2531e+00,  4.3051e+00,  4.0222e+00,  6.3615e+00,\n         2.6519e+00,  4.7256e+00,  1.0898e+00,  5.6918e+00, -1.1902e-01,\n        -1.5588e-01,  4.9494e+00,  3.1878e+00,  4.1551e+00, -2.7960e+00,\n         7.2202e+00,  3.1234e+00,  2.1782e+00,  2.1021e+00,  2.8086e+00,\n        -6.9743e-01,  3.0136e+00,  2.1790e+00,  4.9578e+00,  6.5371e+00,\n        -1.0388e+00, -2.6468e+00,  1.3700e+00, -2.4255e-01,  6.0341e+00,\n        -1.1192e+00, -2.6358e+00, -4.3606e+00,  5.1465e+00, -3.0093e+00,\n        -2.0184e+00,  1.4674e+00,  4.0139e+00,  2.3660e+00,  3.1432e+00,\n         1.0524e+01,  8.9642e+00,  4.8755e+00,  7.7214e+00,  1.0975e+01,\n         1.0583e+01,  7.8134e+00,  8.4188e+00, -2.5092e+00,  1.8614e-01,\n         2.0470e+00, -1.5885e-01], device='cuda:0')\n\u001b[32m2023-08-14 17:37:27.643\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:37:27.650\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 3.4563e+01,  5.4536e+01,  8.8155e-01,  1.6966e+00,  1.7980e+00,\n        -1.0693e+00, -1.0068e+00,  9.3025e-01,  1.0274e+00,  1.8244e+00,\n         5.0809e+00,  3.7241e+00, -1.4315e+00,  3.5722e-01, -2.2633e+00,\n         3.3920e+00,  1.0010e+00,  3.7402e+00,  5.5330e+00,  4.0801e+00,\n         1.1846e+00,  4.2309e+00,  5.1416e+00,  2.5881e+00,  6.6605e+00,\n         5.3632e+00,  4.1784e+00,  7.4665e+00, -3.5858e+00,  3.8442e-01,\n         1.8474e+00,  6.8850e+00,  5.5625e+00,  5.7987e+00,  3.9030e-01,\n         7.9213e+00, -2.6201e+00,  4.2194e+00,  8.2456e+00,  3.5174e+00,\n         9.8536e+00,  7.9613e+00,  2.4385e+00,  5.4579e+00,  6.6470e+00,\n         6.7393e+00,  6.6364e+00,  6.6223e+00,  4.3098e+00,  2.6796e+00,\n         6.0226e-01,  1.7064e+00, -7.3967e-02,  2.7702e+00,  4.7731e-01,\n        -3.7285e+00,  1.6057e+00,  1.6997e+00,  4.9441e+00, -2.2098e-01,\n         2.7085e-01,  4.2604e+00,  4.5215e+00,  6.8138e+00, -5.4014e-01,\n         3.3313e+00,  2.6294e+00,  2.3357e+00,  2.4242e+00,  5.9332e-01,\n         3.7759e+00, -1.7276e+00, -4.9263e-01,  4.3593e+00, -1.1188e+00,\n         4.5383e+00,  5.0369e+00,  1.5277e+01,  7.5928e+00,  1.5802e+00,\n        -5.1678e+00, -3.0927e-01,  2.9638e+00,  1.0561e+00,  7.1979e+00,\n         1.0977e+01,  1.0105e+00,  6.1499e+00,  2.6324e+00, -6.7684e-02,\n        -2.3181e-01,  4.2843e+00,  4.1511e+00, -9.1201e-01,  2.6330e+00,\n         1.6440e+00,  3.1580e+00,  8.3838e+00,  8.3435e+00,  4.7012e+00,\n         6.8169e+00,  3.5930e+00,  6.3288e+00,  3.5642e+00,  5.1565e+00,\n         1.5830e+00, -6.8903e+00,  3.6256e+00, -3.8895e-01,  3.9825e+00,\n        -3.0575e+00,  5.4251e+00,  2.1316e+00,  1.0906e+00, -3.4665e+00,\n         1.6530e-01,  3.5226e+00, -8.3693e-01,  4.8124e-01, -3.7906e+00,\n        -1.8750e+00, -2.4971e+00, -8.3109e+00,  4.3322e+00, -3.3943e+00,\n         3.1770e+00, -2.4080e+00,  2.4858e-01, -5.8558e-01, -7.8317e-01,\n        -4.2307e+00,  4.3103e+00,  1.8476e+00,  7.0660e+00, -3.2817e+00,\n        -1.7197e+00, -3.0666e+00, -6.5907e-01,  5.8979e+00,  5.3419e+00,\n         4.5299e+00,  6.4101e+00, -1.7462e+00,  2.9059e+00,  6.5885e+00,\n         2.2562e-01,  7.4545e+00,  1.3177e+00,  1.9733e+00,  1.9101e+00,\n        -4.4102e+00,  5.1020e+00,  2.4084e-01,  2.2230e+00,  6.9673e+00,\n         7.4742e+00,  7.1221e-01,  2.0784e+00, -5.8637e+00,  3.2032e+00,\n         1.5648e+00,  1.7818e+00, -4.0040e-01,  5.7592e+00,  5.1369e+00,\n         1.5350e+00,  2.3429e+00,  4.8104e+00,  4.1201e+00, -1.0027e+00,\n        -3.1620e+00, -1.5558e+00,  3.1239e+00,  7.8563e-02,  4.1644e+00,\n         4.3081e+00,  6.5075e+00,  4.1579e+00,  3.9794e+00,  4.2798e+00,\n         8.8993e+00,  2.9352e+00,  1.6434e-01,  7.2010e+00, -8.0604e-01,\n         1.9738e+00, -7.5794e-01, -2.6076e+00,  3.2611e+00,  1.6144e-01,\n         2.5887e+00, -2.0708e+00,  5.9349e+00, -1.5318e+00,  4.5121e+00,\n         8.5566e+00, -2.3010e+00,  2.3879e+00,  2.8700e+00,  3.2308e+00,\n        -3.2539e+00,  9.5746e-01,  2.5293e+00,  8.6360e+00,  2.2136e+00,\n         3.2268e+00,  3.9653e+00,  4.4887e-01,  4.0507e+00,  6.5455e+00,\n         1.7793e+00,  2.5373e+00,  4.6833e-02,  2.2210e+00, -4.7823e+00,\n         5.8249e+00, -3.1525e+00,  1.4347e+00,  5.9655e+00, -2.9133e+00,\n        -6.9146e-01,  1.2531e+00,  4.3051e+00,  4.0222e+00,  6.3615e+00,\n         2.6519e+00,  4.7256e+00,  1.0898e+00,  5.6918e+00, -1.1902e-01,\n        -1.5588e-01,  4.9494e+00,  3.1878e+00,  4.1551e+00, -2.7960e+00,\n         7.2202e+00,  3.1234e+00,  2.1782e+00,  2.1021e+00,  2.8086e+00,\n        -6.9743e-01,  3.0136e+00,  2.1790e+00,  4.9578e+00,  6.5371e+00,\n        -1.0388e+00, -2.6468e+00,  1.3700e+00, -2.4255e-01,  6.0341e+00,\n        -1.1192e+00, -2.6358e+00, -4.3606e+00,  5.1465e+00, -3.0093e+00,\n        -2.0184e+00,  1.4674e+00,  4.0139e+00,  2.3660e+00,  3.1432e+00,\n         1.0524e+01,  8.9642e+00,  4.8755e+00,  7.7214e+00,  1.0975e+01,\n         1.0583e+01,  7.8134e+00,  8.4188e+00, -2.5092e+00,  1.8614e-01,\n         2.0470e+00, -1.5885e-01], device='cuda:0')]\u001b[0m\nscores=[tensor([ 3.4563e+01,  5.4536e+01,  8.8155e-01,  1.6966e+00,  1.7980e+00,\n        -1.0693e+00, -1.0068e+00,  9.3025e-01,  1.0274e+00,  1.8244e+00,\n         5.0809e+00,  3.7241e+00, -1.4315e+00,  3.5722e-01, -2.2633e+00,\n         3.3920e+00,  1.0010e+00,  3.7402e+00,  5.5330e+00,  4.0801e+00,\n         1.1846e+00,  4.2309e+00,  5.1416e+00,  2.5881e+00,  6.6605e+00,\n         5.3632e+00,  4.1784e+00,  7.4665e+00, -3.5858e+00,  3.8442e-01,\n         1.8474e+00,  6.8850e+00,  5.5625e+00,  5.7987e+00,  3.9030e-01,\n         7.9213e+00, -2.6201e+00,  4.2194e+00,  8.2456e+00,  3.5174e+00,\n         9.8536e+00,  7.9613e+00,  2.4385e+00,  5.4579e+00,  6.6470e+00,\n         6.7393e+00,  6.6364e+00,  6.6223e+00,  4.3098e+00,  2.6796e+00,\n         6.0226e-01,  1.7064e+00, -7.3967e-02,  2.7702e+00,  4.7731e-01,\n        -3.7285e+00,  1.6057e+00,  1.6997e+00,  4.9441e+00, -2.2098e-01,\n         2.7085e-01,  4.2604e+00,  4.5215e+00,  6.8138e+00, -5.4014e-01,\n         3.3313e+00,  2.6294e+00,  2.3357e+00,  2.4242e+00,  5.9332e-01,\n         3.7759e+00, -1.7276e+00, -4.9263e-01,  4.3593e+00, -1.1188e+00,\n         4.5383e+00,  5.0369e+00,  1.5277e+01,  7.5928e+00,  1.5802e+00,\n        -5.1678e+00, -3.0927e-01,  2.9638e+00,  1.0561e+00,  7.1979e+00,\n         1.0977e+01,  1.0105e+00,  6.1499e+00,  2.6324e+00, -6.7684e-02,\n        -2.3181e-01,  4.2843e+00,  4.1511e+00, -9.1201e-01,  2.6330e+00,\n         1.6440e+00,  3.1580e+00,  8.3838e+00,  8.3435e+00,  4.7012e+00,\n         6.8169e+00,  3.5930e+00,  6.3288e+00,  3.5642e+00,  5.1565e+00,\n         1.5830e+00, -6.8903e+00,  3.6256e+00, -3.8895e-01,  3.9825e+00,\n        -3.0575e+00,  5.4251e+00,  2.1316e+00,  1.0906e+00, -3.4665e+00,\n         1.6530e-01,  3.5226e+00, -8.3693e-01,  4.8124e-01, -3.7906e+00,\n        -1.8750e+00, -2.4971e+00, -8.3109e+00,  4.3322e+00, -3.3943e+00,\n         3.1770e+00, -2.4080e+00,  2.4858e-01, -5.8558e-01, -7.8317e-01,\n        -4.2307e+00,  4.3103e+00,  1.8476e+00,  7.0660e+00, -3.2817e+00,\n        -1.7197e+00, -3.0666e+00, -6.5907e-01,  5.8979e+00,  5.3419e+00,\n         4.5299e+00,  6.4101e+00, -1.7462e+00,  2.9059e+00,  6.5885e+00,\n         2.2562e-01,  7.4545e+00,  1.3177e+00,  1.9733e+00,  1.9101e+00,\n        -4.4102e+00,  5.1020e+00,  2.4084e-01,  2.2230e+00,  6.9673e+00,\n         7.4742e+00,  7.1221e-01,  2.0784e+00, -5.8637e+00,  3.2032e+00,\n         1.5648e+00,  1.7818e+00, -4.0040e-01,  5.7592e+00,  5.1369e+00,\n         1.5350e+00,  2.3429e+00,  4.8104e+00,  4.1201e+00, -1.0027e+00,\n        -3.1620e+00, -1.5558e+00,  3.1239e+00,  7.8563e-02,  4.1644e+00,\n         4.3081e+00,  6.5075e+00,  4.1579e+00,  3.9794e+00,  4.2798e+00,\n         8.8993e+00,  2.9352e+00,  1.6434e-01,  7.2010e+00, -8.0604e-01,\n         1.9738e+00, -7.5794e-01, -2.6076e+00,  3.2611e+00,  1.6144e-01,\n         2.5887e+00, -2.0708e+00,  5.9349e+00, -1.5318e+00,  4.5121e+00,\n         8.5566e+00, -2.3010e+00,  2.3879e+00,  2.8700e+00,  3.2308e+00,\n        -3.2539e+00,  9.5746e-01,  2.5293e+00,  8.6360e+00,  2.2136e+00,\n         3.2268e+00,  3.9653e+00,  4.4887e-01,  4.0507e+00,  6.5455e+00,\n         1.7793e+00,  2.5373e+00,  4.6833e-02,  2.2210e+00, -4.7823e+00,\n         5.8249e+00, -3.1525e+00,  1.4347e+00,  5.9655e+00, -2.9133e+00,\n        -6.9146e-01,  1.2531e+00,  4.3051e+00,  4.0222e+00,  6.3615e+00,\n         2.6519e+00,  4.7256e+00,  1.0898e+00,  5.6918e+00, -1.1902e-01,\n        -1.5588e-01,  4.9494e+00,  3.1878e+00,  4.1551e+00, -2.7960e+00,\n         7.2202e+00,  3.1234e+00,  2.1782e+00,  2.1021e+00,  2.8086e+00,\n        -6.9743e-01,  3.0136e+00,  2.1790e+00,  4.9578e+00,  6.5371e+00,\n        -1.0388e+00, -2.6468e+00,  1.3700e+00, -2.4255e-01,  6.0341e+00,\n        -1.1192e+00, -2.6358e+00, -4.3606e+00,  5.1465e+00, -3.0093e+00,\n        -2.0184e+00,  1.4674e+00,  4.0139e+00,  2.3660e+00,  3.1432e+00,\n         1.0524e+01,  8.9642e+00,  4.8755e+00,  7.7214e+00,  1.0975e+01,\n         1.0583e+01,  7.8134e+00,  8.4188e+00, -2.5092e+00,  1.8614e-01,\n         2.0470e+00, -1.5885e-01], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 3.1103e+01,  4.5558e+01,  6.1764e-01,  5.5194e-01,  2.0308e+00,\n          8.8121e-01, -2.5105e+00, -2.5116e+00,  8.6328e-01, -1.2913e+00,\n          3.5550e+00,  3.7812e+00, -4.6435e-01, -9.7150e-01, -5.1136e+00,\n          3.0662e-01,  2.2697e+00,  3.0351e+00,  6.6535e+00,  4.5475e+00,\n          3.1588e+00,  4.7155e+00,  4.9052e+00,  1.1877e+00,  9.5831e+00,\n          6.9181e+00,  2.9645e+00,  1.0609e+01,  2.7402e-01,  3.2130e+00,\n          3.1676e+00,  6.0325e+00,  5.7256e+00,  4.9337e+00,  7.7899e-01,\n          3.1965e+00,  3.1828e-01,  3.2165e+00,  7.4847e+00,  3.5590e+00,\n          8.9688e+00,  4.7133e+00,  5.7213e+00,  5.5946e+00,  7.8761e+00,\n          5.7570e+00,  7.4900e+00,  5.8368e+00,  2.9156e+00,  5.5842e+00,\n          3.3578e+00,  1.3332e+00,  1.0921e+00,  4.4971e+00, -3.6159e+00,\n         -1.1930e+00,  6.7567e-01,  2.5049e+00,  6.0924e+00,  1.4088e+00,\n          4.5164e-01,  3.8072e+00,  3.3495e+00,  5.2265e+00, -3.3171e-01,\n          2.2967e+00,  4.1047e+00,  1.6385e+00,  1.8171e+00,  4.5149e-01,\n          4.2555e+00, -1.8534e+00,  1.5225e+00,  3.3211e+00, -2.8120e+00,\n          2.0360e+00,  3.1618e+00,  1.2313e+01,  3.1160e+00,  1.7668e+00,\n         -2.9294e+00,  3.0000e-01,  6.0791e+00,  3.3025e+00,  3.3446e+00,\n          1.0657e+01, -1.1894e+00,  5.7803e+00,  5.8899e-01, -6.6022e-01,\n         -3.3949e-02,  1.2974e+00,  5.6828e+00,  1.6392e+00,  2.1605e+00,\n         -2.9855e+00,  2.9291e+00,  5.6572e+00,  7.2352e+00,  6.9867e+00,\n          4.3456e+00,  5.6150e+00,  5.6833e+00,  2.8124e+00,  2.2995e+00,\n          3.4557e+00, -1.3606e+00,  4.6046e+00, -1.1065e+00,  4.1992e+00,\n         -2.6295e+00,  8.6451e+00,  2.6012e+00,  1.7950e+00, -1.8469e+00,\n         -1.5507e-01,  6.7384e-01,  4.4586e-01,  1.7756e+00, -4.5052e+00,\n          3.8609e-01, -2.2867e+00, -9.0681e+00,  1.6863e+00, -3.0415e+00,\n          4.7811e+00, -2.4073e+00,  1.1136e+00, -3.1444e+00,  1.5118e+00,\n         -4.9383e+00,  3.8345e+00,  2.0128e+00,  3.1717e+00, -4.1828e+00,\n         -2.7845e+00, -4.2665e+00,  2.1697e+00,  5.7320e+00,  4.0412e+00,\n         -6.0742e-01,  6.0529e+00, -4.1377e+00,  3.0670e+00,  7.8169e+00,\n          3.0182e-01,  5.8160e+00,  2.6999e+00,  6.8144e+00,  1.1524e+00,\n         -5.0532e+00,  4.8277e+00, -2.1534e+00,  1.8812e-01,  6.8739e+00,\n          9.3821e+00,  4.6735e+00,  8.1731e-01, -7.4808e+00,  4.7217e+00,\n          2.4253e+00,  6.0785e-01,  7.0329e-01,  8.6482e+00,  5.0077e+00,\n          2.9883e+00,  3.8673e-01,  3.7717e+00,  5.5035e+00, -2.2120e+00,\n          2.1797e+00, -5.2636e-01,  3.9453e+00, -8.6308e-01,  2.3548e+00,\n          1.6267e+00,  6.0563e+00,  1.8658e+00,  1.3000e+00,  3.3008e+00,\n          7.3934e+00,  2.6991e+00,  3.2610e+00,  6.1861e+00,  1.5006e+00,\n          4.0856e+00, -1.8935e+00,  2.2984e+00,  3.9094e+00,  6.2709e-01,\n          1.8345e+00,  1.5795e+00,  6.8615e+00, -1.4284e+00,  6.8541e-01,\n          1.0217e+01, -6.9812e-01,  4.0605e+00,  3.0407e+00,  4.6211e+00,\n         -3.9929e+00, -6.5405e-01,  3.2602e-01,  6.7554e+00,  2.4209e+00,\n          1.3602e+00,  4.9494e+00, -2.4914e-01,  2.4291e+00,  4.1950e+00,\n          2.4755e+00,  1.9509e+00, -2.1929e+00,  4.3198e+00, -5.3824e+00,\n          4.4997e+00, -8.8166e-01,  2.2280e+00,  6.6203e+00, -2.7290e+00,\n         -1.8681e-01,  6.1912e-02,  5.6472e+00,  5.8035e+00,  7.0587e+00,\n         -3.8471e-01,  6.4609e+00,  1.8005e+00,  5.2614e+00, -1.2583e+00,\n         -5.2758e-01,  4.4640e+00,  4.0462e+00,  2.6077e+00, -6.6838e-01,\n          8.2156e+00,  7.6633e+00,  6.2104e-01,  1.6783e-02,  7.3723e-01,\n          2.1889e+00,  5.1554e+00,  4.3371e-02,  3.7394e+00,  8.1985e+00,\n         -7.4300e-01, -3.8558e-01,  2.4434e+00, -3.1121e-01,  3.9907e+00,\n         -3.0020e+00, -4.2716e+00, -2.7916e+00,  2.7679e+00, -2.0690e+00,\n         -4.2563e+00, -9.9942e-01,  1.5349e+00,  3.4253e+00,  4.7699e+00,\n          1.1458e+01,  9.5595e+00,  5.8531e+00,  8.2455e+00,  1.0373e+01,\n          8.7781e+00,  7.0754e+00,  9.1339e+00, -3.4729e+00,  1.8167e+00,\n          5.6971e+00,  1.8726e-01]], device='cuda:0')\nvalues_994 = tensor([[ 2.3314e+01,  6.0295e+01,  6.0324e-01,  1.8103e+00,  9.3681e-01,\n         -1.1301e+00, -1.4347e+00, -1.7055e+00,  3.9683e-02,  1.4308e+00,\n          3.1742e+00,  3.4500e+00,  5.6817e-01, -1.4175e+00, -2.1805e+00,\n          1.7757e+00,  1.1628e+00,  2.7469e+00,  4.2402e+00,  4.1973e+00,\n          2.3075e+00,  4.5453e+00,  4.9027e+00,  2.7684e+00,  7.9886e+00,\n          6.2074e+00,  8.7673e+00,  1.0201e+01,  1.5588e-01, -1.2217e-01,\n          3.0350e+00,  7.3035e+00,  5.1325e+00,  4.6427e+00,  1.5674e+00,\n          1.8954e+00,  2.4278e-01,  4.7164e+00,  8.4952e+00,  6.0956e+00,\n          1.1593e+01,  7.2901e+00,  6.4232e+00,  4.3315e+00,  7.8419e+00,\n          3.8571e+00,  6.5397e+00,  7.1138e+00,  2.9138e+00,  3.2048e+00,\n          2.9336e+00,  1.5055e+00,  2.4195e+00,  2.0508e+00,  9.2504e-01,\n         -2.4389e+00,  1.1948e+00,  2.0278e+00,  7.0633e+00, -2.3231e+00,\n          3.1659e-01,  4.3041e+00,  6.9298e+00,  2.3719e+00, -1.5842e-01,\n          1.9144e+00,  1.5563e+00,  3.6481e+00,  1.0779e+00, -3.0367e-01,\n          2.8842e+00, -1.3057e+00,  2.7177e+00,  2.6688e+00, -3.2473e+00,\n          3.0983e+00,  3.9606e+00,  1.1779e+01,  2.6309e+00,  4.5480e+00,\n         -5.4339e+00, -3.8412e-01,  2.9486e+00,  1.3364e+00,  6.1920e+00,\n          1.1015e+01,  8.6931e-01,  3.5560e+00,  9.3794e-01,  2.8919e+00,\n          1.4320e+00,  1.8634e+00,  3.9296e+00,  7.5932e-01, -1.1756e-01,\n         -1.2223e-02,  4.8970e+00,  6.0483e+00,  8.1624e+00,  6.4114e+00,\n          5.3449e+00,  2.5624e+00,  5.2178e+00,  4.0909e+00,  3.9568e+00,\n          1.2612e-01, -5.0299e+00,  2.0860e+00, -1.1568e+00,  3.4138e+00,\n         -3.2828e+00,  6.9744e+00,  3.4337e-01,  1.1682e+00,  9.6175e-01,\n          1.0187e+00,  2.4936e+00,  3.8269e+00, -1.0905e+00, -4.4156e+00,\n         -1.8576e+00, -1.5888e+00, -5.6690e+00,  2.4045e+00, -3.7095e+00,\n          2.4885e+00, -1.2324e-01, -1.2525e+00, -1.0432e+00, -4.8828e+00,\n         -4.4003e+00,  3.5114e+00,  8.9567e-01,  5.7999e+00, -5.4516e+00,\n         -4.5247e+00, -1.4359e+00,  1.1729e+00,  7.6153e+00,  5.4021e+00,\n          4.6831e+00,  4.5156e+00,  1.6387e+00,  3.5467e+00,  5.5139e+00,\n         -3.6967e+00,  9.5325e+00, -2.4865e-01,  4.3063e+00,  2.1682e+00,\n         -4.9042e+00,  2.8573e+00, -3.7167e+00,  8.6942e-01,  7.1731e+00,\n          6.7929e+00, -1.9402e-01,  5.2417e-01, -5.2381e+00,  5.5490e+00,\n          3.4245e+00, -2.9597e-01,  1.4216e-02,  4.3833e+00,  6.7323e+00,\n          1.4614e+00,  3.5673e+00,  4.8256e+00,  4.6992e+00, -3.5051e+00,\n         -2.8891e+00,  7.2504e-02,  2.1632e+00, -2.6867e+00,  2.4065e+00,\n          5.1462e+00,  5.8111e+00,  4.8612e+00,  1.6940e+00,  4.8262e+00,\n          6.7772e+00,  3.2614e+00,  2.7263e-01,  6.1633e+00,  4.7887e+00,\n          2.3840e+00,  3.9667e-01,  1.0295e+00,  1.9564e-01,  3.0025e+00,\n          4.2487e+00, -2.7195e+00,  5.8248e+00, -8.1559e-01, -4.1591e-01,\n          1.0760e+01,  2.7857e+00,  3.6459e+00,  4.5641e-01,  3.4386e+00,\n         -2.9371e+00, -5.8155e-01,  3.1052e+00,  6.1901e+00,  1.3829e+00,\n          3.2022e+00,  4.3939e+00, -6.4606e-01,  2.6720e+00,  8.1612e+00,\n          2.6477e+00,  2.1519e+00,  4.8831e-01,  3.2040e+00, -6.1608e+00,\n          5.4488e+00, -2.8097e+00,  2.2691e+00,  3.4898e+00, -2.7994e+00,\n          1.2390e+00, -1.5392e+00,  3.4496e+00,  5.7174e+00,  5.0816e+00,\n          9.3478e-01,  5.5738e+00,  4.6569e-01,  8.6675e+00, -2.5639e+00,\n          2.4513e+00,  3.0243e+00,  4.5402e+00,  4.3361e+00, -1.1280e-01,\n          7.8976e+00,  6.2787e+00,  1.9159e+00,  2.0276e+00,  1.5847e-01,\n         -2.1983e+00,  3.1505e+00,  3.3372e-01,  6.1316e+00,  7.0117e+00,\n         -8.6501e-01, -6.1088e-01,  1.9846e+00, -1.0220e+00,  3.6569e+00,\n         -2.8914e+00, -2.5130e+00, -4.5084e+00,  3.4481e+00, -2.4958e+00,\n         -3.7011e+00, -1.6150e+00,  2.5241e+00,  1.2280e+00,  5.6336e+00,\n          1.1680e+01,  1.0111e+01,  3.7732e+00,  6.6300e+00,  9.0455e+00,\n          7.2454e+00,  8.9668e+00,  7.3732e+00, -3.1205e+00,  2.5541e+00,\n          2.1824e+00, -6.0541e-01]], device='cuda:0')\nreward[last_non_masked_index]=tensor([-1.1921e-07], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 3.4563e+01,  5.4536e+01,  8.8155e-01,  1.6966e+00,  1.7980e+00,\n        -1.0693e+00, -1.0068e+00,  9.3025e-01,  1.0274e+00,  1.8244e+00,\n         5.0809e+00,  3.7241e+00, -1.4315e+00,  3.5722e-01, -2.2633e+00,\n         3.3920e+00,  1.0010e+00,  3.7402e+00,  5.5330e+00,  4.0801e+00,\n         1.1846e+00,  4.2309e+00,  5.1416e+00,  2.5881e+00,  6.6605e+00,\n         5.3632e+00,  4.1784e+00,  7.4665e+00, -3.5858e+00,  3.8442e-01,\n         1.8474e+00,  6.8850e+00,  5.5625e+00,  5.7987e+00,  3.9030e-01,\n         7.9213e+00, -2.6201e+00,  4.2194e+00,  8.2456e+00,  3.5174e+00,\n         9.8536e+00,  7.9613e+00,  2.4385e+00,  5.4579e+00,  6.6470e+00,\n         6.7393e+00,  6.6364e+00,  6.6223e+00,  4.3098e+00,  2.6796e+00,\n         6.0226e-01,  1.7064e+00, -7.3967e-02,  2.7702e+00,  4.7731e-01,\n        -3.7285e+00,  1.6057e+00,  1.6997e+00,  4.9441e+00, -2.2098e-01,\n         2.7085e-01,  4.2604e+00,  4.5215e+00,  6.8138e+00, -5.4014e-01,\n         3.3313e+00,  2.6294e+00,  2.3357e+00,  2.4242e+00,  5.9332e-01,\n         3.7759e+00, -1.7276e+00, -4.9263e-01,  4.3593e+00, -1.1188e+00,\n         4.5383e+00,  5.0369e+00,  1.5277e+01,  7.5928e+00,  1.5802e+00,\n        -5.1678e+00, -3.0927e-01,  2.9638e+00,  1.0561e+00,  7.1979e+00,\n         1.0977e+01,  1.0105e+00,  6.1499e+00,  2.6324e+00, -6.7684e-02,\n        -2.3181e-01,  4.2843e+00,  4.1511e+00, -9.1201e-01,  2.6330e+00,\n         1.6440e+00,  3.1580e+00,  8.3838e+00,  8.3435e+00,  4.7012e+00,\n         6.8169e+00,  3.5930e+00,  6.3288e+00,  3.5642e+00,  5.1565e+00,\n         1.5830e+00, -6.8903e+00,  3.6256e+00, -3.8895e-01,  3.9825e+00,\n        -3.0575e+00,  5.4251e+00,  2.1316e+00,  1.0906e+00, -3.4665e+00,\n         1.6530e-01,  3.5226e+00, -8.3693e-01,  4.8124e-01, -3.7906e+00,\n        -1.8750e+00, -2.4971e+00, -8.3109e+00,  4.3322e+00, -3.3943e+00,\n         3.1770e+00, -2.4080e+00,  2.4858e-01, -5.8558e-01, -7.8317e-01,\n        -4.2307e+00,  4.3103e+00,  1.8476e+00,  7.0660e+00, -3.2817e+00,\n        -1.7197e+00, -3.0666e+00, -6.5907e-01,  5.8979e+00,  5.3419e+00,\n         4.5299e+00,  6.4101e+00, -1.7462e+00,  2.9059e+00,  6.5885e+00,\n         2.2562e-01,  7.4545e+00,  1.3177e+00,  1.9733e+00,  1.9101e+00,\n        -4.4102e+00,  5.1020e+00,  2.4084e-01,  2.2230e+00,  6.9673e+00,\n         7.4742e+00,  7.1221e-01,  2.0784e+00, -5.8637e+00,  3.2032e+00,\n         1.5648e+00,  1.7818e+00, -4.0040e-01,  5.7592e+00,  5.1369e+00,\n         1.5350e+00,  2.3429e+00,  4.8104e+00,  4.1201e+00, -1.0027e+00,\n        -3.1620e+00, -1.5558e+00,  3.1239e+00,  7.8563e-02,  4.1644e+00,\n         4.3081e+00,  6.5075e+00,  4.1579e+00,  3.9794e+00,  4.2798e+00,\n         8.8993e+00,  2.9352e+00,  1.6434e-01,  7.2010e+00, -8.0604e-01,\n         1.9738e+00, -7.5794e-01, -2.6076e+00,  3.2611e+00,  1.6144e-01,\n         2.5887e+00, -2.0708e+00,  5.9349e+00, -1.5318e+00,  4.5121e+00,\n         8.5566e+00, -2.3010e+00,  2.3879e+00,  2.8700e+00,  3.2308e+00,\n        -3.2539e+00,  9.5746e-01,  2.5293e+00,  8.6360e+00,  2.2136e+00,\n         3.2268e+00,  3.9653e+00,  4.4887e-01,  4.0507e+00,  6.5455e+00,\n         1.7793e+00,  2.5373e+00,  4.6833e-02,  2.2210e+00, -4.7823e+00,\n         5.8249e+00, -3.1525e+00,  1.4347e+00,  5.9655e+00, -2.9133e+00,\n        -6.9146e-01,  1.2531e+00,  4.3051e+00,  4.0222e+00,  6.3615e+00,\n         2.6519e+00,  4.7256e+00,  1.0898e+00,  5.6918e+00, -1.1902e-01,\n        -1.5588e-01,  4.9494e+00,  3.1878e+00,  4.1551e+00, -2.7960e+00,\n         7.2202e+00,  3.1234e+00,  2.1782e+00,  2.1021e+00,  2.8086e+00,\n        -6.9743e-01,  3.0136e+00,  2.1790e+00,  4.9578e+00,  6.5371e+00,\n        -1.0388e+00, -2.6468e+00,  1.3700e+00, -2.4255e-01,  6.0341e+00,\n        -1.1192e+00, -2.6358e+00, -4.3606e+00,  5.1465e+00, -3.0093e+00,\n        -2.0184e+00,  1.4674e+00,  4.0139e+00,  2.3660e+00,  3.1432e+00,\n         1.0524e+01,  8.9642e+00,  4.8755e+00,  7.7214e+00,  1.0975e+01,\n         1.0583e+01,  7.8134e+00,  8.4188e+00, -2.5092e+00,  1.8614e-01,\n         2.0470e+00, -1.5885e-01], device='cuda:0')\nvalues=tensor([[ 3.1103e+01,  4.5558e+01,  6.1764e-01,  5.5194e-01,  2.0308e+00,\n          8.8121e-01, -2.5105e+00, -2.5116e+00,  8.6328e-01, -1.2913e+00,\n          3.5550e+00,  3.7812e+00, -4.6435e-01, -9.7150e-01, -5.1136e+00,\n          3.0662e-01,  2.2697e+00,  3.0351e+00,  6.6535e+00,  4.5475e+00,\n          3.1588e+00,  4.7155e+00,  4.9052e+00,  1.1877e+00,  9.5831e+00,\n          6.9181e+00,  2.9645e+00,  1.0609e+01,  2.7402e-01,  3.2130e+00,\n          3.1676e+00,  6.0325e+00,  5.7256e+00,  4.9337e+00,  7.7899e-01,\n          3.1965e+00,  3.1828e-01,  3.2165e+00,  7.4847e+00,  3.5590e+00,\n          8.9688e+00,  4.7133e+00,  5.7213e+00,  5.5946e+00,  7.8761e+00,\n          5.7570e+00,  7.4900e+00,  5.8368e+00,  2.9156e+00,  5.5842e+00,\n          3.3578e+00,  1.3332e+00,  1.0921e+00,  4.4971e+00, -3.6159e+00,\n         -1.1930e+00,  6.7567e-01,  2.5049e+00,  6.0924e+00,  1.4088e+00,\n          4.5164e-01,  3.8072e+00,  3.3495e+00,  5.2265e+00, -3.3171e-01,\n          2.2967e+00,  4.1047e+00,  1.6385e+00,  1.8171e+00,  4.5149e-01,\n          4.2555e+00, -1.8534e+00,  1.5225e+00,  3.3211e+00, -2.8120e+00,\n          2.0360e+00,  3.1618e+00,  1.2313e+01,  3.1160e+00,  1.7668e+00,\n         -2.9294e+00,  3.0000e-01,  6.0791e+00,  3.3025e+00,  3.3446e+00,\n          1.0657e+01, -1.1894e+00,  5.7803e+00,  5.8899e-01, -6.6022e-01,\n         -3.3949e-02,  1.2974e+00,  5.6828e+00,  1.6392e+00,  2.1605e+00,\n         -2.9855e+00,  2.9291e+00,  5.6572e+00,  7.2352e+00,  6.9867e+00,\n          4.3456e+00,  5.6150e+00,  5.6833e+00,  2.8124e+00,  2.2995e+00,\n          3.4557e+00, -1.3606e+00,  4.6046e+00, -1.1065e+00,  4.1992e+00,\n         -2.6295e+00,  8.6451e+00,  2.6012e+00,  1.7950e+00, -1.8469e+00,\n         -1.5507e-01,  6.7384e-01,  4.4586e-01,  1.7756e+00, -4.5052e+00,\n          3.8609e-01, -2.2867e+00, -9.0681e+00,  1.6863e+00, -3.0415e+00,\n          4.7811e+00, -2.4073e+00,  1.1136e+00, -3.1444e+00,  1.5118e+00,\n         -4.9383e+00,  3.8345e+00,  2.0128e+00,  3.1717e+00, -4.1828e+00,\n         -2.7845e+00, -4.2665e+00,  2.1697e+00,  5.7320e+00,  4.0412e+00,\n         -6.0742e-01,  6.0529e+00, -4.1377e+00,  3.0670e+00,  7.8169e+00,\n          3.0182e-01,  5.8160e+00,  2.6999e+00,  6.8144e+00,  1.1524e+00,\n         -5.0532e+00,  4.8277e+00, -2.1534e+00,  1.8812e-01,  6.8739e+00,\n          9.3821e+00,  4.6735e+00,  8.1731e-01, -7.4808e+00,  4.7217e+00,\n          2.4253e+00,  6.0785e-01,  7.0329e-01,  8.6482e+00,  5.0077e+00,\n          2.9883e+00,  3.8673e-01,  3.7717e+00,  5.5035e+00, -2.2120e+00,\n          2.1797e+00, -5.2636e-01,  3.9453e+00, -8.6308e-01,  2.3548e+00,\n          1.6267e+00,  6.0563e+00,  1.8658e+00,  1.3000e+00,  3.3008e+00,\n          7.3934e+00,  2.6991e+00,  3.2610e+00,  6.1861e+00,  1.5006e+00,\n          4.0856e+00, -1.8935e+00,  2.2984e+00,  3.9094e+00,  6.2709e-01,\n          1.8345e+00,  1.5795e+00,  6.8615e+00, -1.4284e+00,  6.8541e-01,\n          1.0217e+01, -6.9812e-01,  4.0605e+00,  3.0407e+00,  4.6211e+00,\n         -3.9929e+00, -6.5405e-01,  3.2602e-01,  6.7554e+00,  2.4209e+00,\n          1.3602e+00,  4.9494e+00, -2.4914e-01,  2.4291e+00,  4.1950e+00,\n          2.4755e+00,  1.9509e+00, -2.1929e+00,  4.3198e+00, -5.3824e+00,\n          4.4997e+00, -8.8166e-01,  2.2280e+00,  6.6203e+00, -2.7290e+00,\n         -1.8681e-01,  6.1912e-02,  5.6472e+00,  5.8035e+00,  7.0587e+00,\n         -3.8471e-01,  6.4609e+00,  1.8005e+00,  5.2614e+00, -1.2583e+00,\n         -5.2758e-01,  4.4640e+00,  4.0462e+00,  2.6077e+00, -6.6838e-01,\n          8.2156e+00,  7.6633e+00,  6.2104e-01,  1.6783e-02,  7.3723e-01,\n          2.1889e+00,  5.1554e+00,  4.3371e-02,  3.7394e+00,  8.1985e+00,\n         -7.4300e-01, -3.8558e-01,  2.4434e+00, -3.1121e-01,  3.9907e+00,\n         -3.0020e+00, -4.2716e+00, -2.7916e+00,  2.7679e+00, -2.0690e+00,\n         -4.2563e+00, -9.9942e-01,  1.5349e+00,  3.4253e+00,  4.7699e+00,\n          1.1458e+01,  9.5595e+00,  5.8531e+00,  8.2455e+00,  1.0373e+01,\n          8.7781e+00,  7.0754e+00,  9.1339e+00, -3.4729e+00,  1.8167e+00,\n          5.6971e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -8.9174e-07,\n          3.2123e-05,  5.2246e-04,  7.9749e-06, -1.0089e-06, -2.1560e-04,\n          1.8458e-06, -4.7935e-06, -1.1716e-04,  5.9601e-08,  4.7591e-07,\n         -1.3202e-05, -0.0000e+00,  7.7439e-07, -2.4787e-05, -3.5700e-04,\n         -7.1492e-07, -2.4391e-06,  1.8417e-06, -1.8322e-04,  1.2056e-03,\n         -9.5149e-06, -7.1924e-06,  1.6498e-05,  5.9604e-08,  1.1337e-03,\n          5.9587e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4988e-04,\n          1.5398e-05, -0.0000e+00,  5.9601e-08, -4.4003e-05,  5.9590e-08,\n          3.5759e-07,  1.9956e-05,  2.2028e-06, -0.0000e+00,  1.1105e-05,\n         -4.2610e-05, -1.3805e-04, -5.5276e-05, -5.9592e-07,  1.4955e-05,\n          7.1403e-07, -4.2481e-05,  2.5034e-06, -3.5742e-07, -7.4510e-06,\n          1.2517e-05,  2.2256e-04, -1.1920e-07,  4.4267e-03, -3.4559e-04,\n          5.3785e-03, -5.9601e-08,  6.4615e-04, -7.2423e-04, -2.2299e-03,\n         -2.8548e-03, -4.5538e-04, -4.2143e-04,  1.3117e-04,  4.3315e-04,\n          1.7881e-07, -1.3109e-06, -0.0000e+00,  1.1920e-07, -0.0000e+00,\n          2.9795e-07, -1.2589e-03,  3.8867e-04, -3.6783e-06, -3.1819e-05,\n          1.1979e-04,  6.0424e-06,  5.2980e-04, -0.0000e+00, -9.7290e-04,\n         -3.2314e-03, -1.1916e-06, -1.6277e-03,  1.1921e-07, -2.3839e-07,\n         -5.8255e-04, -3.6109e-03,  5.9603e-08, -0.0000e+00,  4.4507e-05,\n         -6.0281e-04, -2.6232e-04,  1.4889e-06,  1.7969e-04, -1.3124e-03,\n          5.0564e-06,  1.4569e-04, -2.1047e-05, -1.1367e-04, -2.0669e-03,\n         -5.9604e-08, -1.6681e-06, -0.0000e+00,  5.9603e-08, -0.0000e+00,\n         -1.1321e-06,  7.9769e-04,  4.8393e-04,  4.6520e-06,  1.1916e-06,\n          3.5646e-07, -6.1503e-04,  3.5813e-04, -9.7789e-06, -7.0107e-04,\n          2.1285e-03,  2.9744e-07,  2.7293e-04, -6.9402e-04, -1.3884e-03,\n          5.5835e-04,  2.3497e-03, -8.1196e-05,  2.3854e-04, -8.8313e-04,\n         -2.4356e-05, -8.7898e-06, -1.9171e-05,  1.6954e-03, -8.0419e-04,\n         -1.1047e-04,  3.0473e-06,  4.7666e-07, -0.0000e+00, -5.2222e-06,\n         -0.0000e+00, -2.4445e-04,  1.6090e-03,  1.7864e-07, -5.3242e-04,\n         -2.0084e-04, -5.0509e-04, -0.0000e+00, -5.9604e-08, -0.0000e+00,\n         -4.7819e-04, -1.8215e-04,  2.2105e-05,  3.2140e-04,  4.8875e-03,\n          5.4783e-04,  1.7797e-05,  4.7596e-05,  1.4323e-04,  4.1986e-04,\n          3.6756e-05,  2.8806e-03,  3.9917e-04, -0.0000e+00, -0.0000e+00,\n         -2.3233e-03, -1.4275e-06,  4.5167e-04, -8.5083e-04,  5.9604e-08,\n         -1.2402e-05, -0.0000e+00, -5.9601e-08,  2.3542e-05, -1.0063e-03,\n         -1.5357e-03, -1.4293e-06, -2.0236e-05, -1.9041e-04, -3.6340e-03,\n          4.2245e-05, -1.1918e-07,  6.8310e-06, -4.7296e-04, -7.5463e-05,\n         -1.4104e-03,  5.7857e-05,  5.9604e-08,  6.8444e-06, -2.1027e-03,\n          1.4287e-05, -1.4995e-04, -8.4996e-04, -1.1896e-06,  1.2491e-06,\n          1.2004e-04, -2.2496e-03, -7.3612e-05,  2.1360e-06,  2.5776e-04,\n         -2.4438e-04,  2.9640e-04, -0.0000e+00,  2.4725e-05, -5.7378e-04,\n         -3.7260e-05, -5.2906e-03,  1.3154e-03, -2.3830e-07, -0.0000e+00,\n         -1.5885e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 3.2812e+01,  5.1862e+01,  4.0496e-01,  1.1663e+00,  2.0187e+00,\n         -1.1928e+00, -1.1923e+00, -7.6889e-01,  7.3848e-01,  4.3361e-01,\n          4.5480e+00,  1.1900e+00,  7.9358e-01,  2.9439e-03, -1.4012e+00,\n          1.7854e+00, -1.5787e-01,  3.3476e+00,  5.9653e+00,  5.7208e+00,\n          3.2310e+00,  4.2902e+00,  5.0877e+00,  5.2906e+00,  6.6179e+00,\n          6.4791e+00,  5.6493e+00,  8.4532e+00, -7.6202e-01,  2.3767e+00,\n          3.2262e+00,  4.7007e+00,  6.2327e+00,  3.3164e+00,  2.6356e+00,\n          4.1799e+00,  1.2546e+00,  5.4111e+00,  6.8000e+00,  6.8378e+00,\n          9.4533e+00,  8.0728e+00,  3.0902e+00,  4.6914e+00,  7.7648e+00,\n          3.9373e+00,  6.3683e+00,  6.7665e+00,  4.2795e+00,  1.2189e+00,\n          2.3235e+00,  2.7603e+00,  2.1447e-01,  1.4093e+00,  9.2175e-01,\n         -7.2955e-01,  1.9114e+00,  2.0845e-01,  3.4480e+00,  1.2389e+00,\n          2.0745e+00,  7.2189e+00,  4.6206e+00,  6.6144e+00,  3.2665e-01,\n          1.8111e+00,  3.5956e+00,  2.8237e+00,  4.5817e+00,  2.4444e-01,\n          3.6452e+00,  1.8919e+00,  1.2502e+00,  6.1608e+00, -2.9838e+00,\n          8.1850e-01,  2.9754e+00,  1.1681e+01,  2.7127e+00, -2.4052e-01,\n         -6.0423e+00,  2.4284e+00,  4.1623e+00, -1.2279e+00,  3.1624e+00,\n          9.9022e+00,  3.5114e+00,  5.5952e+00, -1.2819e+00,  5.2744e-01,\n          2.6049e+00,  2.0179e+00,  4.8363e+00, -6.5285e-01,  2.2203e+00,\n         -1.6067e+00,  3.9838e+00,  6.3403e+00,  6.6168e+00,  4.4876e+00,\n          3.0078e+00,  3.3549e+00,  4.5315e+00,  3.1638e+00,  5.4306e+00,\n          3.7057e+00, -1.4308e+00,  2.2358e+00, -1.1392e-02,  3.4961e+00,\n         -9.6377e-01,  7.1240e+00,  3.3955e+00,  1.1173e+00, -1.6865e-01,\n         -1.9119e+00,  3.9504e+00,  1.2980e+00, -1.0142e+00, -6.4466e+00,\n         -3.1032e+00, -1.2064e+00, -5.8358e+00,  1.8009e+00, -3.1781e+00,\n          5.4087e+00,  4.8789e-01,  4.6841e-01,  5.2030e-02, -1.8465e+00,\n         -9.6398e-01,  4.3895e+00,  3.1279e+00,  5.4746e+00, -3.7748e+00,\n         -3.0626e+00, -3.5710e+00,  1.1084e+00,  4.5454e+00,  5.5713e+00,\n          1.3069e+00,  6.6044e+00, -1.1555e+00,  3.2650e+00,  6.9474e+00,\n         -1.2877e+00,  6.8903e+00, -2.3081e-01,  6.6623e+00,  9.9367e-01,\n         -4.9298e+00,  2.4711e+00, -3.2580e-01, -8.9766e-01,  5.7896e+00,\n          9.4137e+00,  2.5943e+00,  1.8834e+00, -6.4697e+00,  3.1981e+00,\n          1.6461e+00,  2.5474e+00,  2.4212e+00,  6.9521e+00,  3.4510e+00,\n          3.8111e+00,  2.9744e+00,  4.9423e+00,  5.0445e+00, -1.7492e+00,\n         -5.7826e+00, -1.5824e+00,  4.6078e+00, -4.1538e+00,  2.7816e+00,\n          3.3830e+00,  7.2173e+00,  3.4631e+00,  2.4450e+00,  3.6919e+00,\n          8.8000e+00,  5.3423e+00,  2.0203e+00,  6.6789e+00,  1.4092e+00,\n          1.4269e+00, -2.1634e+00, -2.0876e+00,  1.7341e+00,  3.6732e-01,\n          1.9321e+00, -7.9445e-01,  7.0619e+00, -3.2819e+00, -5.6629e-02,\n          1.2067e+01,  9.1204e-01,  1.7527e+00,  3.2213e+00,  4.4305e+00,\n         -3.8561e+00, -3.3146e+00,  4.1605e+00,  6.9943e+00,  1.0395e+00,\n          3.7653e+00,  3.3252e+00,  1.9399e+00, -2.7591e-01,  5.5286e+00,\n          2.4788e+00,  8.5969e-02,  7.6118e-01,  1.5015e+00, -6.9060e+00,\n          5.0374e+00, -2.7407e+00,  3.2358e+00,  4.3071e+00, -2.3583e+00,\n          5.6596e-01,  7.6425e-01,  5.4026e+00,  6.0811e+00,  7.7165e+00,\n         -5.7526e-01,  5.1290e+00,  2.3950e+00,  2.7768e+00, -1.3696e+00,\n          2.9309e+00,  4.7667e+00,  2.3854e+00,  3.3326e+00, -2.9773e+00,\n          9.2385e+00,  5.0839e+00,  2.1419e+00,  1.2597e+00,  1.6984e+00,\n         -1.6559e+00,  5.1270e+00,  4.0348e-01,  5.4624e+00,  9.7439e+00,\n         -8.8558e-01, -1.0049e-01,  7.1907e-01, -8.0329e-01,  3.0055e+00,\n         -3.7424e+00, -4.7980e+00, -1.9319e+00,  2.2582e+00, -1.0793e+00,\n         -2.0877e+00, -3.5639e-01,  2.3058e+00,  3.6314e+00,  2.0148e+00,\n          1.3358e+01,  9.5600e+00,  4.2099e+00,  7.1232e+00,  6.9850e+00,\n          7.5940e+00,  9.2626e+00,  1.0779e+01, -1.5827e+00,  2.9135e+00,\n          3.0689e+00, -8.0345e-01]], device='cuda:0',\n       grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[38.2304, 56.9824,  0.7298,  1.4834,  1.0159, -2.9090, -0.1443, -2.5456,\n          1.0529,  1.2500,  3.7201,  3.0040, -0.5238, -1.4783, -2.8671,  0.7956,\n         -0.7174,  1.7911,  5.3019,  5.2490,  5.9545,  5.0565,  4.5691,  0.7107,\n          8.5453,  5.7260,  7.4272, 10.8397, -1.1304,  0.8573,  2.6077,  9.1445,\n          5.4167,  1.7856,  1.9908,  3.6948,  0.4298,  3.8921,  4.6178,  6.3963,\n         10.4900,  6.2740,  3.3335,  5.4856,  7.8332,  4.9446,  8.6376,  8.1119,\n          4.8041,  2.4503,  0.7571,  1.0672, -0.9918,  0.8983, -1.7862, -3.0787,\n         -0.1788,  0.9661,  3.7495,  0.3309,  0.6812,  3.6931,  5.6017,  7.0370,\n          0.3379,  3.4244,  4.2885,  3.7242,  1.3697, -0.4718,  2.7450,  0.7299,\n          1.3089,  1.1408, -1.3448,  3.6202,  2.7122, 15.2617,  3.1899,  4.0634,\n         -2.8862,  1.1752,  6.7036,  1.2871,  5.6817, 12.1066,  2.1938,  7.8254,\n          2.9729,  0.3837, -0.2560,  3.8363,  4.0919,  1.5981,  0.6123,  1.6226,\n          3.4006,  6.3210,  6.8668,  6.2195,  3.4699,  4.5950,  4.7941,  4.3288,\n          2.4808,  4.1432, -3.0326,  2.9314, -1.4593,  4.4288, -4.0146,  6.8961,\n          2.4926,  1.2217, -0.4482, -0.1995, -0.7497,  1.4825,  2.0103, -1.3735,\n         -3.2713, -1.8869, -6.3991,  1.9994, -1.9746,  0.8925, -2.0157,  0.3995,\n         -2.2692,  3.0485, -2.5708,  2.1799,  4.9569,  5.1393, -4.5522, -2.8858,\n         -2.0825,  3.3770,  5.3687,  6.2919,  0.6635,  4.7172, -1.5113,  3.7573,\n          5.3646, -0.2824,  8.1033, -2.8317,  4.2456,  3.3466, -3.6650,  2.2697,\n          2.3048,  0.6184,  5.6271,  8.8013,  1.9615,  1.0742, -6.7156,  3.6383,\n         -0.1096, -0.6358,  2.8830,  3.9233,  5.4798,  2.2192,  2.5508,  3.8793,\n          2.8203, -1.6473, -1.2165, -3.8495,  3.4957, -2.1544,  1.5870,  4.0621,\n          4.8375,  1.1934, -0.1393,  3.7385,  9.8075,  1.9732,  1.1680, 10.8339,\n          3.5572,  2.5473, -1.3060, -0.0624,  1.9392,  1.7798,  3.9958, -3.6216,\n          4.6131,  0.8751,  1.1139,  9.6200, -0.5265,  0.6548,  3.4668,  6.7067,\n         -2.4285, -1.0956,  2.1473,  7.2079,  2.0598,  2.6994,  4.0884, -0.5005,\n          2.0834,  5.0795,  5.0424,  1.1558, -0.5279,  3.0487, -3.4985,  2.5111,\n         -1.2265,  2.8799,  2.4858, -0.7757,  0.2037,  0.9630,  1.5973,  8.6726,\n          8.3921,  3.3513,  6.2866,  0.2166,  4.1907, -2.6664,  0.7013,  4.7516,\n          2.0096,  4.3223, -2.6295,  7.3752,  7.7917,  2.8550,  1.6557,  4.2868,\n          0.4206,  3.4810, -0.0784,  4.6689,  6.0689,  1.7527, -3.0666,  4.1369,\n          1.4640,  4.0838, -0.6065, -0.9600, -3.5979,  2.1466, -2.6131, -3.0297,\n         -0.4842,  0.5060,  3.4869,  3.9562, 10.9174,  9.7946,  3.9921,  8.3003,\n          8.4715,  9.1843,  7.0870,  7.7445, -2.8743,  2.5945,  5.3548,  0.3319]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\n\u001b[32m2023-08-14 17:37:34.722\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m592\u001b[0m - \u001b[31m\u001b[1mepoch=4, save to ppo_0813_v1step_4\u001b[0m\n5it [04:16, 53.32s/it]\u001b[32m2023-08-14 17:37:35.599\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 31826, 54840, 54738, 54819, 57996,\n        31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:38:36.931\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910, 54840, 54738, 54819, 57996, 51011, 37051, 31923, 45621, 54542,\n        55399, 55440, 31123, 31701, 32591, 31859, 54738, 57344, 55206, 54777,\n        40194, 54542, 53594, 31155, 49141, 32603, 35598, 31123, 31934, 55353,\n        54840, 54738, 54819, 57996, 31211,    13,    13, 30939, 30930, 30910,\n        34484, 37051, 31211, 32342, 31123, 54687, 33379, 32804, 55346, 54534,\n        51251, 54530, 34771, 54547, 31123, 54724, 31695, 40215, 32715, 34810,\n        37051, 31746, 31901, 48953, 54746, 55925, 58550, 31155, 53297, 32314,\n        57996, 54824, 54534, 41078, 34959, 54563, 37920, 31155,    13,    13,\n        30943, 30930, 30910, 31768, 38514, 57996, 31211, 31793, 33379, 32804,\n        33467, 54542, 33692, 31123, 31768, 32570, 33379, 54738, 57996, 31155,\n        31784, 35560, 54738, 57996, 31779, 54853, 54610, 55888, 57996, 31201,\n        55811, 55123, 57996, 54542, 58063, 55312, 57996, 54609, 31155,    13,\n           13, 30966, 30930, 50085, 57996, 54084, 31211, 54687, 41487, 54738,\n        57996, 52322, 54738, 57996, 54084, 54547, 31123, 54724, 36660, 53844,\n        37051, 33609, 31155, 54708, 54547, 54774, 54578, 31123, 38486, 33936,\n        56487, 54588, 53844, 31123, 54772, 54738, 57996, 34959, 55535, 54666,\n        54534, 54738, 32794, 31155,    13,    13, 30972, 30930, 30910, 56689,\n        55602, 43147, 54530, 57996, 31211, 39596, 31751, 54738, 57996, 54534,\n        37051, 34767, 43147, 54530, 50304, 31123, 46566, 56019, 54901, 53844,\n        33454, 31155,    13,    13, 30970, 30930, 30910, 33682, 35603, 31211,\n        34672, 31665, 33682, 30970, 30941, 30939, 30940, 32074, 31123, 54772,\n        54738, 57996, 32116, 55535, 54666, 54534, 54738, 32794, 31155, 31643,\n        54597, 54625, 32934, 32023, 54738, 57996, 34583, 36743, 54746, 54955,\n        56934, 31155,    13,    13, 30978, 30930, 30910, 35583, 46269, 54679,\n        31211, 54571, 56019, 54901, 53844, 37051, 31123, 40218, 46269, 38863,\n        57996, 31155,    13,    13, 30981, 30930, 30910, 31859, 39577, 34785,\n        31211, 31738, 54575, 57344, 31767, 31680, 32036, 35463, 32496, 31123,\n        32108, 36887, 57996, 32030, 54810, 31636, 55108, 55321, 31767, 31859,\n        31155,    13,    13, 30973, 30930, 30910, 55043, 32748, 55761, 56165,\n        54807, 31211, 57996, 54549, 32059, 31643, 54848, 55709, 31123, 31814,\n        55073, 54687, 54738, 57996, 55043, 32748, 55761, 56165, 54807, 31123,\n        32317, 33057, 54839, 55536, 31155,    13,    13, 31772, 31704, 35598,\n        41230, 55353, 54840, 54738, 54819, 57996, 31861, 31123, 54772, 33379,\n        54799, 54738, 31923, 32824, 31404,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:38:36.938\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 31826, 54840, 54738, 54819, 57996,\n        31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:38:36.944\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910, 54840, 54738, 54819, 57996, 51011, 37051, 31923, 45621, 54542,\n        55399, 55440, 31123, 31701, 32591, 31859, 54738, 57344, 55206, 54777,\n        40194, 54542, 53594, 31155, 49141, 32603, 35598, 31123, 31934, 55353,\n        54840, 54738, 54819, 57996, 31211,    13,    13, 30939, 30930, 30910,\n        34484, 37051, 31211, 32342, 31123, 54687, 33379, 32804, 55346, 54534,\n        51251, 54530, 34771, 54547, 31123, 54724, 31695, 40215, 32715, 34810,\n        37051, 31746, 31901, 48953, 54746, 55925, 58550, 31155, 53297, 32314,\n        57996, 54824, 54534, 41078, 34959, 54563, 37920, 31155,    13,    13,\n        30943, 30930, 30910, 31768, 38514, 57996, 31211, 31793, 33379, 32804,\n        33467, 54542, 33692, 31123, 31768, 32570, 33379, 54738, 57996, 31155,\n        31784, 35560, 54738, 57996, 31779, 54853, 54610, 55888, 57996, 31201,\n        55811, 55123, 57996, 54542, 58063, 55312, 57996, 54609, 31155,    13,\n           13, 30966, 30930, 50085, 57996, 54084, 31211, 54687, 41487, 54738,\n        57996, 52322, 54738, 57996, 54084, 54547, 31123, 54724, 36660, 53844,\n        37051, 33609, 31155, 54708, 54547, 54774, 54578, 31123, 38486, 33936,\n        56487, 54588, 53844, 31123, 54772, 54738, 57996, 34959, 55535, 54666,\n        54534, 54738, 32794, 31155,    13,    13, 30972, 30930, 30910, 56689,\n        55602, 43147, 54530, 57996, 31211, 39596, 31751, 54738, 57996, 54534,\n        37051, 34767, 43147, 54530, 50304, 31123, 46566, 56019, 54901, 53844,\n        33454, 31155,    13,    13, 30970, 30930, 30910, 33682, 35603, 31211,\n        34672, 31665, 33682, 30970, 30941, 30939, 30940, 32074, 31123, 54772,\n        54738, 57996, 32116, 55535, 54666, 54534, 54738, 32794, 31155, 31643,\n        54597, 54625, 32934, 32023, 54738, 57996, 34583, 36743, 54746, 54955,\n        56934, 31155,    13,    13, 30978, 30930, 30910, 35583, 46269, 54679,\n        31211, 54571, 56019, 54901, 53844, 37051, 31123, 40218, 46269, 38863,\n        57996, 31155,    13,    13, 30981, 30930, 30910, 31859, 39577, 34785,\n        31211, 31738, 54575, 57344, 31767, 31680, 32036, 35463, 32496, 31123,\n        32108, 36887, 57996, 32030, 54810, 31636, 55108, 55321, 31767, 31859,\n        31155,    13,    13, 30973, 30930, 30910, 55043, 32748, 55761, 56165,\n        54807, 31211, 57996, 54549, 32059, 31643, 54848, 55709, 31123, 31814,\n        55073, 54687, 54738, 57996, 55043, 32748, 55761, 56165, 54807, 31123,\n        32317, 33057, 54839, 55536, 31155,    13,    13, 31772, 31704, 35598,\n        41230, 55353, 54840, 54738, 54819, 57996, 31861, 31123, 54772, 33379,\n        54799, 54738, 31923, 32824, 31404,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:38:37.444\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 2.6605e+01,  5.3986e+01,  7.5152e-01,  2.0713e+00,  1.8304e+00,\n         2.6391e+00,  1.2024e+00,  2.9708e+00,  6.5492e+00,  4.0342e+00,\n        -4.8950e-01, -3.6201e+00, -3.9936e+00,  1.7076e+00, -2.3662e+00,\n         1.3598e+00,  8.8084e-01,  7.6975e+00,  1.2085e+01,  1.6327e+00,\n         8.4757e-01, -7.2046e-01,  2.3800e+00,  5.8911e+00, -4.1201e-01,\n         5.9736e+00,  2.1856e+00, -9.3973e-01, -1.5342e-01,  5.9528e+00,\n        -7.1501e-01,  8.5345e+00,  3.1891e+00,  1.3959e+00,  5.9376e+00,\n         3.5711e+00,  1.4109e+01, -1.1676e+00,  9.3602e-01,  4.9212e+00,\n         5.0100e+00,  6.1076e+00,  2.6324e+00,  1.2323e+01,  7.7522e+00,\n         4.0461e+00,  7.1399e+00,  1.0286e+01,  3.5768e+00,  7.0323e+00,\n         4.9002e+00,  2.5495e+00,  6.9989e-01, -2.1421e+00, -3.9580e+00,\n         3.8076e+00,  5.7599e-01, -1.5303e+00,  3.1791e+00, -1.4553e+00,\n        -2.4403e-02,  3.6008e-02, -3.9950e+00, -1.4562e+00, -3.4064e+00,\n         9.2728e+00,  4.8399e+00,  5.4005e+00,  4.8520e+00, -2.0168e-01,\n         3.9153e+00,  1.9500e+00,  1.5931e+00,  1.8022e+00,  7.7999e+00,\n         4.5138e+00, -1.7431e+00, -5.1942e+00,  8.2462e+00,  3.6414e+00,\n         5.7672e+00,  4.8564e+00,  3.1612e+00,  1.5094e+00, -3.3428e-01,\n         7.5303e-01,  4.8404e+00,  5.2873e+00,  7.4795e+00,  5.7480e+00,\n         4.1810e+00,  5.2095e+00,  8.3358e+00,  3.9134e+00,  4.6208e+00,\n         3.1490e-01,  4.3448e+00,  1.8357e+00,  2.1586e+00,  3.4755e+00,\n         2.6728e-01,  1.1297e+00,  3.1927e+00,  3.8464e+00,  2.9226e+00,\n         1.1010e+01,  8.3746e+00,  6.2991e+00,  5.6055e+00,  1.5339e+00,\n         9.0541e+00,  2.8482e+00,  8.5947e+00,  5.1554e+00,  9.2839e+00,\n         1.9950e+00,  7.0812e+00,  8.2261e+00,  8.0738e+00,  4.2883e+00,\n         1.1959e+01,  4.9204e+00,  4.9497e+00,  3.2393e+00,  3.4357e+00,\n         8.8393e-01, -1.2339e+00,  5.2634e+00,  7.1604e+00,  1.7078e+00,\n         5.5944e+00,  1.5797e+00,  5.1949e-01,  2.7615e+00,  7.0664e+00,\n        -2.6382e-01, -4.7325e-01,  1.7520e+00,  2.4684e+00, -3.5380e+00,\n         2.2542e+00,  4.6433e+00,  4.1909e+00,  1.3981e+00,  3.7384e+00,\n         6.8089e-01,  2.8675e+00,  7.1043e+00,  6.3632e+00,  1.8509e+00,\n        -1.3301e+00,  2.6423e+00,  2.2856e+00,  8.6674e+00,  1.0982e+01,\n         6.6017e+00,  1.0055e+01,  3.1219e+00, -3.2692e+00,  7.8898e-02,\n        -4.6690e+00,  4.1488e+00, -1.0846e+00,  3.3283e+00,  3.2505e+00,\n        -3.8216e-01,  5.1818e+00,  8.0170e+00,  1.4065e-01,  5.3058e+00,\n         2.2211e+00,  5.6201e+00,  2.5727e+00,  9.5203e+00,  6.5565e+00,\n         3.4104e+00,  5.1752e+00,  4.9533e+00, -1.0087e+00,  1.1050e+00,\n        -4.6184e-01, -1.6206e+00, -1.5070e+00, -2.6219e+00,  4.3811e+00,\n         2.6406e+00,  2.6335e+00,  2.4109e+00,  3.7238e+00, -1.5791e+00,\n         3.6886e+00,  4.1215e+00,  7.5760e-01,  6.6180e+00,  1.7879e+00,\n         7.1983e+00, -2.7670e+00,  3.4622e+00, -9.3652e-01,  2.7110e+00,\n        -2.2284e+00,  2.8318e+00,  2.2001e+00,  1.9241e+00,  6.7191e+00,\n         5.6494e+00,  5.2870e+00,  5.9886e+00,  4.3995e+00, -6.4480e-01,\n         2.9888e-01, -2.5275e+00, -4.5426e-01,  1.8573e-01, -3.2907e+00,\n        -5.3684e+00,  3.9726e+00,  6.8789e+00, -7.7130e-01,  3.1854e+00,\n         3.6860e+00,  5.7389e+00,  3.4128e+00, -1.3124e+00,  1.0284e+01,\n         6.8565e+00,  9.9777e+00,  1.1031e+01,  9.1968e+00,  8.9745e+00,\n         6.2798e+00,  1.1847e+01,  2.7978e+00,  3.2896e+00,  3.6058e+00,\n         4.2630e+00,  3.5239e+00,  2.9946e+00, -1.6477e+00, -8.3324e-01,\n         6.5861e+00,  7.2510e+00,  7.4998e+00,  9.1935e+00,  5.6012e+00,\n         5.2056e+00,  8.4316e-01,  6.2920e+00,  4.8571e+00, -2.8898e+00,\n         1.1858e+00,  1.9300e+00, -1.0829e+00,  2.5917e+00,  3.7895e+00,\n         2.1657e+00, -6.0876e-01,  1.7159e-01,  9.6687e-01,  4.0814e+00,\n         5.9137e+00,  4.8479e+00, -1.5163e+00,  2.1820e+00,  4.9938e+00,\n         3.0739e+00,  3.5655e+00,  3.5634e+00,  3.2564e+00, -3.7021e-01,\n         2.3257e+00,  7.3948e-01,  4.6907e+00,  1.8564e+00,  2.8932e+00,\n        -9.9835e-01,  2.7457e+00,  7.5500e+00,  5.2385e+00,  4.9170e+00,\n         1.2304e+01,  6.2027e+00,  6.1499e+00,  2.0193e+00, -1.0933e+00,\n         3.6916e+00, -2.5891e-01,  5.7300e+00, -1.1022e+00,  2.7228e+00,\n         3.3744e+00,  1.1433e+00,  6.6838e+00,  2.1559e+00,  3.7811e+00,\n         7.0636e+00,  6.0733e+00,  5.1596e+00, -1.8115e-01,  3.7246e+00,\n         1.4924e+00,  3.3994e+00,  1.5545e+00,  4.4362e+00,  3.8269e-01,\n         1.8499e+00,  2.7254e+00, -1.8324e+00,  6.0477e+00,  4.3320e+00,\n         4.7233e+00,  6.9347e+00,  1.1214e+01,  8.0065e-01,  2.9080e-01,\n         9.6343e-01,  5.0656e+00,  1.4009e+00, -4.9688e+00,  5.9504e+00,\n         3.5531e+00,  7.2532e+00,  9.0094e+00,  4.3183e+00, -2.5078e+00,\n         1.9810e+00,  4.5783e+00,  1.3167e+00,  9.3081e-01, -8.9298e-01,\n         4.0498e+00,  3.3400e+00,  3.8387e+00,  4.3923e+00,  4.0384e+00,\n         2.0706e+00,  2.9626e+00,  2.3093e+00,  2.6862e+00,  5.4379e+00,\n         5.0925e+00,  4.7880e+00,  8.1986e-01,  3.1011e+00, -4.8511e+00,\n         1.9092e+00, -2.5017e+00, -1.8623e+00,  1.6488e+00,  3.7013e+00,\n        -4.4935e-01], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:38:37.445\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:38:37.446\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:38:37.454\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 2.6605e+01,  5.3986e+01,  7.5152e-01,  2.0713e+00,  1.8304e+00,\n         2.6391e+00,  1.2024e+00,  2.9708e+00,  6.5492e+00,  4.0342e+00,\n        -4.8950e-01, -3.6201e+00, -3.9936e+00,  1.7076e+00, -2.3662e+00,\n         1.3598e+00,  8.8084e-01,  7.6975e+00,  1.2085e+01,  1.6327e+00,\n         8.4757e-01, -7.2046e-01,  2.3800e+00,  5.8911e+00, -4.1201e-01,\n         5.9736e+00,  2.1856e+00, -9.3973e-01, -1.5342e-01,  5.9528e+00,\n        -7.1501e-01,  8.5345e+00,  3.1891e+00,  1.3959e+00,  5.9376e+00,\n         3.5711e+00,  1.4109e+01, -1.1676e+00,  9.3602e-01,  4.9212e+00,\n         5.0100e+00,  6.1076e+00,  2.6324e+00,  1.2323e+01,  7.7522e+00,\n         4.0461e+00,  7.1399e+00,  1.0286e+01,  3.5768e+00,  7.0323e+00,\n         4.9002e+00,  2.5495e+00,  6.9989e-01, -2.1421e+00, -3.9580e+00,\n         3.8076e+00,  5.7599e-01, -1.5303e+00,  3.1791e+00, -1.4553e+00,\n        -2.4403e-02,  3.6008e-02, -3.9950e+00, -1.4562e+00, -3.4064e+00,\n         9.2728e+00,  4.8399e+00,  5.4005e+00,  4.8520e+00, -2.0168e-01,\n         3.9153e+00,  1.9500e+00,  1.5931e+00,  1.8022e+00,  7.7999e+00,\n         4.5138e+00, -1.7431e+00, -5.1942e+00,  8.2462e+00,  3.6414e+00,\n         5.7672e+00,  4.8564e+00,  3.1612e+00,  1.5094e+00, -3.3428e-01,\n         7.5303e-01,  4.8404e+00,  5.2873e+00,  7.4795e+00,  5.7480e+00,\n         4.1810e+00,  5.2095e+00,  8.3358e+00,  3.9134e+00,  4.6208e+00,\n         3.1490e-01,  4.3448e+00,  1.8357e+00,  2.1586e+00,  3.4755e+00,\n         2.6728e-01,  1.1297e+00,  3.1927e+00,  3.8464e+00,  2.9226e+00,\n         1.1010e+01,  8.3746e+00,  6.2991e+00,  5.6055e+00,  1.5339e+00,\n         9.0541e+00,  2.8482e+00,  8.5947e+00,  5.1554e+00,  9.2839e+00,\n         1.9950e+00,  7.0812e+00,  8.2261e+00,  8.0738e+00,  4.2883e+00,\n         1.1959e+01,  4.9204e+00,  4.9497e+00,  3.2393e+00,  3.4357e+00,\n         8.8393e-01, -1.2339e+00,  5.2634e+00,  7.1604e+00,  1.7078e+00,\n         5.5944e+00,  1.5797e+00,  5.1949e-01,  2.7615e+00,  7.0664e+00,\n        -2.6382e-01, -4.7325e-01,  1.7520e+00,  2.4684e+00, -3.5380e+00,\n         2.2542e+00,  4.6433e+00,  4.1909e+00,  1.3981e+00,  3.7384e+00,\n         6.8089e-01,  2.8675e+00,  7.1043e+00,  6.3632e+00,  1.8509e+00,\n        -1.3301e+00,  2.6423e+00,  2.2856e+00,  8.6674e+00,  1.0982e+01,\n         6.6017e+00,  1.0055e+01,  3.1219e+00, -3.2692e+00,  7.8898e-02,\n        -4.6690e+00,  4.1488e+00, -1.0846e+00,  3.3283e+00,  3.2505e+00,\n        -3.8216e-01,  5.1818e+00,  8.0170e+00,  1.4065e-01,  5.3058e+00,\n         2.2211e+00,  5.6201e+00,  2.5727e+00,  9.5203e+00,  6.5565e+00,\n         3.4104e+00,  5.1752e+00,  4.9533e+00, -1.0087e+00,  1.1050e+00,\n        -4.6184e-01, -1.6206e+00, -1.5070e+00, -2.6219e+00,  4.3811e+00,\n         2.6406e+00,  2.6335e+00,  2.4109e+00,  3.7238e+00, -1.5791e+00,\n         3.6886e+00,  4.1215e+00,  7.5760e-01,  6.6180e+00,  1.7879e+00,\n         7.1983e+00, -2.7670e+00,  3.4622e+00, -9.3652e-01,  2.7110e+00,\n        -2.2284e+00,  2.8318e+00,  2.2001e+00,  1.9241e+00,  6.7191e+00,\n         5.6494e+00,  5.2870e+00,  5.9886e+00,  4.3995e+00, -6.4480e-01,\n         2.9888e-01, -2.5275e+00, -4.5426e-01,  1.8573e-01, -3.2907e+00,\n        -5.3684e+00,  3.9726e+00,  6.8789e+00, -7.7130e-01,  3.1854e+00,\n         3.6860e+00,  5.7389e+00,  3.4128e+00, -1.3124e+00,  1.0284e+01,\n         6.8565e+00,  9.9777e+00,  1.1031e+01,  9.1968e+00,  8.9745e+00,\n         6.2798e+00,  1.1847e+01,  2.7978e+00,  3.2896e+00,  3.6058e+00,\n         4.2630e+00,  3.5239e+00,  2.9946e+00, -1.6477e+00, -8.3324e-01,\n         6.5861e+00,  7.2510e+00,  7.4998e+00,  9.1935e+00,  5.6012e+00,\n         5.2056e+00,  8.4316e-01,  6.2920e+00,  4.8571e+00, -2.8898e+00,\n         1.1858e+00,  1.9300e+00, -1.0829e+00,  2.5917e+00,  3.7895e+00,\n         2.1657e+00, -6.0876e-01,  1.7159e-01,  9.6687e-01,  4.0814e+00,\n         5.9137e+00,  4.8479e+00, -1.5163e+00,  2.1820e+00,  4.9938e+00,\n         3.0739e+00,  3.5655e+00,  3.5634e+00,  3.2564e+00, -3.7021e-01,\n         2.3257e+00,  7.3948e-01,  4.6907e+00,  1.8564e+00,  2.8932e+00,\n        -9.9835e-01,  2.7457e+00,  7.5500e+00,  5.2385e+00,  4.9170e+00,\n         1.2304e+01,  6.2027e+00,  6.1499e+00,  2.0193e+00, -1.0933e+00,\n         3.6916e+00, -2.5891e-01,  5.7300e+00, -1.1022e+00,  2.7228e+00,\n         3.3744e+00,  1.1433e+00,  6.6838e+00,  2.1559e+00,  3.7811e+00,\n         7.0636e+00,  6.0733e+00,  5.1596e+00, -1.8115e-01,  3.7246e+00,\n         1.4924e+00,  3.3994e+00,  1.5545e+00,  4.4362e+00,  3.8269e-01,\n         1.8499e+00,  2.7254e+00, -1.8324e+00,  6.0477e+00,  4.3320e+00,\n         4.7233e+00,  6.9347e+00,  1.1214e+01,  8.0065e-01,  2.9080e-01,\n         9.6343e-01,  5.0656e+00,  1.4009e+00, -4.9688e+00,  5.9504e+00,\n         3.5531e+00,  7.2532e+00,  9.0094e+00,  4.3183e+00, -2.5078e+00,\n         1.9810e+00,  4.5783e+00,  1.3167e+00,  9.3081e-01, -8.9298e-01,\n         4.0498e+00,  3.3400e+00,  3.8387e+00,  4.3923e+00,  4.0384e+00,\n         2.0706e+00,  2.9626e+00,  2.3093e+00,  2.6862e+00,  5.4379e+00,\n         5.0925e+00,  4.7880e+00,  8.1986e-01,  3.1011e+00, -4.8511e+00,\n         1.9092e+00, -2.5017e+00, -1.8623e+00,  1.6488e+00,  3.7013e+00,\n        -4.4935e-01], device='cuda:0')]\u001b[0m\nepoch:  5 \nquery: 问：怎么给车打蜡？\n\n答：\nresponse: 给车打蜡可以使车身更加光滑和亮丽，同时也可以保护车漆免受摩擦和磨损。以下是几个步骤，帮助您给车打蜡：\n\n1. 清洁车身：首先，将您的车辆停在平坦的地面上，并使用适当的工具清理车身上的任何灰尘或污垢。这样可以确保蜡质在车上均匀地分散。\n\n2. 选择合适的蜡：根据您的车辆类型和颜色，选择适合您的车蜡。一些常见的车蜡包括光面镜蜡、缘石蜡和镀银蜡等。\n\n3. 使用蜡海绵：将适量的车蜡倒在车蜡海绵上，并轻轻擦拭车身表面。从上至下，沿着车的纹理擦拭，让车蜡均匀附着在车身上。\n\n4. 擦洗多余的蜡：如果您发现车蜡在车身上有多余的涂抹，可以使用湿布擦拭干净。\n\n5. 等待一段时间：大约需要等待5-10分钟，让车蜡充分附着在车身上。时间过长可能会导致车蜡过于干燥或反拨。\n\n6. 清洗残留物：用湿布擦拭车身，去除残留的车蜡。\n\n7. 保护受损部位：对于新漆或者已经受到损伤的地方，建议在上蜡之前先进行修补或者保护。\n\n8. 存放在阴凉处：蜡会随着时间变硬，因此请将车蜡存放在阴凉处，避免阳光直射。\n\n希望这些步骤可以帮助您给车打蜡成功，让您的爱车更加美丽！\nscore: tensor([ 2.6605e+01,  5.3986e+01,  7.5152e-01,  2.0713e+00,  1.8304e+00,\n         2.6391e+00,  1.2024e+00,  2.9708e+00,  6.5492e+00,  4.0342e+00,\n        -4.8950e-01, -3.6201e+00, -3.9936e+00,  1.7076e+00, -2.3662e+00,\n         1.3598e+00,  8.8084e-01,  7.6975e+00,  1.2085e+01,  1.6327e+00,\n         8.4757e-01, -7.2046e-01,  2.3800e+00,  5.8911e+00, -4.1201e-01,\n         5.9736e+00,  2.1856e+00, -9.3973e-01, -1.5342e-01,  5.9528e+00,\n        -7.1501e-01,  8.5345e+00,  3.1891e+00,  1.3959e+00,  5.9376e+00,\n         3.5711e+00,  1.4109e+01, -1.1676e+00,  9.3602e-01,  4.9212e+00,\n         5.0100e+00,  6.1076e+00,  2.6324e+00,  1.2323e+01,  7.7522e+00,\n         4.0461e+00,  7.1399e+00,  1.0286e+01,  3.5768e+00,  7.0323e+00,\n         4.9002e+00,  2.5495e+00,  6.9989e-01, -2.1421e+00, -3.9580e+00,\n         3.8076e+00,  5.7599e-01, -1.5303e+00,  3.1791e+00, -1.4553e+00,\n        -2.4403e-02,  3.6008e-02, -3.9950e+00, -1.4562e+00, -3.4064e+00,\n         9.2728e+00,  4.8399e+00,  5.4005e+00,  4.8520e+00, -2.0168e-01,\n         3.9153e+00,  1.9500e+00,  1.5931e+00,  1.8022e+00,  7.7999e+00,\n         4.5138e+00, -1.7431e+00, -5.1942e+00,  8.2462e+00,  3.6414e+00,\n         5.7672e+00,  4.8564e+00,  3.1612e+00,  1.5094e+00, -3.3428e-01,\n         7.5303e-01,  4.8404e+00,  5.2873e+00,  7.4795e+00,  5.7480e+00,\n         4.1810e+00,  5.2095e+00,  8.3358e+00,  3.9134e+00,  4.6208e+00,\n         3.1490e-01,  4.3448e+00,  1.8357e+00,  2.1586e+00,  3.4755e+00,\n         2.6728e-01,  1.1297e+00,  3.1927e+00,  3.8464e+00,  2.9226e+00,\n         1.1010e+01,  8.3746e+00,  6.2991e+00,  5.6055e+00,  1.5339e+00,\n         9.0541e+00,  2.8482e+00,  8.5947e+00,  5.1554e+00,  9.2839e+00,\n         1.9950e+00,  7.0812e+00,  8.2261e+00,  8.0738e+00,  4.2883e+00,\n         1.1959e+01,  4.9204e+00,  4.9497e+00,  3.2393e+00,  3.4357e+00,\n         8.8393e-01, -1.2339e+00,  5.2634e+00,  7.1604e+00,  1.7078e+00,\n         5.5944e+00,  1.5797e+00,  5.1949e-01,  2.7615e+00,  7.0664e+00,\n        -2.6382e-01, -4.7325e-01,  1.7520e+00,  2.4684e+00, -3.5380e+00,\n         2.2542e+00,  4.6433e+00,  4.1909e+00,  1.3981e+00,  3.7384e+00,\n         6.8089e-01,  2.8675e+00,  7.1043e+00,  6.3632e+00,  1.8509e+00,\n        -1.3301e+00,  2.6423e+00,  2.2856e+00,  8.6674e+00,  1.0982e+01,\n         6.6017e+00,  1.0055e+01,  3.1219e+00, -3.2692e+00,  7.8898e-02,\n        -4.6690e+00,  4.1488e+00, -1.0846e+00,  3.3283e+00,  3.2505e+00,\n        -3.8216e-01,  5.1818e+00,  8.0170e+00,  1.4065e-01,  5.3058e+00,\n         2.2211e+00,  5.6201e+00,  2.5727e+00,  9.5203e+00,  6.5565e+00,\n         3.4104e+00,  5.1752e+00,  4.9533e+00, -1.0087e+00,  1.1050e+00,\n        -4.6184e-01, -1.6206e+00, -1.5070e+00, -2.6219e+00,  4.3811e+00,\n         2.6406e+00,  2.6335e+00,  2.4109e+00,  3.7238e+00, -1.5791e+00,\n         3.6886e+00,  4.1215e+00,  7.5760e-01,  6.6180e+00,  1.7879e+00,\n         7.1983e+00, -2.7670e+00,  3.4622e+00, -9.3652e-01,  2.7110e+00,\n        -2.2284e+00,  2.8318e+00,  2.2001e+00,  1.9241e+00,  6.7191e+00,\n         5.6494e+00,  5.2870e+00,  5.9886e+00,  4.3995e+00, -6.4480e-01,\n         2.9888e-01, -2.5275e+00, -4.5426e-01,  1.8573e-01, -3.2907e+00,\n        -5.3684e+00,  3.9726e+00,  6.8789e+00, -7.7130e-01,  3.1854e+00,\n         3.6860e+00,  5.7389e+00,  3.4128e+00, -1.3124e+00,  1.0284e+01,\n         6.8565e+00,  9.9777e+00,  1.1031e+01,  9.1968e+00,  8.9745e+00,\n         6.2798e+00,  1.1847e+01,  2.7978e+00,  3.2896e+00,  3.6058e+00,\n         4.2630e+00,  3.5239e+00,  2.9946e+00, -1.6477e+00, -8.3324e-01,\n         6.5861e+00,  7.2510e+00,  7.4998e+00,  9.1935e+00,  5.6012e+00,\n         5.2056e+00,  8.4316e-01,  6.2920e+00,  4.8571e+00, -2.8898e+00,\n         1.1858e+00,  1.9300e+00, -1.0829e+00,  2.5917e+00,  3.7895e+00,\n         2.1657e+00, -6.0876e-01,  1.7159e-01,  9.6687e-01,  4.0814e+00,\n         5.9137e+00,  4.8479e+00, -1.5163e+00,  2.1820e+00,  4.9938e+00,\n         3.0739e+00,  3.5655e+00,  3.5634e+00,  3.2564e+00, -3.7021e-01,\n         2.3257e+00,  7.3948e-01,  4.6907e+00,  1.8564e+00,  2.8932e+00,\n        -9.9835e-01,  2.7457e+00,  7.5500e+00,  5.2385e+00,  4.9170e+00,\n         1.2304e+01,  6.2027e+00,  6.1499e+00,  2.0193e+00, -1.0933e+00,\n         3.6916e+00, -2.5891e-01,  5.7300e+00, -1.1022e+00,  2.7228e+00,\n         3.3744e+00,  1.1433e+00,  6.6838e+00,  2.1559e+00,  3.7811e+00,\n         7.0636e+00,  6.0733e+00,  5.1596e+00, -1.8115e-01,  3.7246e+00,\n         1.4924e+00,  3.3994e+00,  1.5545e+00,  4.4362e+00,  3.8269e-01,\n         1.8499e+00,  2.7254e+00, -1.8324e+00,  6.0477e+00,  4.3320e+00,\n         4.7233e+00,  6.9347e+00,  1.1214e+01,  8.0065e-01,  2.9080e-01,\n         9.6343e-01,  5.0656e+00,  1.4009e+00, -4.9688e+00,  5.9504e+00,\n         3.5531e+00,  7.2532e+00,  9.0094e+00,  4.3183e+00, -2.5078e+00,\n         1.9810e+00,  4.5783e+00,  1.3167e+00,  9.3081e-01, -8.9298e-01,\n         4.0498e+00,  3.3400e+00,  3.8387e+00,  4.3923e+00,  4.0384e+00,\n         2.0706e+00,  2.9626e+00,  2.3093e+00,  2.6862e+00,  5.4379e+00,\n         5.0925e+00,  4.7880e+00,  8.1986e-01,  3.1011e+00, -4.8511e+00,\n         1.9092e+00, -2.5017e+00, -1.8623e+00,  1.6488e+00,  3.7013e+00,\n        -4.4935e-01], device='cuda:0')\n\u001b[32m2023-08-14 17:38:37.462\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:38:37.470\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 2.6605e+01,  5.3986e+01,  7.5152e-01,  2.0713e+00,  1.8304e+00,\n         2.6391e+00,  1.2024e+00,  2.9708e+00,  6.5492e+00,  4.0342e+00,\n        -4.8950e-01, -3.6201e+00, -3.9936e+00,  1.7076e+00, -2.3662e+00,\n         1.3598e+00,  8.8084e-01,  7.6975e+00,  1.2085e+01,  1.6327e+00,\n         8.4757e-01, -7.2046e-01,  2.3800e+00,  5.8911e+00, -4.1201e-01,\n         5.9736e+00,  2.1856e+00, -9.3973e-01, -1.5342e-01,  5.9528e+00,\n        -7.1501e-01,  8.5345e+00,  3.1891e+00,  1.3959e+00,  5.9376e+00,\n         3.5711e+00,  1.4109e+01, -1.1676e+00,  9.3602e-01,  4.9212e+00,\n         5.0100e+00,  6.1076e+00,  2.6324e+00,  1.2323e+01,  7.7522e+00,\n         4.0461e+00,  7.1399e+00,  1.0286e+01,  3.5768e+00,  7.0323e+00,\n         4.9002e+00,  2.5495e+00,  6.9989e-01, -2.1421e+00, -3.9580e+00,\n         3.8076e+00,  5.7599e-01, -1.5303e+00,  3.1791e+00, -1.4553e+00,\n        -2.4403e-02,  3.6008e-02, -3.9950e+00, -1.4562e+00, -3.4064e+00,\n         9.2728e+00,  4.8399e+00,  5.4005e+00,  4.8520e+00, -2.0168e-01,\n         3.9153e+00,  1.9500e+00,  1.5931e+00,  1.8022e+00,  7.7999e+00,\n         4.5138e+00, -1.7431e+00, -5.1942e+00,  8.2462e+00,  3.6414e+00,\n         5.7672e+00,  4.8564e+00,  3.1612e+00,  1.5094e+00, -3.3428e-01,\n         7.5303e-01,  4.8404e+00,  5.2873e+00,  7.4795e+00,  5.7480e+00,\n         4.1810e+00,  5.2095e+00,  8.3358e+00,  3.9134e+00,  4.6208e+00,\n         3.1490e-01,  4.3448e+00,  1.8357e+00,  2.1586e+00,  3.4755e+00,\n         2.6728e-01,  1.1297e+00,  3.1927e+00,  3.8464e+00,  2.9226e+00,\n         1.1010e+01,  8.3746e+00,  6.2991e+00,  5.6055e+00,  1.5339e+00,\n         9.0541e+00,  2.8482e+00,  8.5947e+00,  5.1554e+00,  9.2839e+00,\n         1.9950e+00,  7.0812e+00,  8.2261e+00,  8.0738e+00,  4.2883e+00,\n         1.1959e+01,  4.9204e+00,  4.9497e+00,  3.2393e+00,  3.4357e+00,\n         8.8393e-01, -1.2339e+00,  5.2634e+00,  7.1604e+00,  1.7078e+00,\n         5.5944e+00,  1.5797e+00,  5.1949e-01,  2.7615e+00,  7.0664e+00,\n        -2.6382e-01, -4.7325e-01,  1.7520e+00,  2.4684e+00, -3.5380e+00,\n         2.2542e+00,  4.6433e+00,  4.1909e+00,  1.3981e+00,  3.7384e+00,\n         6.8089e-01,  2.8675e+00,  7.1043e+00,  6.3632e+00,  1.8509e+00,\n        -1.3301e+00,  2.6423e+00,  2.2856e+00,  8.6674e+00,  1.0982e+01,\n         6.6017e+00,  1.0055e+01,  3.1219e+00, -3.2692e+00,  7.8898e-02,\n        -4.6690e+00,  4.1488e+00, -1.0846e+00,  3.3283e+00,  3.2505e+00,\n        -3.8216e-01,  5.1818e+00,  8.0170e+00,  1.4065e-01,  5.3058e+00,\n         2.2211e+00,  5.6201e+00,  2.5727e+00,  9.5203e+00,  6.5565e+00,\n         3.4104e+00,  5.1752e+00,  4.9533e+00, -1.0087e+00,  1.1050e+00,\n        -4.6184e-01, -1.6206e+00, -1.5070e+00, -2.6219e+00,  4.3811e+00,\n         2.6406e+00,  2.6335e+00,  2.4109e+00,  3.7238e+00, -1.5791e+00,\n         3.6886e+00,  4.1215e+00,  7.5760e-01,  6.6180e+00,  1.7879e+00,\n         7.1983e+00, -2.7670e+00,  3.4622e+00, -9.3652e-01,  2.7110e+00,\n        -2.2284e+00,  2.8318e+00,  2.2001e+00,  1.9241e+00,  6.7191e+00,\n         5.6494e+00,  5.2870e+00,  5.9886e+00,  4.3995e+00, -6.4480e-01,\n         2.9888e-01, -2.5275e+00, -4.5426e-01,  1.8573e-01, -3.2907e+00,\n        -5.3684e+00,  3.9726e+00,  6.8789e+00, -7.7130e-01,  3.1854e+00,\n         3.6860e+00,  5.7389e+00,  3.4128e+00, -1.3124e+00,  1.0284e+01,\n         6.8565e+00,  9.9777e+00,  1.1031e+01,  9.1968e+00,  8.9745e+00,\n         6.2798e+00,  1.1847e+01,  2.7978e+00,  3.2896e+00,  3.6058e+00,\n         4.2630e+00,  3.5239e+00,  2.9946e+00, -1.6477e+00, -8.3324e-01,\n         6.5861e+00,  7.2510e+00,  7.4998e+00,  9.1935e+00,  5.6012e+00,\n         5.2056e+00,  8.4316e-01,  6.2920e+00,  4.8571e+00, -2.8898e+00,\n         1.1858e+00,  1.9300e+00, -1.0829e+00,  2.5917e+00,  3.7895e+00,\n         2.1657e+00, -6.0876e-01,  1.7159e-01,  9.6687e-01,  4.0814e+00,\n         5.9137e+00,  4.8479e+00, -1.5163e+00,  2.1820e+00,  4.9938e+00,\n         3.0739e+00,  3.5655e+00,  3.5634e+00,  3.2564e+00, -3.7021e-01,\n         2.3257e+00,  7.3948e-01,  4.6907e+00,  1.8564e+00,  2.8932e+00,\n        -9.9835e-01,  2.7457e+00,  7.5500e+00,  5.2385e+00,  4.9170e+00,\n         1.2304e+01,  6.2027e+00,  6.1499e+00,  2.0193e+00, -1.0933e+00,\n         3.6916e+00, -2.5891e-01,  5.7300e+00, -1.1022e+00,  2.7228e+00,\n         3.3744e+00,  1.1433e+00,  6.6838e+00,  2.1559e+00,  3.7811e+00,\n         7.0636e+00,  6.0733e+00,  5.1596e+00, -1.8115e-01,  3.7246e+00,\n         1.4924e+00,  3.3994e+00,  1.5545e+00,  4.4362e+00,  3.8269e-01,\n         1.8499e+00,  2.7254e+00, -1.8324e+00,  6.0477e+00,  4.3320e+00,\n         4.7233e+00,  6.9347e+00,  1.1214e+01,  8.0065e-01,  2.9080e-01,\n         9.6343e-01,  5.0656e+00,  1.4009e+00, -4.9688e+00,  5.9504e+00,\n         3.5531e+00,  7.2532e+00,  9.0094e+00,  4.3183e+00, -2.5078e+00,\n         1.9810e+00,  4.5783e+00,  1.3167e+00,  9.3081e-01, -8.9298e-01,\n         4.0498e+00,  3.3400e+00,  3.8387e+00,  4.3923e+00,  4.0384e+00,\n         2.0706e+00,  2.9626e+00,  2.3093e+00,  2.6862e+00,  5.4379e+00,\n         5.0925e+00,  4.7880e+00,  8.1986e-01,  3.1011e+00, -4.8511e+00,\n         1.9092e+00, -2.5017e+00, -1.8623e+00,  1.6488e+00,  3.7013e+00,\n        -4.4935e-01], device='cuda:0')]\u001b[0m\nscores=[tensor([ 2.6605e+01,  5.3986e+01,  7.5152e-01,  2.0713e+00,  1.8304e+00,\n         2.6391e+00,  1.2024e+00,  2.9708e+00,  6.5492e+00,  4.0342e+00,\n        -4.8950e-01, -3.6201e+00, -3.9936e+00,  1.7076e+00, -2.3662e+00,\n         1.3598e+00,  8.8084e-01,  7.6975e+00,  1.2085e+01,  1.6327e+00,\n         8.4757e-01, -7.2046e-01,  2.3800e+00,  5.8911e+00, -4.1201e-01,\n         5.9736e+00,  2.1856e+00, -9.3973e-01, -1.5342e-01,  5.9528e+00,\n        -7.1501e-01,  8.5345e+00,  3.1891e+00,  1.3959e+00,  5.9376e+00,\n         3.5711e+00,  1.4109e+01, -1.1676e+00,  9.3602e-01,  4.9212e+00,\n         5.0100e+00,  6.1076e+00,  2.6324e+00,  1.2323e+01,  7.7522e+00,\n         4.0461e+00,  7.1399e+00,  1.0286e+01,  3.5768e+00,  7.0323e+00,\n         4.9002e+00,  2.5495e+00,  6.9989e-01, -2.1421e+00, -3.9580e+00,\n         3.8076e+00,  5.7599e-01, -1.5303e+00,  3.1791e+00, -1.4553e+00,\n        -2.4403e-02,  3.6008e-02, -3.9950e+00, -1.4562e+00, -3.4064e+00,\n         9.2728e+00,  4.8399e+00,  5.4005e+00,  4.8520e+00, -2.0168e-01,\n         3.9153e+00,  1.9500e+00,  1.5931e+00,  1.8022e+00,  7.7999e+00,\n         4.5138e+00, -1.7431e+00, -5.1942e+00,  8.2462e+00,  3.6414e+00,\n         5.7672e+00,  4.8564e+00,  3.1612e+00,  1.5094e+00, -3.3428e-01,\n         7.5303e-01,  4.8404e+00,  5.2873e+00,  7.4795e+00,  5.7480e+00,\n         4.1810e+00,  5.2095e+00,  8.3358e+00,  3.9134e+00,  4.6208e+00,\n         3.1490e-01,  4.3448e+00,  1.8357e+00,  2.1586e+00,  3.4755e+00,\n         2.6728e-01,  1.1297e+00,  3.1927e+00,  3.8464e+00,  2.9226e+00,\n         1.1010e+01,  8.3746e+00,  6.2991e+00,  5.6055e+00,  1.5339e+00,\n         9.0541e+00,  2.8482e+00,  8.5947e+00,  5.1554e+00,  9.2839e+00,\n         1.9950e+00,  7.0812e+00,  8.2261e+00,  8.0738e+00,  4.2883e+00,\n         1.1959e+01,  4.9204e+00,  4.9497e+00,  3.2393e+00,  3.4357e+00,\n         8.8393e-01, -1.2339e+00,  5.2634e+00,  7.1604e+00,  1.7078e+00,\n         5.5944e+00,  1.5797e+00,  5.1949e-01,  2.7615e+00,  7.0664e+00,\n        -2.6382e-01, -4.7325e-01,  1.7520e+00,  2.4684e+00, -3.5380e+00,\n         2.2542e+00,  4.6433e+00,  4.1909e+00,  1.3981e+00,  3.7384e+00,\n         6.8089e-01,  2.8675e+00,  7.1043e+00,  6.3632e+00,  1.8509e+00,\n        -1.3301e+00,  2.6423e+00,  2.2856e+00,  8.6674e+00,  1.0982e+01,\n         6.6017e+00,  1.0055e+01,  3.1219e+00, -3.2692e+00,  7.8898e-02,\n        -4.6690e+00,  4.1488e+00, -1.0846e+00,  3.3283e+00,  3.2505e+00,\n        -3.8216e-01,  5.1818e+00,  8.0170e+00,  1.4065e-01,  5.3058e+00,\n         2.2211e+00,  5.6201e+00,  2.5727e+00,  9.5203e+00,  6.5565e+00,\n         3.4104e+00,  5.1752e+00,  4.9533e+00, -1.0087e+00,  1.1050e+00,\n        -4.6184e-01, -1.6206e+00, -1.5070e+00, -2.6219e+00,  4.3811e+00,\n         2.6406e+00,  2.6335e+00,  2.4109e+00,  3.7238e+00, -1.5791e+00,\n         3.6886e+00,  4.1215e+00,  7.5760e-01,  6.6180e+00,  1.7879e+00,\n         7.1983e+00, -2.7670e+00,  3.4622e+00, -9.3652e-01,  2.7110e+00,\n        -2.2284e+00,  2.8318e+00,  2.2001e+00,  1.9241e+00,  6.7191e+00,\n         5.6494e+00,  5.2870e+00,  5.9886e+00,  4.3995e+00, -6.4480e-01,\n         2.9888e-01, -2.5275e+00, -4.5426e-01,  1.8573e-01, -3.2907e+00,\n        -5.3684e+00,  3.9726e+00,  6.8789e+00, -7.7130e-01,  3.1854e+00,\n         3.6860e+00,  5.7389e+00,  3.4128e+00, -1.3124e+00,  1.0284e+01,\n         6.8565e+00,  9.9777e+00,  1.1031e+01,  9.1968e+00,  8.9745e+00,\n         6.2798e+00,  1.1847e+01,  2.7978e+00,  3.2896e+00,  3.6058e+00,\n         4.2630e+00,  3.5239e+00,  2.9946e+00, -1.6477e+00, -8.3324e-01,\n         6.5861e+00,  7.2510e+00,  7.4998e+00,  9.1935e+00,  5.6012e+00,\n         5.2056e+00,  8.4316e-01,  6.2920e+00,  4.8571e+00, -2.8898e+00,\n         1.1858e+00,  1.9300e+00, -1.0829e+00,  2.5917e+00,  3.7895e+00,\n         2.1657e+00, -6.0876e-01,  1.7159e-01,  9.6687e-01,  4.0814e+00,\n         5.9137e+00,  4.8479e+00, -1.5163e+00,  2.1820e+00,  4.9938e+00,\n         3.0739e+00,  3.5655e+00,  3.5634e+00,  3.2564e+00, -3.7021e-01,\n         2.3257e+00,  7.3948e-01,  4.6907e+00,  1.8564e+00,  2.8932e+00,\n        -9.9835e-01,  2.7457e+00,  7.5500e+00,  5.2385e+00,  4.9170e+00,\n         1.2304e+01,  6.2027e+00,  6.1499e+00,  2.0193e+00, -1.0933e+00,\n         3.6916e+00, -2.5891e-01,  5.7300e+00, -1.1022e+00,  2.7228e+00,\n         3.3744e+00,  1.1433e+00,  6.6838e+00,  2.1559e+00,  3.7811e+00,\n         7.0636e+00,  6.0733e+00,  5.1596e+00, -1.8115e-01,  3.7246e+00,\n         1.4924e+00,  3.3994e+00,  1.5545e+00,  4.4362e+00,  3.8269e-01,\n         1.8499e+00,  2.7254e+00, -1.8324e+00,  6.0477e+00,  4.3320e+00,\n         4.7233e+00,  6.9347e+00,  1.1214e+01,  8.0065e-01,  2.9080e-01,\n         9.6343e-01,  5.0656e+00,  1.4009e+00, -4.9688e+00,  5.9504e+00,\n         3.5531e+00,  7.2532e+00,  9.0094e+00,  4.3183e+00, -2.5078e+00,\n         1.9810e+00,  4.5783e+00,  1.3167e+00,  9.3081e-01, -8.9298e-01,\n         4.0498e+00,  3.3400e+00,  3.8387e+00,  4.3923e+00,  4.0384e+00,\n         2.0706e+00,  2.9626e+00,  2.3093e+00,  2.6862e+00,  5.4379e+00,\n         5.0925e+00,  4.7880e+00,  8.1986e-01,  3.1011e+00, -4.8511e+00,\n         1.9092e+00, -2.5017e+00, -1.8623e+00,  1.6488e+00,  3.7013e+00,\n        -4.4935e-01], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 3.0261e+01,  5.7666e+01,  4.2751e-01,  1.6412e+00,  1.5972e+00,\n          2.6384e+00,  7.9681e-01,  1.2967e+00,  7.2943e+00,  2.7551e+00,\n         -1.2407e+00, -4.7604e+00, -4.2684e+00,  1.2183e+00, -2.7984e+00,\n          1.7375e+00,  2.1055e+00,  8.5035e+00,  1.0226e+01, -2.4346e-01,\n         -1.7894e+00,  1.6455e+00,  3.5687e+00,  5.9907e+00,  2.3851e+00,\n          4.6262e+00,  3.7011e+00,  1.7150e+00,  9.5704e-01,  4.1898e+00,\n         -3.0040e-01,  7.0047e+00,  4.7084e+00,  1.5708e+00,  5.5313e+00,\n          3.3815e+00,  1.2596e+01, -2.1094e+00, -1.1637e+00,  1.5690e+00,\n          2.4150e+00,  7.0677e+00, -1.7674e-01,  9.0766e+00,  5.9436e+00,\n          3.7654e+00,  5.2096e+00,  7.5006e+00,  1.3913e+00,  8.0426e+00,\n          4.2156e+00, -8.9940e-02,  2.2900e+00, -1.6707e+00, -4.7205e-01,\n          3.1203e+00,  9.5309e-01,  9.1699e-01,  3.5204e+00, -2.8942e-01,\n         -9.9594e-01, -5.6438e-01, -2.6120e+00,  1.8984e+00, -1.8862e+00,\n          7.9105e+00,  6.8871e+00,  5.1955e+00,  3.4148e+00,  2.1042e+00,\n          4.0993e+00,  1.2007e+00,  1.9686e+00,  2.1779e+00,  6.9273e+00,\n          3.1681e+00, -1.3705e+00, -1.8857e+00,  8.5836e+00,  9.4816e-01,\n          5.4762e+00,  5.2534e+00,  3.5250e+00,  1.9360e+00, -1.5608e+00,\n         -6.0914e-01,  1.7610e+00,  7.1072e+00,  6.7677e+00,  8.3514e+00,\n          4.2607e+00,  2.5268e-01,  1.0714e+01,  2.8934e+00,  5.7842e+00,\n          1.7019e+00,  3.0510e+00,  2.0776e+00,  2.7775e-02,  3.2095e+00,\n          1.5058e+00, -1.3861e+00,  2.7820e+00,  1.7700e+00,  4.2378e+00,\n          9.0171e+00,  1.0388e+01,  6.3361e+00,  7.8293e+00,  1.6418e+00,\n          6.6543e+00,  3.2497e+00,  8.4218e+00,  6.2089e+00,  7.5245e+00,\n          2.9133e+00,  6.7523e+00,  7.7626e+00,  7.4321e+00,  4.8315e+00,\n          1.2285e+01,  2.3772e+00,  2.4378e+00,  2.0356e+00,  5.0501e+00,\n          1.4386e-01, -1.4895e+00,  4.4107e+00,  5.5469e+00,  6.7164e-01,\n          6.6201e+00,  3.4655e+00,  2.1798e+00,  3.6287e+00,  5.7205e+00,\n          4.5196e-01, -2.8733e-01,  3.1144e+00,  1.4053e+00, -4.9007e+00,\n          2.2715e+00,  3.9332e+00,  3.8421e+00,  2.6357e+00,  5.8422e+00,\n          2.3535e+00,  2.4762e+00,  7.7067e+00,  4.6468e+00,  2.8979e-02,\n         -6.5435e-01,  1.6774e+00,  1.5561e+00,  8.5615e+00,  1.2378e+01,\n          8.4774e+00,  9.1648e+00,  2.9822e+00, -4.4503e+00, -2.4427e+00,\n         -2.9692e+00,  3.3268e+00, -5.5529e-01,  2.8297e+00,  3.4080e+00,\n          9.8917e-02,  3.8128e+00,  7.4124e+00,  1.7319e-01,  4.5349e+00,\n          2.5192e+00,  7.2964e+00,  1.6929e+00,  1.1267e+01,  9.7159e+00,\n          3.7286e+00,  3.2510e+00,  6.4378e+00,  2.6001e-01,  2.0961e+00,\n          3.3990e+00, -5.5999e-01, -1.6466e+00, -1.4806e+00,  4.9935e+00,\n         -9.4876e-02,  2.1658e+00,  3.4844e+00,  3.7333e+00, -1.4450e-01,\n          3.3197e+00,  4.2284e+00, -3.6410e+00,  5.0544e+00,  1.4450e-01,\n          6.2319e+00, -2.9234e+00,  1.0302e+00, -3.5831e-01,  4.3235e+00,\n         -1.3757e+00,  1.7467e+00,  3.9999e+00,  2.4226e+00,  6.8224e+00,\n          7.4788e+00,  3.2792e+00,  4.3720e+00,  5.2853e+00, -1.1789e+00,\n         -5.8924e-01, -1.8529e+00, -5.0650e-02, -1.5257e-01, -1.9593e+00,\n         -4.7324e+00,  2.3426e+00,  4.3229e+00, -1.0073e+00,  5.3883e+00,\n          3.6306e+00,  7.8462e+00,  2.4429e+00, -1.1139e+00,  8.2455e+00,\n          5.3583e+00,  5.8478e+00,  1.1352e+01,  9.3074e+00,  1.0150e+01,\n          6.5422e+00,  1.1994e+01,  3.1127e+00,  4.0826e+00,  4.5070e+00,\n          7.7312e+00,  3.8579e+00,  3.6382e+00, -7.3850e-01,  2.4722e-01,\n          6.9961e+00,  7.2140e+00,  7.6781e+00,  4.7728e+00,  2.8447e+00,\n          6.1989e+00,  1.8172e+00,  9.2950e+00,  4.1671e+00, -7.3157e-01,\n          2.6462e+00,  6.6519e-01, -7.0985e-01,  3.8207e+00,  2.2817e+00,\n          2.7818e+00, -1.2359e+00,  5.2062e-01,  2.2610e+00,  6.7024e+00,\n          4.6466e+00,  5.4080e+00, -2.0768e+00,  5.5209e+00,  4.9869e+00,\n          1.3460e+00,  4.1768e+00,  2.9664e+00,  9.1345e-01, -1.3124e+00,\n         -2.6745e+00,  1.6441e+00,  7.8899e+00,  2.9101e+00,  1.5937e-03,\n          2.1855e+00,  9.0536e+00,  5.9566e+00,  4.7862e+00,  6.8594e+00,\n          1.1048e+01,  6.9421e+00,  6.5260e+00,  1.0577e+00,  1.8585e+00,\n         -7.7781e-01, -1.0452e+00,  4.7871e+00, -6.9273e-01,  5.4553e+00,\n          5.0882e+00,  2.0439e+00,  6.0880e+00,  1.7833e-02,  3.3173e+00,\n          6.9492e+00,  6.4957e+00,  5.8412e+00, -1.0937e+00,  2.0647e+00,\n          1.5778e-01,  1.4029e+00,  4.7958e-01,  5.1547e+00,  5.6186e-01,\n         -2.0539e-01,  1.8089e+00,  2.6253e+00,  4.2875e+00,  6.2891e+00,\n          4.8023e+00,  9.0826e+00,  1.0499e+01, -8.4024e-01,  1.6319e+00,\n         -9.7937e-02,  3.8483e+00,  3.9541e+00, -4.1724e+00,  3.2369e+00,\n          3.0057e+00,  6.8300e+00,  7.5394e+00,  4.9226e+00, -5.1708e-01,\n          5.3000e+00,  2.7944e+00,  4.5264e-02,  1.8250e+00,  3.4532e-01,\n          3.7392e+00,  5.8034e+00,  4.1251e+00,  2.1825e+00,  2.5427e-01,\n          2.1943e+00,  3.3911e+00,  3.3549e+00,  3.4427e+00,  6.6441e+00,\n          4.8178e+00,  4.5964e+00, -1.2513e-01,  2.6237e+00, -3.0808e+00,\n          5.0979e+00, -4.7558e+00, -2.1844e+00,  8.3043e-01,  3.7959e+00,\n         -5.2567e-01]], device='cuda:0')\nvalues_994 = tensor([[36.8596, 42.9152,  0.9732,  2.3672,  1.9035,  3.1949, -0.3744,  1.6703,\n          8.1828,  3.3450,  0.3756, -3.5903, -6.8444,  1.4890, -2.9211,  0.8833,\n          4.6664,  9.0203,  7.4173,  3.2953, -2.2690,  0.4159,  5.4684,  5.4167,\n          2.5128,  6.7322,  2.8237,  1.1878, -0.6320,  3.3758, -1.9206,  7.5480,\n          6.5411,  0.5858,  6.3674,  4.0220, 13.4735, -2.8748, -1.3438,  4.4400,\n          2.3758,  4.8687,  0.6581,  9.6953,  7.4940,  6.3276,  4.6612,  8.0763,\n          1.7521,  7.4367,  1.9505,  3.8744,  0.9207, -0.9053,  0.1313,  2.0735,\n          1.5564, -1.2594,  3.0032, -1.6295, -1.5507,  2.3690, -1.2521,  0.6144,\n         -1.3740,  6.4587,  4.4867,  7.6593,  3.3734,  2.0700,  5.1704,  2.1636,\n          2.5178,  1.0852,  4.9159,  2.1931, -0.7434, -3.4561,  6.2022,  0.1114,\n          3.4832,  3.6259,  4.0701,  1.1791, -2.2728,  1.0955,  3.4808,  8.4288,\n          4.8549,  6.1765,  4.3502,  1.8562, 11.7562,  2.7619,  7.6594, -0.3935,\n         -0.6814,  1.7202,  0.7647,  1.2682,  1.2955,  0.7317,  3.0999,  5.3894,\n          0.5052, 10.4698,  4.7386,  5.5998,  9.4586,  3.6953,  6.5900,  3.8805,\n          8.1755,  4.2121,  9.0062,  2.6589,  4.3949,  5.7035,  7.5282,  1.1321,\n         13.2315,  5.3808,  2.2881,  2.7670,  3.7003,  1.1802,  1.3164,  4.4660,\n          5.6328,  3.2206,  3.6373,  2.8720,  1.1772,  3.2290,  6.5987, -0.5405,\n         -0.0981,  6.1510,  1.0303, -2.5555,  1.5735,  2.5580,  4.3350,  2.9186,\n          4.3995,  3.4557,  0.7885,  4.5975,  2.2075,  1.7287, -0.5532, -0.9243,\n          1.3500,  7.5804, 13.4406,  7.2625,  8.8961,  3.3610, -2.0172, -1.3182,\n         -0.9093,  4.4527,  0.7632,  2.6663,  3.1855,  0.1111,  6.3490,  4.4849,\n          0.7559,  7.5795,  3.4159,  5.9015,  3.2572,  8.7604,  6.4622,  2.1023,\n          4.1406,  5.0847, -0.8234,  2.1625,  4.2779, -2.5249, -1.9354, -1.5989,\n          6.9951,  1.7418,  1.4824,  4.4032,  4.3156,  1.6958,  2.1059,  3.2851,\n         -0.6404,  5.3288,  2.2263,  5.9765, -3.3880,  2.0039,  0.8576,  3.8562,\n         -1.2844,  2.3325,  0.4072,  1.4819,  9.0446,  7.1815,  6.8543,  3.9746,\n          4.7682, -2.7672,  1.9547, -2.7942,  2.3143,  1.5139, -1.3434, -7.2390,\n          0.9175,  5.6672, -1.5091,  5.5179,  2.5101,  6.4336,  2.8855, -0.9285,\n         11.6215,  8.4364,  8.6636, 13.3932, 10.6441,  8.0791,  4.6683, 13.0227,\n          2.7423,  3.1695,  2.4477,  4.2210,  3.6237,  3.7658,  0.2367,  2.5441,\n          6.0024,  4.8251,  8.0419,  3.5476,  4.0440,  5.0943,  0.0689,  6.4778,\n          6.9696,  0.6020,  1.9805,  1.0211, -1.9291, -0.5575,  2.8907,  3.5780,\n         -0.8129,  0.7533, -1.0862,  3.0033,  7.0135,  4.0554, -1.1160,  7.8704,\n          4.2522,  1.4347,  2.3589,  4.1993,  2.6976,  0.2221,  2.5114,  0.5591,\n          1.6747,  1.3880,  0.6674,  1.5073,  6.8644,  7.8880,  5.4107,  6.7295,\n         10.8403,  8.6014,  5.9925,  4.2999,  2.2514,  1.0767,  1.1872,  4.8351,\n         -1.9707,  5.1224,  5.4317,  0.0730,  7.3669,  2.5099,  6.6903,  6.2430,\n          5.3260,  6.7716, -2.8378,  1.9547,  2.0030,  3.7690, -0.1865,  3.8068,\n         -0.5927,  0.1996,  2.4161,  2.9730,  4.4243,  4.7516,  3.6960,  8.2000,\n         10.7438,  1.7962,  1.9591,  0.3151,  6.9792,  1.5148, -2.2919,  4.2096,\n          3.3025,  6.5653,  8.7631,  5.5423, -3.7812,  1.5815,  1.8063,  1.7641,\n          4.0429,  1.1273,  1.9262,  3.1539,  4.0162,  2.5717,  0.5819,  3.3551,\n          4.0292,  5.0565,  3.7455,  4.6548,  4.7820,  5.3033, -0.1506,  3.1764,\n         -2.1812,  1.7506, -4.5156, -2.7452,  1.6799,  3.3683, -1.0588]],\n       device='cuda:0')\nreward[last_non_masked_index]=tensor([-0.], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 2.6605e+01,  5.3986e+01,  7.5152e-01,  2.0713e+00,  1.8304e+00,\n         2.6391e+00,  1.2024e+00,  2.9708e+00,  6.5492e+00,  4.0342e+00,\n        -4.8950e-01, -3.6201e+00, -3.9936e+00,  1.7076e+00, -2.3662e+00,\n         1.3598e+00,  8.8084e-01,  7.6975e+00,  1.2085e+01,  1.6327e+00,\n         8.4757e-01, -7.2046e-01,  2.3800e+00,  5.8911e+00, -4.1201e-01,\n         5.9736e+00,  2.1856e+00, -9.3973e-01, -1.5342e-01,  5.9528e+00,\n        -7.1501e-01,  8.5345e+00,  3.1891e+00,  1.3959e+00,  5.9376e+00,\n         3.5711e+00,  1.4109e+01, -1.1676e+00,  9.3602e-01,  4.9212e+00,\n         5.0100e+00,  6.1076e+00,  2.6324e+00,  1.2323e+01,  7.7522e+00,\n         4.0461e+00,  7.1399e+00,  1.0286e+01,  3.5768e+00,  7.0323e+00,\n         4.9002e+00,  2.5495e+00,  6.9989e-01, -2.1421e+00, -3.9580e+00,\n         3.8076e+00,  5.7599e-01, -1.5303e+00,  3.1791e+00, -1.4553e+00,\n        -2.4403e-02,  3.6008e-02, -3.9950e+00, -1.4562e+00, -3.4064e+00,\n         9.2728e+00,  4.8399e+00,  5.4005e+00,  4.8520e+00, -2.0168e-01,\n         3.9153e+00,  1.9500e+00,  1.5931e+00,  1.8022e+00,  7.7999e+00,\n         4.5138e+00, -1.7431e+00, -5.1942e+00,  8.2462e+00,  3.6414e+00,\n         5.7672e+00,  4.8564e+00,  3.1612e+00,  1.5094e+00, -3.3428e-01,\n         7.5303e-01,  4.8404e+00,  5.2873e+00,  7.4795e+00,  5.7480e+00,\n         4.1810e+00,  5.2095e+00,  8.3358e+00,  3.9134e+00,  4.6208e+00,\n         3.1490e-01,  4.3448e+00,  1.8357e+00,  2.1586e+00,  3.4755e+00,\n         2.6728e-01,  1.1297e+00,  3.1927e+00,  3.8464e+00,  2.9226e+00,\n         1.1010e+01,  8.3746e+00,  6.2991e+00,  5.6055e+00,  1.5339e+00,\n         9.0541e+00,  2.8482e+00,  8.5947e+00,  5.1554e+00,  9.2839e+00,\n         1.9950e+00,  7.0812e+00,  8.2261e+00,  8.0738e+00,  4.2883e+00,\n         1.1959e+01,  4.9204e+00,  4.9497e+00,  3.2393e+00,  3.4357e+00,\n         8.8393e-01, -1.2339e+00,  5.2634e+00,  7.1604e+00,  1.7078e+00,\n         5.5944e+00,  1.5797e+00,  5.1949e-01,  2.7615e+00,  7.0664e+00,\n        -2.6382e-01, -4.7325e-01,  1.7520e+00,  2.4684e+00, -3.5380e+00,\n         2.2542e+00,  4.6433e+00,  4.1909e+00,  1.3981e+00,  3.7384e+00,\n         6.8089e-01,  2.8675e+00,  7.1043e+00,  6.3632e+00,  1.8509e+00,\n        -1.3301e+00,  2.6423e+00,  2.2856e+00,  8.6674e+00,  1.0982e+01,\n         6.6017e+00,  1.0055e+01,  3.1219e+00, -3.2692e+00,  7.8898e-02,\n        -4.6690e+00,  4.1488e+00, -1.0846e+00,  3.3283e+00,  3.2505e+00,\n        -3.8216e-01,  5.1818e+00,  8.0170e+00,  1.4065e-01,  5.3058e+00,\n         2.2211e+00,  5.6201e+00,  2.5727e+00,  9.5203e+00,  6.5565e+00,\n         3.4104e+00,  5.1752e+00,  4.9533e+00, -1.0087e+00,  1.1050e+00,\n        -4.6184e-01, -1.6206e+00, -1.5070e+00, -2.6219e+00,  4.3811e+00,\n         2.6406e+00,  2.6335e+00,  2.4109e+00,  3.7238e+00, -1.5791e+00,\n         3.6886e+00,  4.1215e+00,  7.5760e-01,  6.6180e+00,  1.7879e+00,\n         7.1983e+00, -2.7670e+00,  3.4622e+00, -9.3652e-01,  2.7110e+00,\n        -2.2284e+00,  2.8318e+00,  2.2001e+00,  1.9241e+00,  6.7191e+00,\n         5.6494e+00,  5.2870e+00,  5.9886e+00,  4.3995e+00, -6.4480e-01,\n         2.9888e-01, -2.5275e+00, -4.5426e-01,  1.8573e-01, -3.2907e+00,\n        -5.3684e+00,  3.9726e+00,  6.8789e+00, -7.7130e-01,  3.1854e+00,\n         3.6860e+00,  5.7389e+00,  3.4128e+00, -1.3124e+00,  1.0284e+01,\n         6.8565e+00,  9.9777e+00,  1.1031e+01,  9.1968e+00,  8.9745e+00,\n         6.2798e+00,  1.1847e+01,  2.7978e+00,  3.2896e+00,  3.6058e+00,\n         4.2630e+00,  3.5239e+00,  2.9946e+00, -1.6477e+00, -8.3324e-01,\n         6.5861e+00,  7.2510e+00,  7.4998e+00,  9.1935e+00,  5.6012e+00,\n         5.2056e+00,  8.4316e-01,  6.2920e+00,  4.8571e+00, -2.8898e+00,\n         1.1858e+00,  1.9300e+00, -1.0829e+00,  2.5917e+00,  3.7895e+00,\n         2.1657e+00, -6.0876e-01,  1.7159e-01,  9.6687e-01,  4.0814e+00,\n         5.9137e+00,  4.8479e+00, -1.5163e+00,  2.1820e+00,  4.9938e+00,\n         3.0739e+00,  3.5655e+00,  3.5634e+00,  3.2564e+00, -3.7021e-01,\n         2.3257e+00,  7.3948e-01,  4.6907e+00,  1.8564e+00,  2.8932e+00,\n        -9.9835e-01,  2.7457e+00,  7.5500e+00,  5.2385e+00,  4.9170e+00,\n         1.2304e+01,  6.2027e+00,  6.1499e+00,  2.0193e+00, -1.0933e+00,\n         3.6916e+00, -2.5891e-01,  5.7300e+00, -1.1022e+00,  2.7228e+00,\n         3.3744e+00,  1.1433e+00,  6.6838e+00,  2.1559e+00,  3.7811e+00,\n         7.0636e+00,  6.0733e+00,  5.1596e+00, -1.8115e-01,  3.7246e+00,\n         1.4924e+00,  3.3994e+00,  1.5545e+00,  4.4362e+00,  3.8269e-01,\n         1.8499e+00,  2.7254e+00, -1.8324e+00,  6.0477e+00,  4.3320e+00,\n         4.7233e+00,  6.9347e+00,  1.1214e+01,  8.0065e-01,  2.9080e-01,\n         9.6343e-01,  5.0656e+00,  1.4009e+00, -4.9688e+00,  5.9504e+00,\n         3.5531e+00,  7.2532e+00,  9.0094e+00,  4.3183e+00, -2.5078e+00,\n         1.9810e+00,  4.5783e+00,  1.3167e+00,  9.3081e-01, -8.9298e-01,\n         4.0498e+00,  3.3400e+00,  3.8387e+00,  4.3923e+00,  4.0384e+00,\n         2.0706e+00,  2.9626e+00,  2.3093e+00,  2.6862e+00,  5.4379e+00,\n         5.0925e+00,  4.7880e+00,  8.1986e-01,  3.1011e+00, -4.8511e+00,\n         1.9092e+00, -2.5017e+00, -1.8623e+00,  1.6488e+00,  3.7013e+00,\n        -4.4935e-01], device='cuda:0')\nvalues=tensor([[ 3.0261e+01,  5.7666e+01,  4.2751e-01,  1.6412e+00,  1.5972e+00,\n          2.6384e+00,  7.9681e-01,  1.2967e+00,  7.2943e+00,  2.7551e+00,\n         -1.2407e+00, -4.7604e+00, -4.2684e+00,  1.2183e+00, -2.7984e+00,\n          1.7375e+00,  2.1055e+00,  8.5035e+00,  1.0226e+01, -2.4346e-01,\n         -1.7894e+00,  1.6455e+00,  3.5687e+00,  5.9907e+00,  2.3851e+00,\n          4.6262e+00,  3.7011e+00,  1.7150e+00,  9.5704e-01,  4.1898e+00,\n         -3.0040e-01,  7.0047e+00,  4.7084e+00,  1.5708e+00,  5.5313e+00,\n          3.3815e+00,  1.2596e+01, -2.1094e+00, -1.1637e+00,  1.5690e+00,\n          2.4150e+00,  7.0677e+00, -1.7674e-01,  9.0766e+00,  5.9436e+00,\n          3.7654e+00,  5.2096e+00,  7.5006e+00,  1.3913e+00,  8.0426e+00,\n          4.2156e+00, -8.9940e-02,  2.2900e+00, -1.6707e+00, -4.7205e-01,\n          3.1203e+00,  9.5309e-01,  9.1699e-01,  3.5204e+00, -2.8942e-01,\n         -9.9594e-01, -5.6438e-01, -2.6120e+00,  1.8984e+00, -1.8862e+00,\n          7.9105e+00,  6.8871e+00,  5.1955e+00,  3.4148e+00,  2.1042e+00,\n          4.0993e+00,  1.2007e+00,  1.9686e+00,  2.1779e+00,  6.9273e+00,\n          3.1681e+00, -1.3705e+00, -1.8857e+00,  8.5836e+00,  9.4816e-01,\n          5.4762e+00,  5.2534e+00,  3.5250e+00,  1.9360e+00, -1.5608e+00,\n         -6.0914e-01,  1.7610e+00,  7.1072e+00,  6.7677e+00,  8.3514e+00,\n          4.2607e+00,  2.5268e-01,  1.0714e+01,  2.8934e+00,  5.7842e+00,\n          1.7019e+00,  3.0510e+00,  2.0776e+00,  2.7775e-02,  3.2095e+00,\n          1.5058e+00, -1.3861e+00,  2.7820e+00,  1.7700e+00,  4.2378e+00,\n          9.0171e+00,  1.0388e+01,  6.3361e+00,  7.8293e+00,  1.6418e+00,\n          6.6543e+00,  3.2497e+00,  8.4218e+00,  6.2089e+00,  7.5245e+00,\n          2.9133e+00,  6.7523e+00,  7.7626e+00,  7.4321e+00,  4.8315e+00,\n          1.2285e+01,  2.3772e+00,  2.4378e+00,  2.0356e+00,  5.0501e+00,\n          1.4386e-01, -1.4895e+00,  4.4107e+00,  5.5469e+00,  6.7164e-01,\n          6.6201e+00,  3.4655e+00,  2.1798e+00,  3.6287e+00,  5.7205e+00,\n          4.5196e-01, -2.8733e-01,  3.1144e+00,  1.4053e+00, -4.9007e+00,\n          2.2715e+00,  3.9332e+00,  3.8421e+00,  2.6357e+00,  5.8422e+00,\n          2.3535e+00,  2.4762e+00,  7.7067e+00,  4.6468e+00,  2.8979e-02,\n         -6.5435e-01,  1.6774e+00,  1.5561e+00,  8.5615e+00,  1.2378e+01,\n          8.4774e+00,  9.1648e+00,  2.9822e+00, -4.4503e+00, -2.4427e+00,\n         -2.9692e+00,  3.3268e+00, -5.5529e-01,  2.8297e+00,  3.4080e+00,\n          9.8917e-02,  3.8128e+00,  7.4124e+00,  1.7319e-01,  4.5349e+00,\n          2.5192e+00,  7.2964e+00,  1.6929e+00,  1.1267e+01,  9.7159e+00,\n          3.7286e+00,  3.2510e+00,  6.4378e+00,  2.6001e-01,  2.0961e+00,\n          3.3990e+00, -5.5999e-01, -1.6466e+00, -1.4806e+00,  4.9935e+00,\n         -9.4876e-02,  2.1658e+00,  3.4844e+00,  3.7333e+00, -1.4450e-01,\n          3.3197e+00,  4.2284e+00, -3.6410e+00,  5.0544e+00,  1.4450e-01,\n          6.2319e+00, -2.9234e+00,  1.0302e+00, -3.5831e-01,  4.3235e+00,\n         -1.3757e+00,  1.7467e+00,  3.9999e+00,  2.4226e+00,  6.8224e+00,\n          7.4788e+00,  3.2792e+00,  4.3720e+00,  5.2853e+00, -1.1789e+00,\n         -5.8924e-01, -1.8529e+00, -5.0650e-02, -1.5257e-01, -1.9593e+00,\n         -4.7324e+00,  2.3426e+00,  4.3229e+00, -1.0073e+00,  5.3883e+00,\n          3.6306e+00,  7.8462e+00,  2.4429e+00, -1.1139e+00,  8.2455e+00,\n          5.3583e+00,  5.8478e+00,  1.1352e+01,  9.3074e+00,  1.0150e+01,\n          6.5422e+00,  1.1994e+01,  3.1127e+00,  4.0826e+00,  4.5070e+00,\n          7.7312e+00,  3.8579e+00,  3.6382e+00, -7.3850e-01,  2.4722e-01,\n          6.9961e+00,  7.2140e+00,  7.6781e+00,  4.7728e+00,  2.8447e+00,\n          6.1989e+00,  1.8172e+00,  9.2950e+00,  4.1671e+00, -7.3157e-01,\n          2.6462e+00,  6.6519e-01, -7.0985e-01,  3.8207e+00,  2.2817e+00,\n          2.7818e+00, -1.2359e+00,  5.2062e-01,  2.2610e+00,  6.7024e+00,\n          4.6466e+00,  5.4080e+00, -2.0768e+00,  5.5209e+00,  4.9869e+00,\n          1.3460e+00,  4.1768e+00,  2.9664e+00,  9.1345e-01, -1.3124e+00,\n         -2.6745e+00,  1.6441e+00,  7.8899e+00,  2.9101e+00,  1.5937e-03,\n          2.1855e+00,  9.0536e+00,  5.9566e+00,  4.7862e+00,  6.8594e+00,\n          1.1048e+01,  6.9421e+00,  6.5260e+00,  1.0577e+00,  1.8585e+00,\n         -7.7781e-01, -1.0452e+00,  4.7871e+00, -6.9273e-01,  5.4553e+00,\n          5.0882e+00,  2.0439e+00,  6.0880e+00,  1.7833e-02,  3.3173e+00,\n          6.9492e+00,  6.4957e+00,  5.8412e+00, -1.0937e+00,  2.0647e+00,\n          1.5778e-01,  1.4029e+00,  4.7958e-01,  5.1547e+00,  5.6186e-01,\n         -2.0539e-01,  1.8089e+00,  2.6253e+00,  4.2875e+00,  6.2891e+00,\n          4.8023e+00,  9.0826e+00,  1.0499e+01, -8.4024e-01,  1.6319e+00,\n         -9.7937e-02,  3.8483e+00,  3.9541e+00, -4.1724e+00,  3.2369e+00,\n          3.0057e+00,  6.8300e+00,  7.5394e+00,  4.9226e+00, -5.1708e-01,\n          5.3000e+00,  2.7944e+00,  4.5264e-02,  1.8250e+00,  3.4532e-01,\n          3.7392e+00,  5.8034e+00,  4.1251e+00,  2.1825e+00,  2.5427e-01,\n          2.1943e+00,  3.3911e+00,  3.3549e+00,  3.4427e+00,  6.6441e+00,\n          4.8178e+00,  4.5964e+00, -1.2513e-01,  2.6237e+00, -3.0808e+00,\n          5.0979e+00, -4.7558e+00, -2.1844e+00,  8.3043e-01,  3.7959e+00]],\n       device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.6525e-03,\n         -6.3671e-05,  2.4645e-05, -1.4289e-06, -1.9064e-06, -3.6731e-04,\n          8.1803e-06,  2.8207e-03,  2.7893e-06,  9.0575e-04, -7.6044e-04,\n          4.1559e-05,  1.3447e-04, -5.1808e-04,  3.7719e-04,  3.1419e-04,\n         -3.5699e-07,  5.9597e-08, -2.0970e-03,  1.4510e-05, -2.8946e-03,\n          1.4470e-03, -8.8346e-04,  2.1121e-03,  7.0930e-05, -1.8020e-05,\n          7.3174e-04, -5.7407e-06,  2.3839e-07,  1.9972e-04,  1.1920e-07,\n         -0.0000e+00,  9.6741e-06,  3.4177e-04, -2.1440e-04,  4.3447e-06,\n         -3.9032e-05, -5.2917e-04, -3.5968e-06, -2.2225e-04,  7.7220e-05,\n          5.2073e-04,  7.4437e-04,  2.9792e-07,  1.1920e-07, -2.5584e-04,\n         -4.8941e-04,  4.4935e-03, -3.6128e-06,  4.0233e-06,  3.4811e-03,\n          2.7764e-04, -1.6477e-04, -0.0000e+00, -1.0719e-06,  3.3069e-04,\n         -7.5105e-04, -1.7616e-03, -1.9198e-05,  7.1507e-07, -9.9349e-04,\n          1.0629e-04,  7.1516e-07,  9.5341e-07,  2.5103e-03,  9.5974e-04,\n         -1.7880e-07, -5.8131e-04, -0.0000e+00,  5.1884e-06, -0.0000e+00,\n          5.9604e-08, -0.0000e+00,  3.0348e-03,  2.3246e-05, -3.0713e-03,\n          1.7544e-03,  2.0890e-05,  1.1845e-04, -2.4077e-05, -0.0000e+00,\n         -9.2447e-05, -3.0543e-03, -1.0623e-04,  1.1919e-07, -0.0000e+00,\n          3.4752e-04, -8.6920e-05,  4.4823e-05,  5.1224e-04,  8.1875e-06,\n          3.5147e-04, -1.0973e-04, -6.6629e-04, -5.6081e-05, -1.3265e-03,\n         -7.4321e-06, -1.1645e-04,  8.2374e-05, -3.4475e-04, -1.3133e-03,\n         -1.1921e-07,  2.0064e-05,  3.5800e-06, -6.1452e-05, -1.7150e-05,\n         -0.0000e+00,  2.1756e-04, -1.5708e-03,  1.2194e-05,  1.7090e-05,\n          5.0581e-04,  1.8549e-04, -0.0000e+00,  2.4814e-05, -0.0000e+00,\n          5.9601e-08, -0.0000e+00,  4.0738e-05,  1.2600e-04, -6.1816e-04,\n         -7.1883e-05,  2.3013e-04, -1.1914e-06, -3.1522e-06,  8.6337e-04,\n          2.1854e-04,  2.6718e-06, -1.3959e-05, -1.0570e-04,  1.8716e-05,\n         -2.2306e-03,  2.3860e-04,  2.9800e-07, -1.6671e-03, -4.1717e-07,\n         -8.2216e-04, -8.4805e-04, -6.6444e-05,  7.8028e-04, -2.3558e-03,\n         -2.6650e-06,  3.5174e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n          1.3105e-06,  3.5875e-06, -2.8133e-05,  3.5757e-07, -2.3451e-03,\n         -3.6311e-03, -3.1180e-04, -9.1154e-05,  7.8160e-05,  5.9604e-08,\n         -1.7877e-07,  4.7668e-07,  5.9601e-08,  1.8521e-04, -1.2600e-05,\n         -0.0000e+00, -9.1493e-06, -1.0244e-04, -5.1102e-05, -5.9601e-08,\n         -1.2326e-04,  2.4363e-05, -1.2405e-05,  6.7759e-04,  2.1067e-06,\n         -4.4622e-04, -5.8479e-04,  2.9389e-04, -2.1528e-05, -1.1181e-05,\n         -1.6889e-04,  1.5247e-03,  7.1114e-04,  3.8910e-04, -3.3445e-03,\n         -6.4196e-06,  2.3838e-07,  5.9592e-07,  1.1918e-07, -0.0000e+00,\n          2.4913e-05,  2.4503e-04, -4.1807e-04,  1.7316e-03, -0.0000e+00,\n          1.2565e-04, -1.6118e-05,  3.3827e-05, -1.4439e-05,  2.7803e-04,\n          4.9844e-05, -2.9972e-04,  4.9599e-05, -1.2208e-03, -0.0000e+00,\n          1.9623e-05, -1.3363e-05, -5.9601e-08, -2.0403e-05, -0.0000e+00,\n          5.9576e-08, -1.8741e-03,  1.3185e-03,  3.5608e-04, -0.0000e+00,\n          1.9636e-03, -2.9798e-03,  1.2228e-03,  9.7594e-04, -3.5541e-03,\n         -5.6314e-04, -4.9359e-04, -2.5706e-03, -0.0000e+00,  7.3697e-05,\n          1.2109e-03,  3.4547e-05,  4.5301e-04,  2.2650e-06,  9.3060e-05,\n          8.2082e-04,  5.9604e-08,  3.7295e-04, -1.0467e-04,  8.6419e-04,\n         -1.9063e-05, -1.3597e-06, -5.0616e-04,  1.7880e-07,  1.6669e-06,\n          4.4269e-03, -9.1090e-06,  2.1835e-03,  3.5734e-07,  2.8331e-04,\n         -0.0000e+00, -1.2015e-03, -1.8389e-03, -1.0282e-05,  2.9984e-04,\n         -1.3166e-03,  1.7202e-04, -9.8248e-06,  2.4725e-04, -2.5693e-03,\n         -1.1246e-06, -7.3757e-05, -5.3636e-07,  4.6994e-05, -0.0000e+00,\n         -1.1921e-07, -0.0000e+00,  5.4093e-04, -2.5593e-06, -2.9281e-06,\n         -1.4672e-05, -4.3169e-05,  7.7470e-07,  2.6183e-05, -1.5483e-06,\n          4.7668e-07, -1.4980e-03,  2.4983e-06,  5.9488e-07, -1.7494e-05,\n         -2.3833e-07,  2.1013e-05,  4.1783e-05, -5.9603e-08,  5.9597e-08,\n         -6.6106e-03,  3.7780e-04,  1.2895e-05, -0.0000e+00,  4.1831e-04,\n          5.9597e-08,  1.0052e-04, -9.2435e-04,  6.5187e-04, -4.4935e-01]],\n       device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 3.4008e+01,  5.4547e+01,  6.8250e-01, -8.2074e-01,  9.7362e-01,\n          3.5554e+00,  1.8958e+00,  1.8761e+00,  7.9803e+00,  3.3775e+00,\n          9.0976e-01, -2.6718e+00, -5.6406e+00,  1.4597e+00, -4.7817e+00,\n          1.9483e+00,  2.7278e+00,  6.3583e+00,  8.9147e+00,  1.4881e+00,\n         -1.5663e+00,  2.9095e+00,  2.6104e+00,  4.4808e+00,  2.0287e+00,\n          5.4986e+00,  3.0498e+00,  1.3028e+00,  1.9462e+00,  5.2809e+00,\n         -1.6933e+00,  8.5390e+00,  5.7196e+00, -5.6607e-01,  7.8752e+00,\n          3.6625e+00,  1.2394e+01, -1.6425e+00, -4.5518e+00,  4.7764e+00,\n          2.8231e+00,  7.2132e+00,  1.5870e+00,  7.3130e+00,  5.7649e+00,\n          3.1383e+00,  5.3854e+00,  8.2034e+00,  1.6908e+00,  8.1582e+00,\n          3.5139e+00,  5.8958e+00,  2.4418e+00,  9.7289e-02, -5.8794e+00,\n          2.2571e+00,  1.8312e-01,  2.2220e+00,  2.2579e+00, -1.9532e+00,\n         -2.1891e+00,  2.2347e+00, -5.9357e+00,  2.8705e-01, -1.0567e+00,\n          7.6146e+00,  4.5528e+00,  5.6031e+00,  2.6205e+00,  3.1584e+00,\n          3.7935e+00,  2.4296e+00,  3.0420e+00,  2.6072e+00,  7.4121e+00,\n          2.5971e+00,  2.4107e-01, -7.6482e-01,  7.9294e+00,  2.2482e+00,\n          6.9396e+00,  3.2434e+00,  4.8751e+00,  3.3226e+00, -2.3842e-01,\n          2.0998e+00,  1.5428e+00,  7.4035e+00,  8.9816e+00,  5.4255e+00,\n          5.9804e+00,  1.5923e+00,  9.2018e+00,  3.3513e+00,  4.7436e+00,\n          8.3191e-01,  8.2098e-01,  1.3290e+00,  2.9817e+00,  3.6544e+00,\n          2.6387e+00,  6.3205e-02,  7.8661e-01,  2.8799e+00,  4.6609e+00,\n          8.7929e+00,  6.5678e+00,  7.1290e+00,  8.0316e+00,  2.3967e+00,\n          5.6323e+00,  4.6984e+00,  7.3127e+00,  3.2425e+00,  1.1202e+01,\n          4.9395e+00,  6.6290e+00,  7.0555e+00,  7.5807e+00,  6.0281e+00,\n          1.0262e+01,  3.7384e+00,  2.7886e+00,  2.9181e+00,  3.9611e+00,\n          1.6548e+00, -1.0321e+00,  6.5557e+00,  5.4187e+00,  2.8044e+00,\n          4.5478e+00,  6.8852e-01, -3.9527e-01,  1.7488e+00,  7.2923e+00,\n         -9.4148e-01, -4.0449e-01,  2.8718e+00,  1.5102e+00, -2.8166e+00,\n          1.7620e+00,  2.7495e+00,  4.8834e+00,  3.7006e+00,  6.6798e+00,\n          2.2726e+00,  2.5245e+00,  5.4794e+00,  3.9475e+00,  2.0712e+00,\n         -2.1599e+00, -4.9646e-01,  5.2121e+00,  5.1698e+00,  1.0494e+01,\n          8.7950e+00,  8.9036e+00,  6.2624e+00, -2.9138e+00,  7.3588e-01,\n          4.7821e-01,  2.9024e+00,  8.3497e-01,  1.5461e+00, -3.7108e-02,\n          6.1545e-01,  4.3702e+00,  8.1533e+00,  9.4422e-01,  4.9055e+00,\n          2.8726e+00,  4.6612e+00,  2.6629e+00,  9.0895e+00,  5.8971e+00,\n          1.8190e+00,  3.8562e+00,  7.0225e+00, -9.2833e-01,  1.0852e+00,\n          2.0445e+00, -2.0965e+00,  9.1651e-01, -2.2341e+00,  5.5942e+00,\n          3.9059e+00,  2.5013e+00,  4.2910e+00,  3.0533e+00, -2.3144e-02,\n          5.1236e+00,  6.1914e+00,  1.0044e+00,  6.2815e+00,  3.4931e+00,\n          8.2798e+00, -2.1097e+00,  1.9383e+00, -5.9771e-01,  3.8258e+00,\n         -2.2056e+00,  2.9340e+00,  3.7300e+00,  1.7805e+00,  4.2720e+00,\n          6.3825e+00,  2.0227e+00,  3.9929e+00,  4.8870e+00, -1.5755e+00,\n         -1.3884e+00,  3.7418e-01,  7.3660e-01,  2.8480e-01, -2.5327e+00,\n         -2.8461e+00,  7.0198e-01,  9.7638e+00,  1.6721e+00,  6.9059e+00,\n          2.0724e+00,  5.9870e+00,  1.4482e+00,  3.3415e-01,  9.5592e+00,\n          6.0284e+00,  9.1344e+00,  1.2436e+01,  9.9627e+00,  8.2381e+00,\n          3.8438e+00,  1.0654e+01,  2.5682e+00,  1.7966e+00,  2.2076e+00,\n          5.8084e+00,  4.3930e+00,  1.8375e+00,  1.6300e+00, -4.0405e-01,\n          8.2870e+00,  6.8575e+00,  7.6468e+00,  4.6898e+00,  1.2352e+00,\n          6.7654e+00,  2.2739e+00,  8.7986e+00,  6.9680e+00, -1.6369e+00,\n          2.5086e+00,  2.5754e+00, -1.2700e+00, -4.3185e-01,  3.0866e+00,\n          2.8831e+00, -2.1481e+00,  1.7396e+00, -1.8604e+00,  4.1401e+00,\n          4.7957e+00,  4.0914e+00, -5.7201e-01,  7.1787e+00,  5.6549e+00,\n          4.7185e+00,  2.3425e+00,  4.1502e+00,  4.1706e+00, -2.9729e+00,\n          4.0058e-01,  4.4027e+00,  5.7222e+00,  2.1432e+00,  7.6739e-01,\n          5.5715e-01,  9.6924e+00,  7.7713e+00,  4.5460e+00,  8.3129e+00,\n          8.1725e+00,  6.9539e+00,  7.0152e+00,  1.3752e+00,  2.0853e+00,\n         -1.0341e+00,  1.5524e+00,  5.6065e+00, -1.0744e+00,  2.8350e+00,\n          5.1476e+00,  3.6116e+00,  7.7039e+00,  8.2967e-01,  1.9399e+00,\n          6.8728e+00,  6.3987e+00,  4.3710e+00, -2.5307e+00,  1.0500e+00,\n          1.8362e+00,  5.5518e+00, -1.3678e-01,  3.5928e+00,  1.2508e+00,\n          5.7603e-01,  3.1627e+00,  1.5913e+00,  5.2899e+00,  4.4436e+00,\n          5.2343e+00,  7.5609e+00,  9.6502e+00,  3.6129e-01,  1.1152e+00,\n          8.9409e-01,  4.8823e+00,  1.5884e+00, -4.6776e+00,  2.8252e+00,\n          3.0344e+00,  3.8698e+00,  7.1209e+00,  4.3969e+00, -4.0794e+00,\n          5.6794e+00,  5.5740e-01, -4.6894e-01,  4.3474e-02,  1.2374e+00,\n          2.8517e+00,  3.4245e+00,  4.2063e+00,  1.9208e+00,  9.0677e-01,\n          4.3467e+00,  4.2479e+00,  6.4231e+00,  3.1900e+00,  6.3300e+00,\n          6.6760e+00,  3.7185e+00,  3.0967e+00,  4.6813e+00, -8.1753e-01,\n          3.1200e+00, -2.0630e+00, -2.9299e+00,  2.0179e+00,  3.6998e+00,\n          1.5895e-02]], device='cuda:0', grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.5196e+01,  4.9491e+01,  6.6242e-01,  1.1562e+00,  1.8021e+00,\n          3.8112e+00,  5.5704e-01, -2.5638e-01,  8.1279e+00,  2.4650e+00,\n         -1.2217e+00, -3.3140e+00, -6.6004e+00,  1.2354e+00, -3.1190e+00,\n          4.8055e-02,  1.0749e+00,  8.4035e+00,  6.7292e+00,  2.4586e-02,\n          7.5118e-02,  3.9055e+00,  2.5873e+00,  3.0115e+00,  1.8725e+00,\n          5.0566e+00,  3.1407e+00,  3.2778e+00,  1.7144e+00,  3.2602e+00,\n          6.3567e-01,  7.4354e+00,  5.6104e+00,  2.0690e+00,  5.4623e+00,\n          2.2727e+00,  1.2639e+01, -3.1787e-01, -1.7126e+00,  1.0034e+00,\n          3.8205e+00,  7.7717e+00,  1.6513e-01,  9.1899e+00,  4.3364e+00,\n          5.8347e+00,  6.4988e+00,  7.9687e+00,  7.2745e-01,  5.9315e+00,\n          2.5643e+00,  2.8632e+00,  1.9502e+00, -5.7561e-01,  3.5762e-01,\n          9.7648e-01,  9.1689e-01, -2.8005e-01,  1.8893e+00, -1.4799e-01,\n         -8.0572e-01,  1.4533e+00, -2.7923e+00,  2.0078e+00, -1.5666e+00,\n          6.8258e+00,  4.3245e+00,  4.6847e+00,  3.3207e+00,  2.4526e-01,\n          1.7161e+00,  2.1283e+00, -8.7035e-01,  2.0131e+00,  4.7553e+00,\n          5.2579e+00, -1.6598e+00, -1.2781e+00,  5.5116e+00,  1.6068e+00,\n          5.4441e+00,  4.0348e+00,  3.1236e+00,  3.2909e+00, -9.8746e-01,\n         -1.9307e+00,  9.2779e-01,  6.0887e+00,  6.6426e+00,  5.4029e+00,\n          6.1628e+00,  3.9385e+00,  1.0043e+01,  3.4073e+00,  4.2092e+00,\n         -4.8725e-01,  2.4452e+00,  2.7251e+00,  1.6853e+00,  7.6704e+00,\n         -5.4943e-01, -1.4384e+00,  1.4665e+00,  2.9639e+00,  5.6103e+00,\n          8.9054e+00,  6.5824e+00,  4.9658e+00,  8.0780e+00,  9.4682e-01,\n          8.5551e+00,  3.6087e+00,  8.1269e+00,  4.6952e+00,  7.5446e+00,\n          6.5605e+00,  6.8381e+00,  8.7094e+00,  5.8235e+00,  3.8464e+00,\n          1.4520e+01,  5.1365e+00,  5.2073e+00,  1.9771e+00,  2.8627e+00,\n          2.1208e+00,  5.4192e-01,  7.2638e+00,  4.1802e+00,  1.6333e+00,\n          6.0406e+00,  2.1647e+00,  5.2172e-01,  4.5032e+00,  6.2209e+00,\n          1.4195e+00, -1.9580e+00,  2.7682e+00,  3.3613e+00, -3.8380e+00,\n          3.6785e+00,  2.4276e+00,  6.1197e+00,  3.8048e+00,  4.4350e+00,\n          2.2024e+00,  1.6044e+00,  6.2856e+00,  5.0791e+00,  9.3876e-01,\n         -2.5824e+00, -1.6040e+00,  4.6852e+00,  3.4707e+00,  1.2080e+01,\n          6.7052e+00,  6.4374e+00,  3.7613e+00, -3.0122e+00, -2.0007e-02,\n         -2.7274e+00,  3.0529e+00, -2.2526e+00,  2.5892e+00,  4.4937e+00,\n          4.3837e-01,  3.8036e+00,  8.4508e+00, -1.3977e+00,  6.5313e+00,\n          2.4012e+00,  6.4668e+00, -5.8593e-01,  7.4768e+00,  5.9857e+00,\n          4.2440e+00,  4.4419e+00,  4.2167e+00, -3.9221e+00,  1.7189e+00,\n          2.6638e+00, -2.9794e+00, -9.5377e-02, -3.6324e+00,  7.9769e+00,\n          4.3958e+00,  2.6198e+00,  3.2525e+00,  4.6341e+00,  5.9500e-01,\n          4.4859e+00,  5.3840e+00, -2.3310e-01,  6.0148e+00,  3.6147e+00,\n          4.3779e+00, -1.3558e+00,  1.9264e+00, -1.1293e+00,  2.7954e+00,\n         -2.6934e-01,  1.1943e+00,  2.2327e+00,  7.0241e-01,  9.8576e+00,\n          7.7267e+00,  4.8805e+00,  5.9559e+00,  3.7659e+00,  8.3454e-01,\n         -3.6329e-01, -1.3930e+00, -2.3738e+00,  7.2300e-01, -1.0230e+00,\n         -3.0734e+00,  3.0053e+00,  7.0340e+00,  1.2998e+00,  5.0761e+00,\n          8.3626e-01,  8.2150e+00,  1.2174e+00, -2.8722e+00,  8.4720e+00,\n          4.5017e+00,  6.4076e+00,  1.3439e+01,  1.0515e+01,  8.3716e+00,\n          5.8338e+00,  9.7529e+00,  3.3360e+00, -1.5961e-01,  2.5456e+00,\n          5.1227e+00,  3.5627e+00,  3.7251e+00, -2.1694e+00,  1.3569e+00,\n          5.6261e+00,  7.1347e+00,  6.2710e+00,  5.1373e+00,  3.0353e+00,\n          6.9413e+00,  2.0446e+00,  9.4802e+00,  6.9960e+00, -2.2449e+00,\n          1.6443e+00,  2.8210e+00,  1.1998e+00,  3.2901e-01,  3.1709e+00,\n          4.0109e+00, -2.6373e+00, -3.2678e-01,  7.5188e-01,  7.6810e+00,\n          2.8199e+00,  4.7715e+00,  9.7469e-01,  6.0756e+00,  3.9789e+00,\n          1.3529e+00,  2.5714e+00,  3.5262e+00,  2.8138e+00, -1.0568e+00,\n          2.3917e+00,  1.6648e+00,  3.7971e+00,  2.9122e+00,  2.3541e+00,\n         -7.5605e-01,  7.7274e+00,  7.5628e+00,  5.8004e+00,  6.2506e+00,\n          7.9731e+00,  6.9652e+00,  3.2972e+00,  2.0998e+00,  1.9851e+00,\n          8.8243e-01,  3.1390e+00,  6.6845e+00, -2.9903e+00,  3.3306e+00,\n          4.9557e+00,  1.3344e+00,  6.8292e+00,  5.4986e-01,  3.5712e+00,\n          4.9273e+00,  5.3157e+00,  6.0423e+00, -1.3653e+00,  2.8865e-01,\n          1.0870e+00,  4.7407e+00, -1.1470e-01,  5.0343e+00,  4.2591e-01,\n          3.4026e-01,  1.6230e+00,  2.0982e+00,  4.0416e+00,  6.5118e+00,\n          5.7807e+00,  8.4370e+00,  7.7883e+00, -4.8155e-01,  1.4672e-01,\n          1.1697e+00,  6.3579e+00,  2.3640e+00, -4.1746e+00,  8.4654e+00,\n          4.0047e+00,  7.9431e+00,  1.0251e+01,  4.3701e+00, -3.0322e+00,\n          4.1523e+00,  2.5288e+00,  2.3866e+00, -5.2383e-01, -2.9088e-01,\n          4.7454e+00,  4.1722e+00,  4.8620e+00,  1.5179e+00,  4.6055e+00,\n          4.9808e+00,  4.4422e+00,  4.4206e+00,  2.2337e+00,  5.7039e+00,\n          4.8866e+00,  4.6692e+00,  2.4264e-01,  1.5276e+00, -1.2457e-01,\n         -3.9641e-01, -6.9921e-01, -1.8051e+00,  2.5352e+00,  3.9447e+00,\n         -3.7559e-01]], device='cuda:0', grad_fn=<PermuteBackward0>)\n6it [05:25, 58.71s/it]\u001b[32m2023-08-14 17:38:44.783\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 32006, 38039, 56081, 55081, 34598,\n        55282, 31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:25.321\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910, 32006, 56081, 55081, 34598, 33438, 33446, 30932, 32040, 43742,\n        33208, 33438, 30954,    13,    13, 30939, 30930, 30910, 33373, 33588,\n        31675, 32168, 30954, 32102, 34598, 31640, 31849, 31675, 37408, 31201,\n        32635, 35117, 31706, 31689, 30932, 31814, 35527, 31768, 32743, 34598,\n        32932, 49020, 33373, 33588, 31675, 32168, 31155,    13,    13, 30943,\n        30930, 30910, 55418, 55118, 53706, 35894, 31969, 30954, 31949, 34987,\n        34107, 31962, 30932, 34598, 33938, 54530, 34182, 31808, 32723, 40623,\n        35966, 32249, 38027, 33191, 31155, 54617, 31784, 35186, 31768, 32743,\n        34598, 32932, 31722, 31810, 55418, 55118, 30932, 54534, 35651, 46514,\n        36077, 54578, 43282, 31888, 35894, 31969, 31155,    13,    13, 30966,\n        30930, 30910, 31985, 33588, 31634, 30954, 31784, 32145, 31772, 31652,\n        34067, 33588, 48679, 54578, 32150, 44505, 30932, 31814, 31633, 31768,\n        54687, 33799, 43542, 49020, 31985, 33588, 31634, 31155,    13,    13,\n        30972, 30930, 30910, 35801, 31832, 55562, 54967, 30954, 44830, 31796,\n        39881, 31832, 53191, 54746, 32533, 30932, 31768, 32743, 34598, 32932,\n        49020, 30932, 33980, 32071, 33208, 33438, 31155,    13,    13, 30970,\n        30930, 30910, 31740, 31962, 30954, 31784, 32893, 34598, 33938, 38641,\n        32222, 30932, 32780, 59661, 55543, 31201, 43400, 54609, 30932, 31814,\n        31633, 31768, 32743, 34598, 54548, 31823, 33588, 31965, 54542, 32883,\n        35774, 36132, 32622, 31155,    13,    13, 30978, 30930, 30910, 31653,\n        32300, 30954, 35527, 49585, 32743, 34598, 30932, 35231, 32535, 32406,\n        37229, 39207, 30932, 31662, 33450, 54556, 40219, 31674, 35351, 54542,\n        32281, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:25.331\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 32006, 38039, 56081, 55081, 34598,\n        55282, 31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:25.337\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910, 32006, 56081, 55081, 34598, 33438, 33446, 30932, 32040, 43742,\n        33208, 33438, 30954,    13,    13, 30939, 30930, 30910, 33373, 33588,\n        31675, 32168, 30954, 32102, 34598, 31640, 31849, 31675, 37408, 31201,\n        32635, 35117, 31706, 31689, 30932, 31814, 35527, 31768, 32743, 34598,\n        32932, 49020, 33373, 33588, 31675, 32168, 31155,    13,    13, 30943,\n        30930, 30910, 55418, 55118, 53706, 35894, 31969, 30954, 31949, 34987,\n        34107, 31962, 30932, 34598, 33938, 54530, 34182, 31808, 32723, 40623,\n        35966, 32249, 38027, 33191, 31155, 54617, 31784, 35186, 31768, 32743,\n        34598, 32932, 31722, 31810, 55418, 55118, 30932, 54534, 35651, 46514,\n        36077, 54578, 43282, 31888, 35894, 31969, 31155,    13,    13, 30966,\n        30930, 30910, 31985, 33588, 31634, 30954, 31784, 32145, 31772, 31652,\n        34067, 33588, 48679, 54578, 32150, 44505, 30932, 31814, 31633, 31768,\n        54687, 33799, 43542, 49020, 31985, 33588, 31634, 31155,    13,    13,\n        30972, 30930, 30910, 35801, 31832, 55562, 54967, 30954, 44830, 31796,\n        39881, 31832, 53191, 54746, 32533, 30932, 31768, 32743, 34598, 32932,\n        49020, 30932, 33980, 32071, 33208, 33438, 31155,    13,    13, 30970,\n        30930, 30910, 31740, 31962, 30954, 31784, 32893, 34598, 33938, 38641,\n        32222, 30932, 32780, 59661, 55543, 31201, 43400, 54609, 30932, 31814,\n        31633, 31768, 32743, 34598, 54548, 31823, 33588, 31965, 54542, 32883,\n        35774, 36132, 32622, 31155,    13,    13, 30978, 30930, 30910, 31653,\n        32300, 30954, 35527, 49585, 32743, 34598, 30932, 35231, 32535, 32406,\n        37229, 39207, 30932, 31662, 33450, 54556, 40219, 31674, 35351, 54542,\n        32281, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:25.726\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 3.5384e+01,  5.0058e+01,  6.8095e-01,  1.9464e+00,  1.3615e+00,\n         8.1402e-01,  1.7635e+00, -2.2905e+00, -7.8858e-04,  2.9170e+00,\n         1.7123e+00,  7.9068e-01,  5.8406e-01,  1.5640e+00,  2.9933e+00,\n        -2.5480e+00,  4.0337e-02, -4.4394e+00, -7.8668e+00, -1.8086e+00,\n         5.2218e+00,  3.5301e-01,  3.9807e+00, -1.1590e+00,  6.8693e+00,\n        -2.8089e-01, -1.6638e+00,  2.5033e+00,  2.6319e-01,  1.3191e+00,\n        -1.1854e+00, -2.4768e+00, -4.4804e+00, -5.5873e+00, -3.5311e+00,\n        -3.2615e+00, -4.1940e+00, -2.1586e+00, -8.4537e+00,  3.8591e+00,\n         2.2314e+00, -7.8720e-01, -4.9754e+00,  3.9027e+00, -1.5077e-01,\n        -3.1091e+00, -7.6081e+00,  7.9604e-01, -4.2227e+00, -4.0990e+00,\n        -2.8530e+00,  3.2068e+00, -2.7560e+00,  3.8508e+00,  2.1539e+00,\n         1.7747e-01,  3.8236e+00,  1.9516e-01,  7.1977e+00,  6.2626e+00,\n         5.0000e+00,  4.2961e+00,  4.1876e-01, -4.5874e+00,  2.5201e+00,\n        -2.8614e+00, -7.2665e+00, -4.6104e+00,  1.6369e+00,  7.7523e-01,\n        -4.6318e+00, -1.1113e+00, -9.2176e-01, -4.7566e+00, -1.2408e+00,\n        -3.2461e+00, -7.7155e+00, -3.6563e+00, -4.8742e+00,  3.0697e+00,\n         1.4912e+00, -7.8052e+00, -7.1688e+00, -2.2836e+00, -8.5225e-02,\n        -8.2321e+00,  9.2266e+00,  1.2223e+00, -5.4340e+00,  7.3664e-01,\n        -2.7946e+00,  9.7875e-01,  4.4205e+00, -9.8863e+00,  1.2974e+00,\n         1.8177e+00, -9.8730e-01,  6.5883e+00,  1.9431e+00,  9.7176e+00,\n         5.8968e+00,  4.9855e+00,  2.2763e+00,  4.1304e+00,  3.7189e-01,\n         3.7374e+00,  1.2785e+00, -3.4809e+00,  5.2487e+00,  2.1868e+00,\n         6.3101e-02,  4.6017e+00,  1.2390e+00,  5.9604e-01,  5.7727e+00,\n        -3.8627e+00, -3.9997e+00, -1.9158e+00,  2.8297e-01,  2.8779e+00,\n        -7.0650e-01,  5.2284e+00,  8.9841e-01, -4.9915e+00, -4.0187e+00,\n         1.5183e+00,  2.2027e+00,  3.6264e-01, -5.8885e+00,  1.2816e+00,\n         2.2940e+00,  1.7781e+00,  3.9965e+00, -4.5048e+00, -5.5717e+00,\n        -7.1238e-01, -5.6328e+00, -4.5825e+00,  4.9471e+00,  2.2498e+00,\n         7.3431e-01,  5.5481e+00,  4.0181e+00,  1.8004e+00,  1.8189e+00,\n         4.5354e+00, -3.0804e-01, -9.4520e+00, -6.2038e+00, -4.5433e+00,\n        -5.6427e+00, -2.1343e+00, -4.6299e+00, -4.6172e+00, -5.5827e+00,\n        -3.7672e+00, -7.6589e+00, -4.2830e+00, -2.0528e+00, -5.4912e+00,\n        -2.5357e-01, -1.9053e+00, -4.3033e-01,  2.3468e+00,  2.0265e+00,\n         1.6793e+00,  1.3936e+00,  3.8154e+00, -9.6328e-01,  2.0009e-01,\n        -3.3534e+00,  1.5751e+00,  1.9530e+00, -2.2724e-01,  3.9244e+00,\n        -2.9468e-01, -6.4086e-01,  2.0149e+00, -4.0250e+00,  2.4175e-01,\n         3.2579e+00, -1.4480e+00,  5.0554e-01,  1.0299e+00,  3.7422e+00,\n        -2.6969e+00, -5.3124e+00, -4.5145e+00, -1.8847e+00, -6.2179e-01,\n        -6.3095e-01, -7.1701e-01, -2.9350e+00,  2.7438e+00, -4.4784e+00,\n        -3.6555e+00, -6.2094e+00, -7.5887e-01,  3.0667e+00,  4.8431e+00,\n         4.9224e+00, -2.5112e+00,  4.9243e+00,  2.4219e+00,  9.4010e-01,\n         1.2070e+01,  4.5208e+00,  1.3864e+00,  1.7553e-01,  1.6680e+00,\n        -1.5285e+00,  1.5025e+00, -5.5577e-01, -8.2873e-02,  3.9703e-01,\n        -1.1700e+00, -4.8657e-01,  1.8344e+00,  4.6074e+00, -1.0295e+00,\n         3.6750e+00,  6.4844e+00,  5.8971e+00,  2.1285e+00, -1.0526e+00,\n         5.4321e+00,  3.2874e-01,  7.0860e-01,  1.1264e+00, -1.8035e+00,\n         3.5322e+00,  1.9276e+00,  2.5874e+00, -6.4238e-02,  6.9838e+00,\n        -1.9454e+00,  7.7168e-01,  4.3062e+00, -6.3883e-01], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:25.727\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:39:25.728\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:39:25.737\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 3.5384e+01,  5.0058e+01,  6.8095e-01,  1.9464e+00,  1.3615e+00,\n         8.1402e-01,  1.7635e+00, -2.2905e+00, -7.8858e-04,  2.9170e+00,\n         1.7123e+00,  7.9068e-01,  5.8406e-01,  1.5640e+00,  2.9933e+00,\n        -2.5480e+00,  4.0337e-02, -4.4394e+00, -7.8668e+00, -1.8086e+00,\n         5.2218e+00,  3.5301e-01,  3.9807e+00, -1.1590e+00,  6.8693e+00,\n        -2.8089e-01, -1.6638e+00,  2.5033e+00,  2.6319e-01,  1.3191e+00,\n        -1.1854e+00, -2.4768e+00, -4.4804e+00, -5.5873e+00, -3.5311e+00,\n        -3.2615e+00, -4.1940e+00, -2.1586e+00, -8.4537e+00,  3.8591e+00,\n         2.2314e+00, -7.8720e-01, -4.9754e+00,  3.9027e+00, -1.5077e-01,\n        -3.1091e+00, -7.6081e+00,  7.9604e-01, -4.2227e+00, -4.0990e+00,\n        -2.8530e+00,  3.2068e+00, -2.7560e+00,  3.8508e+00,  2.1539e+00,\n         1.7747e-01,  3.8236e+00,  1.9516e-01,  7.1977e+00,  6.2626e+00,\n         5.0000e+00,  4.2961e+00,  4.1876e-01, -4.5874e+00,  2.5201e+00,\n        -2.8614e+00, -7.2665e+00, -4.6104e+00,  1.6369e+00,  7.7523e-01,\n        -4.6318e+00, -1.1113e+00, -9.2176e-01, -4.7566e+00, -1.2408e+00,\n        -3.2461e+00, -7.7155e+00, -3.6563e+00, -4.8742e+00,  3.0697e+00,\n         1.4912e+00, -7.8052e+00, -7.1688e+00, -2.2836e+00, -8.5225e-02,\n        -8.2321e+00,  9.2266e+00,  1.2223e+00, -5.4340e+00,  7.3664e-01,\n        -2.7946e+00,  9.7875e-01,  4.4205e+00, -9.8863e+00,  1.2974e+00,\n         1.8177e+00, -9.8730e-01,  6.5883e+00,  1.9431e+00,  9.7176e+00,\n         5.8968e+00,  4.9855e+00,  2.2763e+00,  4.1304e+00,  3.7189e-01,\n         3.7374e+00,  1.2785e+00, -3.4809e+00,  5.2487e+00,  2.1868e+00,\n         6.3101e-02,  4.6017e+00,  1.2390e+00,  5.9604e-01,  5.7727e+00,\n        -3.8627e+00, -3.9997e+00, -1.9158e+00,  2.8297e-01,  2.8779e+00,\n        -7.0650e-01,  5.2284e+00,  8.9841e-01, -4.9915e+00, -4.0187e+00,\n         1.5183e+00,  2.2027e+00,  3.6264e-01, -5.8885e+00,  1.2816e+00,\n         2.2940e+00,  1.7781e+00,  3.9965e+00, -4.5048e+00, -5.5717e+00,\n        -7.1238e-01, -5.6328e+00, -4.5825e+00,  4.9471e+00,  2.2498e+00,\n         7.3431e-01,  5.5481e+00,  4.0181e+00,  1.8004e+00,  1.8189e+00,\n         4.5354e+00, -3.0804e-01, -9.4520e+00, -6.2038e+00, -4.5433e+00,\n        -5.6427e+00, -2.1343e+00, -4.6299e+00, -4.6172e+00, -5.5827e+00,\n        -3.7672e+00, -7.6589e+00, -4.2830e+00, -2.0528e+00, -5.4912e+00,\n        -2.5357e-01, -1.9053e+00, -4.3033e-01,  2.3468e+00,  2.0265e+00,\n         1.6793e+00,  1.3936e+00,  3.8154e+00, -9.6328e-01,  2.0009e-01,\n        -3.3534e+00,  1.5751e+00,  1.9530e+00, -2.2724e-01,  3.9244e+00,\n        -2.9468e-01, -6.4086e-01,  2.0149e+00, -4.0250e+00,  2.4175e-01,\n         3.2579e+00, -1.4480e+00,  5.0554e-01,  1.0299e+00,  3.7422e+00,\n        -2.6969e+00, -5.3124e+00, -4.5145e+00, -1.8847e+00, -6.2179e-01,\n        -6.3095e-01, -7.1701e-01, -2.9350e+00,  2.7438e+00, -4.4784e+00,\n        -3.6555e+00, -6.2094e+00, -7.5887e-01,  3.0667e+00,  4.8431e+00,\n         4.9224e+00, -2.5112e+00,  4.9243e+00,  2.4219e+00,  9.4010e-01,\n         1.2070e+01,  4.5208e+00,  1.3864e+00,  1.7553e-01,  1.6680e+00,\n        -1.5285e+00,  1.5025e+00, -5.5577e-01, -8.2873e-02,  3.9703e-01,\n        -1.1700e+00, -4.8657e-01,  1.8344e+00,  4.6074e+00, -1.0295e+00,\n         3.6750e+00,  6.4844e+00,  5.8971e+00,  2.1285e+00, -1.0526e+00,\n         5.4321e+00,  3.2874e-01,  7.0860e-01,  1.1264e+00, -1.8035e+00,\n         3.5322e+00,  1.9276e+00,  2.5874e+00, -6.4238e-02,  6.9838e+00,\n        -1.9454e+00,  7.7168e-01,  4.3062e+00, -6.3883e-01], device='cuda:0')]\u001b[0m\nepoch:  6 \nquery: 问：人们为什么要迁离非洲呢？\n\n答：\nresponse: 人们迁离非洲的原因有很多,以下是一些常见的原因:\n\n1. 寻找更好的经济机会:许多非洲国家存在经济落后、就业难度大的情况,因此有些人选择离开非洲前往其他国家寻找更好的经济机会。\n\n2. 移居国外的华人社区:由于历史上的一些原因,非洲大陆的某些地区仍然存在着较高的工作和生活危险。而一些中国人选择离开非洲前往其他地方移居,在远离亲友的环境下建立起新的华人社区。\n\n3. 接受更好的教育:一些家长希望孩子可以在更好的教育资源下成长和学习,因此他们选择将子女带到其他国家接受更好的教育。\n\n4. 寻求政治避难:一些人为了逃避政治迫害或战争,选择离开非洲前往其他国家,这也是一种常见的原因。\n\n5. 健康原因:一些人在非洲大陆患有疾病,例如疟疾、艾滋病等,因此他们选择离开非洲以获得更好的治疗和预防传染病的传播。\n\n6. 文化体验:有些人会选择离开非洲,是为了探索不同的文化和生活方式,通过旅行来拓宽自己的视野和经历。\nscore: tensor([ 3.5384e+01,  5.0058e+01,  6.8095e-01,  1.9464e+00,  1.3615e+00,\n         8.1402e-01,  1.7635e+00, -2.2905e+00, -7.8858e-04,  2.9170e+00,\n         1.7123e+00,  7.9068e-01,  5.8406e-01,  1.5640e+00,  2.9933e+00,\n        -2.5480e+00,  4.0337e-02, -4.4394e+00, -7.8668e+00, -1.8086e+00,\n         5.2218e+00,  3.5301e-01,  3.9807e+00, -1.1590e+00,  6.8693e+00,\n        -2.8089e-01, -1.6638e+00,  2.5033e+00,  2.6319e-01,  1.3191e+00,\n        -1.1854e+00, -2.4768e+00, -4.4804e+00, -5.5873e+00, -3.5311e+00,\n        -3.2615e+00, -4.1940e+00, -2.1586e+00, -8.4537e+00,  3.8591e+00,\n         2.2314e+00, -7.8720e-01, -4.9754e+00,  3.9027e+00, -1.5077e-01,\n        -3.1091e+00, -7.6081e+00,  7.9604e-01, -4.2227e+00, -4.0990e+00,\n        -2.8530e+00,  3.2068e+00, -2.7560e+00,  3.8508e+00,  2.1539e+00,\n         1.7747e-01,  3.8236e+00,  1.9516e-01,  7.1977e+00,  6.2626e+00,\n         5.0000e+00,  4.2961e+00,  4.1876e-01, -4.5874e+00,  2.5201e+00,\n        -2.8614e+00, -7.2665e+00, -4.6104e+00,  1.6369e+00,  7.7523e-01,\n        -4.6318e+00, -1.1113e+00, -9.2176e-01, -4.7566e+00, -1.2408e+00,\n        -3.2461e+00, -7.7155e+00, -3.6563e+00, -4.8742e+00,  3.0697e+00,\n         1.4912e+00, -7.8052e+00, -7.1688e+00, -2.2836e+00, -8.5225e-02,\n        -8.2321e+00,  9.2266e+00,  1.2223e+00, -5.4340e+00,  7.3664e-01,\n        -2.7946e+00,  9.7875e-01,  4.4205e+00, -9.8863e+00,  1.2974e+00,\n         1.8177e+00, -9.8730e-01,  6.5883e+00,  1.9431e+00,  9.7176e+00,\n         5.8968e+00,  4.9855e+00,  2.2763e+00,  4.1304e+00,  3.7189e-01,\n         3.7374e+00,  1.2785e+00, -3.4809e+00,  5.2487e+00,  2.1868e+00,\n         6.3101e-02,  4.6017e+00,  1.2390e+00,  5.9604e-01,  5.7727e+00,\n        -3.8627e+00, -3.9997e+00, -1.9158e+00,  2.8297e-01,  2.8779e+00,\n        -7.0650e-01,  5.2284e+00,  8.9841e-01, -4.9915e+00, -4.0187e+00,\n         1.5183e+00,  2.2027e+00,  3.6264e-01, -5.8885e+00,  1.2816e+00,\n         2.2940e+00,  1.7781e+00,  3.9965e+00, -4.5048e+00, -5.5717e+00,\n        -7.1238e-01, -5.6328e+00, -4.5825e+00,  4.9471e+00,  2.2498e+00,\n         7.3431e-01,  5.5481e+00,  4.0181e+00,  1.8004e+00,  1.8189e+00,\n         4.5354e+00, -3.0804e-01, -9.4520e+00, -6.2038e+00, -4.5433e+00,\n        -5.6427e+00, -2.1343e+00, -4.6299e+00, -4.6172e+00, -5.5827e+00,\n        -3.7672e+00, -7.6589e+00, -4.2830e+00, -2.0528e+00, -5.4912e+00,\n        -2.5357e-01, -1.9053e+00, -4.3033e-01,  2.3468e+00,  2.0265e+00,\n         1.6793e+00,  1.3936e+00,  3.8154e+00, -9.6328e-01,  2.0009e-01,\n        -3.3534e+00,  1.5751e+00,  1.9530e+00, -2.2724e-01,  3.9244e+00,\n        -2.9468e-01, -6.4086e-01,  2.0149e+00, -4.0250e+00,  2.4175e-01,\n         3.2579e+00, -1.4480e+00,  5.0554e-01,  1.0299e+00,  3.7422e+00,\n        -2.6969e+00, -5.3124e+00, -4.5145e+00, -1.8847e+00, -6.2179e-01,\n        -6.3095e-01, -7.1701e-01, -2.9350e+00,  2.7438e+00, -4.4784e+00,\n        -3.6555e+00, -6.2094e+00, -7.5887e-01,  3.0667e+00,  4.8431e+00,\n         4.9224e+00, -2.5112e+00,  4.9243e+00,  2.4219e+00,  9.4010e-01,\n         1.2070e+01,  4.5208e+00,  1.3864e+00,  1.7553e-01,  1.6680e+00,\n        -1.5285e+00,  1.5025e+00, -5.5577e-01, -8.2873e-02,  3.9703e-01,\n        -1.1700e+00, -4.8657e-01,  1.8344e+00,  4.6074e+00, -1.0295e+00,\n         3.6750e+00,  6.4844e+00,  5.8971e+00,  2.1285e+00, -1.0526e+00,\n         5.4321e+00,  3.2874e-01,  7.0860e-01,  1.1264e+00, -1.8035e+00,\n         3.5322e+00,  1.9276e+00,  2.5874e+00, -6.4238e-02,  6.9838e+00,\n        -1.9454e+00,  7.7168e-01,  4.3062e+00, -6.3883e-01], device='cuda:0')\n\u001b[32m2023-08-14 17:39:25.746\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:39:25.754\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 3.5384e+01,  5.0058e+01,  6.8095e-01,  1.9464e+00,  1.3615e+00,\n         8.1402e-01,  1.7635e+00, -2.2905e+00, -7.8858e-04,  2.9170e+00,\n         1.7123e+00,  7.9068e-01,  5.8406e-01,  1.5640e+00,  2.9933e+00,\n        -2.5480e+00,  4.0337e-02, -4.4394e+00, -7.8668e+00, -1.8086e+00,\n         5.2218e+00,  3.5301e-01,  3.9807e+00, -1.1590e+00,  6.8693e+00,\n        -2.8089e-01, -1.6638e+00,  2.5033e+00,  2.6319e-01,  1.3191e+00,\n        -1.1854e+00, -2.4768e+00, -4.4804e+00, -5.5873e+00, -3.5311e+00,\n        -3.2615e+00, -4.1940e+00, -2.1586e+00, -8.4537e+00,  3.8591e+00,\n         2.2314e+00, -7.8720e-01, -4.9754e+00,  3.9027e+00, -1.5077e-01,\n        -3.1091e+00, -7.6081e+00,  7.9604e-01, -4.2227e+00, -4.0990e+00,\n        -2.8530e+00,  3.2068e+00, -2.7560e+00,  3.8508e+00,  2.1539e+00,\n         1.7747e-01,  3.8236e+00,  1.9516e-01,  7.1977e+00,  6.2626e+00,\n         5.0000e+00,  4.2961e+00,  4.1876e-01, -4.5874e+00,  2.5201e+00,\n        -2.8614e+00, -7.2665e+00, -4.6104e+00,  1.6369e+00,  7.7523e-01,\n        -4.6318e+00, -1.1113e+00, -9.2176e-01, -4.7566e+00, -1.2408e+00,\n        -3.2461e+00, -7.7155e+00, -3.6563e+00, -4.8742e+00,  3.0697e+00,\n         1.4912e+00, -7.8052e+00, -7.1688e+00, -2.2836e+00, -8.5225e-02,\n        -8.2321e+00,  9.2266e+00,  1.2223e+00, -5.4340e+00,  7.3664e-01,\n        -2.7946e+00,  9.7875e-01,  4.4205e+00, -9.8863e+00,  1.2974e+00,\n         1.8177e+00, -9.8730e-01,  6.5883e+00,  1.9431e+00,  9.7176e+00,\n         5.8968e+00,  4.9855e+00,  2.2763e+00,  4.1304e+00,  3.7189e-01,\n         3.7374e+00,  1.2785e+00, -3.4809e+00,  5.2487e+00,  2.1868e+00,\n         6.3101e-02,  4.6017e+00,  1.2390e+00,  5.9604e-01,  5.7727e+00,\n        -3.8627e+00, -3.9997e+00, -1.9158e+00,  2.8297e-01,  2.8779e+00,\n        -7.0650e-01,  5.2284e+00,  8.9841e-01, -4.9915e+00, -4.0187e+00,\n         1.5183e+00,  2.2027e+00,  3.6264e-01, -5.8885e+00,  1.2816e+00,\n         2.2940e+00,  1.7781e+00,  3.9965e+00, -4.5048e+00, -5.5717e+00,\n        -7.1238e-01, -5.6328e+00, -4.5825e+00,  4.9471e+00,  2.2498e+00,\n         7.3431e-01,  5.5481e+00,  4.0181e+00,  1.8004e+00,  1.8189e+00,\n         4.5354e+00, -3.0804e-01, -9.4520e+00, -6.2038e+00, -4.5433e+00,\n        -5.6427e+00, -2.1343e+00, -4.6299e+00, -4.6172e+00, -5.5827e+00,\n        -3.7672e+00, -7.6589e+00, -4.2830e+00, -2.0528e+00, -5.4912e+00,\n        -2.5357e-01, -1.9053e+00, -4.3033e-01,  2.3468e+00,  2.0265e+00,\n         1.6793e+00,  1.3936e+00,  3.8154e+00, -9.6328e-01,  2.0009e-01,\n        -3.3534e+00,  1.5751e+00,  1.9530e+00, -2.2724e-01,  3.9244e+00,\n        -2.9468e-01, -6.4086e-01,  2.0149e+00, -4.0250e+00,  2.4175e-01,\n         3.2579e+00, -1.4480e+00,  5.0554e-01,  1.0299e+00,  3.7422e+00,\n        -2.6969e+00, -5.3124e+00, -4.5145e+00, -1.8847e+00, -6.2179e-01,\n        -6.3095e-01, -7.1701e-01, -2.9350e+00,  2.7438e+00, -4.4784e+00,\n        -3.6555e+00, -6.2094e+00, -7.5887e-01,  3.0667e+00,  4.8431e+00,\n         4.9224e+00, -2.5112e+00,  4.9243e+00,  2.4219e+00,  9.4010e-01,\n         1.2070e+01,  4.5208e+00,  1.3864e+00,  1.7553e-01,  1.6680e+00,\n        -1.5285e+00,  1.5025e+00, -5.5577e-01, -8.2873e-02,  3.9703e-01,\n        -1.1700e+00, -4.8657e-01,  1.8344e+00,  4.6074e+00, -1.0295e+00,\n         3.6750e+00,  6.4844e+00,  5.8971e+00,  2.1285e+00, -1.0526e+00,\n         5.4321e+00,  3.2874e-01,  7.0860e-01,  1.1264e+00, -1.8035e+00,\n         3.5322e+00,  1.9276e+00,  2.5874e+00, -6.4238e-02,  6.9838e+00,\n        -1.9454e+00,  7.7168e-01,  4.3062e+00, -6.3883e-01], device='cuda:0')]\u001b[0m\nscores=[tensor([ 3.5384e+01,  5.0058e+01,  6.8095e-01,  1.9464e+00,  1.3615e+00,\n         8.1402e-01,  1.7635e+00, -2.2905e+00, -7.8858e-04,  2.9170e+00,\n         1.7123e+00,  7.9068e-01,  5.8406e-01,  1.5640e+00,  2.9933e+00,\n        -2.5480e+00,  4.0337e-02, -4.4394e+00, -7.8668e+00, -1.8086e+00,\n         5.2218e+00,  3.5301e-01,  3.9807e+00, -1.1590e+00,  6.8693e+00,\n        -2.8089e-01, -1.6638e+00,  2.5033e+00,  2.6319e-01,  1.3191e+00,\n        -1.1854e+00, -2.4768e+00, -4.4804e+00, -5.5873e+00, -3.5311e+00,\n        -3.2615e+00, -4.1940e+00, -2.1586e+00, -8.4537e+00,  3.8591e+00,\n         2.2314e+00, -7.8720e-01, -4.9754e+00,  3.9027e+00, -1.5077e-01,\n        -3.1091e+00, -7.6081e+00,  7.9604e-01, -4.2227e+00, -4.0990e+00,\n        -2.8530e+00,  3.2068e+00, -2.7560e+00,  3.8508e+00,  2.1539e+00,\n         1.7747e-01,  3.8236e+00,  1.9516e-01,  7.1977e+00,  6.2626e+00,\n         5.0000e+00,  4.2961e+00,  4.1876e-01, -4.5874e+00,  2.5201e+00,\n        -2.8614e+00, -7.2665e+00, -4.6104e+00,  1.6369e+00,  7.7523e-01,\n        -4.6318e+00, -1.1113e+00, -9.2176e-01, -4.7566e+00, -1.2408e+00,\n        -3.2461e+00, -7.7155e+00, -3.6563e+00, -4.8742e+00,  3.0697e+00,\n         1.4912e+00, -7.8052e+00, -7.1688e+00, -2.2836e+00, -8.5225e-02,\n        -8.2321e+00,  9.2266e+00,  1.2223e+00, -5.4340e+00,  7.3664e-01,\n        -2.7946e+00,  9.7875e-01,  4.4205e+00, -9.8863e+00,  1.2974e+00,\n         1.8177e+00, -9.8730e-01,  6.5883e+00,  1.9431e+00,  9.7176e+00,\n         5.8968e+00,  4.9855e+00,  2.2763e+00,  4.1304e+00,  3.7189e-01,\n         3.7374e+00,  1.2785e+00, -3.4809e+00,  5.2487e+00,  2.1868e+00,\n         6.3101e-02,  4.6017e+00,  1.2390e+00,  5.9604e-01,  5.7727e+00,\n        -3.8627e+00, -3.9997e+00, -1.9158e+00,  2.8297e-01,  2.8779e+00,\n        -7.0650e-01,  5.2284e+00,  8.9841e-01, -4.9915e+00, -4.0187e+00,\n         1.5183e+00,  2.2027e+00,  3.6264e-01, -5.8885e+00,  1.2816e+00,\n         2.2940e+00,  1.7781e+00,  3.9965e+00, -4.5048e+00, -5.5717e+00,\n        -7.1238e-01, -5.6328e+00, -4.5825e+00,  4.9471e+00,  2.2498e+00,\n         7.3431e-01,  5.5481e+00,  4.0181e+00,  1.8004e+00,  1.8189e+00,\n         4.5354e+00, -3.0804e-01, -9.4520e+00, -6.2038e+00, -4.5433e+00,\n        -5.6427e+00, -2.1343e+00, -4.6299e+00, -4.6172e+00, -5.5827e+00,\n        -3.7672e+00, -7.6589e+00, -4.2830e+00, -2.0528e+00, -5.4912e+00,\n        -2.5357e-01, -1.9053e+00, -4.3033e-01,  2.3468e+00,  2.0265e+00,\n         1.6793e+00,  1.3936e+00,  3.8154e+00, -9.6328e-01,  2.0009e-01,\n        -3.3534e+00,  1.5751e+00,  1.9530e+00, -2.2724e-01,  3.9244e+00,\n        -2.9468e-01, -6.4086e-01,  2.0149e+00, -4.0250e+00,  2.4175e-01,\n         3.2579e+00, -1.4480e+00,  5.0554e-01,  1.0299e+00,  3.7422e+00,\n        -2.6969e+00, -5.3124e+00, -4.5145e+00, -1.8847e+00, -6.2179e-01,\n        -6.3095e-01, -7.1701e-01, -2.9350e+00,  2.7438e+00, -4.4784e+00,\n        -3.6555e+00, -6.2094e+00, -7.5887e-01,  3.0667e+00,  4.8431e+00,\n         4.9224e+00, -2.5112e+00,  4.9243e+00,  2.4219e+00,  9.4010e-01,\n         1.2070e+01,  4.5208e+00,  1.3864e+00,  1.7553e-01,  1.6680e+00,\n        -1.5285e+00,  1.5025e+00, -5.5577e-01, -8.2873e-02,  3.9703e-01,\n        -1.1700e+00, -4.8657e-01,  1.8344e+00,  4.6074e+00, -1.0295e+00,\n         3.6750e+00,  6.4844e+00,  5.8971e+00,  2.1285e+00, -1.0526e+00,\n         5.4321e+00,  3.2874e-01,  7.0860e-01,  1.1264e+00, -1.8035e+00,\n         3.5322e+00,  1.9276e+00,  2.5874e+00, -6.4238e-02,  6.9838e+00,\n        -1.9454e+00,  7.7168e-01,  4.3062e+00, -6.3883e-01], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 3.1211e+01,  4.5522e+01,  1.6436e-01,  9.6135e-01,  1.2761e+00,\n          1.2696e+00,  1.1716e+00, -9.1463e-01, -2.2497e-01,  2.7416e+00,\n         -8.7301e-01,  4.1589e-01,  1.3854e+00,  6.5045e-01,  2.7054e+00,\n          3.9980e-01, -6.1915e+00, -5.1661e+00, -9.8207e+00, -1.6042e+00,\n          6.2683e+00, -7.3922e-01,  5.3606e+00, -1.9704e+00,  7.0669e+00,\n         -2.0730e-01, -1.1255e+00,  3.2430e+00,  2.0269e+00,  2.2452e+00,\n         -2.6889e+00, -3.4052e+00, -5.1765e+00, -7.7592e+00, -2.9649e+00,\n         -5.9822e+00, -6.3534e+00, -2.2813e+00, -5.8214e+00,  2.0209e+00,\n          3.0680e+00, -5.0825e+00, -5.0216e+00,  1.6910e+00, -4.5441e-01,\n         -5.5027e+00, -7.4242e+00, -3.8361e-01, -4.4225e+00, -3.2712e+00,\n         -3.9204e+00,  2.2645e+00, -4.7320e+00,  8.2879e-01,  1.1394e+00,\n         -3.5837e-01,  4.8114e+00,  1.6250e+00,  3.6314e+00,  7.6020e+00,\n          7.0621e+00,  2.9083e+00,  1.0194e+00, -5.6061e+00,  3.8385e-01,\n         -1.5436e+00, -9.2267e+00, -7.3559e+00,  1.5570e-01,  1.7452e+00,\n         -4.8076e+00, -3.4682e-01,  2.3502e+00, -5.0079e+00, -3.2381e+00,\n         -1.2702e+00, -5.7357e+00, -4.0934e+00,  5.5501e-02,  1.7414e+00,\n         -8.7333e-01, -7.2226e+00, -3.7184e+00, -2.9318e+00, -1.9082e+00,\n         -7.0818e+00,  7.8098e+00,  3.6551e+00, -5.4682e+00,  1.5950e+00,\n         -1.3648e+00, -2.3578e+00,  1.8502e+00, -5.6030e+00,  2.1879e+00,\n          1.9457e+00,  1.3518e+00,  6.2824e+00,  1.3951e+00,  6.9878e+00,\n          9.4144e+00,  4.1591e+00,  2.8843e+00,  4.3518e+00,  2.2455e+00,\n          2.2283e+00,  2.8350e+00, -1.2496e+00,  8.5089e+00,  5.3941e+00,\n          4.1590e-01,  3.2582e+00,  1.9481e-03,  2.4552e-01,  1.2704e+00,\n         -3.0934e+00, -3.6702e+00, -2.8260e-01,  2.5003e+00,  5.0305e+00,\n          2.3934e+00,  3.8940e+00,  1.1248e+00, -4.8557e+00, -2.0404e+00,\n          5.2965e-01,  3.4502e+00, -3.0200e+00, -4.6796e+00,  1.0073e+00,\n          3.5620e+00,  2.6054e+00,  4.1466e+00, -2.3250e+00, -6.9318e+00,\n         -3.8046e+00, -4.6638e+00, -6.1569e+00,  2.6038e+00,  4.2944e-01,\n          1.1887e+00,  5.3816e+00,  1.8135e+00,  3.2059e+00,  1.1080e+00,\n          1.7449e+00, -2.0816e+00, -1.1112e+01, -2.5759e+00, -2.1706e+00,\n         -6.1675e+00, -2.9750e+00, -2.4698e+00, -6.6798e+00, -6.1234e+00,\n         -5.0002e+00, -9.1649e+00, -2.2537e+00, -3.1447e+00, -4.6043e+00,\n         -6.3591e+00, -4.2527e+00, -7.4204e-01,  3.1586e+00,  5.3873e-02,\n          9.4110e-01, -1.0903e-01,  1.8663e+00,  1.5226e+00, -5.1017e+00,\n         -2.0978e+00,  2.0543e+00, -4.1332e-01, -7.2241e-01,  1.9150e+00,\n         -2.8508e+00, -2.3268e+00,  1.7644e+00, -4.6723e+00, -5.2540e-01,\n          1.9460e+00, -2.5233e+00, -1.2221e+00,  4.9274e-01,  3.1672e+00,\n         -2.1654e+00, -6.2173e+00, -7.8589e+00,  5.8090e-01, -1.7086e+00,\n          8.5250e-01, -1.6993e+00, -3.8842e+00,  1.6018e-01, -7.7141e+00,\n         -2.3708e+00, -6.1425e+00,  1.4201e+00,  2.0133e+00,  6.0490e+00,\n          3.0114e+00, -2.9382e+00,  5.6202e+00,  9.6692e-01,  8.2350e-01,\n          1.0119e+01,  3.4635e+00,  4.3237e+00,  6.1988e-01,  6.0725e-01,\n         -3.6170e+00,  1.3022e+00,  7.9182e-01, -1.2839e+00,  1.7525e+00,\n          2.4359e-01, -7.2675e-01,  2.3575e+00,  7.1970e+00, -7.5465e-01,\n          1.7277e+00,  5.1426e+00,  1.2213e+00,  8.2796e-01, -4.6687e-01,\n          3.1978e+00, -1.1939e+00,  1.1542e+00,  1.6538e+00, -3.8746e+00,\n          2.8516e+00,  7.6335e-01,  6.8216e-01, -1.0172e-01,  5.9168e+00,\n          1.4364e-01,  1.6663e-01,  3.1250e+00, -7.6574e-01]], device='cuda:0')\nvalues_994 = tensor([[ 3.3911e+01,  3.5774e+01,  9.3126e-01,  1.9360e+00,  2.0424e+00,\n          6.8100e-01, -8.6616e-03, -3.8829e+00, -6.1322e-01,  3.5868e+00,\n          2.1389e+00, -1.1687e+00,  3.1907e-01,  2.8580e-01,  1.9316e+00,\n         -5.4799e-01, -1.3523e+00, -3.7272e+00, -7.9369e+00, -2.6181e+00,\n          6.3482e+00,  2.1305e+00,  2.5782e+00, -3.6364e+00,  5.2137e+00,\n          2.6063e+00, -5.0561e-01,  3.4553e-01,  1.4614e+00,  4.5565e-01,\n         -1.4094e+00, -3.0055e+00, -4.6700e+00, -4.4939e+00, -2.6144e+00,\n         -6.9901e+00, -5.0249e+00, -2.5343e+00, -5.6848e+00,  2.8417e+00,\n          1.5025e+00, -3.4521e+00, -4.2951e+00,  3.0521e-01,  2.7428e-01,\n         -1.6130e+00, -8.1272e+00, -1.6716e-01, -4.5050e+00, -3.3269e+00,\n         -2.6296e+00,  4.9409e+00,  1.3006e-01,  2.8792e+00,  2.3260e+00,\n          1.1693e-01,  4.7992e+00,  1.5982e-01,  5.1221e+00,  9.1667e+00,\n          5.1658e+00,  3.1332e+00,  1.1547e+00, -4.5719e+00,  2.2661e+00,\n         -3.6022e+00, -1.2017e+01, -8.4698e+00,  1.2135e+00,  4.0770e-01,\n         -4.8419e+00, -7.2771e-01,  1.1734e+00, -4.0675e+00, -1.4480e+00,\n         -5.5778e-01, -5.3663e+00, -3.3630e+00, -1.5166e+00,  5.6827e-01,\n         -1.7983e+00, -8.5232e+00, -6.1070e+00, -3.3863e+00, -3.4492e+00,\n         -8.5186e+00,  5.7608e+00,  7.2610e-03, -6.9626e+00,  7.7665e-01,\n         -2.3476e+00, -4.2155e-01,  1.2620e+00, -9.1671e+00, -2.2590e-02,\n          4.5407e-01,  2.5698e+00,  6.8138e+00,  3.9623e+00,  9.3829e+00,\n          4.8222e+00,  4.4018e+00, -6.8960e-01, -3.9054e-01,  5.2977e-01,\n          3.7554e+00,  1.9196e+00, -2.2697e+00,  5.8454e+00,  3.8775e+00,\n          1.3521e-01,  4.1313e+00,  1.7635e+00, -7.7487e-01,  3.8003e+00,\n         -2.7723e+00, -5.4525e+00, -8.2739e-01,  3.1395e+00,  5.6844e+00,\n          6.9012e-01,  5.5566e+00,  2.7499e-01, -4.8633e+00, -3.2936e+00,\n          1.6617e+00,  6.4685e+00,  1.7554e+00, -7.0797e+00,  1.0770e+00,\n          1.4035e+00,  1.7564e-01,  2.8547e+00, -4.8871e+00, -5.3579e+00,\n         -1.2112e+00, -6.1315e+00, -5.9004e+00,  3.5506e+00,  2.5982e+00,\n         -2.5123e-01,  3.9763e+00,  2.6336e+00,  3.9098e+00, -7.1817e-02,\n          3.9317e+00, -3.6079e-02, -7.8637e+00, -4.7008e+00, -8.3241e-01,\n         -4.8493e+00, -3.0710e+00, -5.1462e+00, -6.7654e+00, -4.9921e+00,\n         -4.6397e+00, -7.9926e+00, -5.3584e+00, -2.7181e+00, -5.6338e+00,\n         -4.0376e+00, -5.0046e+00, -2.8091e-01,  3.0500e+00,  1.3041e+00,\n          3.6243e+00,  2.2336e-01,  2.6877e+00,  2.6282e+00, -2.2207e+00,\n         -9.7019e-02,  1.3931e+00,  1.5200e+00, -4.7341e-01,  2.2507e+00,\n         -8.5110e-01, -1.1871e+00,  2.4530e+00, -3.8905e+00,  2.3497e-01,\n          2.0903e+00, -2.7980e+00, -4.9831e-01, -1.4568e+00,  5.2916e+00,\n         -2.5493e+00, -5.9506e+00, -5.0621e+00, -1.1813e+00, -2.0259e+00,\n         -7.9237e-01, -2.6517e+00, -2.3286e+00,  1.0143e+00, -6.5175e+00,\n         -2.2984e+00, -7.4704e+00,  1.1867e+00,  3.5256e+00,  4.3941e+00,\n          4.4314e+00, -3.0067e+00,  5.9855e+00,  2.1214e+00,  3.0202e+00,\n          1.0808e+01,  4.1885e+00,  4.2129e+00, -5.9637e-01,  1.2291e+00,\n         -1.9442e+00,  3.3401e-01,  1.6526e+00, -4.4062e-01,  2.4164e+00,\n          1.4640e-01, -1.9447e+00,  1.6416e+00,  6.1052e+00,  7.5309e-01,\n          3.4726e+00,  4.2624e+00,  5.5328e+00,  5.4601e-02, -1.8997e+00,\n          5.3806e+00, -2.0396e+00,  2.2979e+00,  2.7407e+00, -1.9009e-01,\n          6.4183e+00,  2.6967e-01,  3.2188e+00,  7.4074e-01,  4.1640e+00,\n         -3.1747e+00,  1.1866e+00,  3.5873e+00, -4.5504e-01]], device='cuda:0')\nreward[last_non_masked_index]=tensor([-1.9208e-05], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 3.5384e+01,  5.0058e+01,  6.8095e-01,  1.9464e+00,  1.3615e+00,\n         8.1402e-01,  1.7635e+00, -2.2905e+00, -7.8858e-04,  2.9170e+00,\n         1.7123e+00,  7.9068e-01,  5.8406e-01,  1.5640e+00,  2.9933e+00,\n        -2.5480e+00,  4.0337e-02, -4.4394e+00, -7.8668e+00, -1.8086e+00,\n         5.2218e+00,  3.5301e-01,  3.9807e+00, -1.1590e+00,  6.8693e+00,\n        -2.8089e-01, -1.6638e+00,  2.5033e+00,  2.6319e-01,  1.3191e+00,\n        -1.1854e+00, -2.4768e+00, -4.4804e+00, -5.5873e+00, -3.5311e+00,\n        -3.2615e+00, -4.1940e+00, -2.1586e+00, -8.4537e+00,  3.8591e+00,\n         2.2314e+00, -7.8720e-01, -4.9754e+00,  3.9027e+00, -1.5077e-01,\n        -3.1091e+00, -7.6081e+00,  7.9604e-01, -4.2227e+00, -4.0990e+00,\n        -2.8530e+00,  3.2068e+00, -2.7560e+00,  3.8508e+00,  2.1539e+00,\n         1.7747e-01,  3.8236e+00,  1.9516e-01,  7.1977e+00,  6.2626e+00,\n         5.0000e+00,  4.2961e+00,  4.1876e-01, -4.5874e+00,  2.5201e+00,\n        -2.8614e+00, -7.2665e+00, -4.6104e+00,  1.6369e+00,  7.7523e-01,\n        -4.6318e+00, -1.1113e+00, -9.2176e-01, -4.7566e+00, -1.2408e+00,\n        -3.2461e+00, -7.7155e+00, -3.6563e+00, -4.8742e+00,  3.0697e+00,\n         1.4912e+00, -7.8052e+00, -7.1688e+00, -2.2836e+00, -8.5225e-02,\n        -8.2321e+00,  9.2266e+00,  1.2223e+00, -5.4340e+00,  7.3664e-01,\n        -2.7946e+00,  9.7875e-01,  4.4205e+00, -9.8863e+00,  1.2974e+00,\n         1.8177e+00, -9.8730e-01,  6.5883e+00,  1.9431e+00,  9.7176e+00,\n         5.8968e+00,  4.9855e+00,  2.2763e+00,  4.1304e+00,  3.7189e-01,\n         3.7374e+00,  1.2785e+00, -3.4809e+00,  5.2487e+00,  2.1868e+00,\n         6.3101e-02,  4.6017e+00,  1.2390e+00,  5.9604e-01,  5.7727e+00,\n        -3.8627e+00, -3.9997e+00, -1.9158e+00,  2.8297e-01,  2.8779e+00,\n        -7.0650e-01,  5.2284e+00,  8.9841e-01, -4.9915e+00, -4.0187e+00,\n         1.5183e+00,  2.2027e+00,  3.6264e-01, -5.8885e+00,  1.2816e+00,\n         2.2940e+00,  1.7781e+00,  3.9965e+00, -4.5048e+00, -5.5717e+00,\n        -7.1238e-01, -5.6328e+00, -4.5825e+00,  4.9471e+00,  2.2498e+00,\n         7.3431e-01,  5.5481e+00,  4.0181e+00,  1.8004e+00,  1.8189e+00,\n         4.5354e+00, -3.0804e-01, -9.4520e+00, -6.2038e+00, -4.5433e+00,\n        -5.6427e+00, -2.1343e+00, -4.6299e+00, -4.6172e+00, -5.5827e+00,\n        -3.7672e+00, -7.6589e+00, -4.2830e+00, -2.0528e+00, -5.4912e+00,\n        -2.5357e-01, -1.9053e+00, -4.3033e-01,  2.3468e+00,  2.0265e+00,\n         1.6793e+00,  1.3936e+00,  3.8154e+00, -9.6328e-01,  2.0009e-01,\n        -3.3534e+00,  1.5751e+00,  1.9530e+00, -2.2724e-01,  3.9244e+00,\n        -2.9468e-01, -6.4086e-01,  2.0149e+00, -4.0250e+00,  2.4175e-01,\n         3.2579e+00, -1.4480e+00,  5.0554e-01,  1.0299e+00,  3.7422e+00,\n        -2.6969e+00, -5.3124e+00, -4.5145e+00, -1.8847e+00, -6.2179e-01,\n        -6.3095e-01, -7.1701e-01, -2.9350e+00,  2.7438e+00, -4.4784e+00,\n        -3.6555e+00, -6.2094e+00, -7.5887e-01,  3.0667e+00,  4.8431e+00,\n         4.9224e+00, -2.5112e+00,  4.9243e+00,  2.4219e+00,  9.4010e-01,\n         1.2070e+01,  4.5208e+00,  1.3864e+00,  1.7553e-01,  1.6680e+00,\n        -1.5285e+00,  1.5025e+00, -5.5577e-01, -8.2873e-02,  3.9703e-01,\n        -1.1700e+00, -4.8657e-01,  1.8344e+00,  4.6074e+00, -1.0295e+00,\n         3.6750e+00,  6.4844e+00,  5.8971e+00,  2.1285e+00, -1.0526e+00,\n         5.4321e+00,  3.2874e-01,  7.0860e-01,  1.1264e+00, -1.8035e+00,\n         3.5322e+00,  1.9276e+00,  2.5874e+00, -6.4238e-02,  6.9838e+00,\n        -1.9454e+00,  7.7168e-01,  4.3062e+00, -6.3883e-01], device='cuda:0')\nvalues=tensor([[ 3.1211e+01,  4.5522e+01,  1.6436e-01,  9.6135e-01,  1.2761e+00,\n          1.2696e+00,  1.1716e+00, -9.1463e-01, -2.2497e-01,  2.7416e+00,\n         -8.7301e-01,  4.1589e-01,  1.3854e+00,  6.5045e-01,  2.7054e+00,\n          3.9980e-01, -6.1915e+00, -5.1661e+00, -9.8207e+00, -1.6042e+00,\n          6.2683e+00, -7.3922e-01,  5.3606e+00, -1.9704e+00,  7.0669e+00,\n         -2.0730e-01, -1.1255e+00,  3.2430e+00,  2.0269e+00,  2.2452e+00,\n         -2.6889e+00, -3.4052e+00, -5.1765e+00, -7.7592e+00, -2.9649e+00,\n         -5.9822e+00, -6.3534e+00, -2.2813e+00, -5.8214e+00,  2.0209e+00,\n          3.0680e+00, -5.0825e+00, -5.0216e+00,  1.6910e+00, -4.5441e-01,\n         -5.5027e+00, -7.4242e+00, -3.8361e-01, -4.4225e+00, -3.2712e+00,\n         -3.9204e+00,  2.2645e+00, -4.7320e+00,  8.2879e-01,  1.1394e+00,\n         -3.5837e-01,  4.8114e+00,  1.6250e+00,  3.6314e+00,  7.6020e+00,\n          7.0621e+00,  2.9083e+00,  1.0194e+00, -5.6061e+00,  3.8385e-01,\n         -1.5436e+00, -9.2267e+00, -7.3559e+00,  1.5570e-01,  1.7452e+00,\n         -4.8076e+00, -3.4682e-01,  2.3502e+00, -5.0079e+00, -3.2381e+00,\n         -1.2702e+00, -5.7357e+00, -4.0934e+00,  5.5501e-02,  1.7414e+00,\n         -8.7333e-01, -7.2226e+00, -3.7184e+00, -2.9318e+00, -1.9082e+00,\n         -7.0818e+00,  7.8098e+00,  3.6551e+00, -5.4682e+00,  1.5950e+00,\n         -1.3648e+00, -2.3578e+00,  1.8502e+00, -5.6030e+00,  2.1879e+00,\n          1.9457e+00,  1.3518e+00,  6.2824e+00,  1.3951e+00,  6.9878e+00,\n          9.4144e+00,  4.1591e+00,  2.8843e+00,  4.3518e+00,  2.2455e+00,\n          2.2283e+00,  2.8350e+00, -1.2496e+00,  8.5089e+00,  5.3941e+00,\n          4.1590e-01,  3.2582e+00,  1.9481e-03,  2.4552e-01,  1.2704e+00,\n         -3.0934e+00, -3.6702e+00, -2.8260e-01,  2.5003e+00,  5.0305e+00,\n          2.3934e+00,  3.8940e+00,  1.1248e+00, -4.8557e+00, -2.0404e+00,\n          5.2965e-01,  3.4502e+00, -3.0200e+00, -4.6796e+00,  1.0073e+00,\n          3.5620e+00,  2.6054e+00,  4.1466e+00, -2.3250e+00, -6.9318e+00,\n         -3.8046e+00, -4.6638e+00, -6.1569e+00,  2.6038e+00,  4.2944e-01,\n          1.1887e+00,  5.3816e+00,  1.8135e+00,  3.2059e+00,  1.1080e+00,\n          1.7449e+00, -2.0816e+00, -1.1112e+01, -2.5759e+00, -2.1706e+00,\n         -6.1675e+00, -2.9750e+00, -2.4698e+00, -6.6798e+00, -6.1234e+00,\n         -5.0002e+00, -9.1649e+00, -2.2537e+00, -3.1447e+00, -4.6043e+00,\n         -6.3591e+00, -4.2527e+00, -7.4204e-01,  3.1586e+00,  5.3873e-02,\n          9.4110e-01, -1.0903e-01,  1.8663e+00,  1.5226e+00, -5.1017e+00,\n         -2.0978e+00,  2.0543e+00, -4.1332e-01, -7.2241e-01,  1.9150e+00,\n         -2.8508e+00, -2.3268e+00,  1.7644e+00, -4.6723e+00, -5.2540e-01,\n          1.9460e+00, -2.5233e+00, -1.2221e+00,  4.9274e-01,  3.1672e+00,\n         -2.1654e+00, -6.2173e+00, -7.8589e+00,  5.8090e-01, -1.7086e+00,\n          8.5250e-01, -1.6993e+00, -3.8842e+00,  1.6018e-01, -7.7141e+00,\n         -2.3708e+00, -6.1425e+00,  1.4201e+00,  2.0133e+00,  6.0490e+00,\n          3.0114e+00, -2.9382e+00,  5.6202e+00,  9.6692e-01,  8.2350e-01,\n          1.0119e+01,  3.4635e+00,  4.3237e+00,  6.1988e-01,  6.0725e-01,\n         -3.6170e+00,  1.3022e+00,  7.9182e-01, -1.2839e+00,  1.7525e+00,\n          2.4359e-01, -7.2675e-01,  2.3575e+00,  7.1970e+00, -7.5465e-01,\n          1.7277e+00,  5.1426e+00,  1.2213e+00,  8.2796e-01, -4.6687e-01,\n          3.1978e+00, -1.1939e+00,  1.1542e+00,  1.6538e+00, -3.8746e+00,\n          2.8516e+00,  7.6335e-01,  6.8216e-01, -1.0172e-01,  5.9168e+00,\n          1.4364e-01,  1.6663e-01,  3.1250e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -1.6083e-06,  1.3828e-03, -0.0000e+00,  1.1601e-03,\n         -2.8429e-03, -5.5373e-05, -0.0000e+00, -2.4468e-04,  1.0559e-03,\n          6.9305e-04,  4.7652e-07, -0.0000e+00,  4.3786e-03, -7.8243e-04,\n          1.3569e-04, -7.8854e-04,  2.6328e-05, -7.8440e-05, -4.2111e-04,\n          2.4319e-03,  1.6108e-03,  3.0085e-05,  4.4836e-04,  2.4859e-03,\n          3.1229e-03, -1.0657e-04, -3.2721e-03,  1.9844e-03,  1.6868e-05,\n         -9.5343e-07, -8.3518e-04, -2.9913e-04, -5.2512e-04,  7.4112e-04,\n         -0.0000e+00,  4.7851e-04,  6.6276e-04,  1.6145e-03,  5.0402e-04,\n          3.1937e-03, -8.4490e-06, -4.8068e-03, -1.0136e-03, -1.1579e-04,\n          5.9604e-08, -0.0000e+00,  5.9604e-08, -0.0000e+00,  1.0125e-06,\n         -0.0000e+00,  7.1246e-07, -5.5439e-03,  4.2821e-06, -1.5395e-06,\n          1.3700e-06, -4.9831e-04, -1.0946e-03, -2.9786e-03, -2.2551e-04,\n          2.0933e-03,  1.0573e-04,  4.8545e-03, -1.1165e-04,  1.9941e-03,\n          5.0716e-03, -0.0000e+00,  7.5905e-06,  2.1652e-04,  1.6985e-04,\n          3.1304e-05, -1.0294e-03, -3.5256e-04, -1.7270e-03, -6.5230e-05,\n         -2.3840e-07,  5.9601e-08, -9.5216e-07, -3.5172e-05, -0.0000e+00,\n          2.2601e-06, -0.0000e+00, -1.0715e-06, -2.3458e-03, -2.9157e-03,\n         -7.5583e-04,  1.2456e-06,  7.1467e-07,  2.7249e-03, -1.2803e-04,\n          3.7740e-04, -4.9566e-04, -3.6843e-04, -5.4890e-05, -8.0618e-04,\n         -3.4750e-05, -1.5900e-05,  1.1919e-07, -0.0000e+00,  2.9744e-07,\n         -2.2043e-06, -5.5110e-04,  1.2124e-03, -4.0001e-04,  7.7367e-05,\n         -2.4338e-06, -1.1549e-05, -0.0000e+00,  7.1494e-07,  5.3138e-05,\n         -0.0000e+00,  2.2592e-06,  1.2794e-04, -4.0057e-04, -0.0000e+00,\n         -5.5015e-05,  2.1617e-03, -2.2554e-06, -6.3197e-05,  2.5894e-03,\n          7.2631e-05, -5.3612e-07,  1.7916e-03,  4.0948e-05,  1.1941e-05,\n          1.4671e-04,  7.0997e-05,  3.1535e-06, -1.6813e-05,  3.3285e-06,\n         -2.6200e-06, -2.3307e-05, -2.3068e-05, -0.0000e+00,  7.1244e-03,\n          4.6486e-05,  5.9604e-08,  1.2119e-03, -4.2033e-04,  1.9851e-04,\n         -1.3208e-04,  4.3500e-05, -2.6178e-06, -1.7877e-07, -3.0260e-04,\n         -5.9603e-08, -2.2939e-03,  5.9603e-08, -3.0184e-06,  1.5171e-03,\n          5.4140e-04, -2.7984e-06,  1.5894e-03,  2.4462e-03, -7.4659e-06,\n          1.1919e-07, -1.4931e-03, -5.2035e-05,  2.6349e-05,  1.1747e-03,\n          8.1565e-06, -4.8270e-04,  2.0602e-05,  2.3136e-03,  1.7415e-03,\n          1.7775e-03,  4.2561e-04, -8.9876e-05, -1.3676e-06, -4.8346e-05,\n          2.8840e-04, -0.0000e+00, -6.3885e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n       device='cuda:0')\nvalues_994 = tensor([[ 1.6578e+01,  5.3175e+01,  7.8924e-01,  6.1080e-01,  1.4522e+00,\n          9.6180e-01,  2.2693e+00, -3.1758e+00, -3.0533e+00,  5.1893e+00,\n          3.0594e-01,  2.2493e+00,  1.0127e+00, -7.1317e-01,  1.8155e+00,\n         -5.1202e-01, -2.0125e-01, -4.9505e+00, -5.2470e+00, -3.0933e+00,\n          4.0260e+00, -1.4168e+00,  4.2644e+00, -2.0207e+00,  4.5205e+00,\n         -7.9498e-02,  9.1551e-01,  7.3658e-01,  1.3239e+00,  1.0073e+00,\n         -6.0520e-01, -2.3599e+00, -4.4329e+00, -3.5233e+00, -1.8815e+00,\n         -2.6743e+00, -5.4764e+00, -2.5094e+00, -6.2327e+00,  4.2094e+00,\n          1.6420e+00, -1.5978e+00, -4.6686e+00,  3.8137e+00, -4.7734e-01,\n         -4.2479e+00, -6.1508e+00,  8.0522e-01, -4.0453e+00, -4.4041e+00,\n         -4.9246e+00,  4.0288e+00, -2.5162e+00,  4.7373e-01,  2.3701e+00,\n         -4.5387e-01,  2.5511e+00,  9.9164e-01,  4.0431e+00,  6.5957e+00,\n          7.2928e+00,  4.9252e+00,  1.8035e+00, -4.0973e+00,  7.9505e-01,\n         -3.6083e+00, -1.1633e+01, -6.4935e+00,  1.2480e-01,  8.8889e-01,\n         -3.7143e+00, -5.0032e-01, -9.2418e-01, -6.9722e+00, -1.2299e+00,\n         -3.1248e+00, -6.7706e+00, -2.3946e+00, -1.4313e+00,  1.3764e+00,\n         -1.1452e+00, -5.4013e+00, -6.0799e+00, -3.0528e+00, -1.5034e-01,\n         -1.1176e+01,  6.3495e+00,  1.2074e+00, -5.9096e+00,  5.5718e-01,\n         -4.6510e+00, -1.1263e+00,  7.1785e-01, -1.0499e+01, -1.0754e+00,\n          3.1626e-01,  5.0821e-01,  8.5129e+00,  2.9580e+00,  9.9919e+00,\n          6.4750e+00,  5.2899e+00,  6.4511e-01,  7.1923e-01,  3.0211e+00,\n          4.0422e+00,  6.8665e-01, -1.8242e+00,  6.9781e+00,  2.0560e+00,\n          6.6063e-01,  4.5121e+00,  6.7878e-01,  1.0743e+00,  4.2366e+00,\n         -2.7609e+00, -5.3718e+00, -6.4858e-01,  1.0812e+00,  6.5885e+00,\n          1.8148e+00,  4.7519e+00, -5.5920e-01, -4.0828e+00, -4.3482e+00,\n          2.0121e+00,  4.9435e+00, -3.3304e+00, -4.6219e+00,  5.1761e-01,\n          2.2478e+00,  1.2084e+00,  2.2699e+00, -5.1662e+00, -5.0778e+00,\n         -2.6417e+00, -5.1837e+00, -6.2332e+00,  3.4144e+00,  2.1467e+00,\n          2.0102e+00,  4.3830e+00,  3.8266e+00,  5.7867e+00,  6.7515e-01,\n          3.7560e+00, -4.4858e-01, -8.4267e+00, -2.2666e+00, -8.2950e-01,\n         -3.2536e+00, -3.5598e+00, -4.4906e+00, -5.3648e+00, -5.5752e+00,\n         -6.6110e+00, -6.7183e+00, -6.0400e+00, -1.9475e+00, -6.3376e+00,\n         -4.5780e+00, -3.7863e+00, -2.2289e+00,  2.9785e+00,  1.9556e-01,\n          7.7658e-01,  1.5484e+00,  2.1712e+00, -3.7076e-01, -1.5228e+00,\n         -2.1911e+00, -2.1120e-02,  1.6316e+00, -8.9257e-01,  2.9854e+00,\n         -4.7042e-01, -2.0312e+00,  1.0269e+00, -2.6776e+00,  1.7972e-01,\n          1.1070e+00, -2.0543e+00, -1.1728e+00,  1.8022e+00,  5.3447e+00,\n         -3.2683e+00, -5.6497e+00, -4.0675e+00,  2.5770e+00, -1.7018e+00,\n          2.0386e+00, -2.4867e+00, -3.1360e+00,  1.2256e+00, -5.0267e+00,\n         -1.6322e+00, -2.9314e+00, -1.9041e+00,  3.8794e+00,  5.5947e+00,\n          3.3121e+00,  1.0207e+00,  8.5609e+00,  3.2267e-01,  2.3483e+00,\n          1.0989e+01,  4.7050e+00,  2.4353e+00,  2.7772e+00,  1.1773e+00,\n         -2.2138e+00, -7.5844e-01,  3.4757e-02,  3.1186e-01,  1.5184e+00,\n          5.3313e-01,  1.2926e+00,  8.6103e-01,  5.5240e+00,  2.8789e+00,\n          4.5681e+00,  4.1591e+00,  5.5938e+00,  2.6378e+00, -1.1302e+00,\n          5.5896e+00, -2.0712e+00,  3.6316e+00,  3.3332e+00, -3.4179e-01,\n          5.6126e+00,  7.7497e-01,  1.5725e+00, -9.6165e-01,  5.2344e+00,\n         -3.6604e-02, -2.4829e+00,  2.7498e+00, -2.6839e-01]], device='cuda:0',\n       grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 2.9278e+01,  5.5798e+01,  2.4842e-01,  1.6455e+00,  1.4787e+00,\n          2.2549e+00,  1.5818e+00, -3.1904e+00, -1.9985e+00,  3.9189e+00,\n          3.0794e+00,  1.0906e+00,  8.0429e-01,  1.4684e+00,  3.3470e+00,\n         -1.8394e+00, -2.2592e+00, -4.0316e+00, -7.3417e+00, -2.8694e+00,\n          3.7004e+00, -1.3191e+00,  3.4757e+00, -2.0582e+00,  6.4986e+00,\n         -7.7989e-01, -1.6688e+00,  2.7953e+00,  3.6566e+00,  2.4197e-01,\n          1.1021e+00, -3.8482e+00, -4.3180e+00, -6.7740e+00, -2.2272e+00,\n         -2.9238e+00, -6.2434e+00, -2.6687e-01, -6.1377e+00,  2.2376e+00,\n          2.6732e+00, -1.2284e+00, -1.8006e+00,  2.5504e+00, -1.4619e+00,\n         -4.9171e+00, -6.5914e+00, -1.2349e+00, -4.0564e+00, -2.5384e+00,\n         -1.5554e+00,  1.3620e+00, -1.2775e+00,  2.3349e+00,  1.1790e+00,\n          1.2718e+00,  4.5705e+00,  2.1217e+00,  4.0333e+00,  5.6577e+00,\n          4.8218e+00,  5.2267e+00,  2.3398e+00, -4.0199e+00,  2.2049e+00,\n         -3.3509e+00, -1.2650e+01, -4.6344e+00,  7.9481e-01,  7.4989e-01,\n         -3.8890e+00, -3.7006e+00,  1.1753e+00, -3.9018e+00, -6.0877e-01,\n         -4.2481e+00, -4.1900e+00, -4.1442e+00, -3.5654e+00,  1.2366e+00,\n         -8.0690e-02, -6.2012e+00, -3.0815e+00, -6.3676e+00, -4.7485e-02,\n         -7.8727e+00,  7.4866e+00,  5.1506e-01, -5.3592e+00, -1.9551e-01,\n          8.7819e-01, -1.5014e+00,  1.5809e+00, -1.0632e+01,  1.6308e+00,\n          3.1609e+00,  2.0676e-01,  8.1783e+00,  2.2681e+00,  9.5457e+00,\n          8.0861e+00,  3.8537e+00,  2.2022e+00,  4.4745e+00,  1.3897e+00,\n          5.2972e+00,  1.0783e+00, -3.7405e+00,  8.3435e+00,  1.1782e+00,\n          4.6916e-02,  5.7727e+00, -1.3740e+00, -7.0701e-01,  3.8026e+00,\n         -3.1772e+00, -1.9992e+00, -6.0649e-01,  3.0738e+00,  4.5452e+00,\n          2.8828e+00,  6.1306e+00,  8.6687e-02, -7.3920e+00,  5.8354e-01,\n          4.3398e+00,  2.8617e+00, -3.8564e+00, -4.5856e+00,  3.1966e+00,\n         -1.8054e-01,  1.5356e+00,  1.6188e+00, -3.4290e+00, -3.1510e+00,\n         -7.2101e-01, -7.0786e+00, -4.8011e+00,  4.1484e+00,  2.1882e+00,\n          2.5998e+00,  6.9444e+00,  2.5345e+00,  1.4522e+00,  2.6308e-01,\n          3.9244e+00,  1.8550e-01, -1.0410e+01, -4.0408e+00, -1.1970e+00,\n         -5.9574e+00, -4.8311e+00, -3.4314e+00, -4.6805e+00, -1.8403e+00,\n         -3.4853e+00, -8.2994e+00, -6.3039e+00, -3.6189e+00, -6.9156e+00,\n         -4.0407e+00, -1.6721e+00, -1.2020e+00,  1.9787e+00,  4.7961e-01,\n          4.8168e-01, -9.6912e-01,  3.2879e+00,  1.7330e+00, -2.4175e+00,\n         -2.9260e+00,  1.9062e+00,  1.0599e+00, -1.6774e+00,  3.1348e+00,\n         -3.8929e-01, -6.3868e-02,  1.4774e+00, -2.8200e+00,  2.2244e-01,\n          4.1753e+00, -2.6141e+00,  6.8813e-01, -2.9635e-01,  4.1499e+00,\n         -4.8539e-01, -3.5195e+00, -5.5024e+00, -9.4217e-01, -1.6946e+00,\n         -9.5791e-01, -2.2057e+00, -1.5786e+00,  1.8299e+00, -4.0677e+00,\n         -4.9973e+00, -5.6506e+00, -2.0802e+00,  8.7026e-01,  3.8867e+00,\n          2.0915e+00, -1.1060e+00,  6.4208e+00,  4.6281e+00,  1.2949e+00,\n          9.3394e+00,  4.9840e+00,  1.8411e+00,  6.1441e-01,  1.1471e+00,\n         -2.9873e+00,  1.0100e+00,  2.0564e-01, -1.4774e+00,  8.4210e-01,\n         -4.4228e-01, -1.0251e-01,  4.1397e+00,  5.5265e+00,  4.7923e+00,\n          4.3062e+00,  5.8801e+00,  7.2519e+00,  1.6531e+00, -2.2369e+00,\n          5.1088e+00, -2.0247e+00,  8.7094e-01,  7.1642e-01, -3.5144e+00,\n          3.6239e+00, -8.5678e-01,  7.9262e-01, -8.6733e-01,  7.8552e-01,\n         -2.3132e+00,  1.2062e+00,  4.0578e+00, -8.3416e-01]], device='cuda:0',\n       grad_fn=<PermuteBackward0>)\n\u001b[32m2023-08-14 17:39:32.355\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m592\u001b[0m - \u001b[31m\u001b[1mepoch=6, save to ppo_0813_v1step_6\u001b[0m\n7it [06:14, 55.34s/it]\u001b[32m2023-08-14 17:39:33.181\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 54546, 33058, 55318, 31123, 54622,\n        31813, 54534, 33593, 33992, 54538, 54549, 56105, 31211, 40223, 57605,\n        31716, 55152, 56812, 31514,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:53.247\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910, 31710, 32347, 54565, 32093, 42481, 30932, 33992, 31697, 55442,\n        55176, 32960, 34220, 30932, 31659, 41042, 32479, 31628, 31731, 31951,\n        30932, 32780, 32565, 33400, 31201, 32982, 31201, 31846, 31201, 31747,\n        32608, 31155, 40223, 57605, 54542, 55152, 56812, 54532, 33701, 32406,\n        32697, 30932, 33971, 31817, 35081, 32219, 54542, 53696, 31155, 40223,\n        57605, 32615, 54929, 31201, 34743, 30932, 35386, 56856, 55406, 54542,\n        41473, 57088, 54679, 30932, 54532, 39209, 56856, 55406, 37228, 57088,\n        54718, 30979, 54617, 55152, 56812, 55066, 54664, 36491, 34771, 59002,\n        57088, 30932, 31996, 34896, 31201, 54664, 31817, 34510, 54642, 31155,\n        31814, 30932, 49573, 30932, 33133, 31667, 39425, 32406, 45937, 33400,\n        30932, 32067, 32174, 54563, 33287, 31623, 42078, 31639, 31155,     2],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:53.250\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 54546, 33058, 55318, 31123, 54622,\n        31813, 54534, 33593, 33992, 54538, 54549, 56105, 31211, 40223, 57605,\n        31716, 55152, 56812, 31514,    13,    13, 55437, 31211],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:53.253\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910, 31710, 32347, 54565, 32093, 42481, 30932, 33992, 31697, 55442,\n        55176, 32960, 34220, 30932, 31659, 41042, 32479, 31628, 31731, 31951,\n        30932, 32780, 32565, 33400, 31201, 32982, 31201, 31846, 31201, 31747,\n        32608, 31155, 40223, 57605, 54542, 55152, 56812, 54532, 33701, 32406,\n        32697, 30932, 33971, 31817, 35081, 32219, 54542, 53696, 31155, 40223,\n        57605, 32615, 54929, 31201, 34743, 30932, 35386, 56856, 55406, 54542,\n        41473, 57088, 54679, 30932, 54532, 39209, 56856, 55406, 37228, 57088,\n        54718, 30979, 54617, 55152, 56812, 55066, 54664, 36491, 34771, 59002,\n        57088, 30932, 31996, 34896, 31201, 54664, 31817, 34510, 54642, 31155,\n        31814, 30932, 49573, 30932, 33133, 31667, 39425, 32406, 45937, 33400,\n        30932, 32067, 32174, 54563, 33287, 31623, 42078, 31639, 31155,     2],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:53.560\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 3.5367e+01,  5.7047e+01,  8.8018e-01,  1.8577e+00,  1.7741e+00,\n        -1.5442e+00, -1.4722e+00,  2.3382e+00,  3.7328e-01, -1.4098e+00,\n         4.8246e+00,  4.8596e+00,  1.5276e+00,  6.0181e+00,  1.4583e+00,\n        -6.0259e-01,  1.3206e-01, -1.6428e+00,  3.8705e+00,  6.9777e-01,\n        -5.7942e+00,  1.3917e+00,  1.1131e-01, -2.2285e-01, -1.2398e+00,\n        -2.3531e+00,  1.6608e+00,  1.9702e+00,  1.0802e+00,  1.4332e+00,\n         1.0203e+01,  6.2485e+00,  8.0032e+00,  5.1654e+00,  3.7169e+00,\n         7.4134e+00,  4.0407e+00,  3.2031e-01,  4.3824e+00,  9.6047e+00,\n         7.7374e+00,  2.1613e+00,  4.5010e+00,  8.2323e-01,  6.6779e+00,\n         5.4110e+00,  9.1770e-01,  2.3063e+00, -1.0797e+00,  8.9820e+00,\n         4.0060e+00,  5.2956e+00,  3.4995e+00,  3.3803e+00,  2.2198e+00,\n         8.7193e+00,  2.8463e+00,  2.1744e+00,  1.3850e+00, -6.9579e-01,\n         1.6819e+00,  6.5513e-01,  2.8098e+00, -1.6956e+00,  2.2781e+00,\n         3.3376e+00,  1.7365e+00,  2.8915e+00,  6.9048e+00,  2.5179e+00,\n         3.8698e+00, -3.4806e+00, -3.7194e-02, -4.2325e+00, -5.3739e+00,\n        -2.9640e+00, -2.0572e+00,  2.1534e+00, -7.9930e-01,  3.8550e+00,\n        -1.4619e+00, -3.8566e+00, -2.1441e+00, -6.8602e-01, -6.3481e+00,\n        -1.4606e+00,  8.4348e-01, -3.2661e+00,  2.4124e+00,  3.0675e+00,\n         3.3706e+00,  4.2350e+00, -8.5544e+00, -1.6041e+00, -2.8917e+00,\n         1.7598e+00, -5.9503e+00, -6.6657e+00, -4.3569e-01, -9.4718e-01,\n         1.1137e+00, -4.4822e-01,  3.0188e+00,  1.5053e+00, -4.9399e+00,\n        -7.2466e+00, -3.7639e+00, -5.4731e-02,  1.6004e+00, -2.1917e+00,\n         1.9319e+00,  6.1934e+00, -9.2332e-01, -2.9051e+00, -7.3746e+00,\n        -4.4602e+00, -3.0084e+00,  2.3247e+00,  6.2051e+00,  1.9109e+00,\n         5.0269e+00, -1.6412e+00,  1.4543e+00,  4.8887e-01, -1.0170e+00,\n         5.3787e+00, -1.3826e+00, -7.7770e-03,  5.9159e+00,  6.8492e+00,\n         3.0577e+00,  5.1875e+00,  3.2690e+00,  5.9990e+00,  5.6125e+00,\n         4.1415e+00,  3.0010e+00, -5.4063e-01], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:39:53.561\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:39:53.561\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:39:53.565\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 3.5367e+01,  5.7047e+01,  8.8018e-01,  1.8577e+00,  1.7741e+00,\n        -1.5442e+00, -1.4722e+00,  2.3382e+00,  3.7328e-01, -1.4098e+00,\n         4.8246e+00,  4.8596e+00,  1.5276e+00,  6.0181e+00,  1.4583e+00,\n        -6.0259e-01,  1.3206e-01, -1.6428e+00,  3.8705e+00,  6.9777e-01,\n        -5.7942e+00,  1.3917e+00,  1.1131e-01, -2.2285e-01, -1.2398e+00,\n        -2.3531e+00,  1.6608e+00,  1.9702e+00,  1.0802e+00,  1.4332e+00,\n         1.0203e+01,  6.2485e+00,  8.0032e+00,  5.1654e+00,  3.7169e+00,\n         7.4134e+00,  4.0407e+00,  3.2031e-01,  4.3824e+00,  9.6047e+00,\n         7.7374e+00,  2.1613e+00,  4.5010e+00,  8.2323e-01,  6.6779e+00,\n         5.4110e+00,  9.1770e-01,  2.3063e+00, -1.0797e+00,  8.9820e+00,\n         4.0060e+00,  5.2956e+00,  3.4995e+00,  3.3803e+00,  2.2198e+00,\n         8.7193e+00,  2.8463e+00,  2.1744e+00,  1.3850e+00, -6.9579e-01,\n         1.6819e+00,  6.5513e-01,  2.8098e+00, -1.6956e+00,  2.2781e+00,\n         3.3376e+00,  1.7365e+00,  2.8915e+00,  6.9048e+00,  2.5179e+00,\n         3.8698e+00, -3.4806e+00, -3.7194e-02, -4.2325e+00, -5.3739e+00,\n        -2.9640e+00, -2.0572e+00,  2.1534e+00, -7.9930e-01,  3.8550e+00,\n        -1.4619e+00, -3.8566e+00, -2.1441e+00, -6.8602e-01, -6.3481e+00,\n        -1.4606e+00,  8.4348e-01, -3.2661e+00,  2.4124e+00,  3.0675e+00,\n         3.3706e+00,  4.2350e+00, -8.5544e+00, -1.6041e+00, -2.8917e+00,\n         1.7598e+00, -5.9503e+00, -6.6657e+00, -4.3569e-01, -9.4718e-01,\n         1.1137e+00, -4.4822e-01,  3.0188e+00,  1.5053e+00, -4.9399e+00,\n        -7.2466e+00, -3.7639e+00, -5.4731e-02,  1.6004e+00, -2.1917e+00,\n         1.9319e+00,  6.1934e+00, -9.2332e-01, -2.9051e+00, -7.3746e+00,\n        -4.4602e+00, -3.0084e+00,  2.3247e+00,  6.2051e+00,  1.9109e+00,\n         5.0269e+00, -1.6412e+00,  1.4543e+00,  4.8887e-01, -1.0170e+00,\n         5.3787e+00, -1.3826e+00, -7.7770e-03,  5.9159e+00,  6.8492e+00,\n         3.0577e+00,  5.1875e+00,  3.2690e+00,  5.9990e+00,  5.6125e+00,\n         4.1415e+00,  3.0010e+00, -5.4063e-01], device='cuda:0')]\u001b[0m\nepoch:  7 \nquery: 问：我很好奇，你认为在一场斗争中会赢：美洲豹还是土狼？\n\n答：\nresponse: 作为一个人工智能助手,斗争中的胜负很难预测,因为有许多因素可以影响结果,例如双方策略、实力、资源、环境等等。美洲豹和土狼是两种不同的动物,各自具有独特的优势和弱点。美洲豹速度快、灵活,善于爬树和追踪猎物,是出色的爬树者和猎手;而土狼则更擅长地面狩猎,力量更大、更具有攻击性。因此,在这种情况下,胜利可能取决于不同的情况和策略,无法简单地回答一个特定的问题。\nscore: tensor([ 3.5367e+01,  5.7047e+01,  8.8018e-01,  1.8577e+00,  1.7741e+00,\n        -1.5442e+00, -1.4722e+00,  2.3382e+00,  3.7328e-01, -1.4098e+00,\n         4.8246e+00,  4.8596e+00,  1.5276e+00,  6.0181e+00,  1.4583e+00,\n        -6.0259e-01,  1.3206e-01, -1.6428e+00,  3.8705e+00,  6.9777e-01,\n        -5.7942e+00,  1.3917e+00,  1.1131e-01, -2.2285e-01, -1.2398e+00,\n        -2.3531e+00,  1.6608e+00,  1.9702e+00,  1.0802e+00,  1.4332e+00,\n         1.0203e+01,  6.2485e+00,  8.0032e+00,  5.1654e+00,  3.7169e+00,\n         7.4134e+00,  4.0407e+00,  3.2031e-01,  4.3824e+00,  9.6047e+00,\n         7.7374e+00,  2.1613e+00,  4.5010e+00,  8.2323e-01,  6.6779e+00,\n         5.4110e+00,  9.1770e-01,  2.3063e+00, -1.0797e+00,  8.9820e+00,\n         4.0060e+00,  5.2956e+00,  3.4995e+00,  3.3803e+00,  2.2198e+00,\n         8.7193e+00,  2.8463e+00,  2.1744e+00,  1.3850e+00, -6.9579e-01,\n         1.6819e+00,  6.5513e-01,  2.8098e+00, -1.6956e+00,  2.2781e+00,\n         3.3376e+00,  1.7365e+00,  2.8915e+00,  6.9048e+00,  2.5179e+00,\n         3.8698e+00, -3.4806e+00, -3.7194e-02, -4.2325e+00, -5.3739e+00,\n        -2.9640e+00, -2.0572e+00,  2.1534e+00, -7.9930e-01,  3.8550e+00,\n        -1.4619e+00, -3.8566e+00, -2.1441e+00, -6.8602e-01, -6.3481e+00,\n        -1.4606e+00,  8.4348e-01, -3.2661e+00,  2.4124e+00,  3.0675e+00,\n         3.3706e+00,  4.2350e+00, -8.5544e+00, -1.6041e+00, -2.8917e+00,\n         1.7598e+00, -5.9503e+00, -6.6657e+00, -4.3569e-01, -9.4718e-01,\n         1.1137e+00, -4.4822e-01,  3.0188e+00,  1.5053e+00, -4.9399e+00,\n        -7.2466e+00, -3.7639e+00, -5.4731e-02,  1.6004e+00, -2.1917e+00,\n         1.9319e+00,  6.1934e+00, -9.2332e-01, -2.9051e+00, -7.3746e+00,\n        -4.4602e+00, -3.0084e+00,  2.3247e+00,  6.2051e+00,  1.9109e+00,\n         5.0269e+00, -1.6412e+00,  1.4543e+00,  4.8887e-01, -1.0170e+00,\n         5.3787e+00, -1.3826e+00, -7.7770e-03,  5.9159e+00,  6.8492e+00,\n         3.0577e+00,  5.1875e+00,  3.2690e+00,  5.9990e+00,  5.6125e+00,\n         4.1415e+00,  3.0010e+00, -5.4063e-01], device='cuda:0')\n\u001b[32m2023-08-14 17:39:53.569\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:39:53.573\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 3.5367e+01,  5.7047e+01,  8.8018e-01,  1.8577e+00,  1.7741e+00,\n        -1.5442e+00, -1.4722e+00,  2.3382e+00,  3.7328e-01, -1.4098e+00,\n         4.8246e+00,  4.8596e+00,  1.5276e+00,  6.0181e+00,  1.4583e+00,\n        -6.0259e-01,  1.3206e-01, -1.6428e+00,  3.8705e+00,  6.9777e-01,\n        -5.7942e+00,  1.3917e+00,  1.1131e-01, -2.2285e-01, -1.2398e+00,\n        -2.3531e+00,  1.6608e+00,  1.9702e+00,  1.0802e+00,  1.4332e+00,\n         1.0203e+01,  6.2485e+00,  8.0032e+00,  5.1654e+00,  3.7169e+00,\n         7.4134e+00,  4.0407e+00,  3.2031e-01,  4.3824e+00,  9.6047e+00,\n         7.7374e+00,  2.1613e+00,  4.5010e+00,  8.2323e-01,  6.6779e+00,\n         5.4110e+00,  9.1770e-01,  2.3063e+00, -1.0797e+00,  8.9820e+00,\n         4.0060e+00,  5.2956e+00,  3.4995e+00,  3.3803e+00,  2.2198e+00,\n         8.7193e+00,  2.8463e+00,  2.1744e+00,  1.3850e+00, -6.9579e-01,\n         1.6819e+00,  6.5513e-01,  2.8098e+00, -1.6956e+00,  2.2781e+00,\n         3.3376e+00,  1.7365e+00,  2.8915e+00,  6.9048e+00,  2.5179e+00,\n         3.8698e+00, -3.4806e+00, -3.7194e-02, -4.2325e+00, -5.3739e+00,\n        -2.9640e+00, -2.0572e+00,  2.1534e+00, -7.9930e-01,  3.8550e+00,\n        -1.4619e+00, -3.8566e+00, -2.1441e+00, -6.8602e-01, -6.3481e+00,\n        -1.4606e+00,  8.4348e-01, -3.2661e+00,  2.4124e+00,  3.0675e+00,\n         3.3706e+00,  4.2350e+00, -8.5544e+00, -1.6041e+00, -2.8917e+00,\n         1.7598e+00, -5.9503e+00, -6.6657e+00, -4.3569e-01, -9.4718e-01,\n         1.1137e+00, -4.4822e-01,  3.0188e+00,  1.5053e+00, -4.9399e+00,\n        -7.2466e+00, -3.7639e+00, -5.4731e-02,  1.6004e+00, -2.1917e+00,\n         1.9319e+00,  6.1934e+00, -9.2332e-01, -2.9051e+00, -7.3746e+00,\n        -4.4602e+00, -3.0084e+00,  2.3247e+00,  6.2051e+00,  1.9109e+00,\n         5.0269e+00, -1.6412e+00,  1.4543e+00,  4.8887e-01, -1.0170e+00,\n         5.3787e+00, -1.3826e+00, -7.7770e-03,  5.9159e+00,  6.8492e+00,\n         3.0577e+00,  5.1875e+00,  3.2690e+00,  5.9990e+00,  5.6125e+00,\n         4.1415e+00,  3.0010e+00, -5.4063e-01], device='cuda:0')]\u001b[0m\nscores=[tensor([ 3.5367e+01,  5.7047e+01,  8.8018e-01,  1.8577e+00,  1.7741e+00,\n        -1.5442e+00, -1.4722e+00,  2.3382e+00,  3.7328e-01, -1.4098e+00,\n         4.8246e+00,  4.8596e+00,  1.5276e+00,  6.0181e+00,  1.4583e+00,\n        -6.0259e-01,  1.3206e-01, -1.6428e+00,  3.8705e+00,  6.9777e-01,\n        -5.7942e+00,  1.3917e+00,  1.1131e-01, -2.2285e-01, -1.2398e+00,\n        -2.3531e+00,  1.6608e+00,  1.9702e+00,  1.0802e+00,  1.4332e+00,\n         1.0203e+01,  6.2485e+00,  8.0032e+00,  5.1654e+00,  3.7169e+00,\n         7.4134e+00,  4.0407e+00,  3.2031e-01,  4.3824e+00,  9.6047e+00,\n         7.7374e+00,  2.1613e+00,  4.5010e+00,  8.2323e-01,  6.6779e+00,\n         5.4110e+00,  9.1770e-01,  2.3063e+00, -1.0797e+00,  8.9820e+00,\n         4.0060e+00,  5.2956e+00,  3.4995e+00,  3.3803e+00,  2.2198e+00,\n         8.7193e+00,  2.8463e+00,  2.1744e+00,  1.3850e+00, -6.9579e-01,\n         1.6819e+00,  6.5513e-01,  2.8098e+00, -1.6956e+00,  2.2781e+00,\n         3.3376e+00,  1.7365e+00,  2.8915e+00,  6.9048e+00,  2.5179e+00,\n         3.8698e+00, -3.4806e+00, -3.7194e-02, -4.2325e+00, -5.3739e+00,\n        -2.9640e+00, -2.0572e+00,  2.1534e+00, -7.9930e-01,  3.8550e+00,\n        -1.4619e+00, -3.8566e+00, -2.1441e+00, -6.8602e-01, -6.3481e+00,\n        -1.4606e+00,  8.4348e-01, -3.2661e+00,  2.4124e+00,  3.0675e+00,\n         3.3706e+00,  4.2350e+00, -8.5544e+00, -1.6041e+00, -2.8917e+00,\n         1.7598e+00, -5.9503e+00, -6.6657e+00, -4.3569e-01, -9.4718e-01,\n         1.1137e+00, -4.4822e-01,  3.0188e+00,  1.5053e+00, -4.9399e+00,\n        -7.2466e+00, -3.7639e+00, -5.4731e-02,  1.6004e+00, -2.1917e+00,\n         1.9319e+00,  6.1934e+00, -9.2332e-01, -2.9051e+00, -7.3746e+00,\n        -4.4602e+00, -3.0084e+00,  2.3247e+00,  6.2051e+00,  1.9109e+00,\n         5.0269e+00, -1.6412e+00,  1.4543e+00,  4.8887e-01, -1.0170e+00,\n         5.3787e+00, -1.3826e+00, -7.7770e-03,  5.9159e+00,  6.8492e+00,\n         3.0577e+00,  5.1875e+00,  3.2690e+00,  5.9990e+00,  5.6125e+00,\n         4.1415e+00,  3.0010e+00, -5.4063e-01], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 3.6352e+01,  2.9192e+01,  5.3830e-01,  1.9003e+00,  1.1330e+00,\n         -1.7843e+00, -1.0156e-01,  3.1810e+00, -8.1015e-01, -3.6723e+00,\n          4.8203e+00,  4.5843e+00,  2.8242e+00,  5.5140e+00,  1.8595e+00,\n          1.1091e+00, -1.0387e+00, -3.5835e-02,  3.0223e+00,  3.1772e-01,\n         -3.4985e+00,  1.8283e+00,  9.6605e-01,  2.8659e+00, -2.8239e+00,\n         -3.2855e+00,  6.0370e-01, -4.6669e-01, -8.9907e-01,  1.7789e+00,\n          6.0316e+00,  4.3317e+00,  8.6889e+00,  3.7841e+00,  3.2333e+00,\n          5.4144e+00,  5.1637e+00,  1.0362e+00,  5.9781e+00,  5.9587e+00,\n          8.9167e+00,  1.6506e+00,  3.7743e+00,  3.8701e-01,  3.7552e+00,\n          8.3212e+00,  3.3530e-01,  1.2789e+00, -2.8201e-01,  7.1859e+00,\n          3.1034e+00,  3.6119e+00,  1.4316e+00, -8.3712e-01,  1.4452e+00,\n          1.0808e+01,  3.0433e+00,  9.8743e-01,  4.0777e-01, -4.6846e-02,\n          3.1946e+00,  5.0495e-01,  1.3171e+00, -2.8080e+00,  5.4459e+00,\n          2.9327e+00,  1.8005e+00,  3.4983e+00,  5.9683e+00,  3.7515e+00,\n          4.6145e+00, -1.4582e+00, -5.5563e-02, -4.1767e+00, -4.5889e+00,\n         -5.3477e-01, -4.3872e-01,  2.5013e+00,  1.2573e+00,  2.3317e+00,\n         -1.3350e+00, -3.9755e+00, -1.7410e+00,  1.2244e+00, -5.0754e+00,\n          7.4650e-01,  3.2904e+00, -2.7075e+00,  1.5722e+00,  1.3707e+00,\n          1.2781e-01,  1.3114e+00, -8.6897e+00,  3.9174e-01, -2.3258e-02,\n          4.6179e+00, -2.2800e+00, -4.2897e+00, -3.7085e-01,  3.2891e-01,\n         -7.5497e-01,  2.3962e+00,  2.0680e+00, -4.7738e-01, -4.3292e+00,\n         -4.3104e+00, -4.0180e+00, -7.4978e-01, -4.0678e-01, -2.9995e+00,\n          6.8761e-01,  5.3388e+00, -1.4542e+00, -2.2019e+00, -6.6702e+00,\n         -5.6349e+00, -2.7408e+00,  2.2315e+00,  6.7234e+00,  3.3629e+00,\n          6.5619e+00,  3.0269e+00,  5.8627e-01,  2.1056e+00, -2.1961e+00,\n          8.8883e+00, -2.9007e+00,  2.3013e-01,  4.7368e+00,  5.6953e+00,\n          2.8382e+00,  4.7302e+00,  2.8447e+00,  3.8038e+00,  5.3973e+00,\n          4.9485e+00,  3.1309e+00, -7.0247e-01]], device='cuda:0')\nvalues_994 = tensor([[ 3.1707e+01,  5.5855e+01,  4.7955e-01,  1.7481e+00,  1.7293e+00,\n         -1.0948e+00, -3.6118e+00,  2.4360e+00, -1.8728e+00, -1.8438e+00,\n          5.0504e+00,  4.7376e+00,  3.5968e+00,  4.5047e+00,  1.7146e+00,\n          1.1692e-02,  1.0090e+00, -1.0878e+00,  3.0757e+00,  2.0188e-01,\n         -1.6546e+00,  1.1962e+00,  5.7442e-01, -1.6455e+00, -2.5525e+00,\n         -2.9977e+00,  9.3486e-01,  9.9815e-01, -3.1488e+00,  2.2302e+00,\n          6.4916e+00,  3.7709e+00,  7.1158e+00,  1.1621e+00,  3.6610e+00,\n          6.9408e+00,  3.8308e+00, -1.9600e+00,  4.8312e+00,  7.0773e+00,\n          5.4755e+00,  3.2703e+00,  9.2330e-02,  1.4683e+00,  5.8324e+00,\n          8.1892e+00,  6.2588e-01,  3.5740e+00, -9.2774e-01,  8.1802e+00,\n          6.1472e+00,  5.0257e+00,  3.0316e+00,  1.3859e+00,  1.7645e+00,\n          8.8045e+00,  3.0057e+00,  3.4701e+00,  2.0980e+00, -2.0066e+00,\n          4.2633e+00,  4.2881e+00, -8.7653e-01, -8.4364e-01,  1.7389e+00,\n          3.3191e+00,  2.7348e+00,  2.8794e+00,  9.2614e+00,  3.9996e+00,\n          3.4735e+00, -4.8755e+00,  5.8249e-01, -4.7997e+00, -6.8397e+00,\n         -3.4874e+00, -1.6617e+00,  2.1520e+00, -1.0787e-01,  1.6310e+00,\n          3.0250e-01, -6.2087e+00, -1.5378e+00, -6.5139e-01, -5.0913e+00,\n         -7.0137e-01, -1.6751e-01, -4.9508e+00,  4.7731e-01,  4.2406e-01,\n          1.2807e-01,  5.3900e+00, -6.0931e+00, -4.0950e-01,  4.0080e-01,\n          1.1521e+00, -7.2496e-01, -3.7962e+00, -1.5352e+00,  9.7733e-02,\n         -7.3205e-01,  2.6816e+00,  2.5009e+00, -2.8964e-01, -3.2742e+00,\n         -2.6162e+00, -2.2035e+00, -9.5165e-01, -2.9330e-01, -3.9804e+00,\n          2.3526e+00,  7.0856e+00, -1.2227e+00, -3.9352e+00, -7.2056e+00,\n         -7.0314e+00, -1.4236e+00,  3.4646e+00,  6.3295e+00,  4.0443e+00,\n          6.9220e+00,  1.1653e+00,  3.7308e-01,  1.5954e+00, -2.0902e+00,\n          7.1253e+00, -2.7745e+00, -1.8469e+00,  5.7637e+00,  6.8908e+00,\n          4.1186e+00,  3.5644e+00,  1.4010e+00,  2.1840e+00,  4.9012e+00,\n          4.3061e+00,  3.4059e+00, -6.4052e-01]], device='cuda:0')\nreward[last_non_masked_index]=tensor([7.7416e-07], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 3.5367e+01,  5.7047e+01,  8.8018e-01,  1.8577e+00,  1.7741e+00,\n        -1.5442e+00, -1.4722e+00,  2.3382e+00,  3.7328e-01, -1.4098e+00,\n         4.8246e+00,  4.8596e+00,  1.5276e+00,  6.0181e+00,  1.4583e+00,\n        -6.0259e-01,  1.3206e-01, -1.6428e+00,  3.8705e+00,  6.9777e-01,\n        -5.7942e+00,  1.3917e+00,  1.1131e-01, -2.2285e-01, -1.2398e+00,\n        -2.3531e+00,  1.6608e+00,  1.9702e+00,  1.0802e+00,  1.4332e+00,\n         1.0203e+01,  6.2485e+00,  8.0032e+00,  5.1654e+00,  3.7169e+00,\n         7.4134e+00,  4.0407e+00,  3.2031e-01,  4.3824e+00,  9.6047e+00,\n         7.7374e+00,  2.1613e+00,  4.5010e+00,  8.2323e-01,  6.6779e+00,\n         5.4110e+00,  9.1770e-01,  2.3063e+00, -1.0797e+00,  8.9820e+00,\n         4.0060e+00,  5.2956e+00,  3.4995e+00,  3.3803e+00,  2.2198e+00,\n         8.7193e+00,  2.8463e+00,  2.1744e+00,  1.3850e+00, -6.9579e-01,\n         1.6819e+00,  6.5513e-01,  2.8098e+00, -1.6956e+00,  2.2781e+00,\n         3.3376e+00,  1.7365e+00,  2.8915e+00,  6.9048e+00,  2.5179e+00,\n         3.8698e+00, -3.4806e+00, -3.7194e-02, -4.2325e+00, -5.3739e+00,\n        -2.9640e+00, -2.0572e+00,  2.1534e+00, -7.9930e-01,  3.8550e+00,\n        -1.4619e+00, -3.8566e+00, -2.1441e+00, -6.8602e-01, -6.3481e+00,\n        -1.4606e+00,  8.4348e-01, -3.2661e+00,  2.4124e+00,  3.0675e+00,\n         3.3706e+00,  4.2350e+00, -8.5544e+00, -1.6041e+00, -2.8917e+00,\n         1.7598e+00, -5.9503e+00, -6.6657e+00, -4.3569e-01, -9.4718e-01,\n         1.1137e+00, -4.4822e-01,  3.0188e+00,  1.5053e+00, -4.9399e+00,\n        -7.2466e+00, -3.7639e+00, -5.4731e-02,  1.6004e+00, -2.1917e+00,\n         1.9319e+00,  6.1934e+00, -9.2332e-01, -2.9051e+00, -7.3746e+00,\n        -4.4602e+00, -3.0084e+00,  2.3247e+00,  6.2051e+00,  1.9109e+00,\n         5.0269e+00, -1.6412e+00,  1.4543e+00,  4.8887e-01, -1.0170e+00,\n         5.3787e+00, -1.3826e+00, -7.7770e-03,  5.9159e+00,  6.8492e+00,\n         3.0577e+00,  5.1875e+00,  3.2690e+00,  5.9990e+00,  5.6125e+00,\n         4.1415e+00,  3.0010e+00, -5.4063e-01], device='cuda:0')\nvalues=tensor([[ 3.6352e+01,  2.9192e+01,  5.3830e-01,  1.9003e+00,  1.1330e+00,\n         -1.7843e+00, -1.0156e-01,  3.1810e+00, -8.1015e-01, -3.6723e+00,\n          4.8203e+00,  4.5843e+00,  2.8242e+00,  5.5140e+00,  1.8595e+00,\n          1.1091e+00, -1.0387e+00, -3.5835e-02,  3.0223e+00,  3.1772e-01,\n         -3.4985e+00,  1.8283e+00,  9.6605e-01,  2.8659e+00, -2.8239e+00,\n         -3.2855e+00,  6.0370e-01, -4.6669e-01, -8.9907e-01,  1.7789e+00,\n          6.0316e+00,  4.3317e+00,  8.6889e+00,  3.7841e+00,  3.2333e+00,\n          5.4144e+00,  5.1637e+00,  1.0362e+00,  5.9781e+00,  5.9587e+00,\n          8.9167e+00,  1.6506e+00,  3.7743e+00,  3.8701e-01,  3.7552e+00,\n          8.3212e+00,  3.3530e-01,  1.2789e+00, -2.8201e-01,  7.1859e+00,\n          3.1034e+00,  3.6119e+00,  1.4316e+00, -8.3712e-01,  1.4452e+00,\n          1.0808e+01,  3.0433e+00,  9.8743e-01,  4.0777e-01, -4.6846e-02,\n          3.1946e+00,  5.0495e-01,  1.3171e+00, -2.8080e+00,  5.4459e+00,\n          2.9327e+00,  1.8005e+00,  3.4983e+00,  5.9683e+00,  3.7515e+00,\n          4.6145e+00, -1.4582e+00, -5.5563e-02, -4.1767e+00, -4.5889e+00,\n         -5.3477e-01, -4.3872e-01,  2.5013e+00,  1.2573e+00,  2.3317e+00,\n         -1.3350e+00, -3.9755e+00, -1.7410e+00,  1.2244e+00, -5.0754e+00,\n          7.4650e-01,  3.2904e+00, -2.7075e+00,  1.5722e+00,  1.3707e+00,\n          1.2781e-01,  1.3114e+00, -8.6897e+00,  3.9174e-01, -2.3258e-02,\n          4.6179e+00, -2.2800e+00, -4.2897e+00, -3.7085e-01,  3.2891e-01,\n         -7.5497e-01,  2.3962e+00,  2.0680e+00, -4.7738e-01, -4.3292e+00,\n         -4.3104e+00, -4.0180e+00, -7.4978e-01, -4.0678e-01, -2.9995e+00,\n          6.8761e-01,  5.3388e+00, -1.4542e+00, -2.2019e+00, -6.6702e+00,\n         -5.6349e+00, -2.7408e+00,  2.2315e+00,  6.7234e+00,  3.3629e+00,\n          6.5619e+00,  3.0269e+00,  5.8627e-01,  2.1056e+00, -2.1961e+00,\n          8.8883e+00, -2.9007e+00,  2.3013e-01,  4.7368e+00,  5.6953e+00,\n          2.8382e+00,  4.7302e+00,  2.8447e+00,  3.8038e+00,  5.3973e+00,\n          4.9485e+00,  3.1309e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.0607e-03,\n          3.7313e-06, -1.3183e-04, -1.3748e-03, -0.0000e+00,  1.4817e-03,\n          6.6906e-04,  8.2877e-04,  5.4114e-05, -0.0000e+00, -8.0582e-04,\n          3.1203e-05, -3.9866e-05, -0.0000e+00, -3.5136e-04, -2.3090e-05,\n         -1.6639e-04, -1.3123e-03, -8.2038e-04,  5.6097e-04,  1.4608e-03,\n         -2.3838e-07, -4.7577e-06,  3.4000e-03, -3.6273e-05, -5.9603e-08,\n         -2.7971e-05, -1.2887e-03, -2.6319e-03,  1.4959e-04, -0.0000e+00,\n          9.7908e-05,  4.8842e-05, -2.0086e-04,  4.7740e-05,  1.1940e-05,\n         -0.0000e+00, -0.0000e+00, -2.4724e-04, -8.4545e-05, -2.1812e-05,\n         -3.2067e-05,  2.5660e-04,  5.9604e-08,  8.5738e-04,  3.2622e-04,\n          6.6286e-05, -1.4450e-03, -3.1661e-03,  3.4675e-04, -2.3977e-04,\n         -0.0000e+00,  3.6826e-04, -2.1310e-04, -0.0000e+00,  9.8622e-04,\n         -0.0000e+00,  1.1642e-03, -1.1437e-05,  1.5976e-05, -6.6316e-04,\n         -8.3798e-04,  2.3071e-05, -7.2207e-04, -6.5219e-04, -1.8466e-06,\n         -4.7671e-07,  2.2117e-03,  1.2465e-03,  1.3354e-03, -1.4279e-03,\n         -0.0000e+00, -5.4062e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 2.7522e+01,  5.4429e+01,  6.6101e-01,  5.4873e-01,  1.7950e+00,\n         -1.1585e+00, -6.6679e-01,  3.4426e+00, -1.1334e+00, -8.7236e-01,\n          3.9821e+00,  3.5481e+00,  9.9465e-01,  7.5801e+00,  1.0656e+00,\n         -2.8114e+00, -7.2334e-01, -4.5605e-02,  3.6145e+00,  7.7395e-01,\n         -1.5472e+00,  8.4340e-01,  7.2908e-01, -2.5574e-01, -2.7203e+00,\n         -3.5673e+00,  1.5493e+00,  1.3343e-01,  8.3408e-01,  1.4961e+00,\n          8.1510e+00,  2.9447e+00,  8.7400e+00,  2.9767e+00,  3.3773e+00,\n          6.0301e+00,  2.1803e+00, -2.7604e+00,  6.2353e+00,  7.2251e+00,\n          6.8096e+00,  1.8160e+00,  4.9113e+00,  4.6966e-01,  6.5172e+00,\n          7.5324e+00, -4.1210e-01,  2.9186e+00, -2.4578e-01,  1.0269e+01,\n          3.0545e+00,  4.6181e+00,  7.5870e-01,  1.1788e+00,  3.6424e+00,\n          9.4954e+00,  1.7294e+00,  4.5975e+00,  1.6087e+00, -3.7582e-01,\n          3.1945e+00,  6.0389e-02,  2.5499e+00,  1.1974e-01,  3.0150e+00,\n          6.0896e+00,  9.5030e-01,  3.1288e-01,  6.9156e+00, -4.1214e-01,\n          4.1880e+00, -1.7513e+00, -4.7260e-01, -3.2581e+00, -6.2387e+00,\n         -2.0297e+00, -5.8879e-01,  2.9422e+00, -1.0929e+00,  1.4198e+00,\n         -1.2876e+00, -5.7363e+00, -1.4943e+00, -4.1139e-01, -1.3080e+00,\n         -1.3860e-01,  1.6715e+00, -3.4549e+00,  2.4037e+00,  1.3786e+00,\n          2.8358e+00,  2.3717e+00, -6.9382e+00, -2.2566e+00, -2.0957e+00,\n          5.4406e-01, -5.6479e+00, -7.8185e+00, -3.7078e-01,  3.1094e-01,\n          4.1363e-01,  2.5942e+00, -2.8570e-01,  6.3283e-01, -4.2268e+00,\n         -1.8529e+00, -3.9747e+00,  6.0187e-02,  1.5992e+00, -3.3541e+00,\n          1.9258e+00,  7.7936e+00, -3.3856e-01, -3.5401e+00, -9.4223e+00,\n         -7.0946e+00, -2.2362e+00,  1.5872e+00,  5.1985e+00,  3.1795e+00,\n          2.2589e+00, -9.2099e-01,  1.3313e+00,  1.9947e+00, -1.9342e+00,\n          8.5489e+00, -6.6275e-01, -6.2536e-01,  2.3846e+00,  8.2219e+00,\n          3.8012e+00,  6.0195e+00,  2.4515e+00,  2.8451e+00,  8.1088e+00,\n          6.4426e+00,  5.8900e-01, -9.4375e-01]], device='cuda:0',\n       grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.1247e+01,  5.3940e+01,  7.9648e-01,  2.2315e+00,  1.7760e+00,\n         -1.9798e+00, -2.6357e-01,  2.9674e+00, -3.5575e+00, -1.6141e+00,\n          5.1064e+00,  3.2082e+00,  2.8920e+00,  4.9119e+00,  1.0912e+00,\n         -1.1615e+00,  1.0143e+00, -1.4033e+00,  2.1213e+00, -1.6738e+00,\n         -3.4296e+00,  2.8355e+00,  1.3203e+00, -2.3052e-01, -2.3672e+00,\n         -4.3350e+00, -2.5107e-01, -6.5978e-01,  3.3203e-02,  1.2939e-01,\n          6.2171e+00,  5.4379e+00,  8.2144e+00,  4.2902e-01,  4.3525e+00,\n          6.4144e+00,  4.8244e+00,  4.2426e-01,  4.7639e+00,  5.6546e+00,\n          5.0738e+00,  2.5763e+00,  4.6586e+00,  6.8486e-01,  5.9700e+00,\n          7.1994e+00, -1.1080e+00,  1.4462e+00, -1.2198e+00,  9.5534e+00,\n          2.9838e+00,  7.0856e+00,  4.1046e+00,  1.2927e+00,  2.4863e+00,\n          9.2966e+00,  3.4224e-01,  4.6695e+00,  2.7833e+00, -2.5232e+00,\n          1.0305e+00,  7.2007e-01,  9.0145e-01, -7.3531e-01,  8.0789e-01,\n          2.1609e+00,  2.5288e+00,  1.5997e+00,  9.7806e+00,  1.7193e+00,\n          3.7090e+00, -1.7664e+00,  3.0890e-01, -3.5009e+00, -7.2624e+00,\n         -3.5612e+00, -9.1860e-01,  3.6987e+00, -1.0791e+00,  6.9619e-01,\n          3.5887e+00, -7.0815e+00, -1.9676e+00, -1.0632e+00, -6.9443e+00,\n         -9.3040e-01,  8.4789e-01, -3.3230e+00,  1.3211e-01, -8.0781e-01,\n          1.9040e+00,  4.0463e+00, -1.0431e+01, -1.9846e+00, -2.6069e+00,\n          3.3716e+00, -2.8733e+00, -4.9968e+00,  9.3271e-02, -1.4830e+00,\n          4.4727e-01,  4.7564e-01, -5.7661e-01,  3.0229e+00, -2.7615e+00,\n         -6.1782e-01, -1.9113e+00, -7.6741e-01, -1.6041e-01, -1.2179e+00,\n         -9.5572e-01,  6.7760e+00,  1.3676e-01, -3.9915e+00, -7.2105e+00,\n         -4.2893e+00, -2.6441e+00,  1.5954e+00,  5.8870e+00,  2.8815e+00,\n          4.5477e+00, -5.1369e-01,  3.7844e-01, -5.6105e-01, -2.0624e+00,\n          7.7435e+00, -1.0390e+00, -2.1833e+00,  3.5814e+00,  5.0718e+00,\n          4.3014e+00,  7.7144e+00,  2.9607e+00,  3.9500e+00,  5.0908e+00,\n          3.3119e+00,  2.0980e+00, -9.8897e-01]], device='cuda:0',\n       grad_fn=<PermuteBackward0>)\n8it [06:41, 46.29s/it]\u001b[32m2023-08-14 17:40:00.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 54729, 54901, 54894, 33197, 54534,\n        54711, 31978, 33142, 54537, 32727, 32773, 55282, 31514,    13,    13,\n        55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:08.291\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([47187, 54901, 54894, 33197, 54996, 45361, 31065, 30956, 31065, 30959,\n        31065, 54901, 54894, 30932, 33152, 30939, 30969, 30973, 30969, 36701,\n        30943, 30940, 30940, 30939, 54540, 31978, 32738, 44400, 31155, 37347,\n        54711, 40455, 30932, 54572, 42000, 32102, 32773, 31155, 32040, 43742,\n        54572, 33142, 33248, 32773, 30954,    13,    13, 30939, 30930, 30910,\n        34739, 54730, 54618, 54542, 54776, 55517, 55183, 54848, 30954, 54564,\n        30939, 30969, 30973, 30969, 37625, 30932, 34739, 54530, 31944, 31680,\n        46134, 54535, 36286, 31155, 30939, 30969, 30969, 30939, 31766, 54681,\n        54848, 39720, 54537, 34739, 54530, 56072, 54730, 31155, 31701, 30932,\n        54776, 55517, 33931, 31832, 43805, 33166, 33147, 31800, 43792, 30932,\n        54551, 33313, 31730, 31665, 32579, 32164, 54556, 31818, 31704, 31640,\n        31155,    13,    13, 30943, 30930, 49196, 34126, 31639, 30954, 36887,\n        32369, 30973, 30940, 32404, 30932, 31661, 34126, 31639, 31913, 40860,\n        31155, 54901, 54894, 31683, 34765, 32382, 34126, 30932, 54688, 35971,\n        32058, 32296, 34050, 31155,    13,    13, 30966, 30930, 30910, 32277,\n        54542, 31747, 31639, 30954, 34153, 31990, 54530, 33654, 54542, 32277,\n        33920, 54534, 30939, 30969, 30981, 30966, 43795, 30939, 30969, 30981,\n        30969, 54540, 35227, 34979, 31155,  9628,  9871,  8340,   359, 30950,\n         5378, 30945, 30910, 32598, 30932, 30939, 30969, 30973, 30969, 31766,\n        33300, 33119, 31928, 54703, 30939, 30969, 30981, 30940, 54540, 54589,\n        30972, 30940,  8429, 54617, 46718, 54534, 30939, 30969, 30973, 30939,\n        54540, 35227, 54818, 54639, 57934, 30970, 30930, 30969, 32275, 32228,\n        55555, 31155, 31701, 30932, 54901, 54894, 31683, 54574, 42000, 31879,\n        42763, 32184, 31155,    13,    13, 30972, 30930, 36131, 31775, 30954,\n        54564, 30939, 30969, 30981, 30943, 54540, 34930, 54611, 31770, 44168,\n        54612, 32094, 30932, 31730, 37908, 40932, 34610, 53460, 54538, 54648,\n        33782, 42830, 31155, 30939, 30969, 30969, 30969, 54540, 30932, 44400,\n        47990, 55955, 45672, 32601, 35945, 54932, 54495, 46394, 30932, 39077,\n        32061, 35038, 36503, 30932, 34613, 31775, 31699, 33533, 32285, 54615,\n        31155,    13,    13, 30970, 30930, 48745, 34597, 31829, 54542, 33451,\n        31856, 30954, 54534, 54901, 54894, 33197, 54530, 54711, 40455, 30932,\n        31879, 47344, 34597, 31829, 34528, 31954, 31849, 31155, 32780, 30932,\n        30939, 30969, 30969, 30973, 31766, 56012, 56554, 35224, 35380, 32251,\n        54542, 30943, 30940, 30940, 30940, 31766, 54693, 54717, 55862, 56072,\n        38174, 32251, 54609, 32251, 54110, 54038, 54633, 50966, 39787, 32198,\n        33460, 31155, 32413, 30932, 49788, 38916, 33382, 34559, 33451, 31856,\n        31639, 30932, 31779, 54619, 36372, 31201,  2222,  7676, 40937, 33931,\n        33451, 31856, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:08.299\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 54729, 54901, 54894, 33197, 54534,\n        54711, 31978, 33142, 54537, 32727, 32773, 55282, 31514,    13,    13,\n        55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:08.306\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([47187, 54901, 54894, 33197, 54996, 45361, 31065, 30956, 31065, 30959,\n        31065, 54901, 54894, 30932, 33152, 30939, 30969, 30973, 30969, 36701,\n        30943, 30940, 30940, 30939, 54540, 31978, 32738, 44400, 31155, 37347,\n        54711, 40455, 30932, 54572, 42000, 32102, 32773, 31155, 32040, 43742,\n        54572, 33142, 33248, 32773, 30954,    13,    13, 30939, 30930, 30910,\n        34739, 54730, 54618, 54542, 54776, 55517, 55183, 54848, 30954, 54564,\n        30939, 30969, 30973, 30969, 37625, 30932, 34739, 54530, 31944, 31680,\n        46134, 54535, 36286, 31155, 30939, 30969, 30969, 30939, 31766, 54681,\n        54848, 39720, 54537, 34739, 54530, 56072, 54730, 31155, 31701, 30932,\n        54776, 55517, 33931, 31832, 43805, 33166, 33147, 31800, 43792, 30932,\n        54551, 33313, 31730, 31665, 32579, 32164, 54556, 31818, 31704, 31640,\n        31155,    13,    13, 30943, 30930, 49196, 34126, 31639, 30954, 36887,\n        32369, 30973, 30940, 32404, 30932, 31661, 34126, 31639, 31913, 40860,\n        31155, 54901, 54894, 31683, 34765, 32382, 34126, 30932, 54688, 35971,\n        32058, 32296, 34050, 31155,    13,    13, 30966, 30930, 30910, 32277,\n        54542, 31747, 31639, 30954, 34153, 31990, 54530, 33654, 54542, 32277,\n        33920, 54534, 30939, 30969, 30981, 30966, 43795, 30939, 30969, 30981,\n        30969, 54540, 35227, 34979, 31155,  9628,  9871,  8340,   359, 30950,\n         5378, 30945, 30910, 32598, 30932, 30939, 30969, 30973, 30969, 31766,\n        33300, 33119, 31928, 54703, 30939, 30969, 30981, 30940, 54540, 54589,\n        30972, 30940,  8429, 54617, 46718, 54534, 30939, 30969, 30973, 30939,\n        54540, 35227, 54818, 54639, 57934, 30970, 30930, 30969, 32275, 32228,\n        55555, 31155, 31701, 30932, 54901, 54894, 31683, 54574, 42000, 31879,\n        42763, 32184, 31155,    13,    13, 30972, 30930, 36131, 31775, 30954,\n        54564, 30939, 30969, 30981, 30943, 54540, 34930, 54611, 31770, 44168,\n        54612, 32094, 30932, 31730, 37908, 40932, 34610, 53460, 54538, 54648,\n        33782, 42830, 31155, 30939, 30969, 30969, 30969, 54540, 30932, 44400,\n        47990, 55955, 45672, 32601, 35945, 54932, 54495, 46394, 30932, 39077,\n        32061, 35038, 36503, 30932, 34613, 31775, 31699, 33533, 32285, 54615,\n        31155,    13,    13, 30970, 30930, 48745, 34597, 31829, 54542, 33451,\n        31856, 30954, 54534, 54901, 54894, 33197, 54530, 54711, 40455, 30932,\n        31879, 47344, 34597, 31829, 34528, 31954, 31849, 31155, 32780, 30932,\n        30939, 30969, 30969, 30973, 31766, 56012, 56554, 35224, 35380, 32251,\n        54542, 30943, 30940, 30940, 30940, 31766, 54693, 54717, 55862, 56072,\n        38174, 32251, 54609, 32251, 54110, 54038, 54633, 50966, 39787, 32198,\n        33460, 31155, 32413, 30932, 49788, 38916, 33382, 34559, 33451, 31856,\n        31639, 30932, 31779, 54619, 36372, 31201,  2222,  7676, 40937, 33931,\n        33451, 31856, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:08.885\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 3.7863e+01,  5.3852e+01,  5.6758e-01,  1.7941e+00,  1.8869e+00,\n         1.2930e+00,  1.5533e+00,  1.7920e+00,  1.9575e+00,  1.3611e-01,\n         3.7137e+00,  6.4316e+00,  7.0310e+00,  5.3649e+00,  4.3792e+00,\n         2.9733e+00,  6.3306e+00,  1.3331e+00, -1.8833e+00, -2.8258e+00,\n         3.4504e+00, -5.4614e+00,  2.4658e+00,  4.6472e+00,  4.3308e+00,\n         6.9276e+00, -2.0919e+00, -3.9738e-01, -2.5428e-01,  7.0612e+00,\n         2.8014e+00,  2.7534e+00,  1.4205e+00,  3.5002e+00,  1.2700e+00,\n        -3.5355e-01,  1.4241e+00,  1.4442e+00,  6.6152e+00,  2.1676e+00,\n         7.2985e-01, -3.9575e+00,  4.0342e+00,  4.9197e-01,  2.4763e+00,\n         9.3815e+00,  3.7579e+00,  3.3594e+00, -4.4512e+00,  4.4691e+00,\n         6.1483e-01,  2.5887e-02, -2.3204e+00,  4.7379e+00,  3.0914e-01,\n         1.1096e+00, -2.1657e+00, -1.9952e-01,  3.0120e+00,  1.2865e+00,\n         5.8071e+00, -5.3572e-01,  2.3284e+00,  4.7000e+00,  5.5275e+00,\n         5.6386e+00,  7.4143e+00,  2.8971e+00,  6.7519e+00, -2.3098e+00,\n         1.5910e+00, -1.9379e+00, -4.2637e+00,  3.9273e+00, -2.4595e+00,\n        -2.1388e+00,  3.1221e-01,  5.9195e+00,  3.3296e+00, -4.3598e-01,\n         1.7913e+00, -2.0338e+00,  7.5842e+00,  1.0271e+01,  4.0556e+00,\n         1.9117e+00,  1.8174e-01, -5.5958e-01,  4.4777e+00,  3.9226e+00,\n         6.9989e-01, -2.9964e+00,  4.1758e+00,  1.7646e+00,  3.2691e+00,\n        -3.1950e+00,  3.3478e+00,  9.5116e+00,  1.0231e+01,  3.9139e+00,\n         7.0163e+00,  4.8298e+00,  4.3554e+00,  3.2673e+00,  5.4504e+00,\n        -7.1008e-01, -8.3567e-01,  1.0657e+00,  3.0005e+00, -8.2846e-01,\n         2.2000e+00,  8.1819e+00,  1.5397e+00,  1.0647e+01,  2.2426e+00,\n         6.9633e+00,  3.1549e+00,  3.7843e+00, -3.2941e-01, -1.1928e+00,\n         1.5375e+00, -1.1097e+00, -1.5291e+00,  2.9234e+00,  1.9738e+00,\n         1.2935e+00, -4.3188e+00, -3.6777e+00,  2.2548e+00,  1.6613e-01,\n         5.0434e+00,  6.2210e+00,  6.7997e+00,  7.2690e+00,  4.1016e+00,\n         1.6905e+00, -1.7418e+00,  7.9769e+00,  6.2595e+00,  2.6933e+00,\n         4.9062e+00,  2.2470e+00,  6.9973e+00,  6.0572e+00,  4.9993e+00,\n         2.6601e+00, -1.0649e+00,  4.8900e+00,  6.1277e+00,  4.6014e+00,\n         5.3783e+00,  4.9608e+00,  5.0676e+00,  3.6180e+00,  3.2622e+00,\n         8.3359e+00,  3.3423e+00,  5.0745e-01,  6.7410e+00,  9.5239e-02,\n         3.0643e+00,  6.6253e+00, -2.5326e+00,  3.2799e+00,  7.6232e+00,\n         6.1796e-01,  3.6053e+00,  4.9719e+00, -5.2798e-01, -5.8498e-01,\n         3.0217e+00,  4.8541e-01,  2.5775e+00,  4.8252e+00,  2.0954e+00,\n         3.0525e+00,  2.5458e+00, -3.5009e-01, -1.1679e+00, -1.0699e+00,\n        -2.9441e+00,  5.1672e+00, -2.0341e+00,  3.1124e+00,  1.0355e+01,\n         6.1667e+00,  7.4556e+00,  9.3992e+00,  6.0096e+00,  6.2094e+00,\n         8.2022e+00,  6.7857e+00,  8.1963e+00,  1.4564e+00,  3.1418e+00,\n        -6.7352e-01,  5.0944e+00,  3.4652e+00,  3.2097e+00, -7.5546e+00,\n        -3.5917e+00, -5.0085e+00, -3.3746e-01, -2.1263e+00, -3.3434e-01,\n        -8.7614e-02, -4.4918e+00, -2.5499e+00, -1.2336e+00, -1.9189e+00,\n         6.3603e-01, -5.4520e+00,  4.8107e+00, -4.3778e+00,  5.7467e+00,\n        -4.6491e+00,  5.1716e+00, -3.7738e-01,  2.5591e+00,  6.2613e+00,\n         7.7427e+00,  3.2997e+00,  1.8314e+00,  3.7994e+00, -2.7831e+00,\n        -4.1685e+00, -3.8277e-01,  7.7430e-01,  3.5312e+00,  5.7180e+00,\n         2.1268e+00,  5.8065e+00,  5.5571e+00,  4.4018e+00,  5.7529e+00,\n         2.9959e-01,  4.2276e+00,  2.3516e+00,  3.1027e+00,  3.9387e-01,\n         6.6135e+00,  3.0771e+00,  4.2040e+00,  6.4742e+00,  4.0838e+00,\n         6.9041e+00,  5.6664e+00,  5.7851e+00,  3.6150e+00,  5.2037e+00,\n         6.3837e+00,  7.6622e+00, -3.5896e+00,  3.9522e+00,  7.5572e+00,\n         4.0138e+00,  7.0211e+00, -9.0052e-01, -6.2294e+00, -1.0359e+00,\n         6.8917e-02,  1.7568e+00,  3.1992e+00,  3.8130e+00,  9.2827e+00,\n         6.2802e+00,  1.0256e+01,  1.2026e+01,  6.9746e+00,  3.8179e+00,\n         5.9849e+00,  2.5703e+00,  5.1864e+00,  6.8647e+00,  3.6025e+00,\n         2.4409e+00,  7.2058e+00,  5.7932e+00,  2.0437e+00,  3.7812e+00,\n         4.0180e+00,  7.7326e+00, -1.2353e+00,  5.0266e+00,  4.1715e+00,\n         2.7179e+00,  1.1283e+01,  5.7269e+00,  6.8559e+00,  4.8207e+00,\n        -2.3625e-01,  4.4787e+00, -4.9628e-01, -2.0915e+00, -2.3302e+00,\n         5.6596e-01,  7.9739e+00,  2.5673e+00,  5.4010e+00,  7.2076e+00,\n         5.8506e+00,  3.8366e+00,  4.1370e+00, -6.1974e+00, -2.6524e+00,\n         1.9600e+00,  1.0300e+01,  7.7608e+00, -1.3016e+00,  1.7447e+00,\n         1.2263e+01,  4.3735e+00,  8.2957e-01,  5.2887e+00,  9.1712e+00,\n        -2.5539e+00,  7.3671e-01, -4.1356e-01, -3.2897e+00, -3.3115e+00,\n        -4.2839e+00,  5.6183e-01,  2.7570e+00, -1.0355e+00, -3.4266e+00,\n         2.0960e+00,  6.3183e+00,  5.3296e+00, -2.4670e+00,  2.2042e+00,\n         3.1824e+00,  9.0748e-01,  4.9050e+00,  1.0412e+00, -2.1092e+00,\n        -6.0365e-01,  3.8040e+00,  3.3100e+00,  1.4707e+00, -1.3203e+00,\n        -3.7841e+00, -3.9354e+00, -3.4682e+00,  1.7382e+00,  8.1949e+00,\n         4.5091e+00, -4.9926e+00,  4.0145e-01,  5.3953e+00, -5.6406e+00,\n        -1.0902e+00, -6.8635e-01,  8.1086e-01,  6.4702e+00,  3.0645e+00,\n         5.3921e+00,  2.2627e-01, -4.3421e+00, -2.1993e+00,  8.9068e+00,\n         6.5072e+00, -5.0328e+00, -5.8093e+00, -5.0819e+00,  1.2405e+00,\n         1.1596e+00, -3.2440e+00, -1.6894e+00, -3.5737e-01,  2.2040e+00,\n        -6.5743e+00, -2.6845e-01, -3.1115e+00,  3.8189e+00,  4.4314e+00,\n        -2.3979e+00,  1.4533e+00, -6.7647e-03,  2.0924e+00,  3.6904e+00,\n         2.5151e+00,  3.2929e+00,  3.9448e+00, -2.1955e+00, -1.5002e-01,\n         3.5542e+00, -6.1462e+00, -3.4538e+00,  4.1091e+00, -3.0066e+00,\n         2.9883e-01, -3.4336e+00,  6.1315e-01,  2.0710e+00,  4.7768e+00,\n        -1.0364e+00], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:08.886\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:41:08.887\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:41:08.896\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 3.7863e+01,  5.3852e+01,  5.6758e-01,  1.7941e+00,  1.8869e+00,\n         1.2930e+00,  1.5533e+00,  1.7920e+00,  1.9575e+00,  1.3611e-01,\n         3.7137e+00,  6.4316e+00,  7.0310e+00,  5.3649e+00,  4.3792e+00,\n         2.9733e+00,  6.3306e+00,  1.3331e+00, -1.8833e+00, -2.8258e+00,\n         3.4504e+00, -5.4614e+00,  2.4658e+00,  4.6472e+00,  4.3308e+00,\n         6.9276e+00, -2.0919e+00, -3.9738e-01, -2.5428e-01,  7.0612e+00,\n         2.8014e+00,  2.7534e+00,  1.4205e+00,  3.5002e+00,  1.2700e+00,\n        -3.5355e-01,  1.4241e+00,  1.4442e+00,  6.6152e+00,  2.1676e+00,\n         7.2985e-01, -3.9575e+00,  4.0342e+00,  4.9197e-01,  2.4763e+00,\n         9.3815e+00,  3.7579e+00,  3.3594e+00, -4.4512e+00,  4.4691e+00,\n         6.1483e-01,  2.5887e-02, -2.3204e+00,  4.7379e+00,  3.0914e-01,\n         1.1096e+00, -2.1657e+00, -1.9952e-01,  3.0120e+00,  1.2865e+00,\n         5.8071e+00, -5.3572e-01,  2.3284e+00,  4.7000e+00,  5.5275e+00,\n         5.6386e+00,  7.4143e+00,  2.8971e+00,  6.7519e+00, -2.3098e+00,\n         1.5910e+00, -1.9379e+00, -4.2637e+00,  3.9273e+00, -2.4595e+00,\n        -2.1388e+00,  3.1221e-01,  5.9195e+00,  3.3296e+00, -4.3598e-01,\n         1.7913e+00, -2.0338e+00,  7.5842e+00,  1.0271e+01,  4.0556e+00,\n         1.9117e+00,  1.8174e-01, -5.5958e-01,  4.4777e+00,  3.9226e+00,\n         6.9989e-01, -2.9964e+00,  4.1758e+00,  1.7646e+00,  3.2691e+00,\n        -3.1950e+00,  3.3478e+00,  9.5116e+00,  1.0231e+01,  3.9139e+00,\n         7.0163e+00,  4.8298e+00,  4.3554e+00,  3.2673e+00,  5.4504e+00,\n        -7.1008e-01, -8.3567e-01,  1.0657e+00,  3.0005e+00, -8.2846e-01,\n         2.2000e+00,  8.1819e+00,  1.5397e+00,  1.0647e+01,  2.2426e+00,\n         6.9633e+00,  3.1549e+00,  3.7843e+00, -3.2941e-01, -1.1928e+00,\n         1.5375e+00, -1.1097e+00, -1.5291e+00,  2.9234e+00,  1.9738e+00,\n         1.2935e+00, -4.3188e+00, -3.6777e+00,  2.2548e+00,  1.6613e-01,\n         5.0434e+00,  6.2210e+00,  6.7997e+00,  7.2690e+00,  4.1016e+00,\n         1.6905e+00, -1.7418e+00,  7.9769e+00,  6.2595e+00,  2.6933e+00,\n         4.9062e+00,  2.2470e+00,  6.9973e+00,  6.0572e+00,  4.9993e+00,\n         2.6601e+00, -1.0649e+00,  4.8900e+00,  6.1277e+00,  4.6014e+00,\n         5.3783e+00,  4.9608e+00,  5.0676e+00,  3.6180e+00,  3.2622e+00,\n         8.3359e+00,  3.3423e+00,  5.0745e-01,  6.7410e+00,  9.5239e-02,\n         3.0643e+00,  6.6253e+00, -2.5326e+00,  3.2799e+00,  7.6232e+00,\n         6.1796e-01,  3.6053e+00,  4.9719e+00, -5.2798e-01, -5.8498e-01,\n         3.0217e+00,  4.8541e-01,  2.5775e+00,  4.8252e+00,  2.0954e+00,\n         3.0525e+00,  2.5458e+00, -3.5009e-01, -1.1679e+00, -1.0699e+00,\n        -2.9441e+00,  5.1672e+00, -2.0341e+00,  3.1124e+00,  1.0355e+01,\n         6.1667e+00,  7.4556e+00,  9.3992e+00,  6.0096e+00,  6.2094e+00,\n         8.2022e+00,  6.7857e+00,  8.1963e+00,  1.4564e+00,  3.1418e+00,\n        -6.7352e-01,  5.0944e+00,  3.4652e+00,  3.2097e+00, -7.5546e+00,\n        -3.5917e+00, -5.0085e+00, -3.3746e-01, -2.1263e+00, -3.3434e-01,\n        -8.7614e-02, -4.4918e+00, -2.5499e+00, -1.2336e+00, -1.9189e+00,\n         6.3603e-01, -5.4520e+00,  4.8107e+00, -4.3778e+00,  5.7467e+00,\n        -4.6491e+00,  5.1716e+00, -3.7738e-01,  2.5591e+00,  6.2613e+00,\n         7.7427e+00,  3.2997e+00,  1.8314e+00,  3.7994e+00, -2.7831e+00,\n        -4.1685e+00, -3.8277e-01,  7.7430e-01,  3.5312e+00,  5.7180e+00,\n         2.1268e+00,  5.8065e+00,  5.5571e+00,  4.4018e+00,  5.7529e+00,\n         2.9959e-01,  4.2276e+00,  2.3516e+00,  3.1027e+00,  3.9387e-01,\n         6.6135e+00,  3.0771e+00,  4.2040e+00,  6.4742e+00,  4.0838e+00,\n         6.9041e+00,  5.6664e+00,  5.7851e+00,  3.6150e+00,  5.2037e+00,\n         6.3837e+00,  7.6622e+00, -3.5896e+00,  3.9522e+00,  7.5572e+00,\n         4.0138e+00,  7.0211e+00, -9.0052e-01, -6.2294e+00, -1.0359e+00,\n         6.8917e-02,  1.7568e+00,  3.1992e+00,  3.8130e+00,  9.2827e+00,\n         6.2802e+00,  1.0256e+01,  1.2026e+01,  6.9746e+00,  3.8179e+00,\n         5.9849e+00,  2.5703e+00,  5.1864e+00,  6.8647e+00,  3.6025e+00,\n         2.4409e+00,  7.2058e+00,  5.7932e+00,  2.0437e+00,  3.7812e+00,\n         4.0180e+00,  7.7326e+00, -1.2353e+00,  5.0266e+00,  4.1715e+00,\n         2.7179e+00,  1.1283e+01,  5.7269e+00,  6.8559e+00,  4.8207e+00,\n        -2.3625e-01,  4.4787e+00, -4.9628e-01, -2.0915e+00, -2.3302e+00,\n         5.6596e-01,  7.9739e+00,  2.5673e+00,  5.4010e+00,  7.2076e+00,\n         5.8506e+00,  3.8366e+00,  4.1370e+00, -6.1974e+00, -2.6524e+00,\n         1.9600e+00,  1.0300e+01,  7.7608e+00, -1.3016e+00,  1.7447e+00,\n         1.2263e+01,  4.3735e+00,  8.2957e-01,  5.2887e+00,  9.1712e+00,\n        -2.5539e+00,  7.3671e-01, -4.1356e-01, -3.2897e+00, -3.3115e+00,\n        -4.2839e+00,  5.6183e-01,  2.7570e+00, -1.0355e+00, -3.4266e+00,\n         2.0960e+00,  6.3183e+00,  5.3296e+00, -2.4670e+00,  2.2042e+00,\n         3.1824e+00,  9.0748e-01,  4.9050e+00,  1.0412e+00, -2.1092e+00,\n        -6.0365e-01,  3.8040e+00,  3.3100e+00,  1.4707e+00, -1.3203e+00,\n        -3.7841e+00, -3.9354e+00, -3.4682e+00,  1.7382e+00,  8.1949e+00,\n         4.5091e+00, -4.9926e+00,  4.0145e-01,  5.3953e+00, -5.6406e+00,\n        -1.0902e+00, -6.8635e-01,  8.1086e-01,  6.4702e+00,  3.0645e+00,\n         5.3921e+00,  2.2627e-01, -4.3421e+00, -2.1993e+00,  8.9068e+00,\n         6.5072e+00, -5.0328e+00, -5.8093e+00, -5.0819e+00,  1.2405e+00,\n         1.1596e+00, -3.2440e+00, -1.6894e+00, -3.5737e-01,  2.2040e+00,\n        -6.5743e+00, -2.6845e-01, -3.1115e+00,  3.8189e+00,  4.4314e+00,\n        -2.3979e+00,  1.4533e+00, -6.7647e-03,  2.0924e+00,  3.6904e+00,\n         2.5151e+00,  3.2929e+00,  3.9448e+00, -2.1955e+00, -1.5002e-01,\n         3.5542e+00, -6.1462e+00, -3.4538e+00,  4.1091e+00, -3.0066e+00,\n         2.9883e-01, -3.4336e+00,  6.1315e-01,  2.0710e+00,  4.7768e+00,\n        -1.0364e+00], device='cuda:0')]\u001b[0m\nepoch:  8 \nquery: 问：老布什总统在任期间面临了哪些挑战呢？\n\n答：\nresponse: 老布什总统即乔治·H·W·布什,他在1989年至2001年期间担任美国总统。在其任期内,他面临着许多挑战。以下是一些他面临的主要挑战:\n\n1. 苏联解体和东欧剧变:自1989年以来,苏联的改革已经变得越来越不稳定的。1991年的政变进一步加强了苏联的瓦解。同时,东欧国家的政治和经济状况也在不断恶化,这使得美国需要采取措施来支持这些国家。\n\n2. 世界贫困问题:在上世纪80年代,世界贫困问题继续加剧。布什政府致力于减少贫困,但并未取得明显进展。\n\n3. 能源和环境问题:石油价格的上涨和能源危机在1973年和1979年达到了高峰。 Environmental Protection Agency (EPA) 宣布,1989年的空气污染水平比1970年高40%,而油价在1981年达到了每加仑5.9美元的高峰。同时,布什政府也面临着全球气候变化的问题。\n\n4.中美关系:自1972年签署《上海公报》以来,美国和中国之间的关系一直在微妙中度过了几十年。1999年,美国总统克林顿政府和中共领导人江泽民会晤,结束了二十多年的对抗,两国关系开始走向正常化。\n\n5. 国际恐怖主义和外交政策:在布什总统的任期内,全球范围内的恐怖主义威胁持续存在。例如,1998年的坦桑尼亚爆炸事件和2000年的科特迪瓦袭击事件等事件都对美国和其盟友造成了严重伤害。此外,美国政府也需要应对一系列外交政策问题,包括与伊朗、 North Korea 等国家的外交政策。\nscore: tensor([ 3.7863e+01,  5.3852e+01,  5.6758e-01,  1.7941e+00,  1.8869e+00,\n         1.2930e+00,  1.5533e+00,  1.7920e+00,  1.9575e+00,  1.3611e-01,\n         3.7137e+00,  6.4316e+00,  7.0310e+00,  5.3649e+00,  4.3792e+00,\n         2.9733e+00,  6.3306e+00,  1.3331e+00, -1.8833e+00, -2.8258e+00,\n         3.4504e+00, -5.4614e+00,  2.4658e+00,  4.6472e+00,  4.3308e+00,\n         6.9276e+00, -2.0919e+00, -3.9738e-01, -2.5428e-01,  7.0612e+00,\n         2.8014e+00,  2.7534e+00,  1.4205e+00,  3.5002e+00,  1.2700e+00,\n        -3.5355e-01,  1.4241e+00,  1.4442e+00,  6.6152e+00,  2.1676e+00,\n         7.2985e-01, -3.9575e+00,  4.0342e+00,  4.9197e-01,  2.4763e+00,\n         9.3815e+00,  3.7579e+00,  3.3594e+00, -4.4512e+00,  4.4691e+00,\n         6.1483e-01,  2.5887e-02, -2.3204e+00,  4.7379e+00,  3.0914e-01,\n         1.1096e+00, -2.1657e+00, -1.9952e-01,  3.0120e+00,  1.2865e+00,\n         5.8071e+00, -5.3572e-01,  2.3284e+00,  4.7000e+00,  5.5275e+00,\n         5.6386e+00,  7.4143e+00,  2.8971e+00,  6.7519e+00, -2.3098e+00,\n         1.5910e+00, -1.9379e+00, -4.2637e+00,  3.9273e+00, -2.4595e+00,\n        -2.1388e+00,  3.1221e-01,  5.9195e+00,  3.3296e+00, -4.3598e-01,\n         1.7913e+00, -2.0338e+00,  7.5842e+00,  1.0271e+01,  4.0556e+00,\n         1.9117e+00,  1.8174e-01, -5.5958e-01,  4.4777e+00,  3.9226e+00,\n         6.9989e-01, -2.9964e+00,  4.1758e+00,  1.7646e+00,  3.2691e+00,\n        -3.1950e+00,  3.3478e+00,  9.5116e+00,  1.0231e+01,  3.9139e+00,\n         7.0163e+00,  4.8298e+00,  4.3554e+00,  3.2673e+00,  5.4504e+00,\n        -7.1008e-01, -8.3567e-01,  1.0657e+00,  3.0005e+00, -8.2846e-01,\n         2.2000e+00,  8.1819e+00,  1.5397e+00,  1.0647e+01,  2.2426e+00,\n         6.9633e+00,  3.1549e+00,  3.7843e+00, -3.2941e-01, -1.1928e+00,\n         1.5375e+00, -1.1097e+00, -1.5291e+00,  2.9234e+00,  1.9738e+00,\n         1.2935e+00, -4.3188e+00, -3.6777e+00,  2.2548e+00,  1.6613e-01,\n         5.0434e+00,  6.2210e+00,  6.7997e+00,  7.2690e+00,  4.1016e+00,\n         1.6905e+00, -1.7418e+00,  7.9769e+00,  6.2595e+00,  2.6933e+00,\n         4.9062e+00,  2.2470e+00,  6.9973e+00,  6.0572e+00,  4.9993e+00,\n         2.6601e+00, -1.0649e+00,  4.8900e+00,  6.1277e+00,  4.6014e+00,\n         5.3783e+00,  4.9608e+00,  5.0676e+00,  3.6180e+00,  3.2622e+00,\n         8.3359e+00,  3.3423e+00,  5.0745e-01,  6.7410e+00,  9.5239e-02,\n         3.0643e+00,  6.6253e+00, -2.5326e+00,  3.2799e+00,  7.6232e+00,\n         6.1796e-01,  3.6053e+00,  4.9719e+00, -5.2798e-01, -5.8498e-01,\n         3.0217e+00,  4.8541e-01,  2.5775e+00,  4.8252e+00,  2.0954e+00,\n         3.0525e+00,  2.5458e+00, -3.5009e-01, -1.1679e+00, -1.0699e+00,\n        -2.9441e+00,  5.1672e+00, -2.0341e+00,  3.1124e+00,  1.0355e+01,\n         6.1667e+00,  7.4556e+00,  9.3992e+00,  6.0096e+00,  6.2094e+00,\n         8.2022e+00,  6.7857e+00,  8.1963e+00,  1.4564e+00,  3.1418e+00,\n        -6.7352e-01,  5.0944e+00,  3.4652e+00,  3.2097e+00, -7.5546e+00,\n        -3.5917e+00, -5.0085e+00, -3.3746e-01, -2.1263e+00, -3.3434e-01,\n        -8.7614e-02, -4.4918e+00, -2.5499e+00, -1.2336e+00, -1.9189e+00,\n         6.3603e-01, -5.4520e+00,  4.8107e+00, -4.3778e+00,  5.7467e+00,\n        -4.6491e+00,  5.1716e+00, -3.7738e-01,  2.5591e+00,  6.2613e+00,\n         7.7427e+00,  3.2997e+00,  1.8314e+00,  3.7994e+00, -2.7831e+00,\n        -4.1685e+00, -3.8277e-01,  7.7430e-01,  3.5312e+00,  5.7180e+00,\n         2.1268e+00,  5.8065e+00,  5.5571e+00,  4.4018e+00,  5.7529e+00,\n         2.9959e-01,  4.2276e+00,  2.3516e+00,  3.1027e+00,  3.9387e-01,\n         6.6135e+00,  3.0771e+00,  4.2040e+00,  6.4742e+00,  4.0838e+00,\n         6.9041e+00,  5.6664e+00,  5.7851e+00,  3.6150e+00,  5.2037e+00,\n         6.3837e+00,  7.6622e+00, -3.5896e+00,  3.9522e+00,  7.5572e+00,\n         4.0138e+00,  7.0211e+00, -9.0052e-01, -6.2294e+00, -1.0359e+00,\n         6.8917e-02,  1.7568e+00,  3.1992e+00,  3.8130e+00,  9.2827e+00,\n         6.2802e+00,  1.0256e+01,  1.2026e+01,  6.9746e+00,  3.8179e+00,\n         5.9849e+00,  2.5703e+00,  5.1864e+00,  6.8647e+00,  3.6025e+00,\n         2.4409e+00,  7.2058e+00,  5.7932e+00,  2.0437e+00,  3.7812e+00,\n         4.0180e+00,  7.7326e+00, -1.2353e+00,  5.0266e+00,  4.1715e+00,\n         2.7179e+00,  1.1283e+01,  5.7269e+00,  6.8559e+00,  4.8207e+00,\n        -2.3625e-01,  4.4787e+00, -4.9628e-01, -2.0915e+00, -2.3302e+00,\n         5.6596e-01,  7.9739e+00,  2.5673e+00,  5.4010e+00,  7.2076e+00,\n         5.8506e+00,  3.8366e+00,  4.1370e+00, -6.1974e+00, -2.6524e+00,\n         1.9600e+00,  1.0300e+01,  7.7608e+00, -1.3016e+00,  1.7447e+00,\n         1.2263e+01,  4.3735e+00,  8.2957e-01,  5.2887e+00,  9.1712e+00,\n        -2.5539e+00,  7.3671e-01, -4.1356e-01, -3.2897e+00, -3.3115e+00,\n        -4.2839e+00,  5.6183e-01,  2.7570e+00, -1.0355e+00, -3.4266e+00,\n         2.0960e+00,  6.3183e+00,  5.3296e+00, -2.4670e+00,  2.2042e+00,\n         3.1824e+00,  9.0748e-01,  4.9050e+00,  1.0412e+00, -2.1092e+00,\n        -6.0365e-01,  3.8040e+00,  3.3100e+00,  1.4707e+00, -1.3203e+00,\n        -3.7841e+00, -3.9354e+00, -3.4682e+00,  1.7382e+00,  8.1949e+00,\n         4.5091e+00, -4.9926e+00,  4.0145e-01,  5.3953e+00, -5.6406e+00,\n        -1.0902e+00, -6.8635e-01,  8.1086e-01,  6.4702e+00,  3.0645e+00,\n         5.3921e+00,  2.2627e-01, -4.3421e+00, -2.1993e+00,  8.9068e+00,\n         6.5072e+00, -5.0328e+00, -5.8093e+00, -5.0819e+00,  1.2405e+00,\n         1.1596e+00, -3.2440e+00, -1.6894e+00, -3.5737e-01,  2.2040e+00,\n        -6.5743e+00, -2.6845e-01, -3.1115e+00,  3.8189e+00,  4.4314e+00,\n        -2.3979e+00,  1.4533e+00, -6.7647e-03,  2.0924e+00,  3.6904e+00,\n         2.5151e+00,  3.2929e+00,  3.9448e+00, -2.1955e+00, -1.5002e-01,\n         3.5542e+00, -6.1462e+00, -3.4538e+00,  4.1091e+00, -3.0066e+00,\n         2.9883e-01, -3.4336e+00,  6.1315e-01,  2.0710e+00,  4.7768e+00,\n        -1.0364e+00], device='cuda:0')\n\u001b[32m2023-08-14 17:41:08.905\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:41:08.914\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 3.7863e+01,  5.3852e+01,  5.6758e-01,  1.7941e+00,  1.8869e+00,\n         1.2930e+00,  1.5533e+00,  1.7920e+00,  1.9575e+00,  1.3611e-01,\n         3.7137e+00,  6.4316e+00,  7.0310e+00,  5.3649e+00,  4.3792e+00,\n         2.9733e+00,  6.3306e+00,  1.3331e+00, -1.8833e+00, -2.8258e+00,\n         3.4504e+00, -5.4614e+00,  2.4658e+00,  4.6472e+00,  4.3308e+00,\n         6.9276e+00, -2.0919e+00, -3.9738e-01, -2.5428e-01,  7.0612e+00,\n         2.8014e+00,  2.7534e+00,  1.4205e+00,  3.5002e+00,  1.2700e+00,\n        -3.5355e-01,  1.4241e+00,  1.4442e+00,  6.6152e+00,  2.1676e+00,\n         7.2985e-01, -3.9575e+00,  4.0342e+00,  4.9197e-01,  2.4763e+00,\n         9.3815e+00,  3.7579e+00,  3.3594e+00, -4.4512e+00,  4.4691e+00,\n         6.1483e-01,  2.5887e-02, -2.3204e+00,  4.7379e+00,  3.0914e-01,\n         1.1096e+00, -2.1657e+00, -1.9952e-01,  3.0120e+00,  1.2865e+00,\n         5.8071e+00, -5.3572e-01,  2.3284e+00,  4.7000e+00,  5.5275e+00,\n         5.6386e+00,  7.4143e+00,  2.8971e+00,  6.7519e+00, -2.3098e+00,\n         1.5910e+00, -1.9379e+00, -4.2637e+00,  3.9273e+00, -2.4595e+00,\n        -2.1388e+00,  3.1221e-01,  5.9195e+00,  3.3296e+00, -4.3598e-01,\n         1.7913e+00, -2.0338e+00,  7.5842e+00,  1.0271e+01,  4.0556e+00,\n         1.9117e+00,  1.8174e-01, -5.5958e-01,  4.4777e+00,  3.9226e+00,\n         6.9989e-01, -2.9964e+00,  4.1758e+00,  1.7646e+00,  3.2691e+00,\n        -3.1950e+00,  3.3478e+00,  9.5116e+00,  1.0231e+01,  3.9139e+00,\n         7.0163e+00,  4.8298e+00,  4.3554e+00,  3.2673e+00,  5.4504e+00,\n        -7.1008e-01, -8.3567e-01,  1.0657e+00,  3.0005e+00, -8.2846e-01,\n         2.2000e+00,  8.1819e+00,  1.5397e+00,  1.0647e+01,  2.2426e+00,\n         6.9633e+00,  3.1549e+00,  3.7843e+00, -3.2941e-01, -1.1928e+00,\n         1.5375e+00, -1.1097e+00, -1.5291e+00,  2.9234e+00,  1.9738e+00,\n         1.2935e+00, -4.3188e+00, -3.6777e+00,  2.2548e+00,  1.6613e-01,\n         5.0434e+00,  6.2210e+00,  6.7997e+00,  7.2690e+00,  4.1016e+00,\n         1.6905e+00, -1.7418e+00,  7.9769e+00,  6.2595e+00,  2.6933e+00,\n         4.9062e+00,  2.2470e+00,  6.9973e+00,  6.0572e+00,  4.9993e+00,\n         2.6601e+00, -1.0649e+00,  4.8900e+00,  6.1277e+00,  4.6014e+00,\n         5.3783e+00,  4.9608e+00,  5.0676e+00,  3.6180e+00,  3.2622e+00,\n         8.3359e+00,  3.3423e+00,  5.0745e-01,  6.7410e+00,  9.5239e-02,\n         3.0643e+00,  6.6253e+00, -2.5326e+00,  3.2799e+00,  7.6232e+00,\n         6.1796e-01,  3.6053e+00,  4.9719e+00, -5.2798e-01, -5.8498e-01,\n         3.0217e+00,  4.8541e-01,  2.5775e+00,  4.8252e+00,  2.0954e+00,\n         3.0525e+00,  2.5458e+00, -3.5009e-01, -1.1679e+00, -1.0699e+00,\n        -2.9441e+00,  5.1672e+00, -2.0341e+00,  3.1124e+00,  1.0355e+01,\n         6.1667e+00,  7.4556e+00,  9.3992e+00,  6.0096e+00,  6.2094e+00,\n         8.2022e+00,  6.7857e+00,  8.1963e+00,  1.4564e+00,  3.1418e+00,\n        -6.7352e-01,  5.0944e+00,  3.4652e+00,  3.2097e+00, -7.5546e+00,\n        -3.5917e+00, -5.0085e+00, -3.3746e-01, -2.1263e+00, -3.3434e-01,\n        -8.7614e-02, -4.4918e+00, -2.5499e+00, -1.2336e+00, -1.9189e+00,\n         6.3603e-01, -5.4520e+00,  4.8107e+00, -4.3778e+00,  5.7467e+00,\n        -4.6491e+00,  5.1716e+00, -3.7738e-01,  2.5591e+00,  6.2613e+00,\n         7.7427e+00,  3.2997e+00,  1.8314e+00,  3.7994e+00, -2.7831e+00,\n        -4.1685e+00, -3.8277e-01,  7.7430e-01,  3.5312e+00,  5.7180e+00,\n         2.1268e+00,  5.8065e+00,  5.5571e+00,  4.4018e+00,  5.7529e+00,\n         2.9959e-01,  4.2276e+00,  2.3516e+00,  3.1027e+00,  3.9387e-01,\n         6.6135e+00,  3.0771e+00,  4.2040e+00,  6.4742e+00,  4.0838e+00,\n         6.9041e+00,  5.6664e+00,  5.7851e+00,  3.6150e+00,  5.2037e+00,\n         6.3837e+00,  7.6622e+00, -3.5896e+00,  3.9522e+00,  7.5572e+00,\n         4.0138e+00,  7.0211e+00, -9.0052e-01, -6.2294e+00, -1.0359e+00,\n         6.8917e-02,  1.7568e+00,  3.1992e+00,  3.8130e+00,  9.2827e+00,\n         6.2802e+00,  1.0256e+01,  1.2026e+01,  6.9746e+00,  3.8179e+00,\n         5.9849e+00,  2.5703e+00,  5.1864e+00,  6.8647e+00,  3.6025e+00,\n         2.4409e+00,  7.2058e+00,  5.7932e+00,  2.0437e+00,  3.7812e+00,\n         4.0180e+00,  7.7326e+00, -1.2353e+00,  5.0266e+00,  4.1715e+00,\n         2.7179e+00,  1.1283e+01,  5.7269e+00,  6.8559e+00,  4.8207e+00,\n        -2.3625e-01,  4.4787e+00, -4.9628e-01, -2.0915e+00, -2.3302e+00,\n         5.6596e-01,  7.9739e+00,  2.5673e+00,  5.4010e+00,  7.2076e+00,\n         5.8506e+00,  3.8366e+00,  4.1370e+00, -6.1974e+00, -2.6524e+00,\n         1.9600e+00,  1.0300e+01,  7.7608e+00, -1.3016e+00,  1.7447e+00,\n         1.2263e+01,  4.3735e+00,  8.2957e-01,  5.2887e+00,  9.1712e+00,\n        -2.5539e+00,  7.3671e-01, -4.1356e-01, -3.2897e+00, -3.3115e+00,\n        -4.2839e+00,  5.6183e-01,  2.7570e+00, -1.0355e+00, -3.4266e+00,\n         2.0960e+00,  6.3183e+00,  5.3296e+00, -2.4670e+00,  2.2042e+00,\n         3.1824e+00,  9.0748e-01,  4.9050e+00,  1.0412e+00, -2.1092e+00,\n        -6.0365e-01,  3.8040e+00,  3.3100e+00,  1.4707e+00, -1.3203e+00,\n        -3.7841e+00, -3.9354e+00, -3.4682e+00,  1.7382e+00,  8.1949e+00,\n         4.5091e+00, -4.9926e+00,  4.0145e-01,  5.3953e+00, -5.6406e+00,\n        -1.0902e+00, -6.8635e-01,  8.1086e-01,  6.4702e+00,  3.0645e+00,\n         5.3921e+00,  2.2627e-01, -4.3421e+00, -2.1993e+00,  8.9068e+00,\n         6.5072e+00, -5.0328e+00, -5.8093e+00, -5.0819e+00,  1.2405e+00,\n         1.1596e+00, -3.2440e+00, -1.6894e+00, -3.5737e-01,  2.2040e+00,\n        -6.5743e+00, -2.6845e-01, -3.1115e+00,  3.8189e+00,  4.4314e+00,\n        -2.3979e+00,  1.4533e+00, -6.7647e-03,  2.0924e+00,  3.6904e+00,\n         2.5151e+00,  3.2929e+00,  3.9448e+00, -2.1955e+00, -1.5002e-01,\n         3.5542e+00, -6.1462e+00, -3.4538e+00,  4.1091e+00, -3.0066e+00,\n         2.9883e-01, -3.4336e+00,  6.1315e-01,  2.0710e+00,  4.7768e+00,\n        -1.0364e+00], device='cuda:0')]\u001b[0m\nscores=[tensor([ 3.7863e+01,  5.3852e+01,  5.6758e-01,  1.7941e+00,  1.8869e+00,\n         1.2930e+00,  1.5533e+00,  1.7920e+00,  1.9575e+00,  1.3611e-01,\n         3.7137e+00,  6.4316e+00,  7.0310e+00,  5.3649e+00,  4.3792e+00,\n         2.9733e+00,  6.3306e+00,  1.3331e+00, -1.8833e+00, -2.8258e+00,\n         3.4504e+00, -5.4614e+00,  2.4658e+00,  4.6472e+00,  4.3308e+00,\n         6.9276e+00, -2.0919e+00, -3.9738e-01, -2.5428e-01,  7.0612e+00,\n         2.8014e+00,  2.7534e+00,  1.4205e+00,  3.5002e+00,  1.2700e+00,\n        -3.5355e-01,  1.4241e+00,  1.4442e+00,  6.6152e+00,  2.1676e+00,\n         7.2985e-01, -3.9575e+00,  4.0342e+00,  4.9197e-01,  2.4763e+00,\n         9.3815e+00,  3.7579e+00,  3.3594e+00, -4.4512e+00,  4.4691e+00,\n         6.1483e-01,  2.5887e-02, -2.3204e+00,  4.7379e+00,  3.0914e-01,\n         1.1096e+00, -2.1657e+00, -1.9952e-01,  3.0120e+00,  1.2865e+00,\n         5.8071e+00, -5.3572e-01,  2.3284e+00,  4.7000e+00,  5.5275e+00,\n         5.6386e+00,  7.4143e+00,  2.8971e+00,  6.7519e+00, -2.3098e+00,\n         1.5910e+00, -1.9379e+00, -4.2637e+00,  3.9273e+00, -2.4595e+00,\n        -2.1388e+00,  3.1221e-01,  5.9195e+00,  3.3296e+00, -4.3598e-01,\n         1.7913e+00, -2.0338e+00,  7.5842e+00,  1.0271e+01,  4.0556e+00,\n         1.9117e+00,  1.8174e-01, -5.5958e-01,  4.4777e+00,  3.9226e+00,\n         6.9989e-01, -2.9964e+00,  4.1758e+00,  1.7646e+00,  3.2691e+00,\n        -3.1950e+00,  3.3478e+00,  9.5116e+00,  1.0231e+01,  3.9139e+00,\n         7.0163e+00,  4.8298e+00,  4.3554e+00,  3.2673e+00,  5.4504e+00,\n        -7.1008e-01, -8.3567e-01,  1.0657e+00,  3.0005e+00, -8.2846e-01,\n         2.2000e+00,  8.1819e+00,  1.5397e+00,  1.0647e+01,  2.2426e+00,\n         6.9633e+00,  3.1549e+00,  3.7843e+00, -3.2941e-01, -1.1928e+00,\n         1.5375e+00, -1.1097e+00, -1.5291e+00,  2.9234e+00,  1.9738e+00,\n         1.2935e+00, -4.3188e+00, -3.6777e+00,  2.2548e+00,  1.6613e-01,\n         5.0434e+00,  6.2210e+00,  6.7997e+00,  7.2690e+00,  4.1016e+00,\n         1.6905e+00, -1.7418e+00,  7.9769e+00,  6.2595e+00,  2.6933e+00,\n         4.9062e+00,  2.2470e+00,  6.9973e+00,  6.0572e+00,  4.9993e+00,\n         2.6601e+00, -1.0649e+00,  4.8900e+00,  6.1277e+00,  4.6014e+00,\n         5.3783e+00,  4.9608e+00,  5.0676e+00,  3.6180e+00,  3.2622e+00,\n         8.3359e+00,  3.3423e+00,  5.0745e-01,  6.7410e+00,  9.5239e-02,\n         3.0643e+00,  6.6253e+00, -2.5326e+00,  3.2799e+00,  7.6232e+00,\n         6.1796e-01,  3.6053e+00,  4.9719e+00, -5.2798e-01, -5.8498e-01,\n         3.0217e+00,  4.8541e-01,  2.5775e+00,  4.8252e+00,  2.0954e+00,\n         3.0525e+00,  2.5458e+00, -3.5009e-01, -1.1679e+00, -1.0699e+00,\n        -2.9441e+00,  5.1672e+00, -2.0341e+00,  3.1124e+00,  1.0355e+01,\n         6.1667e+00,  7.4556e+00,  9.3992e+00,  6.0096e+00,  6.2094e+00,\n         8.2022e+00,  6.7857e+00,  8.1963e+00,  1.4564e+00,  3.1418e+00,\n        -6.7352e-01,  5.0944e+00,  3.4652e+00,  3.2097e+00, -7.5546e+00,\n        -3.5917e+00, -5.0085e+00, -3.3746e-01, -2.1263e+00, -3.3434e-01,\n        -8.7614e-02, -4.4918e+00, -2.5499e+00, -1.2336e+00, -1.9189e+00,\n         6.3603e-01, -5.4520e+00,  4.8107e+00, -4.3778e+00,  5.7467e+00,\n        -4.6491e+00,  5.1716e+00, -3.7738e-01,  2.5591e+00,  6.2613e+00,\n         7.7427e+00,  3.2997e+00,  1.8314e+00,  3.7994e+00, -2.7831e+00,\n        -4.1685e+00, -3.8277e-01,  7.7430e-01,  3.5312e+00,  5.7180e+00,\n         2.1268e+00,  5.8065e+00,  5.5571e+00,  4.4018e+00,  5.7529e+00,\n         2.9959e-01,  4.2276e+00,  2.3516e+00,  3.1027e+00,  3.9387e-01,\n         6.6135e+00,  3.0771e+00,  4.2040e+00,  6.4742e+00,  4.0838e+00,\n         6.9041e+00,  5.6664e+00,  5.7851e+00,  3.6150e+00,  5.2037e+00,\n         6.3837e+00,  7.6622e+00, -3.5896e+00,  3.9522e+00,  7.5572e+00,\n         4.0138e+00,  7.0211e+00, -9.0052e-01, -6.2294e+00, -1.0359e+00,\n         6.8917e-02,  1.7568e+00,  3.1992e+00,  3.8130e+00,  9.2827e+00,\n         6.2802e+00,  1.0256e+01,  1.2026e+01,  6.9746e+00,  3.8179e+00,\n         5.9849e+00,  2.5703e+00,  5.1864e+00,  6.8647e+00,  3.6025e+00,\n         2.4409e+00,  7.2058e+00,  5.7932e+00,  2.0437e+00,  3.7812e+00,\n         4.0180e+00,  7.7326e+00, -1.2353e+00,  5.0266e+00,  4.1715e+00,\n         2.7179e+00,  1.1283e+01,  5.7269e+00,  6.8559e+00,  4.8207e+00,\n        -2.3625e-01,  4.4787e+00, -4.9628e-01, -2.0915e+00, -2.3302e+00,\n         5.6596e-01,  7.9739e+00,  2.5673e+00,  5.4010e+00,  7.2076e+00,\n         5.8506e+00,  3.8366e+00,  4.1370e+00, -6.1974e+00, -2.6524e+00,\n         1.9600e+00,  1.0300e+01,  7.7608e+00, -1.3016e+00,  1.7447e+00,\n         1.2263e+01,  4.3735e+00,  8.2957e-01,  5.2887e+00,  9.1712e+00,\n        -2.5539e+00,  7.3671e-01, -4.1356e-01, -3.2897e+00, -3.3115e+00,\n        -4.2839e+00,  5.6183e-01,  2.7570e+00, -1.0355e+00, -3.4266e+00,\n         2.0960e+00,  6.3183e+00,  5.3296e+00, -2.4670e+00,  2.2042e+00,\n         3.1824e+00,  9.0748e-01,  4.9050e+00,  1.0412e+00, -2.1092e+00,\n        -6.0365e-01,  3.8040e+00,  3.3100e+00,  1.4707e+00, -1.3203e+00,\n        -3.7841e+00, -3.9354e+00, -3.4682e+00,  1.7382e+00,  8.1949e+00,\n         4.5091e+00, -4.9926e+00,  4.0145e-01,  5.3953e+00, -5.6406e+00,\n        -1.0902e+00, -6.8635e-01,  8.1086e-01,  6.4702e+00,  3.0645e+00,\n         5.3921e+00,  2.2627e-01, -4.3421e+00, -2.1993e+00,  8.9068e+00,\n         6.5072e+00, -5.0328e+00, -5.8093e+00, -5.0819e+00,  1.2405e+00,\n         1.1596e+00, -3.2440e+00, -1.6894e+00, -3.5737e-01,  2.2040e+00,\n        -6.5743e+00, -2.6845e-01, -3.1115e+00,  3.8189e+00,  4.4314e+00,\n        -2.3979e+00,  1.4533e+00, -6.7647e-03,  2.0924e+00,  3.6904e+00,\n         2.5151e+00,  3.2929e+00,  3.9448e+00, -2.1955e+00, -1.5002e-01,\n         3.5542e+00, -6.1462e+00, -3.4538e+00,  4.1091e+00, -3.0066e+00,\n         2.9883e-01, -3.4336e+00,  6.1315e-01,  2.0710e+00,  4.7768e+00,\n        -1.0364e+00], device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 2.8638e+01,  5.1569e+01,  6.4355e-01,  1.7237e+00,  4.3929e-01,\n          3.6624e-01, -1.3868e+00,  1.1469e+00,  1.5804e+00,  5.5942e-01,\n          1.9624e+00,  4.6756e+00,  7.1064e+00,  1.2143e+00,  4.5253e+00,\n          5.2320e+00,  7.0162e+00,  1.5917e+00, -3.8145e+00, -2.0219e+00,\n          3.5719e+00, -9.8964e+00,  6.9343e-01,  5.6302e+00,  2.7468e+00,\n          3.6371e+00, -5.4016e+00, -8.9943e-02, -6.0794e-01,  9.1677e+00,\n          4.9672e+00,  2.3056e+00,  1.6277e+00,  1.3129e+00,  1.3056e+00,\n         -3.3731e-01, -1.2566e+00,  9.4481e-01,  7.0567e+00,  2.3893e+00,\n         -1.8319e+00, -1.7217e+00,  2.1018e+00,  3.5166e+00,  3.2481e+00,\n          1.0718e+01,  2.5787e+00,  4.1438e+00, -4.8442e+00,  3.8759e+00,\n         -1.2097e+00,  1.7049e+00, -3.2831e+00,  5.0897e+00, -1.6071e+00,\n          5.7888e-01, -6.2377e-01,  3.2653e-01,  2.5172e+00,  1.3938e+00,\n          9.6161e+00,  5.1523e-01, -3.2445e-01,  3.7737e+00,  2.9809e+00,\n          6.4490e+00,  6.5421e+00,  3.8718e+00,  6.0451e+00, -1.8344e+00,\n         -2.9521e+00, -1.2764e+00, -2.1581e+00,  4.8212e+00, -1.1627e+00,\n          9.9432e-02, -1.1176e+00,  7.1957e+00,  4.3139e+00, -1.2325e+00,\n          1.5097e+00, -2.9873e+00,  5.4004e+00,  9.6195e+00,  4.2515e+00,\n          4.7484e+00,  1.5281e+00, -3.4333e-01,  5.1164e+00,  4.4915e-01,\n         -2.4799e+00, -2.4545e+00,  3.1460e+00,  1.8454e+00,  1.4074e+00,\n         -3.6480e+00,  5.5603e+00,  8.9918e+00,  6.5764e+00,  4.1732e+00,\n          6.1780e+00,  4.1085e+00,  9.8482e+00,  1.4114e+00,  2.6553e+00,\n          3.4714e+00,  9.7486e-01, -9.5018e-02,  3.0438e+00, -2.7484e-01,\n          3.8440e+00,  7.9631e+00,  9.4693e-02,  9.0136e+00,  8.8553e-02,\n          3.7954e+00,  5.8043e+00,  7.7034e+00, -1.7913e+00, -2.3881e+00,\n          9.9887e-01,  1.7927e+00,  2.0716e-01,  2.2283e+00,  4.1418e+00,\n          4.2395e+00, -1.9000e+00, -4.6622e+00,  5.7197e+00,  3.7195e+00,\n          2.4455e+00,  7.5061e+00,  6.0941e+00,  6.4724e+00,  6.4381e-01,\n          3.1814e+00,  2.9628e+00,  6.7902e+00,  5.8760e+00,  3.8468e+00,\n          4.0880e+00,  3.0845e+00,  7.0618e+00,  5.1373e+00,  3.8261e+00,\n          4.7728e+00, -2.1530e-01,  5.9066e+00,  3.4584e+00,  3.4490e+00,\n          6.3122e+00,  7.0496e+00,  2.1880e+00,  4.4880e+00,  3.8558e+00,\n          8.8832e+00,  2.8238e+00,  3.3123e+00,  4.9550e+00,  1.7535e+00,\n          4.0162e+00,  6.0557e+00, -1.4946e+00,  3.1192e+00,  7.5729e+00,\n          2.4548e+00,  4.3552e+00,  5.8397e+00, -5.0020e-01, -1.7134e+00,\n          2.6705e+00, -1.7842e-02,  1.8943e+00,  2.7582e+00,  3.4141e+00,\n          3.2873e+00, -1.5001e+00,  1.8312e-01, -2.7423e+00, -1.8335e+00,\n         -2.2326e+00,  4.5454e+00, -3.6214e+00,  4.9039e+00,  9.9114e+00,\n          5.0925e+00,  5.3435e+00,  1.0604e+01,  5.1275e+00,  6.0228e+00,\n          8.2973e+00,  7.4551e+00,  7.7550e+00,  2.1518e+00,  4.4529e+00,\n         -4.2051e-01,  4.8360e+00,  2.8580e+00,  1.4281e-02, -7.0463e+00,\n         -6.9661e-01, -1.7153e+00,  2.2402e+00, -5.5065e+00,  4.3412e+00,\n         -1.1088e+00, -4.4974e+00, -7.1381e-01,  7.4431e-01,  1.7454e+00,\n         -3.1885e-01, -6.3964e+00,  6.7692e+00, -1.0297e+00,  5.4299e+00,\n         -7.5077e-01,  4.3875e+00, -5.6575e-01,  9.7470e-01,  1.0842e+01,\n          6.0840e+00,  3.7012e+00,  1.8696e+00,  3.0745e+00, -3.4055e+00,\n         -2.4061e+00,  7.0759e-01,  1.7199e+00,  3.6761e+00,  8.8986e+00,\n          4.5321e+00,  4.2729e+00,  9.8426e+00,  4.9866e+00,  1.9937e+00,\n         -9.1972e-01,  7.2244e+00,  2.9826e+00,  3.5921e+00,  2.1283e+00,\n          6.0103e+00,  4.6950e+00,  3.9839e+00,  4.5883e+00,  4.3426e+00,\n          7.4345e+00,  5.9878e+00,  7.5127e+00,  2.9055e+00,  3.6570e+00,\n          3.3489e+00,  4.7999e+00, -6.0440e+00,  1.3741e+00,  9.9574e+00,\n          3.4313e+00,  7.9546e+00, -8.6474e-01, -5.8135e+00,  2.9698e-01,\n          1.9092e+00, -1.8260e-02,  1.8777e+00,  6.0709e+00,  1.1204e+01,\n          5.2310e+00,  1.2295e+01,  1.1563e+01,  8.4330e+00,  5.2763e+00,\n          8.1990e+00,  6.0574e+00,  6.1337e+00,  6.8729e+00,  2.2074e+00,\n          7.9569e-01,  7.2762e+00,  5.9919e+00,  3.6896e+00,  5.6961e+00,\n          5.2617e+00,  5.7279e+00,  1.7701e+00,  4.4001e+00,  2.5999e+00,\n          2.5981e-01,  1.0464e+01,  6.4750e+00,  4.8073e+00,  4.9192e+00,\n          1.5442e+00,  1.2651e+00, -2.0631e+00, -4.1057e-01, -2.5517e+00,\n         -2.1665e+00,  9.4424e+00,  4.8484e+00,  6.3586e+00,  8.2190e+00,\n          7.2619e+00,  1.6567e+00,  6.6526e+00, -3.7050e+00, -2.0283e+00,\n          4.9851e+00,  9.9947e+00,  5.6713e+00, -9.1382e-01,  3.5805e+00,\n          8.8891e+00,  5.5518e+00,  1.3378e+00,  3.5248e+00,  9.2181e+00,\n         -1.9323e+00, -5.4727e-01, -2.4071e+00, -2.5702e+00, -4.1797e+00,\n         -6.9181e+00, -1.3740e+00,  2.5040e+00,  8.3290e-01, -3.2638e+00,\n          6.6697e+00,  4.9464e+00,  4.6816e+00, -4.7224e+00,  3.4454e+00,\n          1.6918e+00,  1.9092e+00,  4.2477e+00,  2.1811e+00, -2.8008e+00,\n         -1.3965e+00,  1.7735e-01,  4.2421e+00,  4.3720e+00,  9.6406e-01,\n         -1.5567e+00, -8.0075e+00, -5.1725e+00,  1.5408e+00,  8.3368e+00,\n          6.0022e+00, -1.7854e+00,  1.2078e+00,  2.2104e+00, -4.2300e+00,\n          8.0262e-01,  2.2795e+00,  3.3230e-01,  6.7042e+00,  7.5719e+00,\n          3.8957e+00, -1.0347e+00, -4.5353e+00, -6.9829e-01,  7.4852e+00,\n          6.4770e+00, -3.9408e+00, -5.6928e+00, -3.3174e+00,  3.9203e-01,\n         -9.5384e-01, -5.0343e+00, -2.2528e+00,  2.5444e+00,  3.2311e+00,\n         -7.6463e+00,  2.7793e+00, -2.0753e+00,  4.5191e+00,  9.9232e-01,\n          2.9564e-02,  7.5317e-01, -9.8597e-01,  3.8009e+00,  2.3757e+00,\n          4.4633e+00,  2.7850e+00,  7.8902e+00,  2.1016e+00,  4.1072e-03,\n          3.6038e+00, -6.2150e+00, -5.4825e+00,  4.1513e+00, -3.3581e+00,\n          3.8906e-01, -6.1269e+00,  1.9523e-01,  1.9691e+00,  2.3081e+00,\n          2.9286e-01]], device='cuda:0')\nvalues_994 = tensor([[ 3.3920e+01,  4.2435e+01, -9.8697e-02,  1.8537e+00,  9.4219e-01,\n          7.4081e-01,  2.7633e-01,  1.3722e+00,  1.9671e-01,  1.7563e+00,\n          2.5056e+00,  3.6191e+00,  6.9713e+00,  4.4910e+00,  5.4047e+00,\n          1.9336e+00,  7.0814e+00,  1.6741e+00, -2.8623e+00, -3.7340e+00,\n          3.8352e+00, -7.5772e+00,  5.0400e+00,  5.3681e+00,  2.2497e+00,\n          3.6889e+00, -4.9471e+00,  4.2938e-01,  1.7919e+00,  5.9941e+00,\n          4.2673e+00,  3.5213e+00,  4.1927e+00,  1.7322e+00,  2.2146e-01,\n         -1.5641e+00,  2.9157e-01,  1.3340e+00,  4.3214e+00, -4.4199e-01,\n          4.0597e+00, -2.6594e+00,  4.7599e+00,  2.6995e+00,  4.6367e+00,\n          9.0675e+00,  4.5551e-01,  1.8149e+00, -2.7803e+00,  4.6943e+00,\n         -1.0260e+00, -1.0180e+00, -1.9943e+00,  5.3545e+00, -4.9644e+00,\n          1.2311e+00, -5.0477e+00,  5.9171e-01,  1.6313e+00,  9.9020e-01,\n          6.8528e+00,  8.9395e-02, -3.9836e-01,  3.6887e+00,  1.4490e+00,\n          6.6195e+00,  7.5896e+00,  3.7851e+00,  6.0331e+00, -2.3814e+00,\n         -3.9682e+00,  2.6691e-01, -3.4698e+00,  6.2643e+00, -1.1414e+00,\n         -1.9183e+00,  7.0739e-01,  9.1234e+00,  4.3956e+00,  1.4898e-01,\n          2.7223e+00, -3.2221e+00,  5.2406e+00,  1.0234e+01,  4.7926e+00,\n          6.0451e+00,  3.5308e+00,  1.2183e-01,  7.2775e+00,  2.5037e+00,\n         -2.6501e-01, -1.9508e+00,  3.1561e+00,  3.2015e+00,  1.6038e+00,\n         -1.3062e+00,  1.9304e+00,  9.8096e+00,  8.1019e+00,  3.5401e+00,\n          6.9891e+00,  3.0447e+00,  6.8655e+00,  1.1542e+00,  4.6136e+00,\n          3.0565e+00,  5.8658e-01, -1.1989e+00,  1.7985e+00, -1.0219e-01,\n          9.3426e-01,  8.3919e+00, -8.2127e-01,  9.9373e+00, -1.2542e-01,\n          7.2825e+00,  5.6363e+00,  5.3100e+00, -3.9406e-01,  1.6021e+00,\n          6.1090e-01, -6.8002e-01, -1.5962e+00,  1.6168e+00,  4.2923e+00,\n          1.9859e+00, -5.5541e-01, -3.3934e+00,  3.7471e+00,  9.0598e-01,\n          5.9074e+00,  5.9444e+00,  5.5808e+00,  6.5130e+00,  2.5933e+00,\n          2.1921e+00,  4.5275e+00,  5.7753e+00,  4.9926e+00,  1.9696e+00,\n          2.0582e+00,  2.8420e+00,  5.5425e+00,  7.6709e+00,  7.1996e+00,\n          4.2309e+00,  9.9067e-01,  7.2142e+00,  4.7980e+00,  7.2532e+00,\n          5.7435e+00,  4.3248e+00,  2.8794e+00,  2.4140e+00,  4.3362e+00,\n          1.2965e+01,  2.4518e+00,  2.9819e+00,  3.7374e+00,  2.5119e+00,\n          5.4340e+00,  3.6662e+00, -4.8746e+00,  1.1684e+00,  7.1206e+00,\n          3.9343e+00,  3.6844e+00,  5.7259e+00, -1.3489e+00,  5.0096e-01,\n          3.6912e+00, -2.4122e-01, -6.1010e-01,  4.2711e+00,  3.1839e+00,\n          1.1504e+00,  6.0393e-01,  1.8800e+00, -1.5767e+00, -6.6328e-01,\n         -1.1579e+00,  4.3399e+00, -2.9458e+00,  2.1812e+00,  1.1135e+01,\n          4.8749e+00,  6.7254e+00,  1.3647e+01,  6.2569e+00,  5.5323e+00,\n          7.4950e+00,  4.7319e+00,  1.0516e+01,  2.3475e+00,  2.6562e+00,\n          6.1437e-01,  4.7407e+00,  2.9606e+00, -1.7034e+00, -6.1936e+00,\n         -1.6311e+00, -3.9652e+00,  1.0017e-01, -4.1968e+00,  1.3654e+00,\n          8.3624e-01, -5.4558e+00, -8.9770e-01,  4.6762e+00,  2.8936e-01,\n          1.5534e+00, -8.1213e+00,  6.3716e+00, -2.7554e+00,  5.2481e+00,\n         -1.0792e+00,  3.1879e+00, -4.2961e-01,  3.9690e+00,  6.4764e+00,\n          8.6212e+00,  4.0845e+00,  7.0131e-01,  4.0675e+00, -1.1559e+00,\n         -3.1043e+00,  1.5641e+00,  2.3583e+00,  3.4463e+00,  9.7678e+00,\n          2.3970e+00,  4.0570e+00,  9.8354e+00,  2.8674e+00,  5.2027e+00,\n         -1.5645e-01,  7.0752e+00,  1.9655e+00,  4.4072e+00,  2.1254e+00,\n          7.5835e+00,  4.4669e+00,  6.9349e+00,  6.3257e+00,  4.2287e+00,\n          7.8537e+00,  5.9149e+00,  7.4016e+00,  4.4323e+00,  1.9734e+00,\n          5.8000e+00,  6.9758e+00, -5.1765e+00,  3.5959e+00,  1.0753e+01,\n          3.7976e+00,  6.9837e+00, -8.5488e-01, -5.5053e+00, -2.3101e+00,\n         -2.3857e-01,  9.6312e-02,  2.2711e+00,  6.2107e+00,  9.2807e+00,\n          4.1310e+00,  1.1020e+01,  1.1503e+01,  7.0301e+00,  3.8590e+00,\n          4.2081e+00,  4.5028e+00,  5.1625e+00,  5.5603e+00,  2.3584e+00,\n          1.6824e+00,  8.5494e+00,  3.4856e+00,  3.1788e+00,  3.5733e+00,\n          5.8302e+00,  5.6991e+00, -1.1730e+00,  5.0863e+00,  6.5278e-02,\n          4.3952e+00,  1.0754e+01,  7.7159e+00,  7.8663e+00,  5.3194e+00,\n          2.0443e+00,  3.0391e+00, -4.2754e-02,  1.0403e+00, -8.4961e-01,\n          6.1316e-01,  4.9704e+00,  4.0317e+00,  3.7783e+00,  7.4152e+00,\n          6.6774e+00,  3.8818e+00,  5.4909e+00, -4.4812e+00,  7.5522e-01,\n          4.7692e+00,  1.1385e+01,  5.7262e+00,  1.1318e+00, -7.2703e-02,\n          8.7963e+00,  5.2268e+00,  9.9777e-01,  4.8161e+00,  8.3139e+00,\n         -2.0888e+00,  4.2662e-01, -3.5770e+00, -1.6265e+00, -2.7398e+00,\n         -4.7147e+00,  1.8922e+00,  4.1018e+00,  5.5912e-01, -1.4890e+00,\n          4.9557e+00,  7.2797e+00,  4.2376e+00, -1.8728e+00,  2.3966e+00,\n          3.3051e+00, -2.8233e-01,  5.1265e+00, -1.5670e-01, -3.6196e+00,\n          1.8295e-01,  1.9480e+00,  2.4268e+00,  4.3126e+00,  1.5183e+00,\n         -1.7430e+00, -5.9478e+00, -2.4987e+00,  1.4572e+00,  1.0033e+01,\n          4.4905e+00, -3.2182e+00,  1.5507e+00,  7.2904e+00, -3.5292e+00,\n          9.0151e-01,  1.4599e+00,  1.2475e+00,  5.7172e+00,  1.8754e+00,\n          4.6480e+00,  1.8875e+00, -3.9830e+00, -8.4127e-02,  8.9851e+00,\n          6.4943e+00, -6.0398e+00, -1.8014e+00, -5.5929e+00,  1.0123e+00,\n         -1.0357e+00, -3.9669e+00, -5.2545e+00,  1.6160e+00,  9.9314e-02,\n         -8.0776e+00,  2.7315e+00, -1.4137e+00,  5.5226e+00,  2.1528e+00,\n         -1.4646e-01,  1.1084e+00,  3.1939e-01,  9.0957e-01,  1.3229e+00,\n          4.7104e+00,  3.4942e+00,  7.4854e+00,  8.6183e-01,  1.4077e+00,\n          5.0792e+00, -8.5035e+00, -4.0773e+00, -2.5000e-01, -4.4088e+00,\n          1.5749e+00, -6.6329e+00, -3.1257e-02,  3.0843e+00,  4.4078e+00,\n         -7.3993e-01]], device='cuda:0')\nreward[last_non_masked_index]=tensor([1.8391e-06], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 3.7863e+01,  5.3852e+01,  5.6758e-01,  1.7941e+00,  1.8869e+00,\n         1.2930e+00,  1.5533e+00,  1.7920e+00,  1.9575e+00,  1.3611e-01,\n         3.7137e+00,  6.4316e+00,  7.0310e+00,  5.3649e+00,  4.3792e+00,\n         2.9733e+00,  6.3306e+00,  1.3331e+00, -1.8833e+00, -2.8258e+00,\n         3.4504e+00, -5.4614e+00,  2.4658e+00,  4.6472e+00,  4.3308e+00,\n         6.9276e+00, -2.0919e+00, -3.9738e-01, -2.5428e-01,  7.0612e+00,\n         2.8014e+00,  2.7534e+00,  1.4205e+00,  3.5002e+00,  1.2700e+00,\n        -3.5355e-01,  1.4241e+00,  1.4442e+00,  6.6152e+00,  2.1676e+00,\n         7.2985e-01, -3.9575e+00,  4.0342e+00,  4.9197e-01,  2.4763e+00,\n         9.3815e+00,  3.7579e+00,  3.3594e+00, -4.4512e+00,  4.4691e+00,\n         6.1483e-01,  2.5887e-02, -2.3204e+00,  4.7379e+00,  3.0914e-01,\n         1.1096e+00, -2.1657e+00, -1.9952e-01,  3.0120e+00,  1.2865e+00,\n         5.8071e+00, -5.3572e-01,  2.3284e+00,  4.7000e+00,  5.5275e+00,\n         5.6386e+00,  7.4143e+00,  2.8971e+00,  6.7519e+00, -2.3098e+00,\n         1.5910e+00, -1.9379e+00, -4.2637e+00,  3.9273e+00, -2.4595e+00,\n        -2.1388e+00,  3.1221e-01,  5.9195e+00,  3.3296e+00, -4.3598e-01,\n         1.7913e+00, -2.0338e+00,  7.5842e+00,  1.0271e+01,  4.0556e+00,\n         1.9117e+00,  1.8174e-01, -5.5958e-01,  4.4777e+00,  3.9226e+00,\n         6.9989e-01, -2.9964e+00,  4.1758e+00,  1.7646e+00,  3.2691e+00,\n        -3.1950e+00,  3.3478e+00,  9.5116e+00,  1.0231e+01,  3.9139e+00,\n         7.0163e+00,  4.8298e+00,  4.3554e+00,  3.2673e+00,  5.4504e+00,\n        -7.1008e-01, -8.3567e-01,  1.0657e+00,  3.0005e+00, -8.2846e-01,\n         2.2000e+00,  8.1819e+00,  1.5397e+00,  1.0647e+01,  2.2426e+00,\n         6.9633e+00,  3.1549e+00,  3.7843e+00, -3.2941e-01, -1.1928e+00,\n         1.5375e+00, -1.1097e+00, -1.5291e+00,  2.9234e+00,  1.9738e+00,\n         1.2935e+00, -4.3188e+00, -3.6777e+00,  2.2548e+00,  1.6613e-01,\n         5.0434e+00,  6.2210e+00,  6.7997e+00,  7.2690e+00,  4.1016e+00,\n         1.6905e+00, -1.7418e+00,  7.9769e+00,  6.2595e+00,  2.6933e+00,\n         4.9062e+00,  2.2470e+00,  6.9973e+00,  6.0572e+00,  4.9993e+00,\n         2.6601e+00, -1.0649e+00,  4.8900e+00,  6.1277e+00,  4.6014e+00,\n         5.3783e+00,  4.9608e+00,  5.0676e+00,  3.6180e+00,  3.2622e+00,\n         8.3359e+00,  3.3423e+00,  5.0745e-01,  6.7410e+00,  9.5239e-02,\n         3.0643e+00,  6.6253e+00, -2.5326e+00,  3.2799e+00,  7.6232e+00,\n         6.1796e-01,  3.6053e+00,  4.9719e+00, -5.2798e-01, -5.8498e-01,\n         3.0217e+00,  4.8541e-01,  2.5775e+00,  4.8252e+00,  2.0954e+00,\n         3.0525e+00,  2.5458e+00, -3.5009e-01, -1.1679e+00, -1.0699e+00,\n        -2.9441e+00,  5.1672e+00, -2.0341e+00,  3.1124e+00,  1.0355e+01,\n         6.1667e+00,  7.4556e+00,  9.3992e+00,  6.0096e+00,  6.2094e+00,\n         8.2022e+00,  6.7857e+00,  8.1963e+00,  1.4564e+00,  3.1418e+00,\n        -6.7352e-01,  5.0944e+00,  3.4652e+00,  3.2097e+00, -7.5546e+00,\n        -3.5917e+00, -5.0085e+00, -3.3746e-01, -2.1263e+00, -3.3434e-01,\n        -8.7614e-02, -4.4918e+00, -2.5499e+00, -1.2336e+00, -1.9189e+00,\n         6.3603e-01, -5.4520e+00,  4.8107e+00, -4.3778e+00,  5.7467e+00,\n        -4.6491e+00,  5.1716e+00, -3.7738e-01,  2.5591e+00,  6.2613e+00,\n         7.7427e+00,  3.2997e+00,  1.8314e+00,  3.7994e+00, -2.7831e+00,\n        -4.1685e+00, -3.8277e-01,  7.7430e-01,  3.5312e+00,  5.7180e+00,\n         2.1268e+00,  5.8065e+00,  5.5571e+00,  4.4018e+00,  5.7529e+00,\n         2.9959e-01,  4.2276e+00,  2.3516e+00,  3.1027e+00,  3.9387e-01,\n         6.6135e+00,  3.0771e+00,  4.2040e+00,  6.4742e+00,  4.0838e+00,\n         6.9041e+00,  5.6664e+00,  5.7851e+00,  3.6150e+00,  5.2037e+00,\n         6.3837e+00,  7.6622e+00, -3.5896e+00,  3.9522e+00,  7.5572e+00,\n         4.0138e+00,  7.0211e+00, -9.0052e-01, -6.2294e+00, -1.0359e+00,\n         6.8917e-02,  1.7568e+00,  3.1992e+00,  3.8130e+00,  9.2827e+00,\n         6.2802e+00,  1.0256e+01,  1.2026e+01,  6.9746e+00,  3.8179e+00,\n         5.9849e+00,  2.5703e+00,  5.1864e+00,  6.8647e+00,  3.6025e+00,\n         2.4409e+00,  7.2058e+00,  5.7932e+00,  2.0437e+00,  3.7812e+00,\n         4.0180e+00,  7.7326e+00, -1.2353e+00,  5.0266e+00,  4.1715e+00,\n         2.7179e+00,  1.1283e+01,  5.7269e+00,  6.8559e+00,  4.8207e+00,\n        -2.3625e-01,  4.4787e+00, -4.9628e-01, -2.0915e+00, -2.3302e+00,\n         5.6596e-01,  7.9739e+00,  2.5673e+00,  5.4010e+00,  7.2076e+00,\n         5.8506e+00,  3.8366e+00,  4.1370e+00, -6.1974e+00, -2.6524e+00,\n         1.9600e+00,  1.0300e+01,  7.7608e+00, -1.3016e+00,  1.7447e+00,\n         1.2263e+01,  4.3735e+00,  8.2957e-01,  5.2887e+00,  9.1712e+00,\n        -2.5539e+00,  7.3671e-01, -4.1356e-01, -3.2897e+00, -3.3115e+00,\n        -4.2839e+00,  5.6183e-01,  2.7570e+00, -1.0355e+00, -3.4266e+00,\n         2.0960e+00,  6.3183e+00,  5.3296e+00, -2.4670e+00,  2.2042e+00,\n         3.1824e+00,  9.0748e-01,  4.9050e+00,  1.0412e+00, -2.1092e+00,\n        -6.0365e-01,  3.8040e+00,  3.3100e+00,  1.4707e+00, -1.3203e+00,\n        -3.7841e+00, -3.9354e+00, -3.4682e+00,  1.7382e+00,  8.1949e+00,\n         4.5091e+00, -4.9926e+00,  4.0145e-01,  5.3953e+00, -5.6406e+00,\n        -1.0902e+00, -6.8635e-01,  8.1086e-01,  6.4702e+00,  3.0645e+00,\n         5.3921e+00,  2.2627e-01, -4.3421e+00, -2.1993e+00,  8.9068e+00,\n         6.5072e+00, -5.0328e+00, -5.8093e+00, -5.0819e+00,  1.2405e+00,\n         1.1596e+00, -3.2440e+00, -1.6894e+00, -3.5737e-01,  2.2040e+00,\n        -6.5743e+00, -2.6845e-01, -3.1115e+00,  3.8189e+00,  4.4314e+00,\n        -2.3979e+00,  1.4533e+00, -6.7647e-03,  2.0924e+00,  3.6904e+00,\n         2.5151e+00,  3.2929e+00,  3.9448e+00, -2.1955e+00, -1.5002e-01,\n         3.5542e+00, -6.1462e+00, -3.4538e+00,  4.1091e+00, -3.0066e+00,\n         2.9883e-01, -3.4336e+00,  6.1315e-01,  2.0710e+00,  4.7768e+00,\n        -1.0364e+00], device='cuda:0')\nvalues=tensor([[ 2.8638e+01,  5.1569e+01,  6.4355e-01,  1.7237e+00,  4.3929e-01,\n          3.6624e-01, -1.3868e+00,  1.1469e+00,  1.5804e+00,  5.5942e-01,\n          1.9624e+00,  4.6756e+00,  7.1064e+00,  1.2143e+00,  4.5253e+00,\n          5.2320e+00,  7.0162e+00,  1.5917e+00, -3.8145e+00, -2.0219e+00,\n          3.5719e+00, -9.8964e+00,  6.9343e-01,  5.6302e+00,  2.7468e+00,\n          3.6371e+00, -5.4016e+00, -8.9943e-02, -6.0794e-01,  9.1677e+00,\n          4.9672e+00,  2.3056e+00,  1.6277e+00,  1.3129e+00,  1.3056e+00,\n         -3.3731e-01, -1.2566e+00,  9.4481e-01,  7.0567e+00,  2.3893e+00,\n         -1.8319e+00, -1.7217e+00,  2.1018e+00,  3.5166e+00,  3.2481e+00,\n          1.0718e+01,  2.5787e+00,  4.1438e+00, -4.8442e+00,  3.8759e+00,\n         -1.2097e+00,  1.7049e+00, -3.2831e+00,  5.0897e+00, -1.6071e+00,\n          5.7888e-01, -6.2377e-01,  3.2653e-01,  2.5172e+00,  1.3938e+00,\n          9.6161e+00,  5.1523e-01, -3.2445e-01,  3.7737e+00,  2.9809e+00,\n          6.4490e+00,  6.5421e+00,  3.8718e+00,  6.0451e+00, -1.8344e+00,\n         -2.9521e+00, -1.2764e+00, -2.1581e+00,  4.8212e+00, -1.1627e+00,\n          9.9432e-02, -1.1176e+00,  7.1957e+00,  4.3139e+00, -1.2325e+00,\n          1.5097e+00, -2.9873e+00,  5.4004e+00,  9.6195e+00,  4.2515e+00,\n          4.7484e+00,  1.5281e+00, -3.4333e-01,  5.1164e+00,  4.4915e-01,\n         -2.4799e+00, -2.4545e+00,  3.1460e+00,  1.8454e+00,  1.4074e+00,\n         -3.6480e+00,  5.5603e+00,  8.9918e+00,  6.5764e+00,  4.1732e+00,\n          6.1780e+00,  4.1085e+00,  9.8482e+00,  1.4114e+00,  2.6553e+00,\n          3.4714e+00,  9.7486e-01, -9.5018e-02,  3.0438e+00, -2.7484e-01,\n          3.8440e+00,  7.9631e+00,  9.4693e-02,  9.0136e+00,  8.8553e-02,\n          3.7954e+00,  5.8043e+00,  7.7034e+00, -1.7913e+00, -2.3881e+00,\n          9.9887e-01,  1.7927e+00,  2.0716e-01,  2.2283e+00,  4.1418e+00,\n          4.2395e+00, -1.9000e+00, -4.6622e+00,  5.7197e+00,  3.7195e+00,\n          2.4455e+00,  7.5061e+00,  6.0941e+00,  6.4724e+00,  6.4381e-01,\n          3.1814e+00,  2.9628e+00,  6.7902e+00,  5.8760e+00,  3.8468e+00,\n          4.0880e+00,  3.0845e+00,  7.0618e+00,  5.1373e+00,  3.8261e+00,\n          4.7728e+00, -2.1530e-01,  5.9066e+00,  3.4584e+00,  3.4490e+00,\n          6.3122e+00,  7.0496e+00,  2.1880e+00,  4.4880e+00,  3.8558e+00,\n          8.8832e+00,  2.8238e+00,  3.3123e+00,  4.9550e+00,  1.7535e+00,\n          4.0162e+00,  6.0557e+00, -1.4946e+00,  3.1192e+00,  7.5729e+00,\n          2.4548e+00,  4.3552e+00,  5.8397e+00, -5.0020e-01, -1.7134e+00,\n          2.6705e+00, -1.7842e-02,  1.8943e+00,  2.7582e+00,  3.4141e+00,\n          3.2873e+00, -1.5001e+00,  1.8312e-01, -2.7423e+00, -1.8335e+00,\n         -2.2326e+00,  4.5454e+00, -3.6214e+00,  4.9039e+00,  9.9114e+00,\n          5.0925e+00,  5.3435e+00,  1.0604e+01,  5.1275e+00,  6.0228e+00,\n          8.2973e+00,  7.4551e+00,  7.7550e+00,  2.1518e+00,  4.4529e+00,\n         -4.2051e-01,  4.8360e+00,  2.8580e+00,  1.4281e-02, -7.0463e+00,\n         -6.9661e-01, -1.7153e+00,  2.2402e+00, -5.5065e+00,  4.3412e+00,\n         -1.1088e+00, -4.4974e+00, -7.1381e-01,  7.4431e-01,  1.7454e+00,\n         -3.1885e-01, -6.3964e+00,  6.7692e+00, -1.0297e+00,  5.4299e+00,\n         -7.5077e-01,  4.3875e+00, -5.6575e-01,  9.7470e-01,  1.0842e+01,\n          6.0840e+00,  3.7012e+00,  1.8696e+00,  3.0745e+00, -3.4055e+00,\n         -2.4061e+00,  7.0759e-01,  1.7199e+00,  3.6761e+00,  8.8986e+00,\n          4.5321e+00,  4.2729e+00,  9.8426e+00,  4.9866e+00,  1.9937e+00,\n         -9.1972e-01,  7.2244e+00,  2.9826e+00,  3.5921e+00,  2.1283e+00,\n          6.0103e+00,  4.6950e+00,  3.9839e+00,  4.5883e+00,  4.3426e+00,\n          7.4345e+00,  5.9878e+00,  7.5127e+00,  2.9055e+00,  3.6570e+00,\n          3.3489e+00,  4.7999e+00, -6.0440e+00,  1.3741e+00,  9.9574e+00,\n          3.4313e+00,  7.9546e+00, -8.6474e-01, -5.8135e+00,  2.9698e-01,\n          1.9092e+00, -1.8260e-02,  1.8777e+00,  6.0709e+00,  1.1204e+01,\n          5.2310e+00,  1.2295e+01,  1.1563e+01,  8.4330e+00,  5.2763e+00,\n          8.1990e+00,  6.0574e+00,  6.1337e+00,  6.8729e+00,  2.2074e+00,\n          7.9569e-01,  7.2762e+00,  5.9919e+00,  3.6896e+00,  5.6961e+00,\n          5.2617e+00,  5.7279e+00,  1.7701e+00,  4.4001e+00,  2.5999e+00,\n          2.5981e-01,  1.0464e+01,  6.4750e+00,  4.8073e+00,  4.9192e+00,\n          1.5442e+00,  1.2651e+00, -2.0631e+00, -4.1057e-01, -2.5517e+00,\n         -2.1665e+00,  9.4424e+00,  4.8484e+00,  6.3586e+00,  8.2190e+00,\n          7.2619e+00,  1.6567e+00,  6.6526e+00, -3.7050e+00, -2.0283e+00,\n          4.9851e+00,  9.9947e+00,  5.6713e+00, -9.1382e-01,  3.5805e+00,\n          8.8891e+00,  5.5518e+00,  1.3378e+00,  3.5248e+00,  9.2181e+00,\n         -1.9323e+00, -5.4727e-01, -2.4071e+00, -2.5702e+00, -4.1797e+00,\n         -6.9181e+00, -1.3740e+00,  2.5040e+00,  8.3290e-01, -3.2638e+00,\n          6.6697e+00,  4.9464e+00,  4.6816e+00, -4.7224e+00,  3.4454e+00,\n          1.6918e+00,  1.9092e+00,  4.2477e+00,  2.1811e+00, -2.8008e+00,\n         -1.3965e+00,  1.7735e-01,  4.2421e+00,  4.3720e+00,  9.6406e-01,\n         -1.5567e+00, -8.0075e+00, -5.1725e+00,  1.5408e+00,  8.3368e+00,\n          6.0022e+00, -1.7854e+00,  1.2078e+00,  2.2104e+00, -4.2300e+00,\n          8.0262e-01,  2.2795e+00,  3.3230e-01,  6.7042e+00,  7.5719e+00,\n          3.8957e+00, -1.0347e+00, -4.5353e+00, -6.9829e-01,  7.4852e+00,\n          6.4770e+00, -3.9408e+00, -5.6928e+00, -3.3174e+00,  3.9203e-01,\n         -9.5384e-01, -5.0343e+00, -2.2528e+00,  2.5444e+00,  3.2311e+00,\n         -7.6463e+00,  2.7793e+00, -2.0753e+00,  4.5191e+00,  9.9232e-01,\n          2.9564e-02,  7.5317e-01, -9.8597e-01,  3.8009e+00,  2.3757e+00,\n          4.4633e+00,  2.7850e+00,  7.8902e+00,  2.1016e+00,  4.1072e-03,\n          3.6038e+00, -6.2150e+00, -5.4825e+00,  4.1513e+00, -3.3581e+00,\n          3.8906e-01, -6.1269e+00,  1.9523e-01,  1.9691e+00,  2.3081e+00]],\n       device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00,  5.9604e-08, -0.0000e+00, -0.0000e+00, -2.9798e-07,\n         -3.9026e-05, -2.1309e-04, -3.0969e-06,  1.3089e-06,  1.9991e-04,\n          3.2383e-03, -9.8788e-06,  4.0764e-05,  5.9604e-08, -1.1920e-07,\n          2.4962e-04, -1.6681e-05, -0.0000e+00,  1.8254e-05,  4.1630e-07,\n         -1.2189e-04, -0.0000e+00,  4.5411e-05,  7.1371e-04, -4.5552e-03,\n          3.4535e-04,  1.2682e-03, -1.7658e-04, -1.1451e-03,  9.2506e-04,\n         -3.8335e-03,  8.3397e-07,  2.3840e-07,  1.4881e-06, -1.5435e-03,\n          1.4679e-03, -0.0000e+00, -2.9576e-04,  1.7873e-07, -1.0418e-05,\n         -3.0265e-05, -2.1848e-04, -0.0000e+00,  4.4547e-05, -1.0372e-03,\n         -5.9604e-08,  7.7425e-07,  1.2512e-06, -2.1242e-03, -4.6709e-04,\n          1.3732e-05, -3.5185e-03,  1.3736e-03,  4.5406e-05, -7.6248e-05,\n          1.7876e-07, -6.0970e-04, -8.2273e-06, -2.8265e-04,  1.1717e-03,\n         -1.3385e-04,  9.5934e-05,  8.3195e-06, -4.0841e-04, -1.7231e-06,\n         -3.5713e-06, -8.8522e-06,  1.8467e-06, -0.0000e+00, -0.0000e+00,\n         -1.1920e-07, -9.2316e-04, -1.8985e-03, -1.1154e-04, -0.0000e+00,\n         -2.6941e-04, -5.2839e-06, -1.2193e-05, -0.0000e+00, -9.8284e-05,\n         -2.7267e-05,  2.5220e-04, -7.5690e-05, -1.0126e-05, -2.9811e-03,\n          3.9084e-04,  3.4545e-05,  8.9366e-05, -0.0000e+00,  6.2359e-04,\n         -8.6284e-04, -7.6560e-05, -9.5328e-07,  1.4974e-04, -1.2508e-03,\n          6.5178e-05,  1.1918e-07,  8.8742e-04, -4.6081e-04,  1.1921e-07,\n          4.1347e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -9.4483e-07,\n         -2.2193e-03,  1.5148e-03,  1.2353e-04,  5.7098e-06, -5.9604e-08,\n          5.6225e-04,  1.2551e-04, -3.7337e-06,  2.7327e-04,  5.5887e-05,\n         -9.1601e-05, -1.0678e-03, -7.4157e-04,  2.7176e-06, -0.0000e+00,\n          6.0507e-03, -6.3283e-05, -3.7681e-04, -1.4859e-06,  5.9605e-08,\n         -2.7529e-04,  2.4059e-04,  3.9254e-06, -1.1921e-03, -1.8076e-05,\n          1.0548e-04, -4.0071e-03,  2.5551e-03, -1.4291e-06,  1.4386e-04,\n         -0.0000e+00,  5.9605e-08, -0.0000e+00, -1.3262e-03, -9.4676e-04,\n          3.5586e-06,  8.7962e-05, -2.9798e-07, -7.3817e-04,  1.3136e-03,\n         -1.6138e-03,  2.7699e-03,  6.9854e-04, -8.8131e-06, -4.4772e-04,\n          3.3336e-04,  5.8856e-06, -2.3177e-06,  1.4647e-04,  6.6458e-04,\n          1.9636e-03, -1.5208e-03, -1.1241e-06, -2.5511e-04,  3.2380e-04,\n          1.2058e-03,  6.3111e-06,  6.8900e-06,  8.9384e-07, -1.5487e-04,\n          1.0485e-03,  2.6624e-06,  1.9521e-03, -9.1475e-05, -4.4739e-04,\n          2.9794e-07,  1.7604e-03,  1.9717e-05,  8.1918e-04, -4.7583e-05,\n         -2.0243e-03, -8.9753e-04,  5.9576e-08, -1.0514e-03, -3.5756e-07,\n         -4.2546e-04, -0.0000e+00, -1.2951e-05,  3.8759e-04, -8.8323e-04,\n         -3.2036e-03, -7.8846e-04, -1.1982e-03,  3.0417e-04,  2.3838e-07,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00,  5.0914e-03,  9.6562e-06,\n          4.1717e-07,  1.2410e-04, -4.2101e-05,  1.1919e-07, -8.3272e-07,\n          3.7700e-05, -4.0409e-06,  1.7158e-03, -4.5464e-04, -3.9507e-06,\n         -8.6713e-06, -0.0000e+00,  5.9603e-08, -0.0000e+00, -1.9080e-04,\n          2.4019e-05,  3.0947e-06, -2.7422e-05, -1.9298e-03,  4.2331e-04,\n         -1.5641e-03,  2.1650e-05,  2.5883e-03, -2.3840e-07, -5.2736e-03,\n         -0.0000e+00, -9.3067e-06, -4.2700e-03, -1.8478e-05,  2.3144e-05,\n         -6.6292e-04, -1.0586e-04,  5.9604e-08, -1.9848e-03,  5.9682e-04,\n         -3.3449e-05, -8.3230e-05, -1.1312e-06, -2.6194e-03,  9.2532e-05,\n         -7.9584e-04,  6.3163e-04, -2.3398e-05,  6.5172e-04, -6.8024e-06,\n          6.2871e-04,  2.9478e-05,  6.2089e-04, -5.1478e-04, -1.2643e-05,\n          5.9601e-08, -2.7306e-06,  2.5708e-03, -0.0000e+00,  5.9601e-08,\n         -0.0000e+00, -2.3155e-03,  1.2837e-04, -6.5540e-07,  2.4414e-05,\n          8.3107e-04,  3.9231e-05,  7.1495e-07, -1.0879e-03, -6.8519e-04,\n         -0.0000e+00,  1.3307e-03, -1.9016e-03,  2.9799e-07, -0.0000e+00,\n         -1.1915e-06,  5.2683e-04,  1.9611e-03,  5.9604e-08, -2.9788e-07,\n         -1.6289e-04,  9.8456e-05, -1.2730e-04,  1.9811e-05,  3.8639e-03,\n          1.5758e-05,  4.6450e-06,  5.9605e-08, -5.9603e-08,  7.5512e-05,\n         -1.4305e-03,  4.7281e-03, -6.0983e-05, -1.7880e-07,  6.9564e-05,\n         -4.5449e-05,  5.8629e-05, -1.5474e-04, -0.0000e+00,  1.5482e-06,\n          1.5070e-05, -5.1442e-06,  2.3530e-03, -2.3313e-04,  6.5533e-07,\n          5.9604e-08,  8.8084e-04, -5.9601e-08,  4.6989e-04, -3.2164e-05,\n          1.3270e-03,  1.8091e-03,  7.6973e-04,  2.0614e-05, -1.1969e-04,\n          6.6051e-04,  2.1458e-04,  5.9603e-08, -2.5942e-04, -0.0000e+00,\n         -3.2451e-03, -1.3512e-03,  5.0683e-04, -1.2398e-03, -0.0000e+00,\n         -1.1919e-07,  5.7030e-05, -0.0000e+00,  3.4953e-03, -1.8932e-03,\n          7.7718e-04,  7.3373e-04,  5.0521e-04,  3.6217e-06,  7.5102e-05,\n          3.5705e-07, -1.1970e-05, -1.5471e-05,  2.1664e-03, -1.0364e+00]],\n       device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 3.2178e+01,  5.8883e+01,  6.5364e-01,  1.5478e+00,  6.9927e-01,\n         -2.5337e-01,  7.7692e-01,  1.0788e+00,  1.1159e+00, -4.3515e-01,\n          4.6483e+00,  4.6481e+00,  7.0636e+00,  4.5624e+00,  4.4306e+00,\n          4.7585e+00,  6.6086e+00,  1.5734e+00, -3.6913e+00, -4.1361e+00,\n          2.2385e+00, -8.4226e+00,  1.2654e+00,  2.6127e+00,  2.9523e+00,\n          5.2670e+00, -4.5702e+00, -2.1322e+00, -1.9275e+00,  7.9417e+00,\n          3.5760e+00,  7.2918e+00, -6.3038e-01,  1.8788e+00,  2.0021e+00,\n          1.4183e+00,  1.7548e+00,  8.2055e-01,  5.1619e+00,  4.1170e+00,\n         -7.7277e-02, -1.9562e+00,  4.8329e+00,  2.7285e+00,  1.3553e+00,\n          1.1201e+01,  3.5398e+00,  5.4432e+00, -2.1899e+00,  4.2203e+00,\n          1.2073e+00,  2.2708e+00, -1.5205e-01,  3.7492e+00, -1.1141e+00,\n          3.1113e+00, -1.1012e+00, -6.4736e-01,  1.7944e+00, -1.5616e+00,\n          6.3511e+00, -3.6353e+00,  1.7347e+00,  4.1771e+00,  3.1237e+00,\n          5.5101e+00,  3.9691e+00,  2.5223e+00,  7.1297e+00, -1.3432e+00,\n         -3.5019e+00,  1.4521e+00, -3.3439e-01,  6.2852e+00, -1.2826e+00,\n         -2.3821e+00,  7.6138e-01,  8.5694e+00,  3.2779e+00, -1.9685e+00,\n          1.0126e+00, -1.0994e+00,  7.1905e+00,  1.1145e+01,  3.9620e+00,\n          5.4962e+00,  1.8574e+00,  1.6406e+00,  3.9812e+00,  3.4726e+00,\n          3.6235e+00, -3.0289e+00,  2.9116e+00,  2.7840e+00,  7.5914e-01,\n          2.7223e-01,  5.1191e+00,  1.4029e+01,  7.4895e+00,  5.3523e+00,\n          5.7211e+00,  5.8134e+00,  6.4985e+00,  2.8300e+00,  2.5913e+00,\n          4.1750e+00,  1.2943e+00,  1.7391e+00,  1.4586e+00, -1.1728e+00,\n          8.2401e-01,  6.5163e+00,  2.5271e+00,  1.1087e+01, -1.4299e+00,\n          4.5647e+00,  4.3295e+00,  6.5802e+00, -1.4740e+00, -2.1395e+00,\n          5.3961e-01, -1.9749e+00, -1.2238e+00,  1.2800e+00,  5.0425e+00,\n          2.1627e+00, -2.6850e+00, -2.0198e+00,  3.3972e+00,  6.7828e-01,\n          7.4501e+00,  6.3007e+00,  6.4562e+00,  5.6819e+00,  4.0000e+00,\n          8.0033e-01,  1.4399e+00,  6.1679e+00,  7.9046e+00,  1.8289e+00,\n          4.1310e+00,  1.2633e-01,  7.1333e+00,  8.2466e+00,  6.5029e+00,\n          3.4467e+00,  4.5244e-01,  8.4298e+00,  4.7629e+00,  3.7842e+00,\n          6.1104e+00,  6.7754e+00,  1.3076e+00,  5.4008e+00,  4.3905e+00,\n          1.1222e+01,  2.4407e+00, -8.3846e-01,  3.8635e+00,  2.4599e+00,\n          4.0730e+00,  6.7796e+00, -6.2741e+00,  1.4930e+00,  9.2465e+00,\n          5.1443e+00,  4.7284e+00,  5.7447e+00, -3.4481e+00, -1.3897e+00,\n          8.0482e+00,  5.3180e-01, -3.8620e-01,  1.7463e+00,  2.7195e+00,\n          2.0541e+00,  2.3564e+00, -6.8662e-01, -3.4140e-01, -4.8687e+00,\n         -2.1318e+00,  1.2919e+00, -2.9545e+00,  2.2065e+00,  1.1777e+01,\n          6.3256e+00,  7.4788e+00,  9.0395e+00,  5.8102e+00,  5.8557e+00,\n          4.5492e+00,  5.6697e+00,  1.0207e+01,  2.3957e+00,  5.4180e+00,\n          5.4431e-01,  3.7179e+00,  3.6226e+00,  9.1983e-01, -5.4754e+00,\n         -2.2665e+00, -4.0289e+00,  2.4168e+00, -4.5021e+00,  4.4200e+00,\n          1.5498e+00, -3.9467e+00,  2.5717e-01,  1.2007e+00, -9.1817e-01,\n         -2.9832e-01, -3.0900e+00,  3.8503e+00, -8.0819e-01,  5.2440e+00,\n         -3.9157e+00,  2.3598e+00,  3.8911e-01,  1.2090e+00,  6.2695e+00,\n          7.7972e+00,  2.2491e+00,  1.1554e+00,  6.2808e+00,  9.2601e-01,\n         -3.8114e+00,  2.7842e+00,  8.9201e-01,  3.6259e+00,  9.3029e+00,\n          4.5302e+00,  6.0947e+00,  6.9572e+00,  3.9960e+00,  4.4141e+00,\n         -2.9628e+00,  6.2037e+00,  2.9574e+00,  5.7660e+00,  1.4477e+00,\n          4.3997e+00,  6.4057e+00,  4.4778e+00,  4.3032e+00,  3.4818e+00,\n          7.9863e+00,  6.9599e+00,  6.3401e+00,  3.1646e+00,  2.8487e+00,\n          4.7037e+00,  4.9788e+00, -5.2623e+00,  1.7316e+00,  6.6758e+00,\n          2.5291e+00,  6.3900e+00, -1.1132e+00, -7.6125e+00, -2.7386e+00,\n          1.1028e+00,  2.8814e-01,  1.5076e+00,  4.7260e+00,  6.8748e+00,\n          5.7878e+00,  1.1236e+01,  1.3321e+01,  4.7782e+00,  3.8085e+00,\n          3.4702e+00,  4.1081e+00,  1.9973e+00,  6.1899e+00,  3.5737e+00,\n          2.2323e+00,  8.4530e+00,  6.4046e+00,  4.1595e+00,  5.2295e+00,\n          6.5576e+00,  7.5051e+00, -6.7843e-01,  3.8464e+00,  3.4635e+00,\n          1.1898e+00,  1.1203e+01,  3.4980e+00,  1.7542e+00,  3.2272e+00,\n          3.1158e-01, -5.8833e-01,  1.2827e+00, -2.7718e-01, -2.8659e+00,\n         -2.2055e+00,  6.5249e+00,  2.3114e+00,  3.1122e+00,  5.9142e+00,\n          7.0903e+00,  2.2115e+00,  3.2783e+00, -4.2928e+00, -1.2640e+00,\n          2.8396e+00,  9.3659e+00,  7.3690e+00,  7.1227e-01,  3.4693e+00,\n          1.0996e+01,  4.4284e+00,  2.3037e-01,  3.9269e+00,  9.4304e+00,\n         -9.3407e-01,  8.6349e-01, -1.5655e+00, -2.1833e+00, -2.0700e+00,\n         -8.2499e+00,  2.0599e+00,  4.5814e+00,  1.2849e-01,  2.1747e-02,\n          4.0676e+00,  5.3238e+00,  6.2692e+00, -8.6083e-01,  1.6806e+00,\n          1.4322e+00,  8.3092e-01,  4.4779e+00,  2.3843e+00, -2.5760e+00,\n          4.8384e-01,  2.3166e+00,  2.6228e+00,  3.6562e+00, -2.6444e+00,\n         -3.7865e+00, -7.8906e+00, -2.9215e+00,  5.1307e-02,  5.1493e+00,\n          5.5698e+00, -2.6489e+00,  8.0624e-01,  5.7123e+00, -3.5246e+00,\n         -9.9339e-02,  2.3385e+00,  1.5737e+00,  6.4837e+00,  5.6640e+00,\n          4.5477e+00,  5.4517e-01, -3.9360e+00,  6.6845e-01,  6.9240e+00,\n          6.2036e+00, -5.2908e+00, -5.2918e+00, -3.7104e+00,  2.3110e+00,\n         -1.7503e+00, -3.7414e+00, -8.1784e-01,  3.1068e+00,  1.0665e+00,\n         -6.6542e+00,  2.5011e+00, -2.5448e+00,  2.7533e+00,  3.0883e+00,\n         -1.8182e+00,  3.6502e+00,  1.8717e+00,  1.2281e-01,  1.4447e+00,\n          4.9932e+00,  1.5394e+00,  6.1974e+00,  2.0494e+00,  4.2053e-01,\n          3.9032e+00, -7.9844e+00, -3.7294e+00,  2.6014e-01, -2.1209e+00,\n          1.6072e+00, -2.6453e+00,  1.3901e-01,  3.3468e+00,  3.1794e+00,\n         -6.4299e-01]], device='cuda:0', grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.3887e+01,  4.7875e+01, -4.3645e-01,  6.4759e-02,  2.2682e+00,\n          1.7961e+00,  3.7165e-01,  2.8733e+00,  1.5638e+00,  1.3645e+00,\n          3.7375e+00,  4.5349e+00,  6.9087e+00,  4.7852e+00,  3.1579e+00,\n          3.9889e+00,  4.6993e+00,  2.0291e+00, -6.6069e-01, -3.6304e+00,\n          2.9908e+00, -6.9300e+00,  1.9263e+00,  7.3730e+00,  3.4393e+00,\n          4.6437e+00, -5.6559e+00,  1.8795e-01,  1.5278e+00,  1.1209e+01,\n          3.1783e+00,  2.3721e+00,  2.6032e+00,  2.4138e+00,  1.3756e+00,\n         -8.0121e-01,  1.7570e+00,  1.6574e+00,  8.6485e+00,  1.6729e+00,\n          1.1579e+00, -5.3498e-01,  4.2137e+00,  1.8133e+00,  1.6579e-01,\n          8.3886e+00, -1.1578e+00,  1.6048e+00, -3.6578e+00,  3.6399e+00,\n         -1.3069e+00,  6.5727e-01, -1.0294e+00,  1.6657e+00, -1.2557e+00,\n          1.0434e-01, -2.6217e+00,  4.6163e-01,  1.6940e+00, -3.4864e+00,\n          7.3909e+00,  5.7669e-01, -1.3463e-01,  3.4450e+00,  3.0755e+00,\n          5.7935e+00,  5.4699e+00,  4.2829e+00,  4.6103e+00, -1.4883e+00,\n         -4.0958e+00, -1.5328e+00, -4.6658e+00,  6.9810e+00, -1.2902e+00,\n         -2.1583e+00,  1.4770e-01,  5.6750e+00,  4.1931e+00, -7.1875e-01,\n          2.0131e+00, -7.7234e-01,  5.7771e+00,  1.0051e+01,  6.1270e+00,\n          4.8692e+00,  1.2648e+00,  3.0519e+00,  4.0437e+00,  6.0589e+00,\n         -3.8911e-01, -5.1003e+00,  2.7166e+00,  4.9480e+00,  3.6303e+00,\n         -1.6646e+00,  3.5507e+00,  9.1405e+00,  6.8593e+00,  3.8232e+00,\n          3.4934e+00,  6.0651e+00,  5.2824e+00,  2.9714e+00,  2.2164e+00,\n         -7.3427e-01,  1.7378e+00, -2.8188e-01,  2.3047e+00, -1.4695e+00,\n          3.3345e+00,  6.6518e+00, -3.6597e-01,  7.8521e+00, -4.1711e-01,\n          5.5714e+00,  5.6281e+00,  8.1170e+00,  4.3603e-01, -3.8516e-01,\n         -2.6131e-01,  2.6293e-01,  1.2784e+00,  2.0025e+00,  2.1617e+00,\n          2.7013e+00, -6.1660e-01, -3.8713e+00,  3.2663e+00,  2.1223e+00,\n          3.1384e+00,  6.7960e+00,  4.4709e+00,  5.5691e+00,  3.8526e+00,\n          1.8104e+00, -6.7417e-01,  8.1751e+00,  6.0316e+00,  4.1850e+00,\n          3.4287e+00,  5.3772e+00,  6.7570e+00,  5.3529e+00,  5.6861e+00,\n          2.9760e+00, -1.9085e+00,  6.4360e+00,  5.5106e+00,  5.5012e+00,\n          9.2516e+00,  7.8156e+00,  3.1060e+00,  2.9193e+00,  4.7628e+00,\n          1.0503e+01,  1.7053e+00, -1.5021e-01,  6.2160e+00,  2.5341e+00,\n          5.5321e+00,  6.3413e+00, -4.3599e+00,  1.9358e+00,  5.5535e+00,\n          3.3579e+00,  4.1458e+00,  3.6563e+00, -1.4876e+00,  1.9308e-01,\n          7.4788e+00, -5.2269e-01,  3.0283e+00,  1.7878e+00,  3.6541e+00,\n          2.6381e+00,  1.3678e+00,  1.0090e+00,  1.7532e+00, -1.6047e+00,\n         -4.4756e+00,  4.7647e+00, -3.1883e+00,  4.1600e+00,  1.0081e+01,\n          5.0030e+00,  6.3534e+00,  1.0790e+01,  4.6019e+00,  6.5062e+00,\n          9.2156e+00,  7.6200e+00,  8.4935e+00,  4.3370e+00,  5.5137e+00,\n          4.7091e-01,  6.5078e+00,  2.0278e+00,  6.7245e-01, -2.8461e+00,\n         -2.1295e+00, -1.7479e+00,  6.1385e-01, -3.9641e+00,  3.2150e+00,\n          9.2256e-03, -2.8245e+00, -1.7513e+00,  2.7135e+00,  1.0876e+00,\n          2.9104e+00, -6.9361e+00,  4.5060e+00, -1.7035e+00,  7.8742e+00,\n          3.2935e+00,  4.1163e+00, -2.5645e-02,  1.5159e+00,  5.4694e+00,\n          5.8588e+00,  1.7485e+00,  2.1483e+00,  1.1035e+00,  9.7764e-01,\n         -3.9739e+00,  4.1687e+00,  1.2167e+00,  6.5523e+00,  9.5614e+00,\n          2.3073e+00,  3.3594e+00,  7.5847e+00,  3.3869e+00,  5.6250e+00,\n         -1.2270e+00,  4.8176e+00,  4.2482e-01,  6.2547e+00,  1.1100e+00,\n          5.5532e+00,  6.0338e+00,  4.2959e+00,  3.0281e+00,  2.0224e+00,\n          8.4045e+00,  7.8990e+00,  6.6528e+00,  3.8484e+00,  4.6875e+00,\n          5.6210e+00,  6.2695e+00, -3.5221e+00,  2.1520e+00,  8.1367e+00,\n          4.8845e+00,  5.6387e+00, -7.5814e-01, -6.9331e+00,  1.9666e-02,\n          1.4888e+00,  9.0836e-01,  1.3983e+00,  5.6446e+00,  1.1248e+01,\n          8.9431e+00,  1.1665e+01,  1.6351e+01,  6.8757e+00,  3.8677e+00,\n          1.8527e+00,  4.8188e+00,  5.3782e+00,  5.5414e+00,  1.2386e+00,\n         -9.8225e-02,  4.5186e+00,  5.8722e+00,  1.8112e+00,  3.8816e+00,\n          4.1273e+00,  8.4757e+00, -1.5657e+00,  4.0270e+00,  1.1148e+00,\n          1.6697e+00,  1.1667e+01,  5.0102e+00,  5.0859e+00,  4.2774e+00,\n          1.6958e+00,  3.2071e+00, -7.3214e-01, -1.9865e+00,  3.1079e-02,\n         -3.5713e+00,  9.4254e+00,  2.7716e+00,  3.0024e+00,  9.4071e+00,\n          7.2786e+00, -2.8833e-01,  6.1319e+00, -5.3937e+00,  4.5273e-01,\n          2.1127e+00,  7.6847e+00,  7.7244e+00,  4.2853e-01,  4.0978e+00,\n          9.2763e+00,  4.3338e+00,  1.4031e+00,  6.7207e+00,  1.0419e+01,\n         -1.2756e+00,  2.6715e+00, -7.5125e-01, -1.8311e+00, -3.0767e+00,\n         -5.4259e+00,  1.0595e+00,  5.1152e+00, -1.1548e+00, -3.2643e+00,\n          4.5490e+00,  3.6163e+00,  7.2158e+00, -4.2695e+00,  3.6994e+00,\n          1.5819e+00, -3.2379e+00,  4.1122e+00,  4.0170e+00, -3.6653e+00,\n         -1.9819e+00, -1.8432e+00,  3.6008e+00,  2.5537e+00,  6.1315e-01,\n         -3.4999e+00, -7.9585e+00,  3.9531e-01,  2.5175e+00,  6.9101e+00,\n          2.8174e+00, -2.6183e+00,  1.2033e+00,  3.1144e+00, -3.1740e+00,\n         -1.1302e+00,  2.8350e-01,  1.0640e+00,  4.8691e+00,  4.6213e+00,\n          2.9266e+00,  1.7488e+00, -4.8785e+00, -9.7628e-01,  7.8641e+00,\n          8.2655e+00, -5.0279e+00, -4.5649e+00, -4.6875e+00,  9.9464e-01,\n         -3.5640e-01, -6.2093e+00, -3.0945e+00,  2.0804e+00,  6.3188e-01,\n         -6.7474e+00,  1.9562e+00, -7.5711e-01,  8.0811e+00,  3.4576e+00,\n         -2.1889e+00, -7.1864e-01,  8.1246e-01,  9.8900e-01, -4.8971e-02,\n          4.4696e+00,  2.3871e+00,  7.9102e+00,  3.1931e+00,  1.6857e-01,\n          2.9263e+00, -6.8464e+00, -5.0629e+00,  4.4990e+00, -5.8609e+00,\n          1.2881e+00, -4.8208e+00, -7.6121e-01,  1.4995e+00,  5.0466e+00,\n         -1.3089e+00]], device='cuda:0', grad_fn=<PermuteBackward0>)\n\u001b[32m2023-08-14 17:41:16.593\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m592\u001b[0m - \u001b[31m\u001b[1mepoch=8, save to ppo_0813_v1step_8\u001b[0m\n9it [07:58, 55.99s/it]\u001b[32m2023-08-14 17:41:17.419\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m520\u001b[0m - \u001b[31m\u001b[1mquestion_tensors : [tensor([64790, 64792, 30910, 54761, 31211, 31896, 33103, 54534, 34616, 33567,\n        34396, 31123, 37474, 33575, 32495, 31623, 31910, 38429, 52154, 55398,\n        31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:58.402\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m559\u001b[0m - \u001b[31m\u001b[1mresponse_tensors : [tensor([30910, 31910, 38429, 55025, 32570, 34616, 33567, 52154, 33446, 30932,\n        46753, 43742, 55079, 32487, 31201, 47273, 37128, 32318, 30932, 32780,\n        54573, 55343, 32318, 31155, 31704, 32318, 32955, 31665, 54798, 33309,\n        41313, 47196, 30932, 54724, 38690, 34616, 42113, 33585, 54607, 33058,\n        31155,    13,    13, 31992, 54573, 55343, 32318, 32618, 30932, 31784,\n        31722, 36970, 31779, 30954,    13,    13, 30939, 30930, 30910, 44578,\n        30954, 44578, 32288, 47273, 33567, 52154, 30932, 31665, 35509, 33057,\n        54542, 33576, 31973, 31155, 44578, 31628, 32133, 37025, 44001, 30932,\n        34067, 34616, 56561, 57226, 54538, 33585, 54607, 33058, 31155,    13,\n           13, 30943, 30930, 30910, 60501, 60546, 32318, 30954, 60501, 60546,\n        32318, 32288, 54573, 57646, 32318, 30932, 34570, 38825, 32042, 30932,\n        31701, 32591, 31752, 34396, 31155, 32542, 32955, 31665, 31784, 33057,\n        44269, 30932, 54688, 33459, 31910, 31641, 31155,    13,    13, 30966,\n        30930, 30910, 56554, 54722, 30954, 56554, 54722, 32288, 32887, 54544,\n        34396, 30932, 31817, 36145, 33692, 54542, 56487, 54588, 31155, 32542,\n        31665, 31784, 33057, 54542, 47196, 32017, 33585, 39037, 30932, 54688,\n        33459, 31910, 31641, 31155,    13,    13, 30972, 30930, 30910, 55791,\n        57878, 30954, 55791, 57878, 32288, 47273, 54647, 37255, 34396, 30932,\n        31665, 31784, 33057, 54542, 40215, 33576, 54556, 33585, 31155, 32542,\n        31628, 32133, 54603, 32859, 35798, 44001, 30932, 33923, 34616, 56561,\n        57226, 54538, 33585, 54607, 33058, 31155,    13,    13, 40839, 33943,\n        31768, 30932, 43909, 31674, 42396, 31768, 47273, 38429, 55025, 32570,\n        34616, 33567, 52154, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:58.407\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m467\u001b[0m - \u001b[31m\u001b[1mqueries=[tensor([64790, 64792, 30910, 54761, 31211, 31896, 33103, 54534, 34616, 33567,\n        34396, 31123, 37474, 33575, 32495, 31623, 31910, 38429, 52154, 55398,\n        31514,    13,    13, 55437, 31211], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:58.411\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m468\u001b[0m - \u001b[31m\u001b[1mresponses=[tensor([30910, 31910, 38429, 55025, 32570, 34616, 33567, 52154, 33446, 30932,\n        46753, 43742, 55079, 32487, 31201, 47273, 37128, 32318, 30932, 32780,\n        54573, 55343, 32318, 31155, 31704, 32318, 32955, 31665, 54798, 33309,\n        41313, 47196, 30932, 54724, 38690, 34616, 42113, 33585, 54607, 33058,\n        31155,    13,    13, 31992, 54573, 55343, 32318, 32618, 30932, 31784,\n        31722, 36970, 31779, 30954,    13,    13, 30939, 30930, 30910, 44578,\n        30954, 44578, 32288, 47273, 33567, 52154, 30932, 31665, 35509, 33057,\n        54542, 33576, 31973, 31155, 44578, 31628, 32133, 37025, 44001, 30932,\n        34067, 34616, 56561, 57226, 54538, 33585, 54607, 33058, 31155,    13,\n           13, 30943, 30930, 30910, 60501, 60546, 32318, 30954, 60501, 60546,\n        32318, 32288, 54573, 57646, 32318, 30932, 34570, 38825, 32042, 30932,\n        31701, 32591, 31752, 34396, 31155, 32542, 32955, 31665, 31784, 33057,\n        44269, 30932, 54688, 33459, 31910, 31641, 31155,    13,    13, 30966,\n        30930, 30910, 56554, 54722, 30954, 56554, 54722, 32288, 32887, 54544,\n        34396, 30932, 31817, 36145, 33692, 54542, 56487, 54588, 31155, 32542,\n        31665, 31784, 33057, 54542, 47196, 32017, 33585, 39037, 30932, 54688,\n        33459, 31910, 31641, 31155,    13,    13, 30972, 30930, 30910, 55791,\n        57878, 30954, 55791, 57878, 32288, 47273, 54647, 37255, 34396, 30932,\n        31665, 31784, 33057, 54542, 40215, 33576, 54556, 33585, 31155, 32542,\n        31628, 32133, 54603, 32859, 35798, 44001, 30932, 33923, 34616, 56561,\n        57226, 54538, 33585, 54607, 33058, 31155,    13,    13, 40839, 33943,\n        31768, 30932, 43909, 31674, 42396, 31768, 47273, 38429, 55025, 32570,\n        34616, 33567, 52154, 31155,     2], device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:58.807\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_rewards\u001b[0m:\u001b[36m481\u001b[0m - \u001b[31m\u001b[1mrewards in get_rewards=[tensor([ 2.9692e+01,  5.1240e+01,  1.1526e+00,  2.1750e+00,  1.6428e+00,\n         8.8121e+00,  6.6900e+00,  4.1084e+00,  4.9460e+00, -7.5362e-01,\n         5.0306e-01,  3.4546e-01,  2.2519e+00,  3.4857e+00,  2.7851e-01,\n         2.5328e+00,  3.3126e+00,  1.4041e+00, -1.2010e+00, -4.5795e-01,\n        -5.4320e+00, -1.1995e+00,  2.7372e+00,  4.3788e+00, -3.9832e+00,\n        -3.2411e+00,  5.7026e+00,  9.3433e+00, -4.5785e+00, -1.8661e+00,\n         3.7290e+00,  6.5060e+00, -1.3811e+00, -5.2155e+00, -3.3182e+00,\n        -1.1235e-01,  7.9636e-01, -4.7082e+00,  3.9898e+00, -3.5241e+00,\n         3.0453e+00, -7.8443e-02, -2.6991e+00, -7.1633e-01, -9.2499e+00,\n         8.3862e-01, -8.9444e-01, -9.9327e-01, -1.1844e+00, -9.6551e+00,\n        -7.5467e+00, -9.4614e+00, -3.4667e+00,  1.5044e-01,  8.0290e-01,\n        -4.1101e+00, -5.7960e+00, -2.3951e+00, -4.3391e+00,  4.8420e-01,\n         3.7298e+00,  5.8221e+00, -4.0309e+00,  4.3423e+00,  3.4903e+00,\n        -5.2147e+00,  1.6423e+00, -3.1022e+00, -7.4623e+00,  3.0294e+00,\n         3.0171e+00,  3.3149e+00,  5.3796e+00, -8.2250e-02, -4.6209e+00,\n        -2.2699e+00,  3.4594e+00, -1.4602e+01, -1.1273e+01, -5.0811e+00,\n        -3.7256e+00, -1.9619e+00, -1.2855e+01, -9.8920e+00, -1.8042e+00,\n        -7.0272e-01, -9.6160e-01, -7.8524e+00,  9.7711e-01,  4.6152e+00,\n         9.9231e-01, -5.3143e+00,  5.2166e+00,  3.6602e-02,  6.2164e+00,\n         2.3517e+00,  4.5785e+00,  3.9308e+00, -3.0863e+00,  2.1168e-01,\n         3.9607e+00,  3.0126e+00,  1.0500e+00, -9.1219e-01, -3.7747e+00,\n        -4.4771e+00,  4.0744e+00,  1.3303e+00, -3.1142e+00, -5.0269e-01,\n        -6.4814e-01, -3.2238e+00,  1.9375e+00, -1.7183e+00,  2.5552e-01,\n         1.8648e+00, -9.6436e-01, -4.5042e+00,  1.0171e+00, -1.6999e-01,\n         1.2128e+00, -1.4234e+00, -5.8033e+00, -4.4792e-01,  1.4170e+00,\n         2.4982e+00, -1.9177e+00,  1.2825e+00, -2.9832e-01,  2.6045e+00,\n         3.2418e+00, -1.9796e-01, -2.8025e+00, -5.2604e+00, -2.9677e+00,\n        -4.9785e+00, -3.0915e+00,  4.4121e+00,  2.4238e+00,  3.7264e+00,\n         2.1938e+00,  4.1823e+00, -5.3407e-01, -3.5566e+00,  5.7974e+00,\n         4.9814e+00,  3.4071e+00, -1.9528e+00, -1.0497e-01,  2.6572e+00,\n         1.3332e+00, -4.5220e-01, -6.3876e-01,  5.4588e-01, -4.6271e+00,\n        -6.5372e+00, -2.7579e+00, -1.2450e+00, -3.2899e+00,  1.4429e+00,\n         3.2021e+00,  9.3358e-01, -1.9403e+00,  4.4439e+00,  1.9575e+00,\n        -6.2479e-01,  6.3138e-01,  2.0274e+00,  1.0061e+00,  5.7418e-01,\n         3.9282e+00,  1.0185e+00,  1.6865e+00,  1.4897e+00,  2.8807e+00,\n         2.6897e-01,  2.2065e+00,  6.4426e+00,  2.0440e+00,  8.7477e+00,\n         9.1228e+00,  4.6188e+00,  3.0073e+00, -1.9166e+00, -2.9796e+00,\n         4.5704e-02,  5.8045e-01, -1.1202e+00,  1.2763e+00, -1.2307e+00,\n        -3.9996e-01, -1.7966e+00, -6.4886e+00, -5.2132e-01, -4.6898e+00,\n         2.2445e+00,  1.1643e+00,  8.1478e-01,  2.3356e+00, -3.1794e+00,\n         1.9543e+00,  4.9073e+00,  1.1793e+00,  3.4936e+00, -2.2325e+00,\n         1.9383e+00, -2.9742e+00,  5.5687e+00, -3.8413e+00, -3.6770e+00,\n         4.6979e+00,  3.2820e+00,  2.3087e+00, -3.4260e+00, -5.1061e+00,\n         7.5859e+00,  3.8986e+00,  4.1509e+00,  4.2984e+00,  2.3901e+00,\n         1.7305e+00, -3.7223e+00, -3.6960e+00, -7.6065e+00,  9.4879e-01,\n        -1.4714e+00,  4.0625e+00, -4.3544e-01, -4.6141e+00, -5.0271e-01,\n        -2.8677e+00, -2.2373e+00, -4.0194e-01, -3.9429e+00, -5.2566e+00,\n        -6.7076e+00, -3.1467e+00,  1.5095e+00,  4.1691e+00,  5.2944e+00,\n        -3.0252e+00,  4.9360e+00,  1.1709e+01, -1.4494e+00, -5.2651e-01,\n         6.5421e+00,  6.7481e+00, -3.4802e+00, -2.5140e-01, -3.5041e-01],\n       device='cuda:0')]\u001b[0m\n\u001b[32m2023-08-14 17:41:58.808\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m573\u001b[0m - \u001b[31m\u001b[1mwe are at line 543\u001b[0m\n\u001b[32m2023-08-14 17:41:58.809\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[31m\u001b[1mline 567\u001b[0m\n\u001b[32m2023-08-14 17:41:58.815\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[31m\u001b[1mscores=[tensor([ 2.9692e+01,  5.1240e+01,  1.1526e+00,  2.1750e+00,  1.6428e+00,\n         8.8121e+00,  6.6900e+00,  4.1084e+00,  4.9460e+00, -7.5362e-01,\n         5.0306e-01,  3.4546e-01,  2.2519e+00,  3.4857e+00,  2.7851e-01,\n         2.5328e+00,  3.3126e+00,  1.4041e+00, -1.2010e+00, -4.5795e-01,\n        -5.4320e+00, -1.1995e+00,  2.7372e+00,  4.3788e+00, -3.9832e+00,\n        -3.2411e+00,  5.7026e+00,  9.3433e+00, -4.5785e+00, -1.8661e+00,\n         3.7290e+00,  6.5060e+00, -1.3811e+00, -5.2155e+00, -3.3182e+00,\n        -1.1235e-01,  7.9636e-01, -4.7082e+00,  3.9898e+00, -3.5241e+00,\n         3.0453e+00, -7.8443e-02, -2.6991e+00, -7.1633e-01, -9.2499e+00,\n         8.3862e-01, -8.9444e-01, -9.9327e-01, -1.1844e+00, -9.6551e+00,\n        -7.5467e+00, -9.4614e+00, -3.4667e+00,  1.5044e-01,  8.0290e-01,\n        -4.1101e+00, -5.7960e+00, -2.3951e+00, -4.3391e+00,  4.8420e-01,\n         3.7298e+00,  5.8221e+00, -4.0309e+00,  4.3423e+00,  3.4903e+00,\n        -5.2147e+00,  1.6423e+00, -3.1022e+00, -7.4623e+00,  3.0294e+00,\n         3.0171e+00,  3.3149e+00,  5.3796e+00, -8.2250e-02, -4.6209e+00,\n        -2.2699e+00,  3.4594e+00, -1.4602e+01, -1.1273e+01, -5.0811e+00,\n        -3.7256e+00, -1.9619e+00, -1.2855e+01, -9.8920e+00, -1.8042e+00,\n        -7.0272e-01, -9.6160e-01, -7.8524e+00,  9.7711e-01,  4.6152e+00,\n         9.9231e-01, -5.3143e+00,  5.2166e+00,  3.6602e-02,  6.2164e+00,\n         2.3517e+00,  4.5785e+00,  3.9308e+00, -3.0863e+00,  2.1168e-01,\n         3.9607e+00,  3.0126e+00,  1.0500e+00, -9.1219e-01, -3.7747e+00,\n        -4.4771e+00,  4.0744e+00,  1.3303e+00, -3.1142e+00, -5.0269e-01,\n        -6.4814e-01, -3.2238e+00,  1.9375e+00, -1.7183e+00,  2.5552e-01,\n         1.8648e+00, -9.6436e-01, -4.5042e+00,  1.0171e+00, -1.6999e-01,\n         1.2128e+00, -1.4234e+00, -5.8033e+00, -4.4792e-01,  1.4170e+00,\n         2.4982e+00, -1.9177e+00,  1.2825e+00, -2.9832e-01,  2.6045e+00,\n         3.2418e+00, -1.9796e-01, -2.8025e+00, -5.2604e+00, -2.9677e+00,\n        -4.9785e+00, -3.0915e+00,  4.4121e+00,  2.4238e+00,  3.7264e+00,\n         2.1938e+00,  4.1823e+00, -5.3407e-01, -3.5566e+00,  5.7974e+00,\n         4.9814e+00,  3.4071e+00, -1.9528e+00, -1.0497e-01,  2.6572e+00,\n         1.3332e+00, -4.5220e-01, -6.3876e-01,  5.4588e-01, -4.6271e+00,\n        -6.5372e+00, -2.7579e+00, -1.2450e+00, -3.2899e+00,  1.4429e+00,\n         3.2021e+00,  9.3358e-01, -1.9403e+00,  4.4439e+00,  1.9575e+00,\n        -6.2479e-01,  6.3138e-01,  2.0274e+00,  1.0061e+00,  5.7418e-01,\n         3.9282e+00,  1.0185e+00,  1.6865e+00,  1.4897e+00,  2.8807e+00,\n         2.6897e-01,  2.2065e+00,  6.4426e+00,  2.0440e+00,  8.7477e+00,\n         9.1228e+00,  4.6188e+00,  3.0073e+00, -1.9166e+00, -2.9796e+00,\n         4.5704e-02,  5.8045e-01, -1.1202e+00,  1.2763e+00, -1.2307e+00,\n        -3.9996e-01, -1.7966e+00, -6.4886e+00, -5.2132e-01, -4.6898e+00,\n         2.2445e+00,  1.1643e+00,  8.1478e-01,  2.3356e+00, -3.1794e+00,\n         1.9543e+00,  4.9073e+00,  1.1793e+00,  3.4936e+00, -2.2325e+00,\n         1.9383e+00, -2.9742e+00,  5.5687e+00, -3.8413e+00, -3.6770e+00,\n         4.6979e+00,  3.2820e+00,  2.3087e+00, -3.4260e+00, -5.1061e+00,\n         7.5859e+00,  3.8986e+00,  4.1509e+00,  4.2984e+00,  2.3901e+00,\n         1.7305e+00, -3.7223e+00, -3.6960e+00, -7.6065e+00,  9.4879e-01,\n        -1.4714e+00,  4.0625e+00, -4.3544e-01, -4.6141e+00, -5.0271e-01,\n        -2.8677e+00, -2.2373e+00, -4.0194e-01, -3.9429e+00, -5.2566e+00,\n        -6.7076e+00, -3.1467e+00,  1.5095e+00,  4.1691e+00,  5.2944e+00,\n        -3.0252e+00,  4.9360e+00,  1.1709e+01, -1.4494e+00, -5.2651e-01,\n         6.5421e+00,  6.7481e+00, -3.4802e+00, -2.5140e-01, -3.5041e-01],\n       device='cuda:0')]\u001b[0m\nepoch:  9 \nquery: 问：今年我想在室内种植水果，你能给我推荐一个容易入手的水果吗？\n\n答：\nresponse: 容易入手且适合室内种植的水果有很多,其中一个是一些低维护、易于管理的植物,例如多肉植物。这些植物通常需要少量的水和肥料,并能够在室内环境中生长得很好。\n\n除了多肉植物之外,一些其他的选择包括:\n\n1. 草莓:草莓是一种易于种植的水果,需要一定的阳光和温度控制。草莓可以产生小型花朵,可以在室内盆栽中生长得很好。\n\n2. 匍匐植物:匍匐植物是一种多蔓植物,不需要太多的空间,同时也可以生产水果。它们通常需要一些阳光和水,但也很容易管理。\n\n3. 桑果:桑果是一种多年生水果,具有美丽的颜色和纹理。它们需要一些阳光和肥料才能生长得好,但也很容易管理。\n\n4. 蓝莓:蓝莓是一种易于入手的水果,需要一些阳光和适当的温度来生长。它们可以产生小型的蓝色花朵,并在室内盆栽中生长得很好。\n\n这些都是很好的选择,可以根据自己的喜好选择易于入手且适合室内种植的水果。\nscore: tensor([ 2.9692e+01,  5.1240e+01,  1.1526e+00,  2.1750e+00,  1.6428e+00,\n         8.8121e+00,  6.6900e+00,  4.1084e+00,  4.9460e+00, -7.5362e-01,\n         5.0306e-01,  3.4546e-01,  2.2519e+00,  3.4857e+00,  2.7851e-01,\n         2.5328e+00,  3.3126e+00,  1.4041e+00, -1.2010e+00, -4.5795e-01,\n        -5.4320e+00, -1.1995e+00,  2.7372e+00,  4.3788e+00, -3.9832e+00,\n        -3.2411e+00,  5.7026e+00,  9.3433e+00, -4.5785e+00, -1.8661e+00,\n         3.7290e+00,  6.5060e+00, -1.3811e+00, -5.2155e+00, -3.3182e+00,\n        -1.1235e-01,  7.9636e-01, -4.7082e+00,  3.9898e+00, -3.5241e+00,\n         3.0453e+00, -7.8443e-02, -2.6991e+00, -7.1633e-01, -9.2499e+00,\n         8.3862e-01, -8.9444e-01, -9.9327e-01, -1.1844e+00, -9.6551e+00,\n        -7.5467e+00, -9.4614e+00, -3.4667e+00,  1.5044e-01,  8.0290e-01,\n        -4.1101e+00, -5.7960e+00, -2.3951e+00, -4.3391e+00,  4.8420e-01,\n         3.7298e+00,  5.8221e+00, -4.0309e+00,  4.3423e+00,  3.4903e+00,\n        -5.2147e+00,  1.6423e+00, -3.1022e+00, -7.4623e+00,  3.0294e+00,\n         3.0171e+00,  3.3149e+00,  5.3796e+00, -8.2250e-02, -4.6209e+00,\n        -2.2699e+00,  3.4594e+00, -1.4602e+01, -1.1273e+01, -5.0811e+00,\n        -3.7256e+00, -1.9619e+00, -1.2855e+01, -9.8920e+00, -1.8042e+00,\n        -7.0272e-01, -9.6160e-01, -7.8524e+00,  9.7711e-01,  4.6152e+00,\n         9.9231e-01, -5.3143e+00,  5.2166e+00,  3.6602e-02,  6.2164e+00,\n         2.3517e+00,  4.5785e+00,  3.9308e+00, -3.0863e+00,  2.1168e-01,\n         3.9607e+00,  3.0126e+00,  1.0500e+00, -9.1219e-01, -3.7747e+00,\n        -4.4771e+00,  4.0744e+00,  1.3303e+00, -3.1142e+00, -5.0269e-01,\n        -6.4814e-01, -3.2238e+00,  1.9375e+00, -1.7183e+00,  2.5552e-01,\n         1.8648e+00, -9.6436e-01, -4.5042e+00,  1.0171e+00, -1.6999e-01,\n         1.2128e+00, -1.4234e+00, -5.8033e+00, -4.4792e-01,  1.4170e+00,\n         2.4982e+00, -1.9177e+00,  1.2825e+00, -2.9832e-01,  2.6045e+00,\n         3.2418e+00, -1.9796e-01, -2.8025e+00, -5.2604e+00, -2.9677e+00,\n        -4.9785e+00, -3.0915e+00,  4.4121e+00,  2.4238e+00,  3.7264e+00,\n         2.1938e+00,  4.1823e+00, -5.3407e-01, -3.5566e+00,  5.7974e+00,\n         4.9814e+00,  3.4071e+00, -1.9528e+00, -1.0497e-01,  2.6572e+00,\n         1.3332e+00, -4.5220e-01, -6.3876e-01,  5.4588e-01, -4.6271e+00,\n        -6.5372e+00, -2.7579e+00, -1.2450e+00, -3.2899e+00,  1.4429e+00,\n         3.2021e+00,  9.3358e-01, -1.9403e+00,  4.4439e+00,  1.9575e+00,\n        -6.2479e-01,  6.3138e-01,  2.0274e+00,  1.0061e+00,  5.7418e-01,\n         3.9282e+00,  1.0185e+00,  1.6865e+00,  1.4897e+00,  2.8807e+00,\n         2.6897e-01,  2.2065e+00,  6.4426e+00,  2.0440e+00,  8.7477e+00,\n         9.1228e+00,  4.6188e+00,  3.0073e+00, -1.9166e+00, -2.9796e+00,\n         4.5704e-02,  5.8045e-01, -1.1202e+00,  1.2763e+00, -1.2307e+00,\n        -3.9996e-01, -1.7966e+00, -6.4886e+00, -5.2132e-01, -4.6898e+00,\n         2.2445e+00,  1.1643e+00,  8.1478e-01,  2.3356e+00, -3.1794e+00,\n         1.9543e+00,  4.9073e+00,  1.1793e+00,  3.4936e+00, -2.2325e+00,\n         1.9383e+00, -2.9742e+00,  5.5687e+00, -3.8413e+00, -3.6770e+00,\n         4.6979e+00,  3.2820e+00,  2.3087e+00, -3.4260e+00, -5.1061e+00,\n         7.5859e+00,  3.8986e+00,  4.1509e+00,  4.2984e+00,  2.3901e+00,\n         1.7305e+00, -3.7223e+00, -3.6960e+00, -7.6065e+00,  9.4879e-01,\n        -1.4714e+00,  4.0625e+00, -4.3544e-01, -4.6141e+00, -5.0271e-01,\n        -2.8677e+00, -2.2373e+00, -4.0194e-01, -3.9429e+00, -5.2566e+00,\n        -6.7076e+00, -3.1467e+00,  1.5095e+00,  4.1691e+00,  5.2944e+00,\n        -3.0252e+00,  4.9360e+00,  1.1709e+01, -1.4494e+00, -5.2651e-01,\n         6.5421e+00,  6.7481e+00, -3.4802e+00, -2.5140e-01, -3.5041e-01],\n       device='cuda:0')\n\u001b[32m2023-08-14 17:41:58.822\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m586\u001b[0m - \u001b[31m\u001b[1mwe are at line 551\u001b[0m\n\u001b[32m2023-08-14 17:41:58.828\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m587\u001b[0m - \u001b[31m\u001b[1mrewards=[tensor([ 2.9692e+01,  5.1240e+01,  1.1526e+00,  2.1750e+00,  1.6428e+00,\n         8.8121e+00,  6.6900e+00,  4.1084e+00,  4.9460e+00, -7.5362e-01,\n         5.0306e-01,  3.4546e-01,  2.2519e+00,  3.4857e+00,  2.7851e-01,\n         2.5328e+00,  3.3126e+00,  1.4041e+00, -1.2010e+00, -4.5795e-01,\n        -5.4320e+00, -1.1995e+00,  2.7372e+00,  4.3788e+00, -3.9832e+00,\n        -3.2411e+00,  5.7026e+00,  9.3433e+00, -4.5785e+00, -1.8661e+00,\n         3.7290e+00,  6.5060e+00, -1.3811e+00, -5.2155e+00, -3.3182e+00,\n        -1.1235e-01,  7.9636e-01, -4.7082e+00,  3.9898e+00, -3.5241e+00,\n         3.0453e+00, -7.8443e-02, -2.6991e+00, -7.1633e-01, -9.2499e+00,\n         8.3862e-01, -8.9444e-01, -9.9327e-01, -1.1844e+00, -9.6551e+00,\n        -7.5467e+00, -9.4614e+00, -3.4667e+00,  1.5044e-01,  8.0290e-01,\n        -4.1101e+00, -5.7960e+00, -2.3951e+00, -4.3391e+00,  4.8420e-01,\n         3.7298e+00,  5.8221e+00, -4.0309e+00,  4.3423e+00,  3.4903e+00,\n        -5.2147e+00,  1.6423e+00, -3.1022e+00, -7.4623e+00,  3.0294e+00,\n         3.0171e+00,  3.3149e+00,  5.3796e+00, -8.2250e-02, -4.6209e+00,\n        -2.2699e+00,  3.4594e+00, -1.4602e+01, -1.1273e+01, -5.0811e+00,\n        -3.7256e+00, -1.9619e+00, -1.2855e+01, -9.8920e+00, -1.8042e+00,\n        -7.0272e-01, -9.6160e-01, -7.8524e+00,  9.7711e-01,  4.6152e+00,\n         9.9231e-01, -5.3143e+00,  5.2166e+00,  3.6602e-02,  6.2164e+00,\n         2.3517e+00,  4.5785e+00,  3.9308e+00, -3.0863e+00,  2.1168e-01,\n         3.9607e+00,  3.0126e+00,  1.0500e+00, -9.1219e-01, -3.7747e+00,\n        -4.4771e+00,  4.0744e+00,  1.3303e+00, -3.1142e+00, -5.0269e-01,\n        -6.4814e-01, -3.2238e+00,  1.9375e+00, -1.7183e+00,  2.5552e-01,\n         1.8648e+00, -9.6436e-01, -4.5042e+00,  1.0171e+00, -1.6999e-01,\n         1.2128e+00, -1.4234e+00, -5.8033e+00, -4.4792e-01,  1.4170e+00,\n         2.4982e+00, -1.9177e+00,  1.2825e+00, -2.9832e-01,  2.6045e+00,\n         3.2418e+00, -1.9796e-01, -2.8025e+00, -5.2604e+00, -2.9677e+00,\n        -4.9785e+00, -3.0915e+00,  4.4121e+00,  2.4238e+00,  3.7264e+00,\n         2.1938e+00,  4.1823e+00, -5.3407e-01, -3.5566e+00,  5.7974e+00,\n         4.9814e+00,  3.4071e+00, -1.9528e+00, -1.0497e-01,  2.6572e+00,\n         1.3332e+00, -4.5220e-01, -6.3876e-01,  5.4588e-01, -4.6271e+00,\n        -6.5372e+00, -2.7579e+00, -1.2450e+00, -3.2899e+00,  1.4429e+00,\n         3.2021e+00,  9.3358e-01, -1.9403e+00,  4.4439e+00,  1.9575e+00,\n        -6.2479e-01,  6.3138e-01,  2.0274e+00,  1.0061e+00,  5.7418e-01,\n         3.9282e+00,  1.0185e+00,  1.6865e+00,  1.4897e+00,  2.8807e+00,\n         2.6897e-01,  2.2065e+00,  6.4426e+00,  2.0440e+00,  8.7477e+00,\n         9.1228e+00,  4.6188e+00,  3.0073e+00, -1.9166e+00, -2.9796e+00,\n         4.5704e-02,  5.8045e-01, -1.1202e+00,  1.2763e+00, -1.2307e+00,\n        -3.9996e-01, -1.7966e+00, -6.4886e+00, -5.2132e-01, -4.6898e+00,\n         2.2445e+00,  1.1643e+00,  8.1478e-01,  2.3356e+00, -3.1794e+00,\n         1.9543e+00,  4.9073e+00,  1.1793e+00,  3.4936e+00, -2.2325e+00,\n         1.9383e+00, -2.9742e+00,  5.5687e+00, -3.8413e+00, -3.6770e+00,\n         4.6979e+00,  3.2820e+00,  2.3087e+00, -3.4260e+00, -5.1061e+00,\n         7.5859e+00,  3.8986e+00,  4.1509e+00,  4.2984e+00,  2.3901e+00,\n         1.7305e+00, -3.7223e+00, -3.6960e+00, -7.6065e+00,  9.4879e-01,\n        -1.4714e+00,  4.0625e+00, -4.3544e-01, -4.6141e+00, -5.0271e-01,\n        -2.8677e+00, -2.2373e+00, -4.0194e-01, -3.9429e+00, -5.2566e+00,\n        -6.7076e+00, -3.1467e+00,  1.5095e+00,  4.1691e+00,  5.2944e+00,\n        -3.0252e+00,  4.9360e+00,  1.1709e+01, -1.4494e+00, -5.2651e-01,\n         6.5421e+00,  6.7481e+00, -3.4802e+00, -2.5140e-01, -3.5041e-01],\n       device='cuda:0')]\u001b[0m\nscores=[tensor([ 2.9692e+01,  5.1240e+01,  1.1526e+00,  2.1750e+00,  1.6428e+00,\n         8.8121e+00,  6.6900e+00,  4.1084e+00,  4.9460e+00, -7.5362e-01,\n         5.0306e-01,  3.4546e-01,  2.2519e+00,  3.4857e+00,  2.7851e-01,\n         2.5328e+00,  3.3126e+00,  1.4041e+00, -1.2010e+00, -4.5795e-01,\n        -5.4320e+00, -1.1995e+00,  2.7372e+00,  4.3788e+00, -3.9832e+00,\n        -3.2411e+00,  5.7026e+00,  9.3433e+00, -4.5785e+00, -1.8661e+00,\n         3.7290e+00,  6.5060e+00, -1.3811e+00, -5.2155e+00, -3.3182e+00,\n        -1.1235e-01,  7.9636e-01, -4.7082e+00,  3.9898e+00, -3.5241e+00,\n         3.0453e+00, -7.8443e-02, -2.6991e+00, -7.1633e-01, -9.2499e+00,\n         8.3862e-01, -8.9444e-01, -9.9327e-01, -1.1844e+00, -9.6551e+00,\n        -7.5467e+00, -9.4614e+00, -3.4667e+00,  1.5044e-01,  8.0290e-01,\n        -4.1101e+00, -5.7960e+00, -2.3951e+00, -4.3391e+00,  4.8420e-01,\n         3.7298e+00,  5.8221e+00, -4.0309e+00,  4.3423e+00,  3.4903e+00,\n        -5.2147e+00,  1.6423e+00, -3.1022e+00, -7.4623e+00,  3.0294e+00,\n         3.0171e+00,  3.3149e+00,  5.3796e+00, -8.2250e-02, -4.6209e+00,\n        -2.2699e+00,  3.4594e+00, -1.4602e+01, -1.1273e+01, -5.0811e+00,\n        -3.7256e+00, -1.9619e+00, -1.2855e+01, -9.8920e+00, -1.8042e+00,\n        -7.0272e-01, -9.6160e-01, -7.8524e+00,  9.7711e-01,  4.6152e+00,\n         9.9231e-01, -5.3143e+00,  5.2166e+00,  3.6602e-02,  6.2164e+00,\n         2.3517e+00,  4.5785e+00,  3.9308e+00, -3.0863e+00,  2.1168e-01,\n         3.9607e+00,  3.0126e+00,  1.0500e+00, -9.1219e-01, -3.7747e+00,\n        -4.4771e+00,  4.0744e+00,  1.3303e+00, -3.1142e+00, -5.0269e-01,\n        -6.4814e-01, -3.2238e+00,  1.9375e+00, -1.7183e+00,  2.5552e-01,\n         1.8648e+00, -9.6436e-01, -4.5042e+00,  1.0171e+00, -1.6999e-01,\n         1.2128e+00, -1.4234e+00, -5.8033e+00, -4.4792e-01,  1.4170e+00,\n         2.4982e+00, -1.9177e+00,  1.2825e+00, -2.9832e-01,  2.6045e+00,\n         3.2418e+00, -1.9796e-01, -2.8025e+00, -5.2604e+00, -2.9677e+00,\n        -4.9785e+00, -3.0915e+00,  4.4121e+00,  2.4238e+00,  3.7264e+00,\n         2.1938e+00,  4.1823e+00, -5.3407e-01, -3.5566e+00,  5.7974e+00,\n         4.9814e+00,  3.4071e+00, -1.9528e+00, -1.0497e-01,  2.6572e+00,\n         1.3332e+00, -4.5220e-01, -6.3876e-01,  5.4588e-01, -4.6271e+00,\n        -6.5372e+00, -2.7579e+00, -1.2450e+00, -3.2899e+00,  1.4429e+00,\n         3.2021e+00,  9.3358e-01, -1.9403e+00,  4.4439e+00,  1.9575e+00,\n        -6.2479e-01,  6.3138e-01,  2.0274e+00,  1.0061e+00,  5.7418e-01,\n         3.9282e+00,  1.0185e+00,  1.6865e+00,  1.4897e+00,  2.8807e+00,\n         2.6897e-01,  2.2065e+00,  6.4426e+00,  2.0440e+00,  8.7477e+00,\n         9.1228e+00,  4.6188e+00,  3.0073e+00, -1.9166e+00, -2.9796e+00,\n         4.5704e-02,  5.8045e-01, -1.1202e+00,  1.2763e+00, -1.2307e+00,\n        -3.9996e-01, -1.7966e+00, -6.4886e+00, -5.2132e-01, -4.6898e+00,\n         2.2445e+00,  1.1643e+00,  8.1478e-01,  2.3356e+00, -3.1794e+00,\n         1.9543e+00,  4.9073e+00,  1.1793e+00,  3.4936e+00, -2.2325e+00,\n         1.9383e+00, -2.9742e+00,  5.5687e+00, -3.8413e+00, -3.6770e+00,\n         4.6979e+00,  3.2820e+00,  2.3087e+00, -3.4260e+00, -5.1061e+00,\n         7.5859e+00,  3.8986e+00,  4.1509e+00,  4.2984e+00,  2.3901e+00,\n         1.7305e+00, -3.7223e+00, -3.6960e+00, -7.6065e+00,  9.4879e-01,\n        -1.4714e+00,  4.0625e+00, -4.3544e-01, -4.6141e+00, -5.0271e-01,\n        -2.8677e+00, -2.2373e+00, -4.0194e-01, -3.9429e+00, -5.2566e+00,\n        -6.7076e+00, -3.1467e+00,  1.5095e+00,  4.1691e+00,  5.2944e+00,\n        -3.0252e+00,  4.9360e+00,  1.1709e+01, -1.4494e+00, -5.2651e-01,\n         6.5421e+00,  6.7481e+00, -3.4802e+00, -2.5140e-01, -3.5041e-01],\n       device='cuda:0')],type=<class 'list'>\nvalues_994 = tensor([[ 2.9162e+01,  5.1859e+01,  8.9249e-01,  2.0287e+00,  1.1033e+00,\n          7.5732e+00,  6.8235e+00,  5.0308e+00,  4.8997e+00,  1.4120e-01,\n          1.2775e+00, -7.9170e-01,  3.1940e+00,  2.1049e+00,  8.3565e-01,\n          2.9783e+00,  5.6211e+00,  6.5730e-01, -1.9847e+00,  7.2392e-01,\n         -5.3458e+00, -1.0579e+00,  1.4769e+00,  4.1208e+00, -7.0299e+00,\n         -3.8036e+00,  2.5598e+00,  8.1066e+00, -1.9259e+00, -3.7683e+00,\n          5.5034e+00,  7.4597e+00, -4.3286e-01, -6.9402e+00, -1.3732e+00,\n         -1.5605e+00, -3.1315e-01, -2.6086e+00,  2.5820e+00, -4.4234e+00,\n          3.6017e+00, -2.4453e+00, -2.7792e+00, -4.6647e-01, -8.9384e+00,\n          4.0973e-01,  9.6962e-01, -1.7146e+00, -1.4227e+00, -6.2639e+00,\n         -1.0264e+01, -8.7700e+00, -3.3789e+00, -8.3576e-01,  1.1202e+00,\n         -3.2552e+00, -3.2781e+00, -3.4936e+00, -6.4480e+00,  1.8651e+00,\n          4.9767e+00,  5.6756e+00, -2.5537e+00,  3.5782e+00,  2.6123e+00,\n         -6.4960e+00,  4.8591e-01, -2.9726e+00, -6.8601e+00,  3.1852e+00,\n          1.8840e+00,  1.7852e+00,  6.1109e+00, -1.0776e+00, -1.4428e+00,\n         -3.0677e+00,  5.2831e+00, -1.1548e+01, -8.9482e+00, -4.6077e+00,\n         -6.1066e+00, -4.9407e+00, -1.3532e+01, -8.2315e+00, -1.5334e+00,\n         -2.8505e+00, -2.4887e+00, -7.5422e+00,  8.8251e-01,  5.3347e+00,\n          3.2332e+00, -7.2968e+00,  4.0077e+00,  1.6429e+00,  5.5993e+00,\n          1.4216e+00,  3.0423e+00,  3.7378e+00, -1.7049e+00,  5.8209e-01,\n          4.1918e+00,  3.7802e+00,  3.2577e+00, -2.5296e+00,  3.7481e-01,\n         -2.2431e+00,  1.7667e+00,  3.0036e+00, -3.9776e+00, -8.3356e-01,\n         -2.2285e+00, -3.0640e+00,  2.0379e+00, -2.1186e+00,  2.4004e+00,\n          2.3110e+00, -4.6944e+00, -1.1144e+00,  5.0016e-02, -1.8886e-01,\n         -1.1543e+00,  3.9795e-01, -4.2685e+00, -2.5209e+00,  3.3914e+00,\n          2.2768e+00, -1.1765e+00,  1.1935e+00,  1.2670e+00,  1.2808e+00,\n          8.0669e-01, -3.1669e-01, -4.7307e+00, -6.7033e+00,  2.3514e-01,\n         -7.1323e+00, -3.4136e+00,  3.5310e+00, -1.0396e+00,  1.6603e+00,\n          4.7024e-01,  3.7152e+00,  7.9925e-01,  4.1919e-01,  3.2163e+00,\n          3.4314e+00,  3.5106e+00, -4.1785e+00,  1.0574e+00,  2.3923e+00,\n         -4.9712e-01, -1.3804e+00, -6.7850e-01, -3.3435e-01, -2.8656e+00,\n         -4.2022e+00, -8.4687e-01, -1.0481e+00, -3.0230e+00, -2.0353e-01,\n          2.4430e+00,  1.9464e+00, -2.4138e+00,  2.5399e+00,  2.2451e+00,\n         -3.2584e+00,  1.6783e+00,  9.8884e-01,  2.7985e+00,  1.4859e+00,\n          4.0241e+00, -3.1834e+00,  7.1977e-02, -9.7199e-01,  1.9769e+00,\n          1.6396e+00,  1.2973e+00,  8.1947e+00,  4.9829e+00,  9.6276e+00,\n          9.1141e+00,  2.1340e+00,  9.7840e-01, -3.6220e+00, -5.2435e+00,\n          1.1449e-01,  6.1939e-01, -1.7310e+00,  1.8481e+00, -3.2698e+00,\n         -7.6097e-01, -2.7577e+00, -4.9584e+00, -2.3284e+00, -2.2326e+00,\n          3.1701e+00,  2.4800e+00, -1.2061e+00,  2.4188e+00,  3.2397e-02,\n          6.3150e+00,  5.4460e+00, -2.7039e-01,  3.1651e+00, -1.1294e+00,\n          4.8169e-01, -1.5097e+00,  3.8618e+00, -1.2088e+00, -2.6340e+00,\n          9.3802e-01,  1.7668e-01, -9.9572e-01,  3.4897e-01, -2.9257e+00,\n          8.0671e+00,  5.3291e+00,  3.0985e+00,  3.8840e+00,  1.5583e+00,\n          1.6182e-01, -3.0775e+00, -3.0932e+00, -9.4854e-01,  6.3549e-01,\n         -1.6618e+00,  1.4536e-01,  3.1656e-01, -5.3119e+00,  9.2800e-01,\n         -4.3870e-01, -2.0686e+00, -3.0899e+00, -3.6787e+00, -3.6035e+00,\n         -6.2299e+00, -2.7238e+00,  2.2551e+00,  2.7776e+00,  6.3491e+00,\n         -2.5904e+00,  3.2808e+00,  9.0908e+00, -2.2233e+00, -3.3535e+00,\n          8.2772e+00,  9.0603e+00, -1.4424e+00, -1.3474e+00, -2.9611e-01]],\n       device='cuda:0')\nvalues_994 = tensor([[ 2.8961e+01,  5.2647e+01,  4.1754e-01,  1.8967e+00,  9.1120e-01,\n          6.0888e+00,  3.9100e+00,  4.3374e+00,  4.8555e+00, -4.8622e-01,\n          1.1274e+00,  4.3064e-01,  2.6943e+00,  5.2052e+00,  2.1718e+00,\n          3.2404e+00,  4.3321e+00,  1.2312e+00, -6.0044e-01,  1.5425e+00,\n         -6.0015e+00, -1.3920e-02,  3.4624e-01,  3.2043e+00, -4.8923e+00,\n         -2.9730e+00,  3.0937e+00,  9.8267e+00, -2.6209e+00, -2.6279e+00,\n          5.4389e+00,  5.8882e+00, -4.3126e-01, -7.7113e+00, -2.3906e+00,\n         -3.0991e+00, -1.3834e+00, -1.3573e+00,  2.4345e+00, -3.8075e+00,\n         -3.9245e-01, -1.9638e+00, -1.1014e+00, -2.3259e+00, -1.1770e+01,\n          2.5643e+00,  4.5439e-01,  4.1520e-01, -3.0315e+00, -5.3592e+00,\n         -6.9132e+00, -7.2641e+00, -1.5941e+00,  1.2302e+00,  1.3179e-01,\n         -4.4606e+00, -4.4772e-01, -4.8393e+00, -2.5186e+00,  1.4203e+00,\n          5.0411e+00,  4.5646e+00, -4.1153e+00,  4.0052e+00,  1.4036e+00,\n         -5.1984e+00,  2.1301e-01, -1.0643e+00, -5.6114e+00,  1.8829e+00,\n          1.3647e+00,  2.8198e+00,  3.8364e+00, -1.5336e+00, -3.2886e+00,\n         -1.3449e+00,  5.2227e+00, -1.3805e+01, -1.0194e+01, -5.4785e+00,\n         -5.0344e+00, -3.2777e+00, -1.3305e+01, -6.9066e+00, -2.6733e+00,\n         -2.0160e+00,  3.5760e-01, -7.6307e+00, -6.7888e-01,  4.1105e+00,\n          1.6486e+00, -5.4506e+00,  3.7367e+00,  1.5290e-01,  5.3937e+00,\n          4.3222e+00,  5.0428e+00,  2.6390e+00, -5.3180e-01, -9.9492e-02,\n          4.9606e+00,  4.7822e+00,  3.3727e+00, -2.3792e+00, -2.6093e+00,\n         -4.1936e+00,  3.1429e+00,  2.9778e+00, -3.6528e+00, -2.5719e+00,\n         -1.5997e+00, -9.6861e-01, -7.8097e-01, -2.3828e-01,  1.1989e+00,\n          2.3808e+00, -4.0298e+00, -3.8586e+00,  4.3360e-01, -6.4778e-01,\n          1.4376e-01,  3.4985e-01, -4.2503e+00, -1.0368e+00,  2.9214e+00,\n          1.9937e+00, -3.0499e+00,  1.8017e+00,  1.8451e+00,  6.6590e-01,\n          1.7674e+00,  2.5340e-01, -4.1265e+00, -2.6142e+00, -2.7055e+00,\n         -5.6298e+00, -3.2632e+00,  1.9746e+00, -1.1593e+00,  1.3471e+00,\n          3.2846e+00,  1.8606e+00, -1.3536e+00, -2.1562e-01,  5.2327e+00,\n          2.5944e+00,  1.8177e+00, -2.6075e+00, -2.1870e+00, -2.6783e-01,\n         -2.4040e+00, -1.0193e+00, -1.5532e-01,  2.7175e+00, -4.2094e+00,\n         -7.7236e+00, -2.4938e+00, -3.6289e+00, -1.9370e+00,  1.4275e+00,\n          4.5583e+00, -6.8893e-01, -6.5207e-01,  3.6552e+00,  1.7370e+00,\n         -1.1693e+00,  1.0135e+00,  8.2192e-01,  1.9375e+00,  2.3638e-01,\n          1.0024e+00, -2.4139e+00, -1.5059e+00, -8.6067e-01,  2.0230e+00,\n          2.5510e+00,  2.7913e+00,  5.1481e+00,  3.9489e+00,  9.4728e+00,\n          7.1673e+00,  4.8381e+00,  2.7638e+00, -4.3853e+00, -4.7171e+00,\n         -1.8916e+00, -2.7868e+00, -1.4352e+00,  9.1091e-01, -2.7869e+00,\n         -4.1676e+00, -2.0907e+00, -6.1770e+00,  3.5405e-01, -3.2025e+00,\n          2.2532e+00,  4.4059e-01,  1.8897e+00,  1.2097e+00, -4.7833e+00,\n          3.4337e+00,  6.6434e+00, -8.6929e-01,  3.7576e+00, -2.1682e+00,\n         -1.1116e+00, -4.1984e+00,  4.3113e+00, -9.0226e-01, -3.4601e+00,\n          3.3326e+00,  4.0374e+00, -1.0825e+00, -1.1906e+00,  7.2749e-01,\n          7.3587e+00,  4.2792e+00,  4.2004e+00,  4.3015e+00,  5.4487e+00,\n          2.1321e+00, -1.6553e-01, -6.4249e-02, -3.2955e+00,  8.6695e-01,\n         -2.3328e+00,  1.3623e+00, -1.5847e+00, -4.8172e+00, -1.3033e+00,\n         -2.1517e+00, -1.1983e+00, -3.8367e+00, -3.7041e+00, -5.0380e+00,\n         -5.0175e+00, -3.6616e+00, -1.3062e-01,  2.9832e+00,  4.0938e+00,\n         -2.0023e+00,  7.3241e+00,  8.4397e+00,  3.4023e-01, -2.4630e+00,\n          8.4714e+00,  9.5255e+00, -3.9972e+00,  7.7721e-01, -1.3574e+00]],\n       device='cuda:0')\nreward[last_non_masked_index]=tensor([-0.], device='cuda:0'),type=<class 'torch.Tensor'>\nscore=tensor([ 2.9692e+01,  5.1240e+01,  1.1526e+00,  2.1750e+00,  1.6428e+00,\n         8.8121e+00,  6.6900e+00,  4.1084e+00,  4.9460e+00, -7.5362e-01,\n         5.0306e-01,  3.4546e-01,  2.2519e+00,  3.4857e+00,  2.7851e-01,\n         2.5328e+00,  3.3126e+00,  1.4041e+00, -1.2010e+00, -4.5795e-01,\n        -5.4320e+00, -1.1995e+00,  2.7372e+00,  4.3788e+00, -3.9832e+00,\n        -3.2411e+00,  5.7026e+00,  9.3433e+00, -4.5785e+00, -1.8661e+00,\n         3.7290e+00,  6.5060e+00, -1.3811e+00, -5.2155e+00, -3.3182e+00,\n        -1.1235e-01,  7.9636e-01, -4.7082e+00,  3.9898e+00, -3.5241e+00,\n         3.0453e+00, -7.8443e-02, -2.6991e+00, -7.1633e-01, -9.2499e+00,\n         8.3862e-01, -8.9444e-01, -9.9327e-01, -1.1844e+00, -9.6551e+00,\n        -7.5467e+00, -9.4614e+00, -3.4667e+00,  1.5044e-01,  8.0290e-01,\n        -4.1101e+00, -5.7960e+00, -2.3951e+00, -4.3391e+00,  4.8420e-01,\n         3.7298e+00,  5.8221e+00, -4.0309e+00,  4.3423e+00,  3.4903e+00,\n        -5.2147e+00,  1.6423e+00, -3.1022e+00, -7.4623e+00,  3.0294e+00,\n         3.0171e+00,  3.3149e+00,  5.3796e+00, -8.2250e-02, -4.6209e+00,\n        -2.2699e+00,  3.4594e+00, -1.4602e+01, -1.1273e+01, -5.0811e+00,\n        -3.7256e+00, -1.9619e+00, -1.2855e+01, -9.8920e+00, -1.8042e+00,\n        -7.0272e-01, -9.6160e-01, -7.8524e+00,  9.7711e-01,  4.6152e+00,\n         9.9231e-01, -5.3143e+00,  5.2166e+00,  3.6602e-02,  6.2164e+00,\n         2.3517e+00,  4.5785e+00,  3.9308e+00, -3.0863e+00,  2.1168e-01,\n         3.9607e+00,  3.0126e+00,  1.0500e+00, -9.1219e-01, -3.7747e+00,\n        -4.4771e+00,  4.0744e+00,  1.3303e+00, -3.1142e+00, -5.0269e-01,\n        -6.4814e-01, -3.2238e+00,  1.9375e+00, -1.7183e+00,  2.5552e-01,\n         1.8648e+00, -9.6436e-01, -4.5042e+00,  1.0171e+00, -1.6999e-01,\n         1.2128e+00, -1.4234e+00, -5.8033e+00, -4.4792e-01,  1.4170e+00,\n         2.4982e+00, -1.9177e+00,  1.2825e+00, -2.9832e-01,  2.6045e+00,\n         3.2418e+00, -1.9796e-01, -2.8025e+00, -5.2604e+00, -2.9677e+00,\n        -4.9785e+00, -3.0915e+00,  4.4121e+00,  2.4238e+00,  3.7264e+00,\n         2.1938e+00,  4.1823e+00, -5.3407e-01, -3.5566e+00,  5.7974e+00,\n         4.9814e+00,  3.4071e+00, -1.9528e+00, -1.0497e-01,  2.6572e+00,\n         1.3332e+00, -4.5220e-01, -6.3876e-01,  5.4588e-01, -4.6271e+00,\n        -6.5372e+00, -2.7579e+00, -1.2450e+00, -3.2899e+00,  1.4429e+00,\n         3.2021e+00,  9.3358e-01, -1.9403e+00,  4.4439e+00,  1.9575e+00,\n        -6.2479e-01,  6.3138e-01,  2.0274e+00,  1.0061e+00,  5.7418e-01,\n         3.9282e+00,  1.0185e+00,  1.6865e+00,  1.4897e+00,  2.8807e+00,\n         2.6897e-01,  2.2065e+00,  6.4426e+00,  2.0440e+00,  8.7477e+00,\n         9.1228e+00,  4.6188e+00,  3.0073e+00, -1.9166e+00, -2.9796e+00,\n         4.5704e-02,  5.8045e-01, -1.1202e+00,  1.2763e+00, -1.2307e+00,\n        -3.9996e-01, -1.7966e+00, -6.4886e+00, -5.2132e-01, -4.6898e+00,\n         2.2445e+00,  1.1643e+00,  8.1478e-01,  2.3356e+00, -3.1794e+00,\n         1.9543e+00,  4.9073e+00,  1.1793e+00,  3.4936e+00, -2.2325e+00,\n         1.9383e+00, -2.9742e+00,  5.5687e+00, -3.8413e+00, -3.6770e+00,\n         4.6979e+00,  3.2820e+00,  2.3087e+00, -3.4260e+00, -5.1061e+00,\n         7.5859e+00,  3.8986e+00,  4.1509e+00,  4.2984e+00,  2.3901e+00,\n         1.7305e+00, -3.7223e+00, -3.6960e+00, -7.6065e+00,  9.4879e-01,\n        -1.4714e+00,  4.0625e+00, -4.3544e-01, -4.6141e+00, -5.0271e-01,\n        -2.8677e+00, -2.2373e+00, -4.0194e-01, -3.9429e+00, -5.2566e+00,\n        -6.7076e+00, -3.1467e+00,  1.5095e+00,  4.1691e+00,  5.2944e+00,\n        -3.0252e+00,  4.9360e+00,  1.1709e+01, -1.4494e+00, -5.2651e-01,\n         6.5421e+00,  6.7481e+00, -3.4802e+00, -2.5140e-01, -3.5041e-01],\n       device='cuda:0')\nvalues=tensor([[ 2.9162e+01,  5.1859e+01,  8.9249e-01,  2.0287e+00,  1.1033e+00,\n          7.5732e+00,  6.8235e+00,  5.0308e+00,  4.8997e+00,  1.4120e-01,\n          1.2775e+00, -7.9170e-01,  3.1940e+00,  2.1049e+00,  8.3565e-01,\n          2.9783e+00,  5.6211e+00,  6.5730e-01, -1.9847e+00,  7.2392e-01,\n         -5.3458e+00, -1.0579e+00,  1.4769e+00,  4.1208e+00, -7.0299e+00,\n         -3.8036e+00,  2.5598e+00,  8.1066e+00, -1.9259e+00, -3.7683e+00,\n          5.5034e+00,  7.4597e+00, -4.3286e-01, -6.9402e+00, -1.3732e+00,\n         -1.5605e+00, -3.1315e-01, -2.6086e+00,  2.5820e+00, -4.4234e+00,\n          3.6017e+00, -2.4453e+00, -2.7792e+00, -4.6647e-01, -8.9384e+00,\n          4.0973e-01,  9.6962e-01, -1.7146e+00, -1.4227e+00, -6.2639e+00,\n         -1.0264e+01, -8.7700e+00, -3.3789e+00, -8.3576e-01,  1.1202e+00,\n         -3.2552e+00, -3.2781e+00, -3.4936e+00, -6.4480e+00,  1.8651e+00,\n          4.9767e+00,  5.6756e+00, -2.5537e+00,  3.5782e+00,  2.6123e+00,\n         -6.4960e+00,  4.8591e-01, -2.9726e+00, -6.8601e+00,  3.1852e+00,\n          1.8840e+00,  1.7852e+00,  6.1109e+00, -1.0776e+00, -1.4428e+00,\n         -3.0677e+00,  5.2831e+00, -1.1548e+01, -8.9482e+00, -4.6077e+00,\n         -6.1066e+00, -4.9407e+00, -1.3532e+01, -8.2315e+00, -1.5334e+00,\n         -2.8505e+00, -2.4887e+00, -7.5422e+00,  8.8251e-01,  5.3347e+00,\n          3.2332e+00, -7.2968e+00,  4.0077e+00,  1.6429e+00,  5.5993e+00,\n          1.4216e+00,  3.0423e+00,  3.7378e+00, -1.7049e+00,  5.8209e-01,\n          4.1918e+00,  3.7802e+00,  3.2577e+00, -2.5296e+00,  3.7481e-01,\n         -2.2431e+00,  1.7667e+00,  3.0036e+00, -3.9776e+00, -8.3356e-01,\n         -2.2285e+00, -3.0640e+00,  2.0379e+00, -2.1186e+00,  2.4004e+00,\n          2.3110e+00, -4.6944e+00, -1.1144e+00,  5.0016e-02, -1.8886e-01,\n         -1.1543e+00,  3.9795e-01, -4.2685e+00, -2.5209e+00,  3.3914e+00,\n          2.2768e+00, -1.1765e+00,  1.1935e+00,  1.2670e+00,  1.2808e+00,\n          8.0669e-01, -3.1669e-01, -4.7307e+00, -6.7033e+00,  2.3514e-01,\n         -7.1323e+00, -3.4136e+00,  3.5310e+00, -1.0396e+00,  1.6603e+00,\n          4.7024e-01,  3.7152e+00,  7.9925e-01,  4.1919e-01,  3.2163e+00,\n          3.4314e+00,  3.5106e+00, -4.1785e+00,  1.0574e+00,  2.3923e+00,\n         -4.9712e-01, -1.3804e+00, -6.7850e-01, -3.3435e-01, -2.8656e+00,\n         -4.2022e+00, -8.4687e-01, -1.0481e+00, -3.0230e+00, -2.0353e-01,\n          2.4430e+00,  1.9464e+00, -2.4138e+00,  2.5399e+00,  2.2451e+00,\n         -3.2584e+00,  1.6783e+00,  9.8884e-01,  2.7985e+00,  1.4859e+00,\n          4.0241e+00, -3.1834e+00,  7.1977e-02, -9.7199e-01,  1.9769e+00,\n          1.6396e+00,  1.2973e+00,  8.1947e+00,  4.9829e+00,  9.6276e+00,\n          9.1141e+00,  2.1340e+00,  9.7840e-01, -3.6220e+00, -5.2435e+00,\n          1.1449e-01,  6.1939e-01, -1.7310e+00,  1.8481e+00, -3.2698e+00,\n         -7.6097e-01, -2.7577e+00, -4.9584e+00, -2.3284e+00, -2.2326e+00,\n          3.1701e+00,  2.4800e+00, -1.2061e+00,  2.4188e+00,  3.2397e-02,\n          6.3150e+00,  5.4460e+00, -2.7039e-01,  3.1651e+00, -1.1294e+00,\n          4.8169e-01, -1.5097e+00,  3.8618e+00, -1.2088e+00, -2.6340e+00,\n          9.3802e-01,  1.7668e-01, -9.9572e-01,  3.4897e-01, -2.9257e+00,\n          8.0671e+00,  5.3291e+00,  3.0985e+00,  3.8840e+00,  1.5583e+00,\n          1.6182e-01, -3.0775e+00, -3.0932e+00, -9.4854e-01,  6.3549e-01,\n         -1.6618e+00,  1.4536e-01,  3.1656e-01, -5.3119e+00,  9.2800e-01,\n         -4.3870e-01, -2.0686e+00, -3.0899e+00, -3.6787e+00, -3.6035e+00,\n         -6.2299e+00, -2.7238e+00,  2.2551e+00,  2.7776e+00,  6.3491e+00,\n         -2.5904e+00,  3.2808e+00,  9.0908e+00, -2.2233e+00, -3.3535e+00,\n          8.2772e+00,  9.0603e+00, -1.4424e+00, -1.3474e+00]], device='cuda:0')\nrewards=tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  5.9604e-08,\n          1.3794e-05, -0.0000e+00,  1.2349e-03, -1.2512e-06, -0.0000e+00,\n         -0.0000e+00,  6.6396e-05, -0.0000e+00,  1.0797e-03,  9.0571e-04,\n          6.1309e-03, -9.5837e-05,  4.2226e-05,  1.1921e-07, -0.0000e+00,\n          1.2507e-06, -1.1919e-07,  2.4965e-06, -2.2680e-03,  5.9597e-08,\n         -0.0000e+00,  4.0750e-06, -7.5069e-04,  1.8495e-03,  9.4902e-06,\n         -0.0000e+00, -3.0220e-04,  3.2153e-03, -3.5759e-07,  1.1919e-07,\n          3.0805e-03,  4.8194e-03,  2.1145e-03,  2.3753e-03,  1.2782e-04,\n          6.4555e-04, -5.2214e-04,  8.3089e-05, -0.0000e+00, -7.7605e-04,\n         -1.4535e-03,  3.1991e-03,  2.9771e-06, -7.2992e-06,  1.9583e-06,\n         -1.6078e-06,  4.1713e-07, -0.0000e+00, -5.9604e-08, -0.0000e+00,\n          1.7880e-07, -3.5758e-07,  2.7218e-05, -2.8806e-03, -0.0000e+00,\n         -9.3845e-04, -5.9590e-08, -7.1956e-06,  5.9604e-08, -0.0000e+00,\n          5.4922e-04, -1.0592e-04,  1.3781e-03, -3.2151e-06, -0.0000e+00,\n         -1.1966e-03,  4.2342e-05,  3.2683e-03, -4.2520e-05,  6.2680e-04,\n          3.1895e-03,  5.6925e-03,  3.7726e-05, -1.1921e-07, -2.4447e-03,\n          2.1483e-05,  2.3514e-05,  2.0117e-05, -3.2368e-04, -5.5611e-04,\n          1.1258e-04, -1.9842e-04,  1.5684e-03, -1.9717e-05,  2.7573e-05,\n         -0.0000e+00,  5.9604e-08, -0.0000e+00,  5.9603e-08, -0.0000e+00,\n         -7.7226e-06, -1.3764e-03, -1.2183e-04,  3.5758e-07,  5.9604e-08,\n          2.3489e-05,  2.3839e-07,  1.1997e-03,  1.7873e-07,  4.5422e-05,\n         -2.8324e-05,  3.4704e-03, -4.6372e-04, -5.6162e-05,  3.9844e-06,\n          2.7847e-03, -0.0000e+00,  8.3416e-07,  1.1918e-07,  1.2315e-04,\n         -3.0347e-03, -2.9797e-07,  4.1710e-07, -4.5518e-04,  4.7097e-03,\n          4.1665e-07,  9.2775e-05,  5.9603e-08,  8.9375e-07, -1.6478e-04,\n         -2.9908e-05,  1.4096e-05, -1.2770e-05, -5.4125e-06, -0.0000e+00,\n          1.7880e-07, -0.0000e+00, -7.1146e-05,  1.0246e-03, -5.5267e-06,\n          9.5318e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00,  6.7443e-04,\n          4.3392e-04,  5.9541e-07, -7.5430e-04, -0.0000e+00,  2.1078e-04,\n         -2.4350e-04, -2.2594e-06, -7.6591e-06, -1.8681e-03,  7.1498e-07,\n          7.5220e-04, -0.0000e+00,  2.6189e-05,  3.2096e-05, -1.4531e-04,\n         -3.1435e-04,  3.9421e-03, -4.0548e-05,  3.0255e-04,  1.8752e-04,\n          1.7879e-07,  2.4147e-03, -9.8694e-05,  6.5357e-06,  3.2753e-06,\n         -1.7880e-07,  1.1919e-07, -5.9603e-08, -0.0000e+00, -1.1920e-07,\n         -5.5211e-06, -0.0000e+00,  3.0489e-03,  9.4429e-05, -3.1556e-06,\n         -5.9590e-08, -1.6651e-03,  1.3701e-06, -3.3196e-04, -1.1385e-05,\n          4.0450e-03, -1.3711e-04, -4.2441e-03,  4.7727e-05,  9.3419e-06,\n         -5.9604e-08,  5.9601e-08, -5.9603e-08, -3.5041e-01]], device='cuda:0')\nmask=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\nvalues_994 = tensor([[ 3.6679e+01,  5.6960e+01,  7.4799e-01, -8.5530e-02,  1.0880e+00,\n          8.1548e+00,  7.7027e+00,  2.8849e+00,  4.7180e+00,  8.6753e-01,\n          1.7318e+00,  3.6610e-01,  1.9701e+00,  5.1188e-01,  1.7553e+00,\n          3.5002e+00,  6.3239e+00,  1.3897e+00, -2.2473e+00, -2.6125e-01,\n         -5.3588e+00, -4.2420e-01,  1.7203e+00,  3.9939e+00, -4.5469e+00,\n         -4.0286e+00,  4.8596e+00,  1.1017e+01, -1.8864e-01, -3.9056e+00,\n          7.3847e+00,  2.6988e+00,  2.7737e-01, -5.8353e+00, -3.6855e+00,\n         -3.5965e+00, -4.9324e-01, -4.0208e+00,  8.2787e-01, -4.2261e+00,\n          3.1049e+00, -2.2700e+00, -2.0770e+00, -3.2971e+00, -1.1962e+01,\n          3.0405e+00,  2.8805e+00, -1.5462e-01, -1.5514e+00, -6.9871e+00,\n         -7.3586e+00, -7.1544e+00, -4.6016e+00,  2.8606e-01,  1.4993e+00,\n         -5.3516e+00, -3.1752e+00, -3.4485e+00, -4.2746e+00,  1.4702e-01,\n          4.3707e+00,  3.9991e+00, -2.8476e+00,  3.0402e+00, -1.4812e+00,\n         -4.2902e+00,  4.7401e-01, -2.1330e+00, -6.5241e+00,  3.2084e+00,\n          1.4610e+00,  2.2775e+00,  6.0233e+00, -2.7354e+00, -3.5778e+00,\n         -1.9022e+00,  6.1963e+00, -1.1920e+01, -8.1783e+00, -5.8838e+00,\n         -5.7008e+00, -1.6198e+00, -1.5024e+01, -6.8632e+00, -1.6171e+00,\n         -1.2395e+00, -1.0314e+00, -9.1517e+00,  1.4163e+00,  2.9215e+00,\n          3.1492e+00, -6.2434e+00,  4.9105e+00,  5.4720e-01,  6.1572e+00,\n          3.4819e+00,  2.8139e+00,  6.6799e+00, -1.2006e+00,  1.1906e+00,\n          2.4948e+00,  4.3411e+00,  9.7256e-01, -1.7933e+00, -1.3523e+00,\n         -2.4086e+00,  4.2326e+00,  9.7129e-01, -3.9557e+00, -8.7188e-01,\n         -1.7328e+00,  4.9492e-02,  1.5691e+00,  3.6111e-01,  1.1670e+00,\n          2.9171e+00, -4.2554e+00, -4.0473e-01, -1.7494e-01,  3.7625e-01,\n          6.0468e-01,  2.4942e+00, -3.5554e+00,  2.2606e-01,  2.2326e+00,\n          3.2943e+00, -7.6981e-01,  1.0703e+00,  1.3169e+00,  2.0213e+00,\n         -7.6464e-01, -6.3025e-01, -4.4236e+00, -3.9559e+00, -3.6887e+00,\n         -2.5713e+00, -2.9408e+00,  2.7004e-01,  3.0145e-02,  3.7117e+00,\n         -1.0747e+00,  3.0933e+00, -7.5667e-01, -4.6259e-01,  5.5073e+00,\n          4.8238e+00,  1.7504e+00, -1.9590e+00,  9.6463e-01,  1.9182e+00,\n         -1.2053e+00,  7.2729e-02,  1.0036e-01,  6.4590e-01, -3.2124e+00,\n         -5.7562e+00,  1.2763e+00, -1.5229e+00, -3.0200e+00, -1.2555e+00,\n          3.3323e+00,  1.2574e+00, -4.5112e-01,  4.7581e+00,  5.6949e-01,\n         -1.1853e+00,  1.2863e+00,  5.7970e-01,  1.7630e-01, -8.9533e-01,\n          1.0132e+00, -7.8297e-01,  1.1958e+00, -6.7143e-01,  2.4313e+00,\n         -3.8734e-01,  1.9010e+00,  6.5719e+00,  2.0261e+00,  8.2520e+00,\n          9.5436e+00,  4.6857e+00,  1.7009e+00, -4.1948e+00, -6.6700e+00,\n         -8.4962e-01,  1.4011e-01, -1.4693e+00,  1.5693e+00, -3.4177e+00,\n          6.9250e-01, -3.0313e+00, -6.9302e+00, -9.0168e-01, -3.2479e+00,\n          3.0513e+00,  1.9940e+00, -8.6708e-01,  2.4161e+00, -9.7358e-01,\n          5.0787e+00,  5.5612e+00,  1.9113e+00,  2.3213e+00,  8.1081e-01,\n         -1.0055e+00, -2.6117e+00,  1.7803e+00,  1.0415e+00, -3.5226e+00,\n          5.1471e+00,  2.0537e+00, -6.0876e-01, -1.4461e+00, -1.9639e+00,\n          7.2920e+00,  5.6826e+00,  4.3840e+00,  5.8136e+00,  2.9550e+00,\n          1.6519e+00, -2.0918e+00, -1.7306e+00, -2.9485e+00,  1.9490e+00,\n         -4.1664e+00,  2.9759e+00,  9.5897e-02, -3.3920e+00,  1.5532e-01,\n         -4.0962e+00, -2.4870e+00, -2.2602e+00, -2.7154e+00, -3.8086e+00,\n         -4.6878e+00, -5.1573e+00,  1.0356e+00,  3.9921e+00,  4.6528e+00,\n         -1.0166e+00,  6.7749e+00,  7.0611e+00, -2.7988e+00, -2.8949e+00,\n          5.4225e+00,  9.4392e+00, -5.0798e+00, -6.6196e-01, -5.9011e-01]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\nvalues_994 = tensor([[ 3.4154e+01,  5.4010e+01,  2.3015e-01,  1.5386e+00,  1.1399e+00,\n          7.1620e+00,  6.5573e+00,  4.3101e+00,  5.6906e+00,  1.0672e-02,\n         -5.4045e-01,  1.0406e+00, -3.6361e-01,  3.2815e+00,  1.2510e+00,\n          3.0408e+00,  5.8229e+00,  2.1050e+00, -5.4089e-01,  6.5338e-01,\n         -5.2553e+00, -3.7379e-01, -1.3687e+00,  4.1139e+00, -4.6525e+00,\n         -2.5401e+00,  2.1571e+00,  1.3756e+01, -1.6460e+00, -3.9832e+00,\n          5.4432e+00,  5.5486e+00, -6.0447e-01, -6.5101e+00, -1.6331e+00,\n         -3.0409e+00,  1.2088e+00,  3.6438e-01,  8.0630e-01, -6.0304e+00,\n          5.3532e+00, -1.5983e+00, -2.8297e+00, -1.8324e+00, -1.0794e+01,\n          3.3833e+00,  2.0993e+00, -9.0278e-01, -1.9438e+00, -7.6701e+00,\n         -8.2789e+00, -7.3716e+00, -4.5588e+00, -3.7761e-01,  1.7437e-01,\n         -4.4084e+00, -3.7252e+00, -5.2160e+00, -3.3933e+00,  3.0067e+00,\n          2.3854e+00,  4.4773e+00, -4.2337e+00,  4.4330e+00,  1.7530e+00,\n         -4.0561e+00, -1.0329e+00, -1.5161e+00, -6.5491e+00,  3.4184e+00,\n          4.2348e+00,  4.2987e+00,  4.9782e+00,  3.4420e-01, -4.8181e+00,\n         -2.8741e+00,  3.1372e+00, -1.1293e+01, -1.0457e+01, -3.6251e+00,\n         -6.3532e+00, -2.3194e+00, -1.0054e+01, -9.2605e+00, -3.6052e+00,\n         -2.7665e+00, -2.9084e+00, -8.8062e+00,  6.8037e-01,  1.7218e+00,\n          2.0012e+00, -2.2817e+00,  6.5002e+00,  1.1727e+00,  2.5216e+00,\n          2.0138e+00,  7.0679e+00,  2.0954e+00,  4.3882e-01,  1.9735e+00,\n          3.7550e+00,  3.6510e+00,  4.4552e+00, -1.7001e+00, -2.1786e-01,\n         -3.5696e+00,  5.3388e+00,  5.8573e-01, -3.0836e+00, -2.8516e+00,\n         -2.8306e+00,  1.4706e-02,  1.1828e+00,  1.0473e+00,  5.6060e-01,\n          1.0884e+00, -2.3378e+00, -3.7565e+00,  1.8750e-01,  6.1255e-01,\n          3.6416e+00,  2.2408e+00, -3.6952e+00, -2.1249e+00,  4.6361e+00,\n          1.6639e+00, -4.4584e+00, -8.2058e-01,  2.3195e+00,  1.9684e+00,\n         -2.5518e-01,  2.9449e+00, -6.1440e+00, -2.7896e+00, -1.4324e+00,\n         -6.1280e+00, -2.4348e+00,  2.5535e+00,  2.4921e+00,  4.9232e+00,\n          3.3830e-02,  4.8375e+00,  7.8581e-02, -2.9048e+00,  6.6083e+00,\n          5.3253e+00,  1.2364e+00, -4.7984e+00, -1.2705e+00,  1.1897e+00,\n         -3.2387e-01, -4.5215e+00, -2.0157e-01,  1.4284e-01, -2.7091e+00,\n         -7.5602e+00, -2.1363e+00, -2.4730e+00, -3.3287e+00,  1.8467e-01,\n          1.6151e+00,  5.5459e-01, -8.4059e-01,  3.8384e+00,  1.8469e+00,\n          1.1953e-01, -1.4810e-01,  8.6250e-01,  2.0661e+00, -8.0506e-01,\n          3.0990e+00, -2.3197e+00,  2.3545e+00, -1.9251e+00,  3.3606e+00,\n          9.0340e-01,  2.4263e+00,  7.2199e+00,  4.4316e+00,  7.3555e+00,\n          8.3116e+00,  5.2142e+00,  1.4602e+00, -1.9650e+00, -6.6862e+00,\n         -3.3673e-01, -6.6545e-01, -8.1121e-01, -9.9392e-01, -3.1451e+00,\n         -1.9023e+00, -1.2470e+00, -4.5516e+00, -8.5877e-01, -2.5057e+00,\n          1.9634e+00,  1.0605e+00, -1.7542e+00,  3.3590e+00, -3.7315e+00,\n          2.7496e+00,  4.6677e+00,  1.2538e+00,  1.1774e+00,  9.2966e-01,\n         -9.7864e-01, -5.6400e+00,  2.0264e+00, -4.7895e-01, -4.6929e+00,\n          3.3567e+00,  4.9462e+00,  2.0943e+00, -1.8426e+00, -3.0552e+00,\n          7.1965e+00,  3.0667e+00,  3.8763e+00,  5.8864e+00,  3.7309e+00,\n          1.8943e+00, -2.5681e+00, -2.3115e+00, -3.5185e+00,  1.1988e+00,\n         -1.2443e+00,  4.1249e-01, -1.5283e+00, -5.2065e+00,  1.6871e+00,\n         -1.7201e+00, -3.7330e+00, -3.0382e+00, -2.5860e+00, -2.2270e+00,\n         -6.4793e+00, -5.2718e+00,  3.8069e+00,  4.5498e+00,  3.0524e+00,\n         -2.1437e+00,  5.6078e+00,  9.3868e+00, -3.0999e+00, -4.6682e+00,\n          7.3952e+00,  7.0415e+00, -1.9349e-01,  1.1110e+00, -1.0877e+00]],\n       device='cuda:0', grad_fn=<PermuteBackward0>)\n10it [08:47, 52.70s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"all_values=[]\na=torch.tensor([[35.2010],\n        [56.9074],\n        [ 1.1382],\n        [ 0.2368],\n        [ 2.2143]]).permute(1,0)\nb=torch.tensor([[35.2010],\n        [56.9074],\n        [ 1.1382],\n        [ 0.2368],\n        [ 2.2143]]).permute(1,0)\nall_values.append(a)\nall_values.append(b)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T16:44:12.160955Z","iopub.execute_input":"2023-08-14T16:44:12.161357Z","iopub.status.idle":"2023-08-14T16:44:12.169730Z","shell.execute_reply.started":"2023-08-14T16:44:12.161325Z","shell.execute_reply":"2023-08-14T16:44:12.168433Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"all_values","metadata":{"execution":{"iopub.status.busy":"2023-08-14T16:44:15.034078Z","iopub.execute_input":"2023-08-14T16:44:15.034986Z","iopub.status.idle":"2023-08-14T16:44:15.053842Z","shell.execute_reply.started":"2023-08-14T16:44:15.034927Z","shell.execute_reply":"2023-08-14T16:44:15.052044Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"[tensor([[35.2010, 56.9074,  1.1382,  0.2368,  2.2143]]),\n tensor([[35.2010, 56.9074,  1.1382,  0.2368,  2.2143]])]"},"metadata":{}}]},{"cell_type":"code","source":" torch.cat(all_values)[:, :-1]","metadata":{"execution":{"iopub.status.busy":"2023-08-14T16:45:42.984969Z","iopub.execute_input":"2023-08-14T16:45:42.985384Z","iopub.status.idle":"2023-08-14T16:45:42.994014Z","shell.execute_reply.started":"2023-08-14T16:45:42.985336Z","shell.execute_reply":"2023-08-14T16:45:42.992933Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"tensor([[35.2010, 56.9074,  1.1382,  0.2368],\n        [35.2010, 56.9074,  1.1382,  0.2368]])"},"metadata":{}}]},{"cell_type":"code","source":"scores=[torch.tensor(-1.0057, device='cuda:0')]\nscores=[t.cpu() .numpy() for t in scores]                     \n#scores = torch.tensor(scores).to(self.current_device)\n#scores=torch.tensor(scores)\nscores","metadata":{"execution":{"iopub.status.busy":"2023-08-14T16:01:51.414601Z","iopub.execute_input":"2023-08-14T16:01:51.415583Z","iopub.status.idle":"2023-08-14T16:01:51.426835Z","shell.execute_reply.started":"2023-08-14T16:01:51.415544Z","shell.execute_reply":"2023-08-14T16:01:51.425765Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"[array(-1.0057, dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"score=torch.tensor([26.9585, 54.7772,  0.3836,  1.8755,  1.4875,  0.6672, -1.2902, -1.1666,\n        -3.4029,  2.9045,  2.2146, -0.4719, -1.1094, -3.8322, -0.4235,  2.3752,\n         2.2033,  5.0141,  7.3238,  2.8239,  4.4018,  6.8154,  4.1981,  1.3292,\n         6.6918,  5.5280,  3.6042,  3.8058,  3.5440,  1.3948,  1.1925,  1.9285,\n         3.5308,  7.6298,  7.2233,  7.8028, 10.3878,  2.4796,  6.6148,  3.1376,\n         2.6324,  5.2144,  1.2815,  5.0430,  2.4158,  3.6837,  8.1965,  3.5462,\n         0.8770, 13.3891,  3.6978,  7.1916, -0.8622,  2.6911, -0.7917, -1.9702,\n         7.8929,  6.5023,  4.2341, -3.7883, -2.2751,  4.5737,  2.5624,  0.2927,\n        -1.7391,  5.1636, -1.0061])","metadata":{"execution":{"iopub.status.busy":"2023-08-14T15:48:47.834267Z","iopub.execute_input":"2023-08-14T15:48:47.835481Z","iopub.status.idle":"2023-08-14T15:48:47.846052Z","shell.execute_reply.started":"2023-08-14T15:48:47.835428Z","shell.execute_reply":"2023-08-14T15:48:47.844312Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"torch.tensor([-0.], device='cuda:0')+score[-1]","metadata":{"execution":{"iopub.status.busy":"2023-08-14T15:49:35.043567Z","iopub.execute_input":"2023-08-14T15:49:35.044104Z","iopub.status.idle":"2023-08-14T15:49:35.100301Z","shell.execute_reply.started":"2023-08-14T15:49:35.044067Z","shell.execute_reply":"2023-08-14T15:49:35.099200Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"tensor([-1.0061], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nscores=[torch.tensor([26.9585, 54.7772,  0.3836,  1.8755,  1.4875,  0.6672, -1.2902, -1.1666,\n        -3.4029,  2.9045,  2.2146, -0.4719, -1.1094, -3.8322, -0.4235,  2.3752,\n         2.2033,  5.0141,  7.3238,  2.8239,  4.4018,  6.8154,  4.1981,  1.3292,\n         6.6918,  5.5280,  3.6042,  3.8058,  3.5440,  1.3948,  1.1925,  1.9285,\n         3.5308,  7.6298,  7.2233,  7.8028, 10.3878,  2.4796,  6.6148,  3.1376,\n         2.6324,  5.2144,  1.2815,  5.0430,  2.4158,  3.6837,  8.1965,  3.5462,\n         0.8770, 13.3891,  3.6978,  7.1916, -0.8622,  2.6911, -0.7917, -1.9702,\n         7.8929,  6.5023,  4.2341, -3.7883, -2.2751,  4.5737,  2.5624,  0.2927,\n        -1.7373,  5.1582, -1.0060], device='cuda:0')]","metadata":{"execution":{"iopub.status.busy":"2023-08-14T15:01:56.271117Z","iopub.execute_input":"2023-08-14T15:01:56.271487Z","iopub.status.idle":"2023-08-14T15:01:56.279947Z","shell.execute_reply.started":"2023-08-14T15:01:56.271454Z","shell.execute_reply":"2023-08-14T15:01:56.278859Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"device='cuda:0'\nscores=[t.cpu() .numpy() for t in scores]\naa=torch.tensor(s)\naa=aa.to(device)\naa","metadata":{"execution":{"iopub.status.busy":"2023-08-14T15:03:15.345873Z","iopub.execute_input":"2023-08-14T15:03:15.346251Z","iopub.status.idle":"2023-08-14T15:03:15.362290Z","shell.execute_reply.started":"2023-08-14T15:03:15.346219Z","shell.execute_reply":"2023-08-14T15:03:15.360841Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"tensor([[26.9585, 54.7772,  0.3836,  1.8755,  1.4875,  0.6672, -1.2902, -1.1666,\n         -3.4029,  2.9045,  2.2146, -0.4719, -1.1094, -3.8322, -0.4235,  2.3752,\n          2.2033,  5.0141,  7.3238,  2.8239,  4.4018,  6.8154,  4.1981,  1.3292,\n          6.6918,  5.5280,  3.6042,  3.8058,  3.5440,  1.3948,  1.1925,  1.9285,\n          3.5308,  7.6298,  7.2233,  7.8028, 10.3878,  2.4796,  6.6148,  3.1376,\n          2.6324,  5.2144,  1.2815,  5.0430,  2.4158,  3.6837,  8.1965,  3.5462,\n          0.8770, 13.3891,  3.6978,  7.1916, -0.8622,  2.6911, -0.7917, -1.9702,\n          7.8929,  6.5023,  4.2341, -3.7883, -2.2751,  4.5737,  2.5624,  0.2927,\n         -1.7373,  5.1582, -1.0060]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\na=[25.256540298461914, 49.58720016479492, 0.18187294900417328, 1.4897446632385254, 1.1968485116958618, 0.10057299584150314, -1.5109386444091797, -1.4273135662078857, -3.3894641399383545, 2.263216972351074, 1.5636731386184692, -1.0434900522232056, -1.8036266565322876, -4.275576591491699, -0.6687140464782715, 2.0810747146606445, 1.6051537990570068, 5.046526908874512, 7.157630920410156, 2.9234297275543213, 4.255917072296143, 6.61237096786499, 4.171794414520264, 1.1586885452270508, 6.537792205810547, 5.545578479766846, 3.443131923675537, 3.6469266414642334, 3.330624580383301, 1.313371181488037, 0.9745500087738037, 1.6175665855407715, 3.1739673614501953, 7.654401779174805, 7.4569196701049805, 8.102145195007324, 10.512571334838867, 2.8823323249816895, 6.398488998413086, 3.0214900970458984, 2.5821034908294678, 5.287378311157227, 1.5696346759796143, 5.16638708114624, 2.148916244506836, 3.395231246948242, 8.202319145202637, 3.30208683013916, 0.7855610847473145, 13.19229507446289, 3.4890899658203125, 6.808653831481934, -0.6579917669296265, 2.4623849391937256, -0.7382142543792725, -2.5757625102996826, 7.459266662597656, 5.911978721618652, 3.8411192893981934, -4.349767684936523, -2.815305233001709, 3.5878658294677734, 1.8798978328704834, -0.4172825813293457, -2.3522253036499023, 4.773746490478516, -0.9820916652679443]\nb=torch.tensor(a)\nb","metadata":{"execution":{"iopub.status.busy":"2023-08-14T04:32:44.576482Z","iopub.execute_input":"2023-08-14T04:32:44.576855Z","iopub.status.idle":"2023-08-14T04:32:46.588817Z","shell.execute_reply.started":"2023-08-14T04:32:44.576824Z","shell.execute_reply":"2023-08-14T04:32:46.587655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nscores=torch.tensor([[25.2565, 49.5872],[5,6]] ,device='cuda:0')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T09:07:49.338899Z","iopub.execute_input":"2023-08-14T09:07:49.339314Z","iopub.status.idle":"2023-08-14T09:07:49.345317Z","shell.execute_reply.started":"2023-08-14T09:07:49.339283Z","shell.execute_reply":"2023-08-14T09:07:49.344164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=scores-9","metadata":{"execution":{"iopub.status.busy":"2023-08-14T09:08:59.579039Z","iopub.execute_input":"2023-08-14T09:08:59.579451Z","iopub.status.idle":"2023-08-14T09:08:59.585142Z","shell.execute_reply.started":"2023-08-14T09:08:59.579419Z","shell.execute_reply":"2023-08-14T09:08:59.583950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"execution":{"iopub.status.busy":"2023-08-14T09:09:02.959157Z","iopub.execute_input":"2023-08-14T09:09:02.959598Z","iopub.status.idle":"2023-08-14T09:09:02.969648Z","shell.execute_reply.started":"2023-08-14T09:09:02.959563Z","shell.execute_reply":"2023-08-14T09:09:02.968169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass, field\nfrom typing import Optional\n\nimport torch\nfrom peft import PeftConfig, PeftModel\nfrom transformers import AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, HfArgumentParser","metadata":{"execution":{"iopub.status.busy":"2023-08-14T06:06:23.436059Z","iopub.execute_input":"2023-08-14T06:06:23.436968Z","iopub.status.idle":"2023-08-14T06:06:36.151720Z","shell.execute_reply.started":"2023-08-14T06:06:23.436918Z","shell.execute_reply":"2023-08-14T06:06:36.150772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmymodel = AutoModelForSequenceClassification.from_pretrained(\"THUDM/chatglm2-6b\",trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T06:09:41.926594Z","iopub.execute_input":"2023-08-14T06:09:41.927005Z","iopub.status.idle":"2023-08-14T06:09:45.554784Z","shell.execute_reply.started":"2023-08-14T06:09:41.926973Z","shell.execute_reply":"2023-08-14T06:09:45.552983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/valkryhx/LLaMA-Efficient-Tuning","metadata":{"execution":{"iopub.status.busy":"2023-08-14T07:52:59.473271Z","iopub.execute_input":"2023-08-14T07:52:59.474184Z","iopub.status.idle":"2023-08-14T07:53:00.486024Z","shell.execute_reply.started":"2023-08-14T07:52:59.474144Z","shell.execute_reply":"2023-08-14T07:53:00.484866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/LLaMA-Efficient-Tuning","metadata":{"execution":{"iopub.status.busy":"2023-08-14T07:41:24.593181Z","iopub.execute_input":"2023-08-14T07:41:24.593579Z","iopub.status.idle":"2023-08-14T07:41:24.600898Z","shell.execute_reply.started":"2023-08-14T07:41:24.593546Z","shell.execute_reply":"2023-08-14T07:41:24.599796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n    --stage ppo \\\n    --model_name_or_path THUDM/chatglm2-6b \\\n    --do_train \\\n    --dataset alpaca_gpt4_en \\\n    --template default \\\n    --finetuning_type lora \\\n    --resume_lora_training False \\\n    --checkpoint_dir /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0813-v1/checkpoint-40 \\\n    --reward_model /kaggle/working/chatGLM-6B-QLoRA/output-rm-1k-0813-v1/checkpoint-40 \\\n    --output_dir 0808 \\\n    --per_device_train_batch_size 1 \\\n    --gradient_accumulation_steps 1 \\\n    --lr_scheduler_type cosine \\\n    --logging_steps 10 \\\n    --save_steps 1000 \\\n    --learning_rate 1e-5 \\\n    --num_train_epochs 1.0 \\\n    --plot_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}